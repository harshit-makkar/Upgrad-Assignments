{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, I have implemented an L-layered deep neural network using numpy and trained it on the MNIST dataset. The MNIST dataset contains scanned images of handwritten digits, along with their correct classification labels (between 0-9). MNIST's name comes from the fact that it is a modified subset of two data sets collected by NIST, the United States' National Institute of Standards and Technology.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps I have implemented are three folds - "
   ]
  },
  {
   "attachments": {
    "frwd.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Forward propagation</b> - whereby we go through the layers with some randomly initiated weights and biases and at every layer, store these parameters<br>\n",
    " ![frwd.PNG](attachment:frwd.PNG)\n",
    " \n",
    "B stands for the input matrice having a Batch of data points.<br>\n",
    "H stands for the output at each layer<br>\n",
    "W and B stands for the weights and biases respectively<br>\n",
    "P stands for the output of the output layer after applying softmax activation function"
   ]
  },
  {
   "attachments": {
    "loss.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Loss Calcualtion</b> -  We use the cross entropy loss function to calculate the divergence of the model predictions from the actual output.![loss.PNG](attachment:loss.PNG)\n",
    "\n",
    "Y stands for the true label - 1/0<br>\n",
    "P stands for the probability of the label"
   ]
  },
  {
   "attachments": {
    "back.PNG": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAAHCCAYAAAA3nNjtAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAGLtSURBVHhe7Z3ZsxTF1rf3/8QFQegFRkBwCAjGQA2EgGBUZBACFRCZDvMgo4CowGEWOSAECKgMGnKYZRABQV6ZEVScznud33nyPau/7NrZc/fe1b1/F0/sXZlV1VVZlb9cuXJVZtP//u//ukbn3r17btWqVa5Lly6uZ8+ebsmSJe7gwYPRfQvxyy+/uI8//tj98MMP0XwhhKiENiHKcPv2bffCCy+45cuXuz///DO6D9y5c8cdOnTI/fXXX1npjx8/dvPmzXOjR492zz77rDt79mxWvhBCVIM2I8qIaMeOHd3+/fuj+cbVq1fdwoUL3e+//x7NP3HihERZCFEzWkWUb9686V599VXXvXt3165dO9e5c2c3YMAAT+/evV2HDh3ctGnT3K1bt6LHb9myxR+XPLZfv36uffv2XnzPnDmTdcyOHTtct27dvOiG6UnSLMo//vijGzt2bKbcuM+XXnopU26Uxbp167yLJXZ8Ndi2bVumnO0apkyZ4p48eZLZ58MPP/TP0PLnzJnjfv3116zzCCHiNMUSW4qNGzf6iktF//e//51Jv379uhs8eLAX0StXrmQdQ+V+8803vRCdPn0644rg78qVK71Y7Ny5M8v9gMDOmDHDvfzyy+6nn37KpMeoB0uZBoZy27BhQ6bc+Hv06FF/bW+//bb77bffmh1XLShryohrWLRoUdazA1w948aNc5s2bXJPnz7NyhNC5KdiUaaC/vzzz80qZiFMKBERxDWZTxp5c+fOzfIBM8A2aNAgd/78+Uwav83gG4KMzzgpSPfv3/cWZehP5u+BAwfcN99849577z0v6DB79mzXv39/t3Tp0kzavn37MiLf2qLMdVMmCOLx48ez8h4+fOgGDhzoevXq5W7cuJGVV21oACjvoUOH+t+1dK6PMos9ByFEYUoWZazYHj16eFEwqICxffPx4MEDL650hemWJ/NNSBFIoics/YsvvnDz58/PEuqvvvrKd5MnT57sGwhLN2L+ZH4TF0nSck67pYwVOnLkyKgrhgarT58+rmvXru67777Lyqs2NnD6zDPPuJMnT/o0axxxZ8SegxCiMCWL8sWLF92CBQu8aGIhQTn+Qs7TqVMn74qIHW9WX1JgEOBz585ltsnDMsRii4k74CYhHO7y5ct+my714sWL3T/+8Y9mFn7aRZn7pUyGDx/erEHh2rBeY3nVJrTYV69e7dO4thEjRviGO7m/EKI4ShZlKv7atWujeaWwZ88eX6FDv2iIWeT5Bufu3r3rxRhRNsENIbyNa8WiowGgMQH2D0U6JJcoM3jGtU6YMMFfN3+3b9/e4j5TXC78Pm6WsLfA/7hcEGXcLaW6k8qBXgvXMmzYMC/Io0aNcseOHWuR3xaiUSlZlOmeIgyxvGIJraykX9Qwqw8XB66OZD7dY7rJuCWqKQSFLOViMCuf+0tC+cWOKRZcRZyHwUy7ZyIf1q9f7y34rVu3tpgvN3RhYL0nB1iFEKXTFEvMByFX5kMsF/OL5huQwsJFfHAzJCs6os5gEvn8NYuR8xJuF+7bSGCtE9VAY4Uv3kIBsVQZrOTeW9JKDRtXDewJUR1KEmUq/IoVK9z06dMzo/xYlY8ePYrunwusUdwSY8aM8UKazDfxwQo+depUVh7XYJEWyYE9fMehBdlo2EBersHRQhB6aEJeCPaNnSOkUASNEKJ0ShblCxcuZD4UQDyJhJg5c2ZJVpL5RfGBxgQUXyWiG7O+LNIiObCHOCPSYahco2E+3FyDoy2NRciU20gIIZpTkijHIIrixRdfLHrEHRFGjBGXw4cPN8u3aIpYeJvlQXKQDsHCJVLrqINiqJVP2Vw6uQZHWxoiULCS09JICNEINMUSSwFXBN1di5DYu3evn7gnVyU11wQDQ6Gw4p9EWJnFbdasWd4KC4+zSIvkwJ4dhzuEmeAadaCJcnvjjTdS5SqggUlTIyFEI1CxKGMpDxkyxI/Es/3BBx+4qVOnNhNlXB5vvfWWn6OBihwOVtEFJvyNz4OJQbaBOwPfJSFgHMecCljmHMdfm2OB8+HaCI9rBKzcKCvukXulDPm8ubUG1hBjnhkNJNfDnBvMZdLIg6xCtBRNscRiQTxxRbz77rvNhFQIIUTplC3K+G6ZLF6f1AohRPUoSZTpLuMvZqCN7upnn32m2FQhhKgiFbkvhBBCVBeJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBVgAUWBg0a5CZMmODhf2ZSZKmsESNGuPHjx2cWghAiHxJlISqEBR5YCWbfvn1+WSxbu9DWY2RtSZbysgWHhciHRFmICvnhhx/cjBkzMqK7Y8cO16VLl8walCyZtnDhQr+sWXicEDEkykJUCGL7+PFjbyXzPwI9fPjwzMrqpLHwbfI4IWJIlANYSWXs2LF+gVK6m++99567c+dOdN9CsIjorl273NOnT6P59QwCwwrWffv29YumshoN91qOJcjKNZ9++qm7dOlSNL8lOXPmjF/0l8VgX375Zbdy5Up3/fr16L65YBV2FpXFnZFGy7hRn10tqMb7YJSiBxLlBBs3bnTdunVzV69ejeYbCDjd1mQ6LyiC/sILL7iRI0d6Cyq5TyNA5R43bpwfyEquXB5Co3bo0CH3119/ZaVTodeuXesbQfyvBw4cyMpvLb744gt/PeWujG7+ZPzLsfw0UOyzQ6h5LmbxG2l9drWg2PcBsf7yyy+bpZejBxLlAF5Cup60iskXMcny5ct9BYzlAYvKNrIo0yD16dPHrVu3znfbY/sAjVs+fyr5NIKlVGysDayYWizYi9hgRd64caNZ3o8//uj9xPnuN+lPTiPFPjsEG0s6ZnxAOc+u3sj3PoScOHHC7xvLg1L0oCJRZmCDi6m0ctCdevHFF12HDh2866Bfv35uwIABvhvYsWNHv43lwSg3+x88eND17t3bdyuge/fubtWqVe7hw4e+9adbRjrnGzhwoDt//rz7448/3DvvvOPTyGMfrOLwpbSuJ4Jrv5WLNIkyXSPCrygHuzfKDygn7nnatGnu1q1b0eMREITEyoxnEZY/6ckKjOVQjAVRbVHmXZs+fbrbuXNnM+v7gw8+8O8K7xDXzL1TLohKvjw7HgsSqyaXBclvv/XWWz6qIiZm1qiH/uRKKLVeYMHy3g0ZMsQfk8taL/bZpU2UqffhO8kztPecd75r166+zHK5CLZs2eKPg7CO2HvBeWnsbf9C70NIq4sylWHv3r3+gjHPk5WjHIjhxMTv37+/u3fvXiadF23z5s2+0JYuXZp5Aeku9OjRwz8kxNT2ByoNBY9QJyvP1q1b3eLFi6MPDpHlwezfv79ZXpI0Wso0Mtz3tm3bsu6bsho8eLCvQFeuXMk6Bigv7huhCxtYKi3pkydPbtbwFmtBVFOUuadNmzZ54ctVSey9SL5HYBZiLC/Mz2dBcr8cf/r06Uya+Wnnzp3ry4v74R37+uuvs44th1LrBfBudurUyRsjlhZS7LNLo6VsrhcEOOyNoEGINuWPLiXfV+4FcUWEeXZWXvzFV0w5Jhv6Yt4Ho1VFmZt49913/Y3wYsT2KQfzxb399tvNzss26bxohBeRhlWMFcxLwcth+1J4VBDEicGWsDB5qXlguZz1dD2T5+PB4BNlQIN7Nvg4gEEA216zZk3Wy9vSomxWGmUYCoZBGnkIR1iB7TjKLHwhia3t1auXGzp0qO+2WzrksiCOHTvmhZwBUiuX2bNne0FBOCwNC85+q5SKzb5YjrnEBvh9nn3Mujl58qSvfLF3DGIWJO8ZBojtbw0D90852H61otR6Yc8mV8OT79l98803fjDKnhPPjPPwDC1t/fr1mV5Aa4iyCWWsN8KzQRh5/viCwzyOo86G7w77Y5DwTtCQJcs33/tAg2BlAmgB5w/TQh9zTUV59+7dvguXbIkqxaxbxCEUUgPBJB9Ll20TZVpMBMT2o/XHCmDfBQsWZCq/VSZaw9j5TZxCfzL7YY3ELOe0WcoPHjzwLwVdsaSIgrlmkpUVS4yvzcJj7t6968UYUY75RmMWBK6smTNnNrO+qLjVsJT5HSrca6+9lvcjDOstsG/yOds7lOsdi1mQVG5cH+H+lAmuIkTe0mpFqfXCnk2uLncpz47j02YpY5EiojQUoXFhWKMc1n3gOc6fPz/rGPbN1ROEYt8HaDVLmYrLiXkYsfxyoaCw4Chsbi62j72cZv1aix8OqnAeWiheMPYNrRkKdsqUKe7Ro0dZ5zWsmxiGMiG6Y8aMib6UaRNlLCUsplyVMVcjhp859EvyclJOvKxYTzEhsBHpzz//3G9zLP46xDdpbVRLlClHyjOXOIE1rDz748ePZ+UVesd4T+gW00DZO8NzHzVqlLtw4UJ039WrV2elV5ty6oX1BnKVUynPLo2ibI0u9x3Lp5ySdR8Q4HPnzmW28/UEoZT3AVpNlHl4DBh99NFH3uKiFcFvW6nVjGWKzzOXlQeIIIVNl4qXjRcGASLNuhcWV3jkyBH/YtqD4cVDrA8fPhx9UfFFcV8cQ6GzLw+EwZJc8aa5RBnXyLJly7zAI2xUqlioTLXZs2ePL4tcldF8rVSiXI2qlRPlEBtIoyw5/7Bhw9wzzzzjGz9eNt6FsKKH5BJltukqW7lzzrBrnMQaHZ5hLB+sNxC7x3zvGELGc+J54XNcsWKFt57YDiulYWLJHBelvvscS+XFksvVUBnl1AsTLQb7uHZEh2eGGJT67HKJcqnPrlrQaGAw5POXWz3IZZxAoZ5gqe8D5BLlcvSgKZYYwwoEXw4/xAvAxWGZUOl42WLHFYNVuIkTJ0ZvOBRgayF5McwqQpTZB//aqVOnMi04liEWool1NV0uhSzlYjArJ4ldd+yYGCYSHJu0EA1eGioQLg5cHcl8nifXwz7cW9JqKpdcolwqXD/iEfOXGzwP9uEeEDIbXQe2SaehrsZ7QAWMDTIXgnKg6824TKE6U2q9sDrBfVqjaufAQk4eX4hcolwJVjfD993gGceOMXINehq8wzROnMsaqeQ+xfQEy6GQpVwKTbHEGNZqm1Vq8NARkUoeHN0fCpKbihUS58YPxsMMowdo6TmOF5KXjgeBmNiDp9JwLC9qvsGhese69rT8Sb+gQdlSVkQFJC1gMP8aFgSWBGmIBmVZSYNbLXjGSddLEmvkYvdY6B0rlWKup1JKrRfWUwgbHqsL1JXk8fWGNbq5BmqtHtAoJXUKeI/pCVKm/LX3muMIK03u31o0xRJjmE8y2ZrRejE1IQ8/TC8WXjZr3XJ1TRFc8hHXsEtiosxLy+CjRVXYy4l1RHeO7kMahKVWWMXD/x3zWWFl4Y5BdOlJJPPNv5bsztHgUgGq2cMol0IiyPO13kIyPpd3DDdUvnesVGotyuXUC7OKQxG3farVGLUm1ujmctHZ/SPMybEj9ud4BDs5sIdG5AoAaA2aYokxrGInnfq01lhX5YqytW6ISuwcjAwz4h7z/9hDYrCPB2XWkTUg5OH3NrFuVMyiytVlo2LyMsbcEuZfi3XnGEPIVQFamkIiaD05sxrDvELvWDnUWpTLqRe8B0krETEmjXfA0uqR0DUTc3PQKBNdkcstEfYEQ/884oxIp6knXbQoc5M84GTFx8eXy+dVDPmsPOtu5CpoE2UqYzhxkL3Q1qrGuutpwK4/SSk+Zcokn0VlVnAs7Idt/Gu86MmBPV5c/M/5fLgtCRWRAarwi6sQs5Ji8auUAQKaqydRDtSFcnzKxVJOvWCQK2woKAfKA2Oq1oNwxWL3lXznIZ9POV/IJ/dPXeL9iA1QWx2IGXY0VmhFWsoHmmKJubh27ZoXQJsVyip1GMdLYDWDA6GbIR/WvUrGFSKyc+bM8fGgRFPEhNUsQMQoFGwbAAn9o42K9WCojOELR8WlfHr27OlmzZrVTDysYlP2oQVNOdKzGD16tB9Vjw0KtgTJ98iENVdX3noLyfeoUF45UHa4SsoReY5l4BO/N//H9oFy6gXPH+Eh9MuEChFLClE9Yo1u0gCkx0ADyWfT3G+xPUGrHzQQRJBV472oFk2xxHzw1Q8VFiuBluvo0aNZN0RgNZEOhUSZEBzOQWHx8oXfouNy4Nx8uJGvBUM86GInLUC6OoTsYFWFYt1I8DLiR7c5QGicLOKAciX8DX8wFTRW+QkD5BiOTc4hQBrkGhRsCZLvkfV+CL0K9+NjpvA94q8ZDvnywnOUijWE5fhp2R9rLldvqJJ6wXPGWkaEcG0g/uVOPZsWiAnmmdl7SblQPpQH7zvRGHxNi/WcfBYW6cJx4ZwuNp8I6dSB2KBga9IUSxQibVDhEEHEsFxXWbXA8qTRy9fdzgddeKa9TFOXWaQHibKoGxCz559/vlUHZWgcbO6LZA+tWOiKF3JfiLaLRFnUDQgiczbkilNtCYgDpztdbsPAPeCaKdfKFo2PRFnUFVinfN7bGnGl/DYNAgNK5frasY4ZtGzpaxf1g0RZ1B3MhU2oXrnug3JhMAnXQ5pG6kXjIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEuE1YiZvFMlixfsGBBq60ZJ+qXs2fP+vcH9u/fH91HtD1aRZS/+eYb9+abb7ohQ4b4FYpj+5QDywPNnDnT9e7d27Vr184dPny42T6I6ahRo9z27dub5ZXCw4cPvSjfv3+/Wd6GDRtcv379XPv27f11dO/e3Vc81nZL7lsMBw8edC+++KLr0KGDP1/nzp39+VatWqUVkRsA3osdO3ZE80Tbo8VF+cKFC279+vV+4Uio9npnnA/LtVu3bu7KlSvN8u/evesbg08//bRZXinkE2X44YcfXJ8+fbw4s7ZbbJ9SePz4sRs5cqTr1KlTqy2xTwPw1VdfuaFDh1a1MW10CpWbRFmEtLgoL1++3H3xxRfRvGrwyy+/uHHjxrnhw4d7qzi2TzUoJMosIY+lXK3l8KnMNDS1vq8Y33//vXv55Zd9D6Rjx46ua9eufkXm2L7i/1NsuUmURUhJomzCQBc6yaFDh6LHhPz666/ebYFgxfKrwfXr112PHj3c4sWLm1nhbCNo165d85ZnmFcqhUR548aNvlxwZVRjOXkaMs43e/bsVnNZ2POTKJdGoXKTKIuQplhiLhiYWLhwYZYoYAUuXbrU3b59O2vfJHTneTGxGLAcwsENxPLo0aNu0KBB3nf6yiuveL8zeX/88Yd/aRFa9kHs6AauXbs26/yGide+ffua5WFFz5gxw1+DNQyIJj5afMw0LGPGjPHXN3HixJyCC/lE+ffff/e/g6VcrQaI++W+KItYfksgUS4PibIohZJFOWkRX7582bskirHeclnKu3fv9gN0T58+9duXLl1ygwcP9hat7bNkyRL3+uuvu5s3b2bSYnAtufzJkLwGrNhFixZ5PzO+Wra5l/nz57stW7Y0O97IJ8qkvfTSS1XzJ9OY8Fut6U8GiXJ5VEOU6QH27dvXu6/yGQui/ilJlJMgYFhwWLCx/CQxUb5z544bNmyYu3jxYiYNUZw7d26WNYwoF7ISi/Enx64hdm62SQ/TQvKJMo3Xs88+6/OJCEnml4oNGg4cONDdu3cvuk9LIFEuj2qIMsZPly5dfE+yGg29SC8ViTKCysv24MGDaH6SmCAiYLgjELlwX15U9uUYtosR5Xz+ZKMUUZ4yZUrOQbp8osyxuBpoVJL+ZBochLoUPzPXmmvQkPvEP57rfquJRLk8qiHKwHmsPojGpSJRxn8bE55cxASR/7EAk6JMCFGpopzPn2zEriGXKIe/nySXKJuVz3XE4qTpVfB7pYhovkFDLKjp06dHLXIsqrFjx2Y+UMgH+xWywKzsJMqlUajcihVl0TYoW5Sx2PADnz59OpofIyaIJ0+e9KKcFLekKBYSZcSKAUf8yd9++60XqZifO3YN1RRl3Cb4w7mOZEwqZYaA0uCE6fngGCz22KAh90yjuHPnzpIs73IpJC4iTqFykyiLkLJFGQtt/PjxJYWWxQSRqA1EGTeGpZnAhgNthUQ59CdzbURPxPyvtRZlfOMMyBHFkSwb+4DArot7R1Sx8HOJKvu88MIL0UFDKjgNQK5BzWqTT1xoPCgznlkuPzrHE5kSy4NGzSe9GqJc6PdFY1CWKJuFRrc6mbd37143b948/wIl8+zlDAWRc61bt85bg1aZEVUiLfj6zvYrJMocO2HCBN9QbN261V9fzEUQu4ZqivKBAwe8q4GvCu33+XvkyBFvPYf+7j179vh980Vp2KAhjQwND2mUGVEYuB24hlwiWG2s7GLiYv78XG4bG6iigYmFTzZyfr5yg2JEudDvi8ahLFFmgM8s0mTeBx984KZOndpMzOjWIywWp4yYWIQEoXDvv/9+Jn6ZDyT4DfKwwBA4YoltDolck7cQLofovffee9Hoi+Q1cK2cy869efNmvx9CyDb7Idgx6yQpypyHMDiOQZhsfgrgf9IQ17AxQGSPHz/uG5JkZeUawmM5L+cnjWsjDT755JOcVna1oNy413A+D7s/6+HQ0NBLILwwJjBEkCAoo0ePdo8ePWoT+cWUGxQjyoV+XzQOTbHEQjCQhlXaUhZaGsllKZcKkSuTJk1q1VC3akHjsGzZspJ85qJ494VoG5QlyvhKzZJtq1RLlLGwV69eHXW11Bs3btzw3fRiQyTF/yFRFiFlibKojijjR548eXLBULR6gM/hcV0cO3as5u6URkOiLEIkymVSLUtZCImyCJEol4kN4jBokyvaRIh82GAuELUU20e0PSTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKQgiRIiTKrcDXX3/tXnjhBff888+7H374IbpPmvnuu+/c8OHDXceOHd358+ej++Ti3//+t7tw4YI7cOCA++uvv6L7JPnqq6/coEGD3IQJEzz8/+qrr7o333zTjRgxwo0fP97dvn07emxrUEn5/Pbbb+7TTz91ly5diuaLxkei3EqsXbvWi8qvv/4azU87iOrQoUPdvXv3stJ///13n/fTTz9lpcORI0fcxIkTXc+ePd2MGTP8vsl9kvz5559u0aJFbt++fV7Qz54965599ln38ccf+3wE8I033nBPnjxpdmxrUmr5IMa8E2PHjvX3xz5hvmg7SJRbgV9++cWNGzfOrVu3zgtNbJ9K+f777921a9eieZWCUM6dO9fNnDnTi0mYRyMzb968nD0A8mmMkqL8448/usuXLzcrD87Dvia6O3bscF26dPH7sn3x4kW3cOHCogS+paikfK5eveq6desmUW7DSJTzQIXCSuvcubNr166d27lzZ0Y09u/f71588UXXoUMHn9e9e3c3ePBg313Nl8exVEjyP//886zfqxZ098eMGeOFju0NGzb4a+BaoHfv3t7SvHnzpnvllVd8N5t0/o4aNcpf388//+wmTZrk2rdvn7mHQ4cO+fM9fvzYjRw50m3evDnrd6FcUeb33nrrLX9doTCzD79HGv9zHK4BszRJo5Gz/XPBveLysHLgmQ4YMMBDefCspk2b5m7duhU9nkaAxoBj2Zfnx7EvvfRSpvyska2kfCTKoimWKLLZuHGj71KePn06Kx1hQGy7du2asdwMq5ixvC+++ML17dvX3bhxIyu9GiDEXNOpU6ey0k+ePOkFlq5+UsSWLFniRWXPnj1Z6fh8FyxY4LZt2+atP0vHOu3Ro4c7c+ZM1v5QrigD5dG/f/9m5Wzcv3/fiyANZfLYYuFZcq/cUyj+169f9+WGIF65ciXrGKCxQHxpmGlALJ0GkPTJkydn0ispH4mykCgXwKyzfv36ZSxPA38mosvA04MHD7LyqORUzNCqM/AdMjhVjIVXCgjn8uXLfdc52W22yj5w4ED38OHDrGNmz57thQrXQPKY119/3T169CgrHcHgnikPymfXrl1u5cqVnqVLl3ph5ZyWtn79+kwZ5BNlRHLTpk3RhgPMn4x/OZlXDPYsYw0skEYe5Rc2QnYcPY5wcJLn36tXL+87Dt+NSspHoiwaRpQRIawZKkgoOpVi1nBsUA6LFzF7++23m4kgFhR5VL6wgiM2iE4t/MlYmn369PHXlcyzyo6licVp6Vhz1v3eunVrJp1rxiI9duxYJg24ZtJj/lKoxFIGehW4GLDsk3lJf3Kp0HAilrEGFswSRzTDAToiO2hEw2Pu3r3r3zVEObyeSstHoiwaQpSxcPDvES5VbVE2axgrKSmiWLyxrjBYN9miBAwqI/5I/I1z5sypqrVMRS5FcBAIxHHKlCn+WhETuw/EmutLNkTmllmzZo0Xl+RvVSrKlAeDoKtXr85KN2s11vMoFtwKnTp1ijawwHtDT4LnzXO3dPzMWOfWuOKmoMxozGi0wmdfaflIlEVDiDJdSioGLzSDOZWIMl31FStWeIGnchGihC8Wyzfczyxe8k6cOJGVh4VEpUUAknGqiCPCgvDQrU2KebkgGHS7GeBDGJL5McFhQHLZsmW+4QhFGeFAAGMxtuRNnTrVDxDSKIW9AMvPJTpYv4sXL/aiA/yfjMe1+6D8ET/KmQaRNETQjiPWOzyuGPCZc5+xBhbM5cRv8C4l84Hrw+XAc8e/nIy1Lrd8zM3BYCPnHjZsWJZbQ7QdGkKUjUpF2bqk77zzjhdWLErroiYH5ahUuAqo5Ize20g+WOQFIpiMUwUqIJUt18cTZi1x7iTJBsCgsmMBxlwpEA48IspcF40KQsQ5ObdZkCbWSUExSOf6Y/n5RLlYELOkm6VSuFaEnfs8fvx4dB/KAUGMjREAQk4Dxj747mPlDLUuH9HYNMUS65VKRJkKhh8QAUaoSLOuNB88JN0MVoERtnA0HmxAKpdA1gKzhEMXRIiJtgk7A2rbt2/3DYOJMvdC40MkQWuKBsKXdCFUijVKsQbWMHcUlniswbRICxpqGnDSEF7eu5gAC1EOEuX/wmANg0ihyJrFSmVNCp35jGN5DEiRl6ubXAtKEeUtW7Z494pFVZjfnBjlVatWZcVjtwa1EGV7lrncO9YAI7rJcELgWhD05MAefmoa32TDLES5SJT/S8zfyGALaYcPH87aF+sXUcNSTvqabUCKPCzQMK+WFBJlsHhkBI97sv1MsMjDmkyGwLU0tRBle5aEpMXKh4iVXG4Jc2vFBvZo4Fqy8RWNT1MssV6phiibv5FKRgVGrBiMYvDPBqUIkWJCoVhX2KIcckVBFEMokklyCb1ZwvlcJibKSZeL+ccRpVCsW4tKfMqUQzKqw54l955sYMGs4PADEINta4CTA3s8X/zPuT52EaIcmmKJ9UpMlPfu3esHVqis4b5JzH1hlRYLmE9xEQeiBviIwgZ/zGcc8zXny6slCA9WMvefa3IeXC7cYzKqwqxsxKe1u+E2IJfLzZAPe4Y0mOGsceaawPoOXQ/8FhYyEyTNmjWrWSNAPpEWiHloQVPWjDuMHj3aR0nEBgWFKJeGEGUm3yEECesUQST6gc+DqUQffPCBD1EqJMpYQMSiIsIIKpPcsI0Fxfm+/PJLb6USXWFzYdgcCEePHs2bF/u9WpAvThloXOgRJAelEC0G/mo1gVEpmIDGfPWFwOJHkBFLXDA0TsynQXQMzwRrl/LhOfGcCX+jZ3Hu3LnoQN3Bgwf9MRwbRtjYM4Zcg4JClEtTLFHUJ7hSaERiX/TVC1iyiGVL+uOFSBMS5QYCa49udvLT7noBy9jmvlA0g2irSJQbDKzlfDOtpRmuPZziVIi2iES5AWGQkpjjO3fuRPPTCJYx/l3C4eSjFW0ZiXKDwuBnbF7gtMLgJB9iSJBFW0eiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKiLIQQKUKi3MJ8/fXXfnHP559/3i/0GdsnrbCo6fz58/3itCxIG9unnqnnZyMaB4lyK8BKzW+++WbBFbbTCGLFKt2sbhLLrxWsOfjTTz/VfO3Ben42ojGQKLcwtoT+unXrSl5CPw2wUnbfvn39enqx/FqxZ88ex5L+GzZsaJaHULOu36NHj5rllULy2fz+++/u7Nmz7vHjx9H9hagFEuX/cPPmTffqq6+67t27+4rfuXNnN2DAAE/v3r1dhw4d3LRp09ytW7eix2/ZssUflzy2X79+rn379q5jx47uzJkzfl+zND///PNm56kmiBRdcX5/4MCB7t69ez4da5PVou1euTeuZ/HixX5Nv1x5v/32mz8eS3L8+PFewMLfqyWI7ty5c12XLl3chQsXmuW9++67buXKlZlrDKn02dh6h3fv3s2kCVFLmmKJbZWNGzf6yrtt27YsK/b69et+leVu3bo1W/eObi7dXSo6K0hb95q/CAUVf+fOnZm151rS0rx9+7YXZhYkTQqWWZ4LFixoti7egQMHonmtZeXTkFD+U6dObeZWoDxfeeWVqJVcjWfDfXK/sTIUohZIlP8LXdUZM2b4QazY8vykkYfFZpUbsK4GDRqUtSw+FZlVman0y5cvz6rMLWlp0vXmmunyhyLK/4sWLfLCy3WGxwDXTN6+ffuy0gtZ+dwnliUChhBOmDDB7d692z18+DC6f7GwoCpW8v79+7PSsf6HDh3qDh8+HG0kqvVsWNSV3saXX36ZlS5ELah7Ub5//75bsWKFtwjh/fffd0+fPo3um48HDx74Cky3lkqYzOd3XnrpJde/f/+MKwCwrohICIUaYaJbPHnyZL90vqVT2XEPtJSliTWM+Jw4cSIr3SzeWANk19ipU6csMQPuK5eV/91333kX0NatW31Zcn80dByDcIYWaalguSPyiGyYTqNBIxF7XlCtZ8PxCxcudG+99ZasZVFz6lqUcSvQxcYXyjaVrFzRwxpDiHKNvGPtYS117drVC5ClU8nPnTuX2SavV69eXoiSYmGW5ubNm92cOXOaWWTVhPvHGo41MlxHnz59mjUwYC4PGijENcwzS5K/obVs98x9xcr98uXLvtwQ5lKfC/svXbrU+41DcbWezezZs7PSQ6r5bBB4jm3pAU7R9qhrUabCJq0vKs/IkSNLHjEPR/djwkED0KNHD+9Xvnr1arN8YDCICk/lRYiS+Vjbw4cP91bqrl27ShaofHAuRAiXAQ3TiBEjvFXL/6FFCOzHvcYaoJMnT3rrOiZ2uCLoLUyaNCkz8IXliIhxP9xXUngRQspk7969/tqSosYgK9eB9co1hdAI0jBQlsmBNms8cj2vJJU+G2u0jx8/npUuRLVpiiXWM+WIMuKDrxghyFXpcAEgVjELEhC+KVOmeHE5duxYTqHAwmPgKldXHsFH+JMCBUk3hMFv4Sel0bh06ZJPY5tjsGqT10IaeVwrIotrwLDIi5hVyzblGgo5Aocr4MmTJ174xowZ4z755BO/Lw0ZjQO+WLaJhGAw1Y6lcUDoGMD77LPPvOXLb/NhCnmURaFySvq9Y1Tj2VjvYseOHc3yhKgmTbHEesV8fzEhygdCg5Dn656akBEelqy0/C6j+eTz1yxMzoslGO5bCwjpQnBWrVqVuTYaJ64n2chYRAINDMIX5hUa7IzB74TWKsL88ssve1EnlCwUQaxNng/lc+3aNV/e4WCb+e1Xr16dOX8uaKC4v+Q9JKnWszH3FS6hUt4tIUqlKZZYrxDDSuhUqX4/s7qw8mIWtg2MIXynTp3KyqOC2mh+cvAIq7AcP2opIDIIXSiy/B5+2FgjY93+WJ6JYq7Bzhjce9J6xHrG4t6+fXtWA0Y5z5w505eRXR/WtOXbtZFXqMyKEeVqPhuJsmgpGkaUsdCwzApZTjEsLjeXGGANUrGTIVTA7yHWycEjBAAhSEYwVBuL4Q2F1Cz/WCNjPuOYr9lC6HINdsagbNavX5/ZtueAXxaLGUvZ8sxSRuC4vokTJ2YNqNnvF+OSKEaUq/lsJMqipWgIUaaSYYGZ7xLrER9gMZWHfRBjKjjxrsl8G7FPWlphHiQHj8y3jWiG6YUo1adsohwKnJ2D+/rmm2+8W+OPP/7wefaBTMzFg8VLXrGDZ8B987Ujv40g06PAp4yFjBWMIJpw4lPGOuVDD645FDieGY1evhC3kEI+5Wo/G/mURUvRFEusJwiHIyyOSmhpDMStWbPG+0gZ9Z83b15Oy89cE4RshZUXkaDy9uzZ082aNct37cPjECAEJzl4ZMchGKGPt1aY+4IYYQbbaDgQScQV9wHiawNv5jMmL+lrzpeXD3oORGrgJiC6gr/hPfNcGBwluuX111/3Qm3XjLVO+XNtlCFllm8gLsRcLaGVbtTi2Vj0RazhFqKa1LUoE4NKBWN+ijCCgK48scrsw0h+7PNcBIyPATgWIaJLz3EcT2UnkoEv0/gNKnN4LAKGEHGczQ/Bcfxl285XjiulHGzOirFjx3pxxh0zffp079elQSEWmevl/rguro887o9jc+Ulewa5MKsUKzwmdPj6LU7Z8rGWaUxxdSDWXCeCXYwggzUiydC9Wj0bxJx7LHW8QohSaYolClEq+GdpzPiiz9wCCCTiN2zYMJ9e7a/hcF0wMMgAYSy/WphlH2vchag2EmVRNfi8HYvy73//u7dOsdr5Qg5rvFgLuBTCuS9i+dUCHzcumHDQUohaIVEWdQ2TFJUzoFosNCa4wvi4qNqWvhAxJMqirsG1wLwYy5Yta+b7rwa4XxgILiYiRIhqIFEWdQ9izIBs7PP3SsAnTuw0McqxfCFqgURZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShEQ5hbDC8/z5892zzz7rF36N7VMPpPE+Kr2mmzdvul27dvmlr2L5SVhZe/z48X5prDfffNMvXwX8/9prr/llpkpZPVw0PhLllPLDDz/4FZhbakXsWpHG+yjnmi5duuRXDGehVpafevz4cXS/JKxZOG/ePL8yOMdwLILMAqw0EKyozqKzsWNF20SinFKozH379q37Je0rvQ8szQsXLri//vorml8OlVzTkiVLmokygnvmzJlm1jMrlyxYsMBfP9vfffed69q1q19Mlm1EeebMmb6RCI8TbRuJcoQNGzZ4S6pDhw6uffv2rl+/fn51ZpbQ79ixo99meXtbE+7gwYOud+/erl27dp7u3bu7VatW+WWEsIo6d+7s0znfwIEDvWX0xx9/uHfeecenkcc+GzduzKz6vHbtWt/tpeKG11YNSr2/ENJYbj+8V44FK4NQ8Cq5D0RsxIgR7vLly1npLJKK1cpvW7lyP4sXL/YrZ+fKs4VPK7mmmCjzzD7++GNv9SLQlk5Dwn5WjgcOHPBuk9OnT2flV7PBEfVPUyxR/K+7ffu276r279/fL2Vv6VRsLB3EbOnSpZkKd/36ddejRw8vbPfv38/sD1RYBAKhTi61v3XrVi8YoZWFWLBYJ6so12Jpfij1/gzWwcMPOnr0aH/PJiiI0ZQpU7yosxQ/113JfTx58sRNmDDBNw65jt2zZ48vV6zRpLAhgLG8Sss2JspAuWH1Ivix85K2aNEiX3ZahFXkQ6KcAxbMxKp5++23my0tzzbpnTp1chcvXvRpWMVYwd26dXNXr17N7EtlxDJFIKiUYYVFDLHqEDdLA/N5fv7551np1aTU+zM4DmEJu9wI98qVK72Q79y5MyOCldwHDRniiVUcyzeRo1zZN5m/fPlyn4eoh+nJa6LsufZcbN++PavBzCXKgJuChg4LP5nH/hwXK28hQupelHnB9+7d64YMGeJ69erlZs+e7buwsX1LwaxbBDVm+ezYscPnY+mybaKMzzCslHTj6c6zb2i1cc5NmzZ5EUuenwGoWvuTS70/AxcL123H8JdzIcgIYSg45d4HQjx8+PCs30liFm/oDgjzaOxoVJKDaJWWbT5RpreAdR/rESX9yULkoimWWE/QhaXiUQkQBISBihH69koFy2/u3LleaE6cOBHdx0TNrF8Tgi5dumR8oGZB0q1lX/LZjzxEge7+o0ePss4L5vPkby2s5XLujzQalE8//TTLskfkcFlMnjy5WZmXex9Y4/Q48kUlYPH26dOnmfsFzDWDRY+7JcyrtGzziTLQaA0bNqyZhZ/0JwuRi7oX5SRUaOJAsVxj+cVAhRo8eLAf8Mrl/7PuMX5XRIsQJwb1SLNQK0bkp06d6o4cOeIF0ETZxPrw4cPNLCrYvXu3901PmjTJRx8k8yulnPuL7YP1R++E8o6dp9z7QNjyXRtQxlyfhZeFeSdPnvTlTa+Jsg7zyr0mGqJly5Z5sacRolH78ssvm+1HZEfYMDMIbMdxTdOmTXMfffSRXBgiJw0nylTWfJZMMeBHpes7ceLEjGUbEgowFiVphD/NmDEjI8rsg//w1KlT3seM5Yd7g8bCxDqXNY8Icv1JsQkxSzaJ/UbsGKOc+0uCoCHGiHIyOsIo5j5iYI3ivsjlTwYsXa4PgURkLQIELPIi5hoq95qKxXz11jALUSpNscR6BZFDTPbv3x/NLxYbuafix6xE6zojtFeuXMmkIyYmZFhMWJlYRCbKiAfHIt6t+cFAufdnUM64XrD8uFc7B0JdqWVvDULo6sm1D7+fFD9rHFvLVWDPGp98LF+IQjSEKOPrpHtJRc4XQlUMHIuYIlq4F2L7ILjkU/lDi8tEGbEjZtV8r4TIIch0yema051NdqtbikruD8z1Qn44sEc6ny9XaiEWI8rmM8ZKTw7YhWXdGqFnEmVRKU2xxHrDLL/nnnvOR2FYnGxs30LQtcX9QcUKQ9sM4meZsyDWbTeXAj5Fohos0sIiM8hj5D8cKGtpKrk/ypR7xEJNDuwR8cJxlQphMaJsPmP2SbqAzH3AOZINSksgURaV0hCijJWGAAIDK1QK/LaxfQthlWrMmDFewMI8sxLDDyTCfBNlBtHCsDwTQvJCsa4E+60khXzKldwfVjB5yYE99iN8rdgYXFwM+QSTHkcsgsGgt8G9xtwvFsqXK9Sv1sinLCqlKZZYz2BdYUFt2bLFbxPDzIQwxVpN1nVPfgmGyM6ZM8cPIhFNERNWjsWCS0ZVmPWHmFXqc62Ucu/PIi2SFjQfVjCghlh/8sknBYWQ38G9EPswxUBYc7kfwgHV5Oxq+fJaCso3Fh8tRLE0nCibAGJJss30jEQ6FBJlYlYRC8SFSs1cFDaaj8uBmFcC//NFBOCWoDFIdqkRC6Z7xHpvDesNKrk/XBqjRo3yx3E85+E4hJNGiHSs79igYBLOj5WOTziXGwdrkw8tvvnmm0wajS0hbuFv0oBgnSP0ufKSz6LWYMUXihwRIh9NscR6BmFAMGL+UlEfIGgIGwIXy08rNAD2RV81XFSibdIwoow/9Ouvv/YugkojMETrQ08n5vdOM8x9wbwaxfQYhMhF3Yvy+++/77u6dL+xUIixje0n6gus5ZdffrnZhEJphQFOPqev1kCuaLs0nPtCNA4MLtLzSbvlSa8My55PqFvahy0aD4mySDVEqxDJgHsqlp8GEGK+HswVVy1EKUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUhRAiRUiUWwCWqWKh0Oeff75hVkZh7uD58+f75fRZnDa2jxCidCTKLcTatWv9KtuFVtWuJ2hgWJPuq6++iuYLIUpHotwCYFWOGzfOrVu3rqEWdP3iiy9c37593Y0bN6L5QojSkShHYPFLLMAOHTq49u3bu379+rkBAwa4l156yXXs2NFvs6CnLVH0/fffu4kTJ/r0Xr16NRMpsyg///zzrPRqw8rPWOO9e/d27dq189fKNXPtXNszzzzjXnvtNXfp0qXo8Xfu3PH7c2x439C5c2efzuKgLBLK/lj/48eP1zJIQlQRiXIObt++7f3A/fv3d/fu3cukI0ibN2/2orV06dKMMLP68uDBg6PL4re0RcnvIaALFizIWln5/v377o033vB+4GPHjmUdAydOnPDCvXr1an8/ls4CpjQ2LGL6448/+rRGtf6FaG0aRpSfPHnizp07V7Xl3c+ePevF6+23385YhgbbpHfq1MldvHjRpyFcXbt2bSaE0NIWJb+HKMeW56dhQGAR1OT1cNzcuXOz7peFSxFjjrl8+XImvaWsfyHaGg0jykePHvXiEVq1lcCS8QgbroyYJbhjxw6fv3XrVr994MABv81x4X4IH9ZpS1mUDCTiwqDBYBXoZL5dT5cuXbJElnSOu3DhQiaNVZqnTJni3SBY1uH1M7gnf7IQ1achRNks1y1btkTzSwWXBBYjLgq69LF9TLQXLVrkxWr58uVRITSLEpfHnDlzam4tm9tl0KBB7sGDB83yTbS59jBqAnfF7t27vRCzTRmsXLnSl8HOnTtzWv/8lbUsRPVoCFHG4hs+fLgfqIrll4r5hxnoMh9qEkQYYcOvjJDhDsCi5DoQPY4/efKk9+OSRv6uXbtqbi3zmwjp7NmzM/7uELu3fA0O10ijwz7cZ9J9Awg4g4KTJk3yLo5kvhCiPOpelBGehQsXVs1KBvzEWL1EVMQs29DaRLywhvv06ZPld924caO3WLFcf//9dy+Gxfq7lyxZ4s+dhN8sFOfM77Lvtm3bog3A1atXXbdu3Tz8n8wHLGgamMmTJ2cs5yScmwHNRoq7FiINNMUS6wl8mqNHj66alQzmH6ZrHhM2E2GE7cqVK17E2J9uvu1v7o1c1mgtQPxnzJjhByhPnz4d3cfuDb9yTHAt0gL4nzTu6dq1a+7p06fN9hdCVJe6FmXEYtOmTZ6YeJYD58ElgXAdPnw4uo+FnCGAWIpYp6EQmk86nzjWAnzI+JJzuV1CXzmRGckys0iL5MAe1j69hmoNogohclPXoox1PGHChIwA4U9FUJP7lQJd8pEjR+bs3hN6xwcY5qow63TgwIEZ0bJzMMCXyyddCyyML5ebg8gKoi5ibgm2ibSIDewR2cIgZcxHLYSoLnUtylh7YagZrgL8scn9SsF8rrGPQBAlIhJCS5JBMMQMd4D5n7GOEUfC6cqJmy7Xp2wuk1gYn1nB4Qcght0XxyYH9qwRisU8CyGqT1MssR5g4Gzq1KlZAhMT5b1797p58+YVPSCV62s4rHKsxe7du7sjR45k5THIOGrUKH9NZnESopdrkKwWmGuCaz9+/Hgmnes8c+aMGzJkiPe937x5M+s4xNsiLZIWNPc8a9Ys3yu4fv161nFCiNpQt6JMVx2BtLkZgDkfmKOB/xFVLD6mlUS8C4kysbY2twXCZucBPpLAV0usMcKbPJY0fg9hRvgQuZYaFMN98s4773g/MsLKtVMOdu09evTw8cQINfsmjyeu2u45LE/+Jw1yDQoKIapPUyyxXqmG+0IIIVoTibIQQqSIhhJlQsKIG47lCSFEPdBQoiyEEPWORFkIIVKERFkIIVKERFkIIVKERFkIIVKERFkIIVKERFkIIVKERFkIIVKERFkIIVKERFkIIVKERFkIIVKERFkIIVKERFkIIVKERFkIIVKERLkIfvjhB7d+/Xq3du3aZsspCSFENZEoF+DatWt+vT3WAmSdOhYeZc078lgolUVKWS6K5aNYC3DXrl3RZZdaGtbeY/XqAwcOlLV4qxCidZAoFwDr+IUXXsgs0Lpx48asVaUR5nHjxhVcabolYWHXiRMnup49e7oZM2akopEQQhSHRLkAiPHFixcz1iaLomIZ37p1y2/j2ujTp49bt25ds2X9WxMaCBqKehNlGrn58+e7Z5991i96G9tHiEZGopwHRJZ1/1jNGTGeNm2aGzhwoHv++ee9GLPPV1995QWEv8njW5N6FWWgbF988cXUlakQLYFEOQ+IAq6L7777zm/zt2vXrn7Jfiw60nBvYDnfuHEj69jWpp5F+YsvvkhlmQrREkiUc/DkyRM3atSoLF+xifI//vEPb0UjzFjRSX/ysWPH3OXLlzPbrUE5ovz48WN/TO/evV27du1cx44d3UsvveQGDBjg+vXr55555hn32muvuUuXLmWOOXjwYGZ/6N69u1u1apV7+PChPxcDoKR36NDB9zLOnz/v/vjjD/fOO+/4NPLYB1+9uX9o6MKGT4i2RFMsUfyvu3r1quvWrZvbvHlzJg0XBt1qojDYjvmTEfOZM2e2upVXiaWMpYpYLliwICty4/79+74Rwl1Dw2PplEePHj28gLOPpQNlxrkQ6qTPfevWrW7x4sXu6dOnmTQbOE2bj16IlqLhRPnPP/90P//8c8UV+s6dO15k9u3b57cZ8Bs5cqTftnMjXgjU559/7rf57S1btriFCxe63377LXOu1qASUcZSRUjt3kNobHr16uWF0yxZrGKsYBoxGjPbl3IiZJBzLVq0KOuZ3Lt3zwu8NXCG+ZOtTIVoa9S9KJuVRsU3li9fHt23VE6ePOkGDx7s/v73v7vXX3/dHT9+3FuOiBFiM2zYMN+lxzJesmSJ69+/f5ZItxZcNxYoIgn8H7oc8mFi3qlTJ+9qSOaby6ZLly4ZF42JMq4d878DAo5vmGcSWt2I86ZNm9zOnTubNZ748eVPFm2ZuhdlwtWo8HSbEQcI/buiNG7fvu0HNwcNGuQePHjQLN9EG6G16IiYUNNrWLlypW+w2Jd8s6wR3ClTprhHjx5lzmuYP5m/spZFW6TuRZmQNSpwLE+UDlZ2+/bt3ezZs72wJvN/+ukn33tgH8qetJhQ89Xj1KlT/Ycs7GuibGJ9+PDhZlYy7N6927uNJk2a5O7evdssX4hGp+5FmYEkPiWO5dUbuEAQtiQIXktZ/0RB8Jvbtm2LiqYNgIb+Y3zW+K45DlHmWvk0/dSpU5n9cW/QizGxxu+fPDfwm0SBqLcj2ipNscR6glF6rLtYnigNE1f84qdPn47uQwOI+GL5hsJqDQqNJAOgS5cu9YOdJspYvwzicf6Yr1oI8X/UtShjVa1YscJNnz7dW2JEBRD5EPNV5gIhaUli11Apsd8pROw8+JDxJROTbHN9hOB6mDt3rndHhFEoYKKMK+mtt97KRFXg60eQOSdW+LJly6JuESHE/9EUS6wXEAVmQiM2mG18lsybwOBSa4ek1SNnz571VnIudwllzWDe5MmTm7kfLB6ZfCJTLNLCIjPII6oiGQInhMimrkU5BtEY4Qce9URr+5RNWBHVpD+ZQTemLYWYFW3HMghIjLel4x8mvtvOG36MIoRoTlMssZ7Bh8lnwTYItXfvXj/PsQaO8mOuCcSTeGxLR0QZnBsyZIgbPXp0zkn+8SPj1khGVVDuNCqIuaIphChMw4kyljICQrwt20z/yGh/a4ky0QjMa5zWsD0G95iHAp8vooooM5cFDRvwYQ5xwwh1vi8D6ZnwNWPSrcExTPyPsCetbyFEcxpKlLH2GPV/9913yx5MwgdKONjq1au9D7VSIbHBMyzJWH61ILKBiAg+/OBjmjVr1ngx5fNm7gXXAdaqIh+ESDcNI8p81IBPli/FcsXAFoJIAeZM/vbbb/3cDKzesX//fm/ljR071luS5DMZzyeffOIFkJnU6PZjKX799dfeKgZEEOu8pXzcTO7z/vvv+9/68MMPfaOEGBOOhhCbG0Ef2giRbupalImwwF9MKNyrr77qPvvss4qiLojBZc4HLGS2sW7towf+Z54LBNr2pxFgljisVLb5bSxThNj24Zzh5D21gvPzhR3uBj51tphji0TBncO96NNlIdJNw/mUKwHxxao0YUfksIRJ43/8rfb1IBEIWKWhKOM/ZtVrc53g+sCdAi3hT92xY4cbPny47zVYfDBREeQdPXrUr5jCAKgGPYVILxLlAGY4o4uPK4CPUBA4E2WbEwJRRnTx2b7yyiuZfGKl8eXa2n2A9YqVbEJeS7gm3ChY6ljJWOtYzVj2odVMo3Ho0KHoOYQQrY9E+b8gyPiIbUIdszQZpMMqts+FmfQe9wbTYbICCR9b8NHFnj17fJRBaBHjR8aaRpixVC29FmAdjxgxwl8H24QCsnIK98E14ePGfcEgaLk+dyFE7ZEo/wcsSWZFIzqBAT7STJSxfnFnmCgzV7P5jRFwXBr//Oc/vRWK+yM8L+KH33nOnDkSQiFEUUiU/4N9Cmxdf9LwIf/tb3/zM52xbSLNenJYnbgLzM/MfgwyhucUQohykCj/B6zYCRMm+BAy2ybm10LLSDPhxp1hfmObKwIrW4NnQohqIFH+L/h/GbhjHmAEGZ9sGF7HHA4vv/yyj2Ywv7F90h2GwAkhRCVIlIsEIcaCNssZ+B+x1iQ7QohqIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVEWQogUIVFOQGzykSNH3MqVK92nn36aFasshBC1RqIcQNzxunXr/KQ+zPDGhEPhytjMuMbSUnxazYckCHetJ6/PBWvlMQHS06dPo/lCiPpEohzAvMjMj8zcFmwzMTwzxzHHhe3DZPd8Wm2zybU0ly5dyiz7xCrRfLwS208IUZ9IlAOwiJkb2WZ7s/kuWHzV9mE5pb59+7obN25k0loDZp9rbVFm+SsaBybPt4n+hRCVIVEOsKk2mZ4Ta5l5kJnE3kQZlwZWKhPht/YERGkQZaCRSkN5CNEoSJT/C4LMoqv4ifEtM9cFU3niqrB17cy9gd85nMy+NUiDKNvKKmkoDyEahYYSZZZkwv+LwMby83Hw4EFvFZuv2ESZWeDCNfiS/mRcHMkZ5VqCckQZ65+VUDp06OCXturXr5+/P+aJ5t7Z3rdvX2bSpe+//96v6E06i9MmXTaUC+fTYqxCVI+GEGVmaUMYcS0wEFbOrG2InC39xPaDBw/8djincsyfzMAf7o2WthTLtZRt8LJ///6ZVVaARoWlrhBrFnq1e2aZqcGDB7sxY8Y0+y3uPQ3+dSEaiboXZcSDdedwO1RirW7ZssUNGzbMixCivn37dt81Z8UR8q2rPn78eP8/aViKrIPHmn3huVqCckXZJuZn3uhkebFNeqdOnTJzRLN2YdeuXf2yWMnGjkYqLA8hROXUvSjv3r3bvfXWW2W5LEI4HnfF6NGjvTAh8ibIrGTNStF08enur1ixwk2ePNlvt7QoERe9bNkyb+3y+1zXl19+Gd03BpP0E2eNKyNm3e/YscPns6I326zEzTbHhftxz/RM5E8WorrUtSjjasBaZAWQWL7Ihl4FIo6LIoy9DjHRpoFCbIlEwXImVDDcz/zJuDxYGFbWshDVoa5FGZfDtGnT3EcffeR9pPg3V61aVbHV3KiYf5iBO/OdJ0GEEWX8ypSjhQUOHz7ch75xPD0HehGkkc+XhbKWhagOdSvK+D8JYUMY6NIjClhrM2bMcAsXLswMVKUFfMCIXZKWjPHFT4zVS0RFzLLlOrgerguL2UIAiby4fPmy32fjxo3edcKAISt/mw8+eS4hRHk0xRLrAbP6kp87Izx8hWdhbOL/Y/5hBuhilq2JcLdu3dyVK1d82bL/zp07M/ubeyOX+0MIURl1K8r2CXRSHLDgRowYUbSfGYGpFrHzV0rsd4oheR5EFZcEeYcPH26WD4S4kU9vA6sZq5hIjdOnT/t880mHaUKI6tIUS6wH6H7jz8T6C9Ox9oYOHarBvwSEzjEoihUcKxs+vHnttdcyrgpcE4gzDZ/FM9s5GODL5ZMWQlRG3Yoylh/dcKy/sCuOBZfLZ9qatLZPGSFGkGMfgWABEwLIgN6xY8d8eZrPnrA3K0vKFiuZcDr5kYWoDU2xxHrh2rVr3q/MV3xsEy2AkOzfvz+zD1/6zZs3r81PmGOuieRHIHfu3PEhbd27d/eT+4d5RLfwcQz+eytbYrgV3SJE7ahrUYZvvvnGf/DB/A18Fn306NEsYeETaCamr4UoMxDWs2dPb7HH8tMA81LY3BaIcufOnf0HMEAIIWVGrDHCmzyWNEQcYaaMGeTTpPpC1Ja6F+VqwwDitm3b3OrVq/3n06FrJInNj4EVGsuvFvjJbWJ7RHLNmjX+S0I+8OA6cSfgR09+4CGEqD8kygF8EMHHKN9++60f3MI3jSuELr5FHYQzohF+x6BXrZeE4pPn999/3/+WTZCEGOMjRogtvjjNFrsQojgkygFEcvBxhU0whAVM9AHWc2xGNPYnAqTWg4qcn9C/Hj16ZEVG2PqBhAFynZpCU4j6R6IcgPhiedrsaQghvthz5875KI8wUsLifpPRH7WCiYL4ehE/LxY9fmKbJAg/OksyEWHR1gc0hah3JMoBTFOJ8OIu4FNtRBBRZi064nOZM4J0Br344i0WJ10L7KMNfMhYybhNsJpZXTu0mtevX+8OHToUPYcQoj6QKP8XBJmBNPts26xRBvIQ5d69e/sYXvPfIoT4eBFmLNXk+aoJ1jFfKe7Zs8dvE+ZHRATXiJXOQB/uC+aVVriaEPWNRPk/YG3Onj3bRzDY12smykQ7fPLJJ5kVm+2rNkQZy5UYXwmhEKJaSJT/g82jYe4B0vAn/+1vf3OnTp3y01maPxm/La4DJtdPnkcIISpFovwfsHQnTJjgw8xsm7hgCz8j1AzLmAHATZs2eZcFlnTyPEIIUSkS5f9CrPErr7ziPyNGkMMVqlnVmcl6Fi9e7N0Vt27dana8EEJUA4myEEKkCImyEEKkCImyEEKkCImyEEKkCImyEEKkCImyEEKkCImyEEKkCImyEEKkCImyEEKkCImyEEKkCImyEEKkCImyEEKkCIlymTDxPBMXsVQ/cy7b5EWivvjggw/8M2QyKiaeiu0jREvSKqL8zTff+PmJhwwZ4ucnju1TDky5ybJIrBLSrl07d/jw4Wb7IKas2rF9+/ZmeaXAHMyIsqbwTC+syMISXu3bt/fvQ/fu3b0A29qGBvNk896w+kyYLkRrULIoP3r0yK9Tx8vN6s5YiaTF9o3BStGsJccyRvDXX39F9ysXzsc1sfw+6+gl8+/evesbg08//bRZXinkE2VWL6GMWFQ1mVcILG7WCGQVlOeee84NGzbMHT9+vOrl1FZgtZg+ffp4cf7xxx+j+0iURZooSZTt5WWtOhNULE4EiMngY8ckYRUPluuP5VUDluNnEnpb+Tm2TzWIiTJdYSo/K5NgmbGSSSkrXVOGa9as8StX8z8CTXlxrp07d5Z0LvF/sIIMljLzZOdyMUmURZooSZSZCH7WrFle+MI0JoAvRgB5+XFbUFFi+dWA60EUmZA+aV2yzXVeu3bNr7UX5pVKPkuZ+ytHlM2qC9cKxL2D1c96gXKVlM7GjRv9s8CVketZSJRFmihZlBHgO3fuZNIQknnz5vkXO9w3CfshyCzZj88X98f+/ft9HmLJitCsHM0K0Qy64Hcm748//vA+QISWfahkiBZLNIXnN7DCqYT79u1rlkdjwrJOXIM1DFTWzp07e4uf5fnHjBnjr2/ixIl5RbBWoswCrbiFbty44dP4HdYP7Nq1q0SjRFhvkeeNpZzPEJAoizRRkijT/ePlNTFCTLds2ZJZlr8QuSxlFiHlvE+fPvXbly5dcoMHD/YWre2zZMkS9/rrr7ubN29m0mLQ3c/lT4bkNSCaiCd+5vPnz/ttXAfz58/395Y83qiFKAPXhxVvx5n1jDCb9SyKg2dDDyOfPxmKFeU9e/a4Dh06uHfffbdod50QpVKSKAODeogR1uXo0aO9dVms8MREGaubwayLFy9m0njh586dm2UNI8rJUfMkxfiTY9cQOzfbpIdpIbUS5SRcB+eiLJLuGJGfs2fPumeffdY/JyJzYvtAsaJMI82zoMGWKItaUZIoIzCfffaZW7lypQ83w3pDALHmYvsniQkiFQd3BCIX7osYsS/HsF2MKOfzJxuliPKUKVNyDg61hCjTU+jVq5cfpMonKiJO2KAlnwOiSpmSXqwosy/HSJBFLSlJlAlnmz59ekYgECwiDkaOHBkVpyQxQeR/xD0pyrhEShXlfP5koxRRDn8/Sa1FmTKmUeAc4cCqKA7rbfEcYvHqjE/w3Gm8ixVlIVqCkkQZiyMpXuYyCEUuFzFBPHnypBflpLglRbGQKCN+xAXjT/72229zWjT1IMpcO43fqlWrfMPHfeBnt8ZQFAb3FeMSvA/JD5QoU8rXxkIkyiJNlCzKya4goox4Ia7hvjFignj79m0vyrgxLM0ENhxoKyTKoT/58uXLPnoiNjDW2qLMAOTq1avduXPnstINBBgxNkEmDYHhWux+Cp0D64/yyNUg1Ht+ofsHxig6derko2mS4Y+IcRh2WKwocz1cF9cXyxeiGpQkymfOnHEvvPCCFz22eUnpGiJOT5488Wl79+7NGSIXE0TOsW7dOt9VN0uQ8xNpwdd3tl8hUebYCRMmuPHjx/sv4nINjLW2KNvHIK+++mqmzAz25XfxI3MsvnuYPXu2vzcTl3znQNT5mId8wgfDvEbIh3z3bxw4cMDvw9ed9h7w98iRI956DscdihVlG+jDLcJ1xvYRolKaYom5QDQIG2PuCMSZWOMVK1ZkfWaNj3nq1KnNxAxrD+vV4pQRNIuQIBTu/fffz8QvI0IWC421SMUi2sPmLrD45iSEy1HZ3nvvvWj0RfIauFbOZefevHmz3w+rnW32Q7CJd02eKybKnIvr43xUXuJjCccKJyziOBoyLLikoNtAJccmCb9Iy3cOnhH3RdQB15NsFOo9H/LdP8cQBsezo9x4FjyT8Llw7rBRLlaU+TSfYzEiZC2LWtEUSxSFyWcpFwIfJyJQiY+4GueoZ6p5/8WKshAtgUS5TMoVZSw/LK1PPvkkagUWQzXOUc9U+/4lyiJNSJTLpFxRJqyQT38rsfCqcY56ptr3L1EWaUKiXCaVuC9EupAoizQhUS4TBg0RZQaQipmQSaQTBhV5hnwAxUBrbB8hWhKJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBCpAiJshBV5q+//nL/+te/3OrVq92OHTvcL7/8Et1PiBgSZSGqzJ49e9wHH3zgxfjTTz91Y8aMcT/99JPPu3fvnlu1apXr0qWL69mzp1uyZIk7ePBgs3OItotEWYgq8vjxYzdy5Eg3d+5c98cff3hhHjdunPv4448z+9y+fdu98MILbvny5e7PP//MOl4IiXIV+e6779zw4cNdx44d3fnz56P7NDpff/21F5znn3/e/fDDD9F9GhlcFxcvXnQ//vij3/7111/dm2++6f7+9797kSbt7Nmz/h3Zv39/1rFCgES5yhw4cMANHTrUd1Nj+W2BtWvXeiFCkGL5jcxvv/3mNm7c6GbPnu0++ugjN378eNetWze//fvvv/t98DOTdvXq1WbHCyFRriJ0Rem2zpw501fO2D6NjnXX161b5/79739H92lUeP4rV650U6ZMcT///LNPQ4DbtWvnNm/e7LcR5hkzZriXX34542cWIqRNi/KGDRtc9+7dfaWB3r17e9/fzZs33SuvvOK7mKTzd9SoUb47TmWbNGmSa9++vc/j+EOHDvnzmT/RKmDa4T4Rhw4dOmTuE0G9e/euLxvKIywbLECE9ujRo65z584+nWOxik1gKKMXX3zRff75581+r9HBZUUZhv5jRJlBvQsXLvjt+/fvu5deeinLn8xfeljm8hBtm6ZYYlvi5MmTXmDfeOONZqFLjIwjPIymh+n4DRcsWOC2bduWNVCDL7FHjx7uzJkzWfunGSx6LDvu86uvvsrKo3tNNxt3zMOHD7PyLl++7F599dVmfuMvvvjC9e3b1924cSMrvS2AGCPAlA3b5k/GdWGunJg/GTGeNm2aLGfhafOibMIzcODALOFBbKlMiBXWTvKY119/3T169CgrHWtn0KBBdWfxWOMTWniA5depUydv2WHhWbp10/ft29fMRYE/GT9qW4zNpQfRp08f3yBZj2LIkCHu+vXrmX3obYTC/fTpU7d48WL3j3/8o825e0SchhFlLD5EJWbV5cNEOSk8WLvmvti6dWsmHUFatGiRO3bsWCYNqFCk16M/2UQ5bHy4B+6F9P79+2cNXNIVnz59esZvaiDE9Djaoj8ZeDdw+/AOEm0xa9Ys7yIi786dO77BIjKFho6eFvTq1StLpIVoCFE+ffq0GzBggJswYULJomw+vlB46GoyGGPdesTWRAaxnjNnTrPIAvMnr1mzxs2bN6+urGUbjAobH1wZCGy/fv1c165dfbgf6Yg193fq1KnMvob5k/GpU0Zt0VoWolIaQpTx8SKaWL34OUsRZfbFdREKD/6+ZcuWecs7FGUT61gMMnlTp071A4RYRKGvOe0k7xPfJoJMzPHgwYOzygaxXrhwYbQ3QANHnDaDhbt27UqVtYzFiuWK22n06NFu/vz5GfcTzy7ZyArRWjSEKBvliLJZuCY8WMsIEn7AEydOeLGymFsT61yCSzqCVktBxgIfO3as7xkUA/sWstrxhYeijEjTsOCe4N7JoyxMrK9cuRI9DxDyxX40lLH8lob7wfeNiwofL9f15MkT99prr/l7w5pHoJODnEK0Fm1elBHbUHg2bdrktm/f7iuviTJCxODN5MmTG/IrtbDxoTHiL0Ielg2ihVjjM02L4BYD/m98tsw3EV43IWmk0yBhPT948CDrOCFaC4lyIDxbtmzxfmTr1mI5Y0ETo0yl3rlzZ6q65NXCRHnixIm+J2BRFYD1TB5iTDkxYBU7R7UppUeQqzdAjwVXCwNrSZeTuWyIMy/1uXJcSxK7BtG4NMUS65VyRBks+gABPnz4cKaCcj66veTh4kiGwDUKdp/PPfecHywN42WtbIjljoXApRnuA584YwbJz95NlOkFJaNIhGhNJMr/wYQnWUFxVRB3iiCFYm1gia1fv95HbzDIh1UGnMeEDSHHysYCJcSMqRy///57/1Ug4VF0r7HWiWjgYxR+B+stl9+2VJ8y00beunUrei7DRPnZZ59tFuqHb5myYfAuFOtCMPnO+++/77/8C+d9MPgKkvuvZUyziTLPI/kbJsrHjx/PSsfFwb711PiIxqLhRXnv3r1e8BC+cN8QC+hPdnE5D1ZWOJdBCL9HrClfY/G7RB+QxifJfLmFKPAZMx9aIOD4ZXEHrFixwkcnMJManyOHnybjHsAqj0V41AqbSpJ5O5JRFYgX8drlDITZICrnSOYhfAh9LaevRFiJmeaDHj4dJw3RZcCP8qax5f0gRhifsrk7EGveieT5hGgJGkKUsTwJRSOmFmuPCodYIjBMNo4Vm0+U+dSaT6mT4oBwMPB37dq1rHQD6+9//ud/vPDYfBd8Zmxf9VlUA9eAMGEpcy4EHjHAkkWQ8enal2D8Jl94xXyktcLuM/zyzLCyiYXAFSLfZ+fWeNV6jgzKmhVAiF/nncAvTm8EEaaBpNyJqaZHg4jzrHiHiLRpDWuZhgwjgutqxEFlUZiGspRbAwYD+SqLD1jM0kJ8sbIRV8Qg6c9kP6xSaziwyqwbT0UsZNmnjaSLxuK0k5+d40YhH+uYXgIuE8Q5eb56g2eGG4v7ti/4KoEGnF4E70MsXzQ2EuUKCS1jXA/4MKlUWF/4VIcNG5bxxWKJ4ktFcHGJUImxxrDY+CgFy5uv6nbv3t3sd9IKlij3Yi4aGil84lj/4TSmuEgoJ8oGFwL33AhzZNDzefvtt/3z5/nSCNO74D6ZmImGh8aKsQP+4grCVYSI05hhmTPTHm4u3CrWYNNwxX5PND4S5QrBQmQeCIQW8SV6ASsHKxELGcGiMn744YdeuCykjK/lEGyzrBFzLGsqacx/nVYQEkLOzEWBy4Ltf/7zn1luHcIN6VGYi6bW/uSWgoYVkbXeAL0eXCQ8Q8Q1bJRtjMIaYNIoDxpwPmhh2/zwNPZsi7aHRFlUBMIaumjs6zkWA8UvilhjKdM4hS4a/P7sU08NUAzEmIbIPkwxCxlXDVE9oW8YoWVw0USZBum9997zvQo7H+4cxhoawa0jykOiLCoCC9isQaw9egr0ChBn3BUMIDItJVajiREDbQg3rhoG4erVWsb1hKAScocYE4WDJWzrE9JgmSjTaGFB0xjxMRJlhUvj3XffzRpERbixlLGYw98SbQeJsqgI/KIMWOJ6oRtOVAkig1hhMSLS+JkRIMSb/XDXENuNy+bSpUvR89YDhAniuuD+2LYvQK1HgFATask90gCxZh/CjOjixqLc7FgDIaecKKN670WI8pAoi5qBMNX7QF4usHSxeBFZi5QxUbYJ6xFlwusIKaTBwvplgBNrmk+7GexL9hIYJES0GXMI00XbQaIsRBng88UFE67HiAjjnrB4byxp4tSZq9vmn8bPjF8ZP3yhLy1F20SiLEQZ4H7ABYPvnG0G/LBww/lBcOEgyrhszG9MtAbWsx0nRBKJshBlgqsBvzhLPzH9J/NohNOD8qk9g36h3xhrmtn4LAROiCQSZSFqBP5iBuvCz7XxPzeqn11UB4myEEKkCImyEEKkCImyEEKkCImyEEKkCImyEEKkCImyaJMQuvavf/3Lz72xY8cORUSI1CBRFm0SPn1mmlTEmHUTWcvQpthk8iCmZGXeip49e/qv8JjRLnkOIWqBRFm0OWzOYmauY4FXhJn5nfmww/axdQsbYc5nUV9IlHNQaDXmeocJbxAdm2Yytk+jguuCOZBtYno+6GBiIb7M47mTxtd4rBLCWn3hsULUGolyHsyiCi2oRoJ5GMJZztoKzEPBCiE0tkynyVSbTC4UNr74mUnTZPOipZEo5yHfasz1jnXZWYI//Ay40cEVwbJcrIRi8xUjwEwcZDO+IcxMyM+6eeZnFqKlaNOiTBf1lVde8cI7fPjwZhUwuRpzPfH999/7iW/69euXWRsvzLclmWq9xH/aOH/+vHdLhL0fRJlBPSbiZ/v+/ft+BrjQn8xf3od6fBdEfdHmLWXmvkWU6bqGAzr8H67GHB5TL9DIMIsZkQXJ5YVYdoiVQZJi3eggxgjw5cuX/bb5k3n+5saJ+ZMRY5Z7kuUsak2bF2WbiHzbtm1Z3XjzJ4eTmNcbthIGyw6FU0oC/uRGWOK/VFh9m3XzaIx43mwPGTIkMzE94G8Ohfvp06d+TmRbUcT2E6IW1L0o09VcsWKFjyQAIiaoRLF9YyBOrAQRrigMCJqtxhym1xN0t2lwkgOVCDGLfbY1fzLQA9qwYYNf+YNoi1mzZrmbN2/6PCau533gPerUqZNvzAD3TyjSQtSSuhZlrBsqDZWJbQZuShEb3BIM+OB3TfoKzZ/Masz1ai3jE0Vc8KOG6eZP5r5YO66tWctCpJm6FmWEN9ktL2WJdvtAgC4+I+0IOgN/iH1yNebY8WnGoivwjTKIid8U/zKrZdC7II38Xbt2pdZaptFkdexXX33Vvf322/76jx07lnnuPOPk8xei3ql790WSUkSZAR3WS6Mri6Vsg3uIFaJmxI6tBfg3BwwYUDTLli3LfOyQBGsY9wtdb+t24yulEaIxIuyLQau0ihoNB89h8uTJmcE1ni2NDOMAhCsi1FqGXzQaDSXKiOrChQu9X7AY649QKPzJVHJLY56DRvhowAYwWcreygLfMmlJ/3na4DnOnz/fNyjhAJxFyuCyYm6KTz75JLVWvhDl0lCiTJwpXdxiwrzMKg5jeK3LH4vrrTewiukFnD592m/b/YZptYAolphVH4N9Y+fAsmdgLRmm+PDhQzdw4EDvJ6c3ZGMJxUBjVC1i5xeiWjTFEuuRu3fvulGjRmVZvfmwkDf8yNYFti7/a6+9VterDdsXaQgYM56RZvfLAF/aP4BgBjfEL7TywUSZhgVXj6xk0Yg0hCgjqnzk8eWXX/qKinWFwOartPZhxaJFizL77du3z7szDh8+7K0wPhbAB0t3mUgGBv0Ip7L9L1265MWPKSAZSOM3mQZy9OjRmWXk6XLz8ca5c+fcvHnzfHouP3WpPuV33nknOlGSRZXQ4NhvYR0jZlx/Pj8yg5oMAuK7TUZtIPBY2+TV8ktAE+VkA2uiHCtDPvyIlYUQ9UbdizLiiWiGERIPHjxwa9as8ZWU0XvEMDnpDsKN/xkxZz8sbcQIXyWiRlQCMc8W+8z++GRtEJH4ZXzPCAcivXTpUu/jJO6Vjwzs8+zwU20iB3CPtIQVvmXLFt9zoPGh0UKkix0Y45oZ/DQrO4TBtlr73HEdEfmCz9/SGPjjOT733HNu2LBhfh/cVTwXc3fYIGZ4LiHqjboWZaxPBKJ3795ZFiRxx8Qqsw9W7NSpU6MzoVGBsX6BsCsEx3yYWGIMiDGwRKUnHSsRyxphw0JmAnSsawYWAbGmQZg+fbpvKBB3xBox5H8ajnfffbdFLDrEmGtAmLHcaVCK+ajG7jP2ebk1Pi3xJSCN3ogRI3xZvvXWW76nwkcerBbCvBR8hYe1zjXRQ0GQuc9Hjx5Fz1cJNLw8a55xLF+IatIQ7otagaVmExVhkSP4iPCtW7d8Nzo2ATpCT96hQ4e8cGEZ28cnWKDJr+taC8QMscFF8+GHH3pBo9Ew37NdM/e3e/du/5EJjQsukNh91xs0OEeOHPEzxuFySjZAITS09HZotGP5QlQTiXIOQssYyxZ/LxUTUWYeBPy1rO/Gvggc+VjU+JDpehMDbbONIcZmXV+7dq3Zb7UGCDLWJULM9XOfuDi4bpuulHTcIDRMuHfYl8iUep9ZjmdLTwrfNQ0n7iZ6BviscV/hMw+/4iQmmgHSMDxPiFohUc4B1jHdZyou2wx6IWJYi1ROvozjK0BEiy49FjDWFhX+vffe8118RJ39+UoQIWcAEaFL/lZLQwOBy8ZcFNYAYSH/85//zPjA6R3QqFjcd0v4k1sCi7Jh0JNt+7ITd1VsDm0aVfugyNKEqBUS5TaIfYRhrhQaIKxhGhf80CbWNDxhpAXiTGOD1VzP7gvujUYWy5hti+pg/IEyCQc5aYwoF0hDgyoaH4lyG8QsYFwxbGMBYx0jVFjLRK4Q6UC0CJYxLg18zYT2EbGCf7merWV6Cny5iW8caxkrmMYHlwYuJpvulLLAeiYfazl2LiGqjUS5DYLFh+Bi9WL98kkzkQ1EqBCpgruFdLrrTIs6adIkL8T40fEpW9hg7NxpB0HGd84AH9Y+ZYE/nQFMQhppnOyjFYR77Nix3rWBMDNuEDunENVEoiyyQKhwZ9SzeyIfBw8e9FaxfZhiokxkDREzf/vb33yPgcFdrGbGDbCaaZQQ9OT5hKg2EmXRpsD6tYFMti3cjbBAPhgyf7KlE1feqA2USCcSZdGmIFqGLwLpDfC5+fbt271rgvBF/Mb2xab52RUGJ1oaibJoU+CCwF3BxzKEK+JbRpDJIwoDnzqDmeQxt0nyeCFqjURZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFShERZCCFSw/+6/weLHsczruaXMQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. Back propagation/Training</b> - In this step we calculate the derivative of Loss wrt the parameters and then depending upon the orientation of the derivative/slop, give new values to parameters - Weights and Biases so as to reach the global minima of loss(least loss)<br>![back.PNG](attachment:back.PNG)\n",
    "<br>\n",
    "m stands for the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset we use here is 'mnist.pkl.gz' which is divided into training, validation and test data. The following function <i> load_data() </i> unpacks the file and extracts the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    f.seek(0)\n",
    "    training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    return (training_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([5, 0, 4, ..., 8, 4, 8], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "# shape of data\n",
    "# there are 50000 data points and each data point has 784 features each representing a pixel of the 28*28 image\n",
    "print(training_data[0].shape)\n",
    "print(training_data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature dataset is:[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "The target dataset is:[5 0 4 ... 8 4 8]\n",
      "The number of examples in the training dataset is:50000\n",
      "The number of points in a single input is:784\n"
     ]
    }
   ],
   "source": [
    "print(\"The feature dataset is:\" + str(training_data[0]))\n",
    "print(\"The target dataset is:\" + str(training_data[1]))\n",
    "print(\"The number of examples in the training dataset is:\" + str(len(training_data[0])))\n",
    "print(\"The number of points in a single input is:\" + str(len(training_data[0][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the function <i> one_hot </i> to convert the target dataset to one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(j):\n",
    "    # input is the target dataset of shape (m,) where m is the number of data points\n",
    "    # returns a 2 dimensional array of shape (10, m) where each target value is converted to a one hot encoding\n",
    "    n = j.shape[0]\n",
    "    new_array = np.zeros((10, n))\n",
    "    index = 0\n",
    "    for res in j:\n",
    "        new_array[res][index] = 1.0\n",
    "        index = index + 1\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking it\n",
    "data = np.array([0, 2, 3, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(data.shape)\n",
    "one_hot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function data_wrapper() will convert the dataset into the desired shape and also convert the ground truth labels to one_hot matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrapper():\n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    \n",
    "    # we feed the data such that the input neurons form the features and hence the data to input\n",
    "    # should be of the shape ( features, data points )\n",
    "    training_inputs = np.array(tr_d[0][:]).T\n",
    "    training_results = np.array(tr_d[1][:])\n",
    "    train_set_y = one_hot(training_results)\n",
    "    \n",
    "    validation_inputs = np.array(va_d[0][:]).T\n",
    "    validation_results = np.array(va_d[1][:])\n",
    "    validation_set_y = one_hot(validation_results)\n",
    "    \n",
    "    test_inputs = np.array(te_d[0][:]).T\n",
    "    test_results = np.array(te_d[1][:])\n",
    "    test_set_y = one_hot(test_results)\n",
    "    \n",
    "    return (training_inputs, train_set_y, test_inputs, test_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x, train_set_y, test_set_x, test_set_y = data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape: (784, 50000)\n",
      "train_set_y shape: (10, 50000)\n",
      "test_set_x shape: (784, 10000)\n",
      "test_set_y shape: (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "print (\"train_set_x shape: \" + str(train_set_x.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data_wrapper has converted the training and validation data into numpy array of desired shapes. Let's convert the actual labels into a dataframe to see if the one hot conversions are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target dataset is:[5 0 4 ... 8 4 8]\n",
      "The one hot encoding dataset is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>49990</th>\n",
       "      <th>49991</th>\n",
       "      <th>49992</th>\n",
       "      <th>49993</th>\n",
       "      <th>49994</th>\n",
       "      <th>49995</th>\n",
       "      <th>49996</th>\n",
       "      <th>49997</th>\n",
       "      <th>49998</th>\n",
       "      <th>49999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  50000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    1.0    0.0  ...   \n",
       "2    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  ...   \n",
       "4    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  ...   \n",
       "5    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "6    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "8    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "9    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   49990  49991  49992  49993  49994  49995  49996  49997  49998  49999  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0  \n",
       "5    0.0    1.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
       "6    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "8    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0  \n",
       "9    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[10 rows x 50000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The target dataset is:\" + str(training_data[1]))\n",
    "print(\"The one hot encoding dataset is:\")\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us visualise the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f8b0e71a90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index  = 5\n",
    "k = train_set_x[:,index]\n",
    "k = k.reshape((28, 28))\n",
    "plt.title('Label is {label}'.format(label= training_data[1][index]))\n",
    "plt.imshow(k, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid\n",
    "This is one of the activation functions. It takes the cumulative input to the layer, the matrix **Z**, as the input. Upon application of the **`sigmoid`** function, the output matrix **H** is calculated. Also, **Z** is stored as the variable **sigmoid_memory** since it will be later used in backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \n",
    "    # Z is numpy array of shape (n, m) where n is number of neurons in the layer and m is the number of samples \n",
    "    # sigmoid_memory is stored as it is used later on in backpropagation\n",
    "    \n",
    "    H = 1/(1+np.exp(-Z))\n",
    "    sigmoid_memory = Z\n",
    "    \n",
    "    return H, sigmoid_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = \n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]]\n",
      "\n",
      "\n",
      "sigmoid(Z) = \n",
      "[[0.5        0.73105858]\n",
      " [0.88079708 0.95257413]\n",
      " [0.98201379 0.99330715]\n",
      " [0.99752738 0.99908895]]\n"
     ]
    }
   ],
   "source": [
    "# checking if it works fine\n",
    "Z = np.arange(8).reshape(4,2)\n",
    "print(\"Z = \"+\"\\n\"+str(sigmoid(Z)[1]))\n",
    "print(\"\\n\")\n",
    "print (\"sigmoid(Z) = \"+\"\\n\"+str(sigmoid(Z)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relu\n",
    "This is one of the activation functions. It takes the cumulative input to the layer, matrix **Z** as the input. Upon application of the **`relu`** function, matrix **H** which is the output matrix is calculated. Also, **Z** is stored as **relu_memory** which will be later used in backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    # Z is numpy array of shape (n, m) where n is number of neurons in the layer and m is the number of samples \n",
    "    # relu_memory is stored as it is used later on in backpropagation\n",
    "    \n",
    "    H = np.maximum(0,Z)\n",
    "    \n",
    "    assert(H.shape == Z.shape)\n",
    "    \n",
    "    relu_memory = Z \n",
    "    return H, relu_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu(Z) = (array([[ 1,  3],\n",
      "       [ 0,  0],\n",
      "       [ 0,  7],\n",
      "       [ 9, 18]]), array([[ 1,  3],\n",
      "       [-1, -4],\n",
      "       [-5,  7],\n",
      "       [ 9, 18]]))\n"
     ]
    }
   ],
   "source": [
    "# checking it\n",
    "Z = np.array([1, 3, -1, -4, -5, 7, 9, 18]).reshape(4,2)\n",
    "print (\"relu(Z) = \" + str(relu(Z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax\n",
    "This is the activation of the last layer. It takes the cumulative input to the layer, matrix **Z** as the input. Upon application of the **`softmax`** function, the output matrix **H** is calculated. Also, **Z** is stored as **softmax_memory** which will be later used in backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    # Z is numpy array of shape (n, m) where n is number of neurons in the layer and m is the number of samples \n",
    "    # softmax_memory is stored as it is used later on in backpropagation\n",
    "   \n",
    "    Z_exp = np.exp(Z)\n",
    "\n",
    "    Z_sum = np.sum(Z_exp,axis = 0, keepdims = True)\n",
    "    \n",
    "    H = Z_exp/Z_sum  #normalising step\n",
    "    softmax_memory = Z\n",
    "    \n",
    "    return H, softmax_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[11,19,10], [12, 21, 23]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.68941421e-01 1.19202922e-01 2.26032430e-06]\n",
      " [7.31058579e-01 8.80797078e-01 9.99997740e-01]]\n",
      "[[11 19 10]\n",
      " [12 21 23]]\n"
     ]
    }
   ],
   "source": [
    "#Z = np.array(np.arange(30)).reshape(10,3)\n",
    "H, softmax_memory = softmax(Z)\n",
    "print(H)\n",
    "print(softmax_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize_parameters\n",
    "Let's now create a function **`initialize_parameters`** which initializes the weights and biases of the various layers. One way to initialise is to set all the parameters to 0. This is not a considered a good strategy as all the neurons will behave the same way and it'll defeat the purpose of deep networks. Hence, we initialize the weights randomly to very small values but not zeros. The biases are initialized to 0. Note that the **`initialize_parameters`** function initializes the parameters for all the layers in one `for` loop. \n",
    "\n",
    "The inputs to this function is a list named `dimensions`. The length of the list is the number layers in the network + 1 (the plus one is for the input layer, rest are hidden + output). The first element of this list is the dimensionality or length of the input (784 for the MNIST dataset). The rest of the list contains the number of neurons in the corresponding (hidden and output) layers.\n",
    "\n",
    "For example `dimensions = [784, 3, 7, 10]` specifies a network for the MNIST dataset with two hidden layers and a 10-dimensional softmax output.\n",
    "\n",
    "Also, notice that the parameters are returned in a dictionary. This will help us in implementing the feedforward through the layer and the backprop throught the layer at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(dimensions):\n",
    "\n",
    "    # dimensions is a list containing the number of neuron in each layer in the network\n",
    "    # It returns parameters which is a python dictionary containing the parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "\n",
    "    np.random.seed(2)\n",
    "    parameters = {}\n",
    "    L = len(dimensions)            # number of layers in the network + 1\n",
    "\n",
    "    for l in range(1, L): \n",
    "        parameters['W' + str(l)] = np.random.randn(dimensions[l], dimensions[l-1]) * 0.1\n",
    "        parameters['b' + str(l)] = np.zeros((dimensions[l], 1)) \n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (dimensions[l], dimensions[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (dimensions[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.04167578 -0.00562668 -0.21361961 ... -0.06168445  0.03213358\n",
      "  -0.09464469]\n",
      " [-0.05301394 -0.1259207   0.16775441 ... -0.03284246 -0.05623108\n",
      "   0.01179136]\n",
      " [ 0.07386378 -0.15872956  0.01532001 ... -0.08428557  0.10040469\n",
      "   0.00545832]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[ 0.06650944 -0.19626047  0.2112715 ]\n",
      " [-0.28074571 -0.13967752  0.02641189]\n",
      " [ 0.10925169  0.06646016  0.08565535]\n",
      " [-0.11058228  0.03715795  0.13440124]\n",
      " [-0.16421272 -0.1153127   0.02013163]\n",
      " [ 0.13985659  0.07228733 -0.10717236]\n",
      " [-0.05673344 -0.03663499 -0.15460347]]\n",
      "b2 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W3 = [[ 0.20406947 -0.04960206 -0.06131668 -0.17449682  0.01840741 -0.00795452\n",
      "   0.12406296]\n",
      " [ 0.08625738 -0.01239074  0.05854764  0.19336815 -0.07322525 -0.039205\n",
      "   0.07512152]\n",
      " [-0.05947453  0.04753173 -0.1083593   0.08228398  0.07047718 -0.05854343\n",
      "  -0.12699409]\n",
      " [ 0.03255273  0.00457369 -0.13662463  0.10202692 -0.07310626  0.1496712\n",
      "   0.13433165]\n",
      " [ 0.02566371  0.0734615  -0.14332651  0.00178312  0.05686418 -0.1263975\n",
      "  -0.14590294]\n",
      " [ 0.15906599  0.04026281  0.14249133  0.10019812 -0.28192685 -0.11228612\n",
      "  -0.01523209]\n",
      " [ 0.00556535  0.01378749 -0.0675063  -0.00885622 -0.10151087  0.12861383\n",
      "  -0.09708002]\n",
      " [-0.0577768   0.08917285 -0.05625892  0.01765442 -0.09055266 -0.00368937\n",
      "   0.04094553]\n",
      " [-0.15298018 -0.16785625 -0.116733    0.08260156  0.05470732  0.08330186\n",
      "   0.14913897]\n",
      " [-0.04016882 -0.07274709 -0.01175106  0.0241847   0.10988869  0.01330499\n",
      "   0.05696497]]\n",
      "b3 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "dimensions  = [784, 3,7,10]\n",
    "parameters = initialize_parameters(dimensions)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "print(\"b3 = \" + str(parameters[\"b3\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer_forward\n",
    "\n",
    "The function **`layer_forward`** implements the forward propagation for a certain layer 'l'. It calculates the cumulative input into the layer **Z** and uses it to calculate the output of the layer **H**. It takes **H_prev, W, b and the activation function** as inputs and stores the **linear_memory, activation_memory** in the variable **memory** which will be used later in backpropagation. \n",
    "\n",
    "<br> We first calculate the **Z**(using the forward propagation equation), **linear_memory**(H_prev, W, b) and then calculate **H, activation_memory**(Z) by applying activation functions - **`sigmoid`**, **`relu`** and **`softmax`** on **Z**.\n",
    "\n",
    "<br> Note that $H^{L-1}$ is referred here as H_prev. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_forward(H_prev, W, b, activation = 'relu'):\n",
    "\n",
    "    # H_prev is of shape (size of previous layer, number of examples)\n",
    "    # W is weights matrix of shape (size of current layer, size of previous layer)\n",
    "    # b is bias vector of shape (size of the current layer, 1)\n",
    "    # activation is the activation to be used for forward propagation : \"softmax\", \"relu\", \"sigmoid\"\n",
    "\n",
    "    # H is the output of the activation function \n",
    "    # memory is a python dictionary containing \"linear_memory\" and \"activation_memory\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z = np.dot(W,H_prev)+b\n",
    "        linear_memory = (H_prev, W, b)\n",
    "        H, activation_memory = sigmoid(Z)\n",
    " \n",
    "    elif activation == \"softmax\":\n",
    "        Z = np.dot(W,H_prev)+b\n",
    "        linear_memory = (H_prev, W, b)\n",
    "        H, activation_memory = softmax(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z = np.dot(W,H_prev)+b\n",
    "        linear_memory = (H_prev, W, b)\n",
    "        H, activation_memory = relu(Z)\n",
    "        \n",
    "    assert (H.shape == (W.shape[0], H_prev.shape[1]))\n",
    "    memory = (linear_memory, activation_memory)\n",
    "\n",
    "    return H, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "       [0.99908895, 0.99330715, 0.99999969, 1.        , 0.99987661],\n",
       "       [0.73105858, 0.5       , 0.99330715, 0.9999546 , 0.88079708]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify\n",
    "# l-1 has two neurons, l has three, m = 5\n",
    "# H_prev is (l-1, m)\n",
    "# W is (l, l-1)\n",
    "# b is (l, 1)\n",
    "# H should be (l, m)\n",
    "H_prev = np.array([[1,0, 5, 10, 2], [2, 5, 3, 10, 2]])\n",
    "W_sample = np.array([[10, 5], [2, 0], [1, 0]])\n",
    "b_sample = np.array([10, 5, 0]).reshape((3, 1))\n",
    "\n",
    "H = layer_forward(H_prev, W_sample, b_sample, activation=\"sigmoid\")[0]\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L_layer_forward\n",
    "**`L_layer_forward`** performs one forward pass through the whole network for all the training samples (note that we are feeding all training examples in one single batch). We will use the **`layer_forward`** we created above here to perform the feedforward for layers 1 to 'L-1' in the for loop with the activation **`relu`**. The last layer having a different activation **`softmax`** is calculated outside the loop. Notice that the **memory** is appended to **memories** for all the layers. These will be used in the backward order during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_forward(X, parameters):\n",
    "\n",
    "    # X is input data of shape (input size, number of examples)\n",
    "    # parameters is output of initialize_parameters()\n",
    "    \n",
    "    # HL is the last layer's post-activation value\n",
    "    # memories is the list of memory containing (for a relu activation, for example):\n",
    "    # - every memory of relu forward (there are L-1 of them, indexed from 1 to L-1), \n",
    "    # - the memory of softmax forward (there is one, indexed L) \n",
    "\n",
    "    memories = []\n",
    "    H = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement relu layer (L-1) times as the Lth layer is the softmax layer\n",
    "    for l in range(1, L):\n",
    "        H_prev = H\n",
    "        \n",
    "        H, memory = layer_forward(H_prev,parameters[ \"W\" + str(l) ],parameters[ \"b\" + str(l) ],\"relu\")\n",
    "        \n",
    "        memories.append(memory)\n",
    "    \n",
    "    # Implement the final softmax layer\n",
    "    # HL here is the final prediction P as specified in the lectures\n",
    "    HL, memory = layer_forward(H,parameters[ \"W\" + str(L) ],parameters[ \"b\" + str(L) ],\"softmax\")\n",
    "    \n",
    "    memories.append(memory)\n",
    "\n",
    "    assert(HL.shape == (10, X.shape[1]))\n",
    "            \n",
    "    return HL, memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n",
      "[[0.10106734 0.10045152 0.09927757 0.10216656 0.1       ]\n",
      " [0.10567625 0.10230873 0.10170271 0.11250099 0.1       ]\n",
      " [0.09824287 0.0992886  0.09967128 0.09609693 0.1       ]\n",
      " [0.10028288 0.10013048 0.09998149 0.10046076 0.1       ]\n",
      " [0.09883601 0.09953443 0.09931419 0.097355   0.1       ]\n",
      " [0.10668575 0.10270912 0.10180736 0.11483609 0.1       ]\n",
      " [0.09832513 0.09932275 0.09954792 0.09627089 0.1       ]\n",
      " [0.09747092 0.09896735 0.0995387  0.09447277 0.1       ]\n",
      " [0.09489069 0.09788255 0.09929998 0.08915178 0.1       ]\n",
      " [0.09852217 0.09940447 0.09985881 0.09668824 0.1       ]]\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "# X is (784, 10)\n",
    "# parameters is a dict\n",
    "# HL should be (10, 10)\n",
    "x_sample = train_set_x[:, 10:20]\n",
    "print(x_sample.shape)\n",
    "HL,memories = L_layer_forward(x_sample, parameters=parameters)\n",
    "print(HL[:,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "\n",
    "### compute_loss\n",
    "The next step is to compute the loss function after every forward pass to keep checking whether it is decreasing with training.<br> **`compute_loss`** here calculates the cross-entropy loss. Do not forget that it is the average loss across all the data points in the batch. It takes the output of the last layer **HL** and the ground truth label **Y** as input and returns the **loss**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(HL, Y):\n",
    "\n",
    "    # HL is probability matrix of shape (10, number of examples)\n",
    "    # Y is true \"label\" vector shape (10, number of examples)\n",
    "\n",
    "    # loss is the cross-entropy loss\n",
    "\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    loss = -np.sum( np.multiply ( Y,np.log(HL) ) ,axis=0) \n",
    "    \n",
    "    average_loss = np.sum(loss) * (1./m)\n",
    "    \n",
    "    average_loss = np.squeeze(average_loss)      # To make sure that the loss's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(average_loss.shape == ())\n",
    "    \n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4359949  0.02592623 0.54966248 0.43532239 0.4203678 ]\n",
      " [0.33033482 0.20464863 0.61927097 0.29965467 0.26682728]\n",
      " [0.62113383 0.52914209 0.13457995 0.51357812 0.18443987]\n",
      " [0.78533515 0.85397529 0.49423684 0.84656149 0.07964548]\n",
      " [0.50524609 0.0652865  0.42812233 0.09653092 0.12715997]\n",
      " [0.59674531 0.226012   0.10694568 0.22030621 0.34982629]\n",
      " [0.46778748 0.20174323 0.64040673 0.48306984 0.50523672]\n",
      " [0.38689265 0.79363745 0.58000418 0.1622986  0.70075235]\n",
      " [0.96455108 0.50000836 0.88952006 0.34161365 0.56714413]\n",
      " [0.42754596 0.43674726 0.77655918 0.53560417 0.95374223]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "0.8964600261334035\n"
     ]
    }
   ],
   "source": [
    "# sample\n",
    "# HL is (10, 5), Y is (10, 5)\n",
    "np.random.seed(2)\n",
    "HL_sample = np.random.rand(10,5)\n",
    "Y_sample = train_set_y[:, 10:15]\n",
    "print(HL_sample)\n",
    "print(Y_sample)\n",
    "\n",
    "print(compute_loss(HL_sample, Y_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "Let's now get to the next step - backpropagation. Let's start with sigmoid_backward.\n",
    "\n",
    "### sigmoid-backward\n",
    "You might remember that we had created **`sigmoid`** function that calculated the activation for forward propagation. Now, we need the activation backward, which helps in calculating **dZ** from **dH**. Notice that it takes input **dH** and **sigmoid_memory** as input. **sigmoid_memory** is the **Z** which we had calculated during forward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dH, sigmoid_memory):\n",
    "    \n",
    "    # Implement the backpropagation of a sigmoid function\n",
    "    # dH is gradient of the sigmoid activated activation of shape same as H or Z in the same layer    \n",
    "    # sigmoid_memory is the memory stored in the sigmoid(Z) calculation\n",
    "    \n",
    "    Z = sigmoid_memory\n",
    "    \n",
    "    H = 1/(1+np.exp(-Z))\n",
    "    dZ = dH * H * (1-H) # because H*(1-H) is what we get after differentiating the sigmoid function\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relu-backward\n",
    "You might remember that we had created **`relu`** function that calculated the activation for forward propagation. Now, we need the activation backward, which helps in calculating **dZ** from **dH**. Notice that it takes input **dH** and **relu_memory** as input. **relu_memory** is the **Z** which we calculated uring forward propagation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dH, relu_memory):\n",
    "    \n",
    "    # Implement the backpropagation of a relu function\n",
    "    # dH is gradient of the relu activated activation of shape same as H or Z in the same layer    \n",
    "    # relu_memory is the memory stored in the sigmoid(Z) calculation\n",
    "    \n",
    "    Z = relu_memory\n",
    "    dZ = np.array(dH, copy=True) # dZ = dH * (differentiation of the activation function, which for relu is 1)\n",
    "    \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer_backward\n",
    "\n",
    "**`layer_backward`** is a complimentary function of **`layer_forward`**. Like **`layer_forward`** calculates **H** using **W**, **H_prev** and **b**, **`layer_backward`** uses **dH** to calculate **dW**, **dH_prev** and **db**. To calculate **dZ**, use the **`sigmoid_backward`** and **`relu_backward`** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_backward(dH, memory, activation = 'relu'):\n",
    "    \n",
    "    # takes dH and the memory calculated in layer_forward and activation as input to calculate the dH_prev, dW, db\n",
    "    # performs the backprop depending upon the activation function\n",
    "    \n",
    "\n",
    "    linear_memory, activation_memory = memory\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dH, activation_memory)\n",
    "        H_prev, W, b = linear_memory\n",
    "        m = H_prev.shape[1]\n",
    "        dW = np.dot(dZ,H_prev.T)*(1./m) # refer to the formulae shared at the start of this notebook\n",
    "        db = np.sum(dZ,axis=1,keepdims=True)*(1./m) # refer to the formulae shared at the start of this notebook\n",
    "        dH_prev = np.dot(W.T,dZ) # refer to the formulae shared at the start of this notebook\n",
    "        \n",
    "        # we have divided the matrice dW and db so that we can get the average value across the 50000 datapoints.\n",
    "        # we wanted to have the same shape of dW as W in order to update the new weights. \n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dH, activation_memory) #write your code here\n",
    "        H_prev, W, b = linear_memory\n",
    "        m = H_prev.shape[1]\n",
    "        dW = np.dot(dZ,H_prev.T)*(1./m)\n",
    "        db = np.sum(dZ,axis=1,keepdims=True)*(1./m) \n",
    "        dH_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dH_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dH_prev is \n",
      " [[5.6417525  0.66855959 6.86974666 5.46611139 4.92177244]\n",
      " [2.17997451 0.12963116 2.74831239 2.17661196 2.10183901]]\n",
      "dW is \n",
      " [[1.67565336 1.56891359]\n",
      " [1.39137819 1.4143854 ]\n",
      " [1.3597389  1.43013369]]\n",
      "db is \n",
      " [[0.37345476]\n",
      " [0.34414727]\n",
      " [0.29074635]]\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "# l-1 has two neurons, l has three, m = 5\n",
    "# H_prev is (l-1, m)\n",
    "# W is (l, l-1)\n",
    "# b is (l, 1)\n",
    "# H should be (l, m)\n",
    "H_prev = np.array([[1,0, 5, 10, 2], [2, 5, 3, 10, 2]])\n",
    "W_sample = np.array([[10, 5], [2, 0], [1, 0]])\n",
    "b_sample = np.array([10, 5, 0]).reshape((3, 1))\n",
    "\n",
    "H, memory = layer_forward(H_prev, W_sample, b_sample, activation=\"relu\")\n",
    "np.random.seed(2)\n",
    "dH = np.random.rand(3,5)\n",
    "dH_prev, dW, db = layer_backward(dH, memory, activation = 'relu')\n",
    "print('dH_prev is \\n' , dH_prev)\n",
    "print('dW is \\n' ,dW)\n",
    "print('db is \\n', db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L_layer_backward\n",
    "\n",
    "**`L_layer_backward`** performs backpropagation for the whole network. Recall that the backpropagation for the last layer, i.e. the softmax layer, is different from the rest, hence it is outside the reversed `for` loop. You need to use the function **`layer_backward`** here in the loop with the activation function as **`relu`**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_backward(HL, Y, memories):\n",
    "    \n",
    "    # Takes the predicted value HL and the true target value Y and the \n",
    "    # memories calculated by L_layer_forward as input\n",
    "    \n",
    "    # returns the gradients calulated for all the layers as a dict\n",
    "\n",
    "    gradients = {}\n",
    "    L = len(memories) # the number of layers\n",
    "    m = HL.shape[1]\n",
    "    Y = Y.reshape(HL.shape) # after this line, Y is the same shape as HL\n",
    "    \n",
    "    # Perform the backprop for the last layer that is the softmax layer\n",
    "    current_memory = memories[-1]\n",
    "    linear_memory, activation_memory = current_memory\n",
    "    dZ = HL - Y\n",
    "    H_prev, W, b = linear_memory\n",
    "    # Use the expressions we have used in 'layer_backward'\n",
    "    gradients[\"dH\" + str(L-1)] = np.dot(W.T,dZ) \n",
    "    gradients[\"dW\" + str(L)] = np.dot(dZ,H_prev.T)*(1./m) \n",
    "    gradients[\"db\" + str(L)] = np.sum(dZ,axis=1,keepdims=True)*(1./m) \n",
    "    \n",
    "    # Perform the backpropagation l-1 times\n",
    "    for l in reversed(range(L-1)):\n",
    "        # Lth layer gradients: \"gradients[\"dH\" + str(l + 1)] \", gradients[\"dW\" + str(l + 2)] , gradients[\"db\" + str(l + 2)]\n",
    "        current_memory = memories[l]\n",
    "        \n",
    "        gradients[\"dH\" + str(l)] =  layer_backward(gradients[\"dH\"+str(l+1)],current_memory, activation = 'relu')[0] #write your code here\n",
    "        gradients[\"dW\" + str(l + 1)] = layer_backward(gradients[\"dH\"+str(l+1)], current_memory, activation = 'relu')[1]#write your code here\n",
    "        gradients[\"db\" + str(l + 1)] = layer_backward(gradients[\"dH\"+str(l+1)], current_memory, activation = 'relu')[2]#write your code here\n",
    "\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW3 is \n",
      " [[ 0.02003701  0.0019043   0.01011729  0.0145757   0.00146444  0.00059863\n",
      "   0.        ]\n",
      " [ 0.02154547  0.00203519  0.01085648  0.01567075  0.00156469  0.00060533\n",
      "   0.        ]\n",
      " [-0.01718407 -0.00273711 -0.00499101 -0.00912135 -0.00207365  0.00059996\n",
      "   0.        ]\n",
      " [-0.01141498 -0.00158622 -0.00607049 -0.00924709 -0.00119619  0.00060381\n",
      "   0.        ]\n",
      " [ 0.01943173  0.0018421   0.00984543  0.01416368  0.00141676  0.00059682\n",
      "   0.        ]\n",
      " [ 0.01045447  0.00063974  0.00637621  0.00863306  0.00050118  0.00060441\n",
      "   0.        ]\n",
      " [-0.06338911 -0.00747251 -0.0242169  -0.03835708 -0.00581131  0.0006034\n",
      "   0.        ]\n",
      " [ 0.01911373  0.001805    0.00703101  0.0120636   0.00138836 -0.00140535\n",
      "   0.        ]\n",
      " [-0.01801603  0.0017357  -0.01489228 -0.02026076  0.00133528  0.00060264\n",
      "   0.        ]\n",
      " [ 0.0194218   0.00183381  0.00594427  0.01187949  0.00141043 -0.00340965\n",
      "   0.        ]]\n",
      "db3 is \n",
      " [[ 0.10031756]\n",
      " [ 0.00460183]\n",
      " [-0.00142942]\n",
      " [-0.0997827 ]\n",
      " [ 0.09872663]\n",
      " [ 0.00536378]\n",
      " [-0.10124784]\n",
      " [-0.00191121]\n",
      " [-0.00359044]\n",
      " [-0.00104818]]\n",
      "dW2 is \n",
      " [[ 4.94428956e-05  1.13215514e-02  5.44180380e-02]\n",
      " [-4.81267081e-05 -2.96999448e-05 -1.81899582e-02]\n",
      " [ 5.63424333e-05  4.77190073e-03  4.04810232e-02]\n",
      " [ 1.49767478e-04 -1.89780927e-03 -7.91231369e-03]\n",
      " [ 1.97866094e-04  1.22107085e-04  2.64140566e-02]\n",
      " [ 0.00000000e+00 -3.75805770e-04  1.63906102e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "db2 is \n",
      " [[ 0.013979  ]\n",
      " [-0.01329383]\n",
      " [ 0.01275707]\n",
      " [-0.01052957]\n",
      " [ 0.03179224]\n",
      " [-0.00039877]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "# X is (784, 10)\n",
    "# parameters is a dict\n",
    "# HL should be (10, 10)\n",
    "x_sample = train_set_x[:, 10:20]\n",
    "y_sample = train_set_y[:, 10:20]\n",
    "\n",
    "HL, memories = L_layer_forward(x_sample, parameters=parameters)\n",
    "gradients  = L_layer_backward(HL, y_sample, memories)\n",
    "print('dW3 is \\n', gradients['dW3'])\n",
    "print('db3 is \\n', gradients['db3'])\n",
    "print('dW2 is \\n', gradients['dW2'])\n",
    "print('db2 is \\n', gradients['db2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Updates\n",
    "\n",
    "Now that we have calculated the gradients. let's do the last step which is updating the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, gradients, learning_rate):\n",
    "\n",
    "    # parameters is the python dictionary containing the parameters W and b for all the layers\n",
    "    # gradients is the python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    # returns updated weights after applying the gradient descent update\n",
    "\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - (learning_rate * gradients[\"dW\" + str(l + 1)])#write your code here\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate * gradients[\"db\" + str(l + 1)])#write your code here\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the bits and pieces of the feedforward and the backpropagation, let's now combine all that to form a model. The list `dimensions` has the number of neurons in each layer specified in it. For a neural network with 1 hidden layer with 45 neurons, one would specify the dimensions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [784, 45, 10] #  three-layer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### L_layer_model\n",
    "\n",
    "This is a composite function which takes the training data as input **X**, ground truth label **Y**, the **dimensions** as stated above, **learning_rate**, the number of iterations **num_iterations** and if we want to print the loss, **print_loss**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, dimensions, learning_rate = 0.0075, num_iterations = 3000, print_loss=False):\n",
    "    \n",
    "    # X and Y are the input training datasets\n",
    "    # learning_rate, num_iterations are gradient descent optimization parameters\n",
    "    # returns updated parameters\n",
    "\n",
    "    np.random.seed(2)\n",
    "    losses = []                         # keep track of loss\n",
    "    \n",
    "    # Parameters initialization\n",
    "    parameters = initialize_parameters(dimensions)\n",
    " \n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation\n",
    "        HL, memories = L_layer_forward(X,parameters=parameters)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = compute_loss(HL, Y)\n",
    "    \n",
    "        # Backward propagation\n",
    "        gradients = L_layer_backward(HL, Y, memories)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, gradients, learning_rate) \n",
    "                \n",
    "        # Printing the loss every 100 training example\n",
    "        if print_loss and i % 100 == 0:\n",
    "            print (\"Loss after iteration %i: %f\" %(i, loss))\n",
    "            losses.append(loss)\n",
    "            \n",
    "    # plotting the loss\n",
    "    plt.plot(np.squeeze(losses))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, it'll take a lot of time to train the model on 50,000 data points, we take a subset of 5,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 5000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_x_new = train_set_x[:,0:5000]\n",
    "train_set_y_new = train_set_y[:,0:5000]\n",
    "train_set_x_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call the function L_layer_model on the dataset we have created.This will take 10-20 mins to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 2.422624\n",
      "Loss after iteration 100: 2.129232\n",
      "Loss after iteration 200: 1.876095\n",
      "Loss after iteration 300: 1.604213\n",
      "Loss after iteration 400: 1.350205\n",
      "Loss after iteration 500: 1.144823\n",
      "Loss after iteration 600: 0.990554\n",
      "Loss after iteration 700: 0.876603\n",
      "Loss after iteration 800: 0.791154\n",
      "Loss after iteration 900: 0.725441\n",
      "Loss after iteration 1000: 0.673485\n",
      "Loss after iteration 1100: 0.631386\n",
      "Loss after iteration 1200: 0.596598\n",
      "Loss after iteration 1300: 0.567342\n",
      "Loss after iteration 1400: 0.542346\n",
      "Loss after iteration 1500: 0.520746\n",
      "Loss after iteration 1600: 0.501865\n",
      "Loss after iteration 1700: 0.485205\n",
      "Loss after iteration 1800: 0.470368\n",
      "Loss after iteration 1900: 0.457054\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(train_set_x_new, train_set_y_new, dimensions, num_iterations = 2000, print_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \n",
    "    # Performs forward propogation using the trained parameters and calculates the accuracy\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_layer_forward(X, parameters)\n",
    "    \n",
    "    p = np.argmax(probas, axis = 0)\n",
    "    act = np.argmax(y, axis = 0)\n",
    "\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == act)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the accuray we get on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8774000000000002\n"
     ]
    }
   ],
   "source": [
    "pred_train = predict(train_set_x_new, train_set_y_new, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get ~ 88% accuracy on the training data. Let's see the accuray on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8674000000000002\n"
     ]
    }
   ],
   "source": [
    "pred_test = predict(test_set_x, test_set_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is ~87%. You can train the model even longer and get better result. You can also try to change the network structure. \n",
    "<br>Below, you can see which all numbers are incorrectly identified by the neural network by changing the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f8b0f0eac0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index  = 3443\n",
    "k = test_set_x[:,index]\n",
    "k = k.reshape((28, 28))\n",
    "plt.title('Label is {label}'.format(label=(pred_test[index], np.argmax(test_set_y, axis = 0)[index])))\n",
    "plt.imshow(k, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
