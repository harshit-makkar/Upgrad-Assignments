{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import os\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "# This was not used. We used rewards per episode to track the convergence\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        # action size/space is 21 ( includes (0,0) )\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        #hyper parameters for the DQN\n",
    "        self.discount_factor = 0.75\n",
    "        self.learning_rate = 0.01      \n",
    "        self.epsilon = 1\n",
    "        self.epsilon_decay = 0.99 \n",
    "        self.epsilon_min = 0.01\n",
    "        self.batch_size = 100        \n",
    "        # replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # main model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "\n",
    "    # building the model\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # input share is 36 as the state is encoded with the size 5(locations)+24(time hours)+7(week days)       \n",
    "        input_shape = 36\n",
    "        model.add(Dense(32, input_dim=input_shape, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        # the output layer: output is of size num_actions which is 21\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "\n",
    "        model.summary\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state):\n",
    "        \n",
    "        # returns the possible requests given the current state\n",
    "        # Each location has a different propensity to generate requests for rides\n",
    "        possible_actions_idx,actions = env.requests(state)\n",
    "        \n",
    "        # Exploration\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            \n",
    "            return random.sample(actions,1)[0]\n",
    "\n",
    "        # Exploitation - Greedy Approach    \n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state_encod = env.state_encod_arch2(state)\n",
    "            state_encod = state_encod.reshape(1, self.state_size)\n",
    "            \n",
    "            q_value = self.model.predict(state_encod)\n",
    "            \n",
    "            # at each location, not all actions are available\n",
    "            # we need to select the best action from the possible set of actions/requests\n",
    "            q_value_values = q_value[0]\n",
    "            \n",
    "            listt_q_values = []\n",
    "            \n",
    "            q_value_v2 = []\n",
    "            \n",
    "            # selecting q values of the actions which were there in possible_actions_idx\n",
    "            listt_q_values = [value for idx,value in enumerate(q_value_values) if idx in possible_actions_idx]\n",
    "                        \n",
    "            q_value_v2.append(listt_q_values)\n",
    "            \n",
    "            return actions[np.argmax(q_value_v2[0])]\n",
    "    \n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state):\n",
    "        \n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "    \n",
    "\n",
    "    # picking samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))\n",
    "            actions, rewards = [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state = mini_batch[i]\n",
    "                state_encod = env.state_encod_arch2(state)\n",
    "                next_state_encod = env.state_encod_arch2(next_state)           \n",
    "                \n",
    "                \n",
    "                # Updating the 'update_output' and 'update_input' batch and storing actions and rewards\n",
    "                update_input[i] = state_encod\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = next_state_encod\n",
    "\n",
    "            \n",
    "            # predicting the target q-values from states s\n",
    "            target = self.model.predict(update_input)\n",
    "\n",
    "            # target for q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "                                    \n",
    "            # update the target values\n",
    "            for i in range(self.batch_size):\n",
    "                \n",
    "                target[i][env.action_space.index(actions[i])] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "                                \n",
    "            # model fit\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "\n",
    "    # saving model weights\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "        \n",
    "    # saving model architecture    \n",
    "    def save_model_arch(self):\n",
    "        model_json = self.model.to_json()\n",
    "        with open(\"model.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 7000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, reward 65.0, memory_length 160, epsilon 1.0\n",
      "travel time- 723.0\n",
      "--- 19.67903995513916 seconds ---\n",
      "episode 1, reward -358.0, memory_length 332, epsilon 0.9995001249791693\n",
      "travel time- 724.0\n",
      "--- 2.3255536556243896 seconds ---\n",
      "episode 2, reward -23.0, memory_length 499, epsilon 0.999000499833375\n",
      "travel time- 721.0\n",
      "--- 2.2163305282592773 seconds ---\n",
      "episode 3, reward -79.0, memory_length 660, epsilon 0.9985011244377109\n",
      "travel time- 720.0\n",
      "--- 2.136045217514038 seconds ---\n",
      "episode 4, reward -10.0, memory_length 819, epsilon 0.9980019986673331\n",
      "travel time- 730.0\n",
      "--- 2.159180164337158 seconds ---\n",
      "episode 5, reward -81.0, memory_length 989, epsilon 0.9975031223974601\n",
      "travel time- 720.0\n",
      "--- 2.1930692195892334 seconds ---\n",
      "episode 6, reward 184.0, memory_length 1126, epsilon 0.997004495503373\n",
      "travel time- 723.0\n",
      "--- 1.7810935974121094 seconds ---\n",
      "episode 7, reward -216.0, memory_length 1268, epsilon 0.9965061178604149\n",
      "travel time- 721.0\n",
      "--- 1.8709735870361328 seconds ---\n",
      "episode 8, reward -257.0, memory_length 1423, epsilon 0.9960079893439915\n",
      "travel time- 727.0\n",
      "--- 2.0344650745391846 seconds ---\n",
      "episode 9, reward -404.0, memory_length 1583, epsilon 0.9955101098295706\n",
      "travel time- 725.0\n",
      "--- 2.0857584476470947 seconds ---\n",
      "episode 10, reward -308.0, memory_length 1735, epsilon 0.9950124791926823\n",
      "travel time- 723.0\n",
      "--- 2.098342180252075 seconds ---\n",
      "episode 11, reward 179.0, memory_length 1881, epsilon 0.9945150973089191\n",
      "travel time- 722.0\n",
      "--- 1.998300313949585 seconds ---\n",
      "episode 12, reward -379.0, memory_length 2000, epsilon 0.9940179640539353\n",
      "travel time- 725.0\n",
      "--- 2.1989328861236572 seconds ---\n",
      "episode 13, reward -15.0, memory_length 2000, epsilon 0.9935210793034477\n",
      "travel time- 729.0\n",
      "--- 1.790959358215332 seconds ---\n",
      "episode 14, reward -467.0, memory_length 2000, epsilon 0.9930244429332351\n",
      "travel time- 725.0\n",
      "--- 2.313218832015991 seconds ---\n",
      "episode 15, reward -30.0, memory_length 2000, epsilon 0.9925280548191384\n",
      "travel time- 720.0\n",
      "--- 1.774498701095581 seconds ---\n",
      "episode 16, reward -69.0, memory_length 2000, epsilon 0.9920319148370607\n",
      "travel time- 726.0\n",
      "--- 1.9588379859924316 seconds ---\n",
      "episode 17, reward -125.0, memory_length 2000, epsilon 0.9915360228629667\n",
      "travel time- 720.0\n",
      "--- 1.897918462753296 seconds ---\n",
      "episode 18, reward -8.0, memory_length 2000, epsilon 0.9910403787728836\n",
      "travel time- 722.0\n",
      "--- 1.9590659141540527 seconds ---\n",
      "episode 19, reward 42.0, memory_length 2000, epsilon 0.9905449824429005\n",
      "travel time- 723.0\n",
      "--- 2.231192111968994 seconds ---\n",
      "episode 20, reward 80.0, memory_length 2000, epsilon 0.9900498337491681\n",
      "travel time- 720.0\n",
      "--- 1.727957010269165 seconds ---\n",
      "episode 21, reward -14.0, memory_length 2000, epsilon 0.9895549325678993\n",
      "travel time- 726.0\n",
      "--- 1.7425107955932617 seconds ---\n",
      "episode 22, reward -343.0, memory_length 2000, epsilon 0.9890602787753687\n",
      "travel time- 725.0\n",
      "--- 2.1018900871276855 seconds ---\n",
      "episode 23, reward 179.0, memory_length 2000, epsilon 0.988565872247913\n",
      "travel time- 722.0\n",
      "--- 1.8639411926269531 seconds ---\n",
      "episode 24, reward -263.0, memory_length 2000, epsilon 0.9880717128619305\n",
      "travel time- 723.0\n",
      "--- 1.9021525382995605 seconds ---\n",
      "episode 25, reward -83.0, memory_length 2000, epsilon 0.9875778004938814\n",
      "travel time- 728.0\n",
      "--- 2.0496609210968018 seconds ---\n",
      "episode 26, reward -61.0, memory_length 2000, epsilon 0.9870841350202876\n",
      "travel time- 724.0\n",
      "--- 1.925713300704956 seconds ---\n",
      "episode 27, reward -96.0, memory_length 2000, epsilon 0.9865907163177327\n",
      "travel time- 726.0\n",
      "--- 1.6879456043243408 seconds ---\n",
      "episode 28, reward -399.0, memory_length 2000, epsilon 0.9860975442628619\n",
      "travel time- 723.0\n",
      "--- 1.952528715133667 seconds ---\n",
      "episode 29, reward 163.0, memory_length 2000, epsilon 0.9856046187323824\n",
      "travel time- 724.0\n",
      "--- 2.1854472160339355 seconds ---\n",
      "episode 30, reward -184.0, memory_length 2000, epsilon 0.9851119396030626\n",
      "travel time- 720.0\n",
      "--- 1.9429638385772705 seconds ---\n",
      "episode 31, reward -76.0, memory_length 2000, epsilon 0.9846195067517329\n",
      "travel time- 722.0\n",
      "--- 2.293032169342041 seconds ---\n",
      "episode 32, reward -325.0, memory_length 2000, epsilon 0.9841273200552851\n",
      "travel time- 722.0\n",
      "--- 2.353917360305786 seconds ---\n",
      "episode 33, reward 204.0, memory_length 2000, epsilon 0.9836353793906724\n",
      "travel time- 722.0\n",
      "--- 2.117828130722046 seconds ---\n",
      "episode 34, reward -20.0, memory_length 2000, epsilon 0.9831436846349096\n",
      "travel time- 724.0\n",
      "--- 1.997023105621338 seconds ---\n",
      "episode 35, reward -480.0, memory_length 2000, epsilon 0.9826522356650732\n",
      "travel time- 722.0\n",
      "--- 2.435467481613159 seconds ---\n",
      "episode 36, reward -169.0, memory_length 2000, epsilon 0.9821610323583008\n",
      "travel time- 725.0\n",
      "--- 2.0982611179351807 seconds ---\n",
      "episode 37, reward -384.0, memory_length 2000, epsilon 0.9816700745917915\n",
      "travel time- 720.0\n",
      "--- 2.2622203826904297 seconds ---\n",
      "episode 38, reward -223.0, memory_length 2000, epsilon 0.981179362242806\n",
      "travel time- 727.0\n",
      "--- 1.9009184837341309 seconds ---\n",
      "episode 39, reward -58.0, memory_length 2000, epsilon 0.9806888951886662\n",
      "travel time- 728.0\n",
      "--- 2.5124895572662354 seconds ---\n",
      "episode 40, reward -444.0, memory_length 2000, epsilon 0.9801986733067553\n",
      "travel time- 721.0\n",
      "--- 1.9706978797912598 seconds ---\n",
      "episode 41, reward -91.0, memory_length 2000, epsilon 0.9797086964745179\n",
      "travel time- 720.0\n",
      "--- 1.9580180644989014 seconds ---\n",
      "episode 42, reward -221.0, memory_length 2000, epsilon 0.9792189645694596\n",
      "travel time- 720.0\n",
      "--- 2.2950093746185303 seconds ---\n",
      "episode 43, reward -226.0, memory_length 2000, epsilon 0.9787294774691476\n",
      "travel time- 721.0\n",
      "--- 1.9006378650665283 seconds ---\n",
      "episode 44, reward -392.0, memory_length 2000, epsilon 0.97824023505121\n",
      "travel time- 729.0\n",
      "--- 1.8953826427459717 seconds ---\n",
      "episode 45, reward -463.0, memory_length 2000, epsilon 0.9777512371933363\n",
      "travel time- 722.0\n",
      "--- 2.320728063583374 seconds ---\n",
      "episode 46, reward -424.0, memory_length 2000, epsilon 0.9772624837732771\n",
      "travel time- 723.0\n",
      "--- 2.0696637630462646 seconds ---\n",
      "episode 47, reward 83.0, memory_length 2000, epsilon 0.9767739746688439\n",
      "travel time- 732.0\n",
      "--- 2.0344347953796387 seconds ---\n",
      "episode 48, reward -396.0, memory_length 2000, epsilon 0.9762857097579093\n",
      "travel time- 728.0\n",
      "--- 2.195582866668701 seconds ---\n",
      "episode 49, reward -142.0, memory_length 2000, epsilon 0.9757976889184073\n",
      "travel time- 734.0\n",
      "--- 2.353055238723755 seconds ---\n",
      "episode 50, reward -299.0, memory_length 2000, epsilon 0.9753099120283326\n",
      "travel time- 723.0\n",
      "--- 1.8617024421691895 seconds ---\n",
      "episode 51, reward -21.0, memory_length 2000, epsilon 0.9748223789657411\n",
      "travel time- 726.0\n",
      "--- 2.00329327583313 seconds ---\n",
      "episode 52, reward 12.0, memory_length 2000, epsilon 0.9743350896087494\n",
      "travel time- 722.0\n",
      "--- 1.9588708877563477 seconds ---\n",
      "episode 53, reward -70.0, memory_length 2000, epsilon 0.973848043835535\n",
      "travel time- 720.0\n",
      "--- 2.108769178390503 seconds ---\n",
      "episode 54, reward -78.0, memory_length 2000, epsilon 0.9733612415243368\n",
      "travel time- 720.0\n",
      "--- 2.1650450229644775 seconds ---\n",
      "episode 55, reward 54.0, memory_length 2000, epsilon 0.972874682553454\n",
      "travel time- 727.0\n",
      "--- 1.9908826351165771 seconds ---\n",
      "episode 56, reward -83.0, memory_length 2000, epsilon 0.9723883668012469\n",
      "travel time- 724.0\n",
      "--- 2.0137078762054443 seconds ---\n",
      "episode 57, reward -119.0, memory_length 2000, epsilon 0.9719022941461366\n",
      "travel time- 733.0\n",
      "--- 2.032949686050415 seconds ---\n",
      "episode 58, reward 26.0, memory_length 2000, epsilon 0.9714164644666048\n",
      "travel time- 723.0\n",
      "--- 2.1842494010925293 seconds ---\n",
      "episode 59, reward 80.0, memory_length 2000, epsilon 0.9709308776411942\n",
      "travel time- 722.0\n",
      "--- 2.1610164642333984 seconds ---\n",
      "episode 60, reward 63.0, memory_length 2000, epsilon 0.9704455335485082\n",
      "travel time- 722.0\n",
      "--- 1.814279556274414 seconds ---\n",
      "episode 61, reward -80.0, memory_length 2000, epsilon 0.9699604320672105\n",
      "travel time- 720.0\n",
      "--- 1.8637537956237793 seconds ---\n",
      "episode 62, reward -213.0, memory_length 2000, epsilon 0.9694755730760259\n",
      "travel time- 723.0\n",
      "--- 2.0030226707458496 seconds ---\n",
      "episode 63, reward 136.0, memory_length 2000, epsilon 0.9689909564537397\n",
      "travel time- 724.0\n",
      "--- 1.7720952033996582 seconds ---\n",
      "episode 64, reward -89.0, memory_length 2000, epsilon 0.9685065820791976\n",
      "travel time- 721.0\n",
      "--- 2.242018461227417 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 65, reward -248.0, memory_length 2000, epsilon 0.968022449831306\n",
      "travel time- 730.0\n",
      "--- 1.9400184154510498 seconds ---\n",
      "episode 66, reward -251.0, memory_length 2000, epsilon 0.967538559589032\n",
      "travel time- 729.0\n",
      "--- 2.0181217193603516 seconds ---\n",
      "episode 67, reward -162.0, memory_length 2000, epsilon 0.9670549112314029\n",
      "travel time- 720.0\n",
      "--- 2.0555944442749023 seconds ---\n",
      "episode 68, reward -383.0, memory_length 2000, epsilon 0.9665715046375066\n",
      "travel time- 726.0\n",
      "--- 1.9575493335723877 seconds ---\n",
      "episode 69, reward -332.0, memory_length 2000, epsilon 0.9660883396864915\n",
      "travel time- 734.0\n",
      "--- 1.7753186225891113 seconds ---\n",
      "episode 70, reward -299.0, memory_length 2000, epsilon 0.9656054162575665\n",
      "travel time- 725.0\n",
      "--- 2.29790997505188 seconds ---\n",
      "episode 71, reward -672.0, memory_length 2000, epsilon 0.9651227342300005\n",
      "travel time- 723.0\n",
      "--- 2.1055657863616943 seconds ---\n",
      "episode 72, reward -119.0, memory_length 2000, epsilon 0.9646402934831231\n",
      "travel time- 720.0\n",
      "--- 2.0926620960235596 seconds ---\n",
      "episode 73, reward -209.0, memory_length 2000, epsilon 0.964158093896324\n",
      "travel time- 724.0\n",
      "--- 1.8359882831573486 seconds ---\n",
      "episode 74, reward -199.0, memory_length 2000, epsilon 0.9636761353490535\n",
      "travel time- 726.0\n",
      "--- 2.2599399089813232 seconds ---\n",
      "episode 75, reward -195.0, memory_length 2000, epsilon 0.9631944177208218\n",
      "travel time- 720.0\n",
      "--- 2.1427407264709473 seconds ---\n",
      "episode 76, reward -342.0, memory_length 2000, epsilon 0.9627129408911995\n",
      "travel time- 720.0\n",
      "--- 2.094033718109131 seconds ---\n",
      "episode 77, reward 212.0, memory_length 2000, epsilon 0.9622317047398176\n",
      "travel time- 723.0\n",
      "--- 1.8762030601501465 seconds ---\n",
      "episode 78, reward -314.0, memory_length 2000, epsilon 0.9617507091463667\n",
      "travel time- 725.0\n",
      "--- 2.227992534637451 seconds ---\n",
      "episode 79, reward -394.0, memory_length 2000, epsilon 0.9612699539905982\n",
      "travel time- 725.0\n",
      "--- 2.0967705249786377 seconds ---\n",
      "episode 80, reward -336.0, memory_length 2000, epsilon 0.9607894391523232\n",
      "travel time- 724.0\n",
      "--- 2.123816728591919 seconds ---\n",
      "episode 81, reward -476.0, memory_length 2000, epsilon 0.960309164511413\n",
      "travel time- 727.0\n",
      "--- 1.9655590057373047 seconds ---\n",
      "episode 82, reward -56.0, memory_length 2000, epsilon 0.9598291299477989\n",
      "travel time- 722.0\n",
      "--- 2.1144416332244873 seconds ---\n",
      "episode 83, reward -40.0, memory_length 2000, epsilon 0.9593493353414723\n",
      "travel time- 722.0\n",
      "--- 2.1602602005004883 seconds ---\n",
      "episode 84, reward -255.0, memory_length 2000, epsilon 0.9588697805724845\n",
      "travel time- 722.0\n",
      "--- 1.8654329776763916 seconds ---\n",
      "episode 85, reward -52.0, memory_length 2000, epsilon 0.958390465520947\n",
      "travel time- 723.0\n",
      "--- 2.1444125175476074 seconds ---\n",
      "episode 86, reward -134.0, memory_length 2000, epsilon 0.9579113900670306\n",
      "travel time- 734.0\n",
      "--- 2.0970025062561035 seconds ---\n",
      "episode 87, reward -72.0, memory_length 2000, epsilon 0.957432554090967\n",
      "travel time- 722.0\n",
      "--- 2.1110455989837646 seconds ---\n",
      "episode 88, reward -289.0, memory_length 2000, epsilon 0.9569539574730467\n",
      "travel time- 737.0\n",
      "--- 2.0353293418884277 seconds ---\n",
      "episode 89, reward 63.0, memory_length 2000, epsilon 0.9564756000936208\n",
      "travel time- 730.0\n",
      "--- 2.2488715648651123 seconds ---\n",
      "episode 90, reward -332.0, memory_length 2000, epsilon 0.9559974818331\n",
      "travel time- 726.0\n",
      "--- 2.0364339351654053 seconds ---\n",
      "episode 91, reward -261.0, memory_length 2000, epsilon 0.9555196025719545\n",
      "travel time- 725.0\n",
      "--- 2.081632614135742 seconds ---\n",
      "episode 92, reward 29.0, memory_length 2000, epsilon 0.9550419621907147\n",
      "travel time- 725.0\n",
      "--- 2.112431049346924 seconds ---\n",
      "episode 93, reward -161.0, memory_length 2000, epsilon 0.9545645605699703\n",
      "travel time- 734.0\n",
      "--- 2.079651355743408 seconds ---\n",
      "episode 94, reward 67.0, memory_length 2000, epsilon 0.9540873975903711\n",
      "travel time- 721.0\n",
      "--- 2.0600500106811523 seconds ---\n",
      "episode 95, reward -247.0, memory_length 2000, epsilon 0.9536104731326264\n",
      "travel time- 727.0\n",
      "--- 1.9084563255310059 seconds ---\n",
      "episode 96, reward 203.0, memory_length 2000, epsilon 0.9531337870775047\n",
      "travel time- 722.0\n",
      "--- 1.8980185985565186 seconds ---\n",
      "episode 97, reward -246.0, memory_length 2000, epsilon 0.9526573393058348\n",
      "travel time- 731.0\n",
      "--- 2.0380849838256836 seconds ---\n",
      "episode 98, reward -224.0, memory_length 2000, epsilon 0.9521811296985049\n",
      "travel time- 724.0\n",
      "--- 2.3812942504882812 seconds ---\n",
      "episode 99, reward -234.0, memory_length 2000, epsilon 0.9517051581364622\n",
      "travel time- 722.0\n",
      "--- 2.0722382068634033 seconds ---\n",
      "episode 100, reward 81.0, memory_length 2000, epsilon 0.951229424500714\n",
      "travel time- 720.0\n",
      "--- 1.9911937713623047 seconds ---\n",
      "episode 101, reward 87.0, memory_length 2000, epsilon 0.9507539286723269\n",
      "travel time- 725.0\n",
      "--- 2.026874542236328 seconds ---\n",
      "episode 102, reward 42.0, memory_length 2000, epsilon 0.950278670532427\n",
      "travel time- 722.0\n",
      "--- 1.8585846424102783 seconds ---\n",
      "episode 103, reward -109.0, memory_length 2000, epsilon 0.9498036499621996\n",
      "travel time- 723.0\n",
      "--- 2.162963390350342 seconds ---\n",
      "episode 104, reward 47.0, memory_length 2000, epsilon 0.9493288668428895\n",
      "travel time- 724.0\n",
      "--- 2.0155112743377686 seconds ---\n",
      "episode 105, reward 136.0, memory_length 2000, epsilon 0.9488543210558013\n",
      "travel time- 723.0\n",
      "--- 1.7909259796142578 seconds ---\n",
      "episode 106, reward 45.0, memory_length 2000, epsilon 0.9483800124822982\n",
      "travel time- 729.0\n",
      "--- 1.8781213760375977 seconds ---\n",
      "episode 107, reward -164.0, memory_length 2000, epsilon 0.9479059410038031\n",
      "travel time- 725.0\n",
      "--- 1.8829567432403564 seconds ---\n",
      "episode 108, reward -94.0, memory_length 2000, epsilon 0.9474321065017983\n",
      "travel time- 725.0\n",
      "--- 2.087432384490967 seconds ---\n",
      "episode 109, reward -340.0, memory_length 2000, epsilon 0.9469585088578251\n",
      "travel time- 722.0\n",
      "--- 2.1477293968200684 seconds ---\n",
      "episode 110, reward 18.0, memory_length 2000, epsilon 0.9464851479534838\n",
      "travel time- 729.0\n",
      "--- 1.9716508388519287 seconds ---\n",
      "episode 111, reward -79.0, memory_length 2000, epsilon 0.9460120236704347\n",
      "travel time- 725.0\n",
      "--- 1.8314871788024902 seconds ---\n",
      "episode 112, reward -89.0, memory_length 2000, epsilon 0.9455391358903963\n",
      "travel time- 724.0\n",
      "--- 1.9394330978393555 seconds ---\n",
      "episode 113, reward -322.0, memory_length 2000, epsilon 0.9450664844951467\n",
      "travel time- 725.0\n",
      "--- 2.0965046882629395 seconds ---\n",
      "episode 114, reward -167.0, memory_length 2000, epsilon 0.9445940693665233\n",
      "travel time- 725.0\n",
      "--- 1.9174342155456543 seconds ---\n",
      "episode 115, reward -301.0, memory_length 2000, epsilon 0.9441218903864221\n",
      "travel time- 721.0\n",
      "--- 2.1287238597869873 seconds ---\n",
      "episode 116, reward -133.0, memory_length 2000, epsilon 0.9436499474367985\n",
      "travel time- 722.0\n",
      "--- 1.730393409729004 seconds ---\n",
      "episode 117, reward -320.0, memory_length 2000, epsilon 0.9431782403996666\n",
      "travel time- 720.0\n",
      "--- 2.0517220497131348 seconds ---\n",
      "episode 118, reward -54.0, memory_length 2000, epsilon 0.9427067691570997\n",
      "travel time- 723.0\n",
      "--- 1.9434013366699219 seconds ---\n",
      "episode 119, reward -289.0, memory_length 2000, epsilon 0.94223553359123\n",
      "travel time- 720.0\n",
      "--- 1.9986960887908936 seconds ---\n",
      "episode 120, reward 92.0, memory_length 2000, epsilon 0.9417645335842487\n",
      "travel time- 723.0\n",
      "--- 2.043783187866211 seconds ---\n",
      "episode 121, reward -197.0, memory_length 2000, epsilon 0.9412937690184057\n",
      "travel time- 721.0\n",
      "--- 2.4857375621795654 seconds ---\n",
      "episode 122, reward -116.0, memory_length 2000, epsilon 0.9408232397760097\n",
      "travel time- 721.0\n",
      "--- 1.9843974113464355 seconds ---\n",
      "episode 123, reward -195.0, memory_length 2000, epsilon 0.9403529457394286\n",
      "travel time- 725.0\n",
      "--- 2.1279592514038086 seconds ---\n",
      "episode 124, reward -245.0, memory_length 2000, epsilon 0.9398828867910889\n",
      "travel time- 721.0\n",
      "--- 1.7705986499786377 seconds ---\n",
      "episode 125, reward -268.0, memory_length 2000, epsilon 0.9394130628134758\n",
      "travel time- 726.0\n",
      "--- 2.08453631401062 seconds ---\n",
      "episode 126, reward -160.0, memory_length 2000, epsilon 0.9389434736891332\n",
      "travel time- 721.0\n",
      "--- 2.1129631996154785 seconds ---\n",
      "episode 127, reward -106.0, memory_length 2000, epsilon 0.938474119300664\n",
      "travel time- 721.0\n",
      "--- 1.9421544075012207 seconds ---\n",
      "episode 128, reward 225.0, memory_length 2000, epsilon 0.9380049995307295\n",
      "travel time- 720.0\n",
      "--- 2.2260489463806152 seconds ---\n",
      "episode 129, reward -62.0, memory_length 2000, epsilon 0.9375361142620497\n",
      "travel time- 728.0\n",
      "--- 1.8592369556427002 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 130, reward -338.0, memory_length 2000, epsilon 0.9370674633774034\n",
      "travel time- 728.0\n",
      "--- 1.9576265811920166 seconds ---\n",
      "episode 131, reward 110.0, memory_length 2000, epsilon 0.9365990467596279\n",
      "travel time- 722.0\n",
      "--- 1.7379388809204102 seconds ---\n",
      "episode 132, reward -180.0, memory_length 2000, epsilon 0.9361308642916188\n",
      "travel time- 729.0\n",
      "--- 1.7344415187835693 seconds ---\n",
      "episode 133, reward -233.0, memory_length 2000, epsilon 0.9356629158563308\n",
      "travel time- 720.0\n",
      "--- 2.045578718185425 seconds ---\n",
      "episode 134, reward -148.0, memory_length 2000, epsilon 0.9351952013367766\n",
      "travel time- 724.0\n",
      "--- 2.048966407775879 seconds ---\n",
      "episode 135, reward -153.0, memory_length 2000, epsilon 0.9347277206160275\n",
      "travel time- 728.0\n",
      "--- 2.1784989833831787 seconds ---\n",
      "episode 136, reward -521.0, memory_length 2000, epsilon 0.9342604735772135\n",
      "travel time- 721.0\n",
      "--- 2.1467254161834717 seconds ---\n",
      "episode 137, reward -114.0, memory_length 2000, epsilon 0.9337934601035228\n",
      "travel time- 723.0\n",
      "--- 2.0990676879882812 seconds ---\n",
      "episode 138, reward -240.0, memory_length 2000, epsilon 0.933326680078202\n",
      "travel time- 723.0\n",
      "--- 2.314915895462036 seconds ---\n",
      "episode 139, reward 8.0, memory_length 2000, epsilon 0.932860133384556\n",
      "travel time- 725.0\n",
      "--- 2.215811252593994 seconds ---\n",
      "episode 140, reward -131.0, memory_length 2000, epsilon 0.9323938199059483\n",
      "travel time- 725.0\n",
      "--- 2.2269718647003174 seconds ---\n",
      "episode 141, reward -108.0, memory_length 2000, epsilon 0.9319277395258003\n",
      "travel time- 722.0\n",
      "--- 2.1864430904388428 seconds ---\n",
      "episode 142, reward -380.0, memory_length 2000, epsilon 0.9314618921275921\n",
      "travel time- 721.0\n",
      "--- 2.3841819763183594 seconds ---\n",
      "episode 143, reward -372.0, memory_length 2000, epsilon 0.9309962775948618\n",
      "travel time- 723.0\n",
      "--- 1.8033874034881592 seconds ---\n",
      "episode 144, reward -554.0, memory_length 2000, epsilon 0.9305308958112057\n",
      "travel time- 721.0\n",
      "--- 2.362781286239624 seconds ---\n",
      "episode 145, reward -105.0, memory_length 2000, epsilon 0.9300657466602785\n",
      "travel time- 728.0\n",
      "--- 2.1725995540618896 seconds ---\n",
      "episode 146, reward -420.0, memory_length 2000, epsilon 0.9296008300257927\n",
      "travel time- 721.0\n",
      "--- 2.0865252017974854 seconds ---\n",
      "episode 147, reward -73.0, memory_length 2000, epsilon 0.9291361457915193\n",
      "travel time- 728.0\n",
      "--- 1.6476304531097412 seconds ---\n",
      "episode 148, reward -93.0, memory_length 2000, epsilon 0.9286716938412872\n",
      "travel time- 723.0\n",
      "--- 2.2045881748199463 seconds ---\n",
      "episode 149, reward -211.0, memory_length 2000, epsilon 0.9282074740589834\n",
      "travel time- 724.0\n",
      "--- 1.9576025009155273 seconds ---\n",
      "episode 150, reward -515.0, memory_length 2000, epsilon 0.9277434863285529\n",
      "travel time- 725.0\n",
      "--- 2.0080366134643555 seconds ---\n",
      "episode 151, reward -218.0, memory_length 2000, epsilon 0.9272797305339988\n",
      "travel time- 726.0\n",
      "--- 2.10331392288208 seconds ---\n",
      "episode 152, reward -208.0, memory_length 2000, epsilon 0.9268162065593822\n",
      "travel time- 720.0\n",
      "--- 2.4148147106170654 seconds ---\n",
      "episode 153, reward -142.0, memory_length 2000, epsilon 0.9263529142888222\n",
      "travel time- 727.0\n",
      "--- 2.2182576656341553 seconds ---\n",
      "episode 154, reward 101.0, memory_length 2000, epsilon 0.9258898536064953\n",
      "travel time- 725.0\n",
      "--- 2.009098768234253 seconds ---\n",
      "episode 155, reward -521.0, memory_length 2000, epsilon 0.9254270243966368\n",
      "travel time- 720.0\n",
      "--- 2.3240959644317627 seconds ---\n",
      "episode 156, reward -74.0, memory_length 2000, epsilon 0.9249644265435393\n",
      "travel time- 724.0\n",
      "--- 2.0113046169281006 seconds ---\n",
      "episode 157, reward -56.0, memory_length 2000, epsilon 0.9245020599315531\n",
      "travel time- 728.0\n",
      "--- 2.42399525642395 seconds ---\n",
      "episode 158, reward 178.0, memory_length 2000, epsilon 0.9240399244450868\n",
      "travel time- 723.0\n",
      "--- 1.8622491359710693 seconds ---\n",
      "episode 159, reward 33.0, memory_length 2000, epsilon 0.9235780199686064\n",
      "travel time- 732.0\n",
      "--- 1.7597122192382812 seconds ---\n",
      "episode 160, reward -92.0, memory_length 2000, epsilon 0.9231163463866358\n",
      "travel time- 720.0\n",
      "--- 2.032367467880249 seconds ---\n",
      "episode 161, reward -2.0, memory_length 2000, epsilon 0.9226549035837566\n",
      "travel time- 722.0\n",
      "--- 1.9127235412597656 seconds ---\n",
      "episode 162, reward -225.0, memory_length 2000, epsilon 0.922193691444608\n",
      "travel time- 723.0\n",
      "--- 1.7746901512145996 seconds ---\n",
      "episode 163, reward -195.0, memory_length 2000, epsilon 0.9217327098538872\n",
      "travel time- 726.0\n",
      "--- 1.808577299118042 seconds ---\n",
      "episode 164, reward -309.0, memory_length 2000, epsilon 0.9212719586963487\n",
      "travel time- 722.0\n",
      "--- 1.668449878692627 seconds ---\n",
      "episode 165, reward -153.0, memory_length 2000, epsilon 0.9208114378568045\n",
      "travel time- 720.0\n",
      "--- 1.7141554355621338 seconds ---\n",
      "episode 166, reward 131.0, memory_length 2000, epsilon 0.9203511472201247\n",
      "travel time- 723.0\n",
      "--- 2.003873109817505 seconds ---\n",
      "episode 167, reward -107.0, memory_length 2000, epsilon 0.9198910866712364\n",
      "travel time- 727.0\n",
      "--- 2.095625162124634 seconds ---\n",
      "episode 168, reward 25.0, memory_length 2000, epsilon 0.9194312560951247\n",
      "travel time- 723.0\n",
      "--- 1.7847802639007568 seconds ---\n",
      "episode 169, reward -117.0, memory_length 2000, epsilon 0.9189716553768317\n",
      "travel time- 722.0\n",
      "--- 2.1305360794067383 seconds ---\n",
      "episode 170, reward 13.0, memory_length 2000, epsilon 0.9185122844014574\n",
      "travel time- 723.0\n",
      "--- 2.1426031589508057 seconds ---\n",
      "episode 171, reward -366.0, memory_length 2000, epsilon 0.9180531430541589\n",
      "travel time- 731.0\n",
      "--- 2.1446805000305176 seconds ---\n",
      "episode 172, reward 33.0, memory_length 2000, epsilon 0.9175942312201509\n",
      "travel time- 728.0\n",
      "--- 2.178009271621704 seconds ---\n",
      "episode 173, reward -240.0, memory_length 2000, epsilon 0.9171355487847056\n",
      "travel time- 732.0\n",
      "--- 2.163682699203491 seconds ---\n",
      "episode 174, reward 93.0, memory_length 2000, epsilon 0.9166770956331523\n",
      "travel time- 725.0\n",
      "--- 1.8519384860992432 seconds ---\n",
      "episode 175, reward 1.0, memory_length 2000, epsilon 0.9162188716508776\n",
      "travel time- 720.0\n",
      "--- 2.278968095779419 seconds ---\n",
      "episode 176, reward -162.0, memory_length 2000, epsilon 0.9157608767233256\n",
      "travel time- 721.0\n",
      "--- 2.0959713459014893 seconds ---\n",
      "episode 177, reward 93.0, memory_length 2000, epsilon 0.9153031107359976\n",
      "travel time- 720.0\n",
      "--- 1.8255951404571533 seconds ---\n",
      "episode 178, reward 218.0, memory_length 2000, epsilon 0.914845573574452\n",
      "travel time- 723.0\n",
      "--- 1.7507514953613281 seconds ---\n",
      "episode 179, reward -253.0, memory_length 2000, epsilon 0.9143882651243046\n",
      "travel time- 720.0\n",
      "--- 2.093304395675659 seconds ---\n",
      "episode 180, reward -108.0, memory_length 2000, epsilon 0.9139311852712282\n",
      "travel time- 720.0\n",
      "--- 1.8731424808502197 seconds ---\n",
      "episode 181, reward -440.0, memory_length 2000, epsilon 0.9134743339009529\n",
      "travel time- 723.0\n",
      "--- 2.121596336364746 seconds ---\n",
      "episode 182, reward -646.0, memory_length 2000, epsilon 0.9130177108992658\n",
      "travel time- 721.0\n",
      "--- 1.8146650791168213 seconds ---\n",
      "episode 183, reward -175.0, memory_length 2000, epsilon 0.9125613161520112\n",
      "travel time- 723.0\n",
      "--- 2.1891610622406006 seconds ---\n",
      "episode 184, reward 111.0, memory_length 2000, epsilon 0.9121051495450904\n",
      "travel time- 733.0\n",
      "--- 2.137531280517578 seconds ---\n",
      "episode 185, reward -127.0, memory_length 2000, epsilon 0.9116492109644617\n",
      "travel time- 722.0\n",
      "--- 2.1880760192871094 seconds ---\n",
      "episode 186, reward -154.0, memory_length 2000, epsilon 0.9111935002961405\n",
      "travel time- 723.0\n",
      "--- 2.5535311698913574 seconds ---\n",
      "episode 187, reward -171.0, memory_length 2000, epsilon 0.9107380174261992\n",
      "travel time- 725.0\n",
      "--- 2.154409646987915 seconds ---\n",
      "episode 188, reward -65.0, memory_length 2000, epsilon 0.910282762240767\n",
      "travel time- 720.0\n",
      "--- 2.3240654468536377 seconds ---\n",
      "episode 189, reward 4.0, memory_length 2000, epsilon 0.90982773462603\n",
      "travel time- 723.0\n",
      "--- 2.398397922515869 seconds ---\n",
      "episode 190, reward -94.0, memory_length 2000, epsilon 0.9093729344682314\n",
      "travel time- 723.0\n",
      "--- 1.8429770469665527 seconds ---\n",
      "episode 191, reward -392.0, memory_length 2000, epsilon 0.9089183616536712\n",
      "travel time- 722.0\n",
      "--- 1.9407837390899658 seconds ---\n",
      "episode 192, reward -278.0, memory_length 2000, epsilon 0.9084640160687062\n",
      "travel time- 727.0\n",
      "--- 2.1495909690856934 seconds ---\n",
      "episode 193, reward -9.0, memory_length 2000, epsilon 0.9080098975997498\n",
      "travel time- 720.0\n",
      "--- 2.072968006134033 seconds ---\n",
      "episode 194, reward -95.0, memory_length 2000, epsilon 0.9075560061332727\n",
      "travel time- 727.0\n",
      "--- 1.9947633743286133 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 195, reward -109.0, memory_length 2000, epsilon 0.9071023415558017\n",
      "travel time- 733.0\n",
      "--- 2.226339340209961 seconds ---\n",
      "episode 196, reward -10.0, memory_length 2000, epsilon 0.9066489037539209\n",
      "travel time- 722.0\n",
      "--- 2.3375792503356934 seconds ---\n",
      "episode 197, reward -43.0, memory_length 2000, epsilon 0.9061956926142708\n",
      "travel time- 720.0\n",
      "--- 2.062601089477539 seconds ---\n",
      "episode 198, reward 24.0, memory_length 2000, epsilon 0.9057427080235485\n",
      "travel time- 729.0\n",
      "--- 2.0547034740448 seconds ---\n",
      "episode 199, reward -209.0, memory_length 2000, epsilon 0.905289949868508\n",
      "travel time- 724.0\n",
      "--- 2.063581943511963 seconds ---\n",
      "episode 200, reward 157.0, memory_length 2000, epsilon 0.9048374180359595\n",
      "travel time- 727.0\n",
      "--- 1.8661773204803467 seconds ---\n",
      "episode 201, reward -319.0, memory_length 2000, epsilon 0.9043851124127704\n",
      "travel time- 729.0\n",
      "--- 2.2815983295440674 seconds ---\n",
      "episode 202, reward -370.0, memory_length 2000, epsilon 0.9039330328858641\n",
      "travel time- 724.0\n",
      "--- 2.19274640083313 seconds ---\n",
      "episode 203, reward -296.0, memory_length 2000, epsilon 0.9034811793422207\n",
      "travel time- 732.0\n",
      "--- 2.022874116897583 seconds ---\n",
      "episode 204, reward -347.0, memory_length 2000, epsilon 0.9030295516688768\n",
      "travel time- 726.0\n",
      "--- 2.1852118968963623 seconds ---\n",
      "episode 205, reward 127.0, memory_length 2000, epsilon 0.9025781497529256\n",
      "travel time- 721.0\n",
      "--- 1.9992897510528564 seconds ---\n",
      "episode 206, reward -182.0, memory_length 2000, epsilon 0.9021269734815165\n",
      "travel time- 722.0\n",
      "--- 1.932297945022583 seconds ---\n",
      "episode 207, reward 78.0, memory_length 2000, epsilon 0.9016760227418554\n",
      "travel time- 720.0\n",
      "--- 2.1430346965789795 seconds ---\n",
      "episode 208, reward -308.0, memory_length 2000, epsilon 0.9012252974212047\n",
      "travel time- 724.0\n",
      "--- 1.9796860218048096 seconds ---\n",
      "episode 209, reward 135.0, memory_length 2000, epsilon 0.9007747974068832\n",
      "travel time- 732.0\n",
      "--- 1.9354560375213623 seconds ---\n",
      "episode 210, reward -193.0, memory_length 2000, epsilon 0.9003245225862656\n",
      "travel time- 727.0\n",
      "--- 1.954573154449463 seconds ---\n",
      "episode 211, reward -96.0, memory_length 2000, epsilon 0.8998744728467833\n",
      "travel time- 732.0\n",
      "--- 1.8503501415252686 seconds ---\n",
      "episode 212, reward -212.0, memory_length 2000, epsilon 0.899424648075924\n",
      "travel time- 727.0\n",
      "--- 2.196359872817993 seconds ---\n",
      "episode 213, reward -364.0, memory_length 2000, epsilon 0.8989750481612314\n",
      "travel time- 726.0\n",
      "--- 2.2540509700775146 seconds ---\n",
      "episode 214, reward -327.0, memory_length 2000, epsilon 0.8985256729903055\n",
      "travel time- 727.0\n",
      "--- 2.1744203567504883 seconds ---\n",
      "episode 215, reward -262.0, memory_length 2000, epsilon 0.8980765224508026\n",
      "travel time- 720.0\n",
      "--- 2.1759657859802246 seconds ---\n",
      "episode 216, reward -311.0, memory_length 2000, epsilon 0.8976275964304349\n",
      "travel time- 724.0\n",
      "--- 2.659359931945801 seconds ---\n",
      "episode 217, reward -267.0, memory_length 2000, epsilon 0.897178894816971\n",
      "travel time- 725.0\n",
      "--- 2.204702615737915 seconds ---\n",
      "episode 218, reward -444.0, memory_length 2000, epsilon 0.8967304174982355\n",
      "travel time- 723.0\n",
      "--- 2.0845766067504883 seconds ---\n",
      "episode 219, reward -215.0, memory_length 2000, epsilon 0.896282164362109\n",
      "travel time- 721.0\n",
      "--- 1.8656642436981201 seconds ---\n",
      "episode 220, reward -173.0, memory_length 2000, epsilon 0.8958341352965282\n",
      "travel time- 727.0\n",
      "--- 1.9686126708984375 seconds ---\n",
      "episode 221, reward -399.0, memory_length 2000, epsilon 0.895386330189486\n",
      "travel time- 722.0\n",
      "--- 2.1057322025299072 seconds ---\n",
      "episode 222, reward -491.0, memory_length 2000, epsilon 0.894938748929031\n",
      "travel time- 720.0\n",
      "--- 2.413677215576172 seconds ---\n",
      "episode 223, reward -191.0, memory_length 2000, epsilon 0.8944913914032678\n",
      "travel time- 720.0\n",
      "--- 2.0293445587158203 seconds ---\n",
      "episode 224, reward -110.0, memory_length 2000, epsilon 0.8940442575003572\n",
      "travel time- 729.0\n",
      "--- 1.823481798171997 seconds ---\n",
      "episode 225, reward 2.0, memory_length 2000, epsilon 0.8935973471085157\n",
      "travel time- 724.0\n",
      "--- 1.8455514907836914 seconds ---\n",
      "episode 226, reward -95.0, memory_length 2000, epsilon 0.8931506601160155\n",
      "travel time- 721.0\n",
      "--- 1.8352580070495605 seconds ---\n",
      "episode 227, reward -260.0, memory_length 2000, epsilon 0.892704196411185\n",
      "travel time- 724.0\n",
      "--- 2.1280531883239746 seconds ---\n",
      "episode 228, reward -139.0, memory_length 2000, epsilon 0.8922579558824083\n",
      "travel time- 720.0\n",
      "--- 2.025670051574707 seconds ---\n",
      "episode 229, reward 15.0, memory_length 2000, epsilon 0.8918119384181252\n",
      "travel time- 723.0\n",
      "--- 1.8315706253051758 seconds ---\n",
      "episode 230, reward -278.0, memory_length 2000, epsilon 0.8913661439068313\n",
      "travel time- 732.0\n",
      "--- 2.094210386276245 seconds ---\n",
      "episode 231, reward -72.0, memory_length 2000, epsilon 0.8909205722370781\n",
      "travel time- 723.0\n",
      "--- 2.1934149265289307 seconds ---\n",
      "episode 232, reward -217.0, memory_length 2000, epsilon 0.8904752232974726\n",
      "travel time- 723.0\n",
      "--- 2.012056350708008 seconds ---\n",
      "episode 233, reward 247.0, memory_length 2000, epsilon 0.8900300969766776\n",
      "travel time- 724.0\n",
      "--- 2.018321990966797 seconds ---\n",
      "episode 234, reward -70.0, memory_length 2000, epsilon 0.8895851931634113\n",
      "travel time- 723.0\n",
      "--- 2.1041512489318848 seconds ---\n",
      "episode 235, reward -189.0, memory_length 2000, epsilon 0.889140511746448\n",
      "travel time- 722.0\n",
      "--- 1.972639799118042 seconds ---\n",
      "episode 236, reward -108.0, memory_length 2000, epsilon 0.8886960526146174\n",
      "travel time- 727.0\n",
      "--- 2.2133917808532715 seconds ---\n",
      "episode 237, reward -202.0, memory_length 2000, epsilon 0.8882518156568044\n",
      "travel time- 722.0\n",
      "--- 1.9578313827514648 seconds ---\n",
      "episode 238, reward -328.0, memory_length 2000, epsilon 0.8878078007619501\n",
      "travel time- 720.0\n",
      "--- 1.9762070178985596 seconds ---\n",
      "episode 239, reward -580.0, memory_length 2000, epsilon 0.8873640078190504\n",
      "travel time- 725.0\n",
      "--- 2.2570340633392334 seconds ---\n",
      "episode 240, reward -624.0, memory_length 2000, epsilon 0.8869204367171575\n",
      "travel time- 724.0\n",
      "--- 2.2655975818634033 seconds ---\n",
      "episode 241, reward -198.0, memory_length 2000, epsilon 0.8864770873453783\n",
      "travel time- 735.0\n",
      "--- 2.125614643096924 seconds ---\n",
      "episode 242, reward -56.0, memory_length 2000, epsilon 0.8860339595928756\n",
      "travel time- 729.0\n",
      "--- 2.0947091579437256 seconds ---\n",
      "episode 243, reward -216.0, memory_length 2000, epsilon 0.8855910533488673\n",
      "travel time- 730.0\n",
      "--- 2.033520221710205 seconds ---\n",
      "episode 244, reward -329.0, memory_length 2000, epsilon 0.8851483685026271\n",
      "travel time- 720.0\n",
      "--- 2.263568162918091 seconds ---\n",
      "episode 245, reward -113.0, memory_length 2000, epsilon 0.8847059049434836\n",
      "travel time- 721.0\n",
      "--- 2.132009983062744 seconds ---\n",
      "episode 246, reward 35.0, memory_length 2000, epsilon 0.8842636625608209\n",
      "travel time- 723.0\n",
      "--- 1.8603990077972412 seconds ---\n",
      "episode 247, reward -198.0, memory_length 2000, epsilon 0.8838216412440785\n",
      "travel time- 720.0\n",
      "--- 2.1024727821350098 seconds ---\n",
      "episode 248, reward 40.0, memory_length 2000, epsilon 0.8833798408827509\n",
      "travel time- 723.0\n",
      "--- 2.3810102939605713 seconds ---\n",
      "episode 249, reward 83.0, memory_length 2000, epsilon 0.8829382613663882\n",
      "travel time- 721.0\n",
      "--- 3.8207144737243652 seconds ---\n",
      "episode 250, reward -16.0, memory_length 2000, epsilon 0.8824969025845955\n",
      "travel time- 725.0\n",
      "--- 3.0430569648742676 seconds ---\n",
      "episode 251, reward -188.0, memory_length 2000, epsilon 0.8820557644270329\n",
      "travel time- 727.0\n",
      "--- 3.3965091705322266 seconds ---\n",
      "episode 252, reward -311.0, memory_length 2000, epsilon 0.8816148467834161\n",
      "travel time- 721.0\n",
      "--- 3.8006420135498047 seconds ---\n",
      "episode 253, reward 136.0, memory_length 2000, epsilon 0.8811741495435155\n",
      "travel time- 726.0\n",
      "--- 2.542531967163086 seconds ---\n",
      "episode 254, reward -213.0, memory_length 2000, epsilon 0.880733672597157\n",
      "travel time- 723.0\n",
      "--- 1.9926488399505615 seconds ---\n",
      "episode 255, reward 22.0, memory_length 2000, epsilon 0.8802934158342212\n",
      "travel time- 723.0\n",
      "--- 1.9898278713226318 seconds ---\n",
      "episode 256, reward -385.0, memory_length 2000, epsilon 0.8798533791446438\n",
      "travel time- 720.0\n",
      "--- 2.4104771614074707 seconds ---\n",
      "episode 257, reward -149.0, memory_length 2000, epsilon 0.879413562418416\n",
      "travel time- 724.0\n",
      "--- 3.475905418395996 seconds ---\n",
      "episode 258, reward -182.0, memory_length 2000, epsilon 0.8789739655455832\n",
      "travel time- 724.0\n",
      "--- 3.5606746673583984 seconds ---\n",
      "episode 259, reward -216.0, memory_length 2000, epsilon 0.8785345884162464\n",
      "travel time- 722.0\n",
      "--- 3.0361950397491455 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 260, reward -387.0, memory_length 2000, epsilon 0.8780954309205613\n",
      "travel time- 723.0\n",
      "--- 3.412121534347534 seconds ---\n",
      "episode 261, reward -272.0, memory_length 2000, epsilon 0.8776564929487385\n",
      "travel time- 726.0\n",
      "--- 2.808091163635254 seconds ---\n",
      "episode 262, reward -291.0, memory_length 2000, epsilon 0.8772177743910435\n",
      "travel time- 723.0\n",
      "--- 2.123446226119995 seconds ---\n",
      "episode 263, reward 67.0, memory_length 2000, epsilon 0.8767792751377967\n",
      "travel time- 722.0\n",
      "--- 2.2159030437469482 seconds ---\n",
      "episode 264, reward -276.0, memory_length 2000, epsilon 0.8763409950793732\n",
      "travel time- 723.0\n",
      "--- 1.8900442123413086 seconds ---\n",
      "episode 265, reward 15.0, memory_length 2000, epsilon 0.8759029341062031\n",
      "travel time- 728.0\n",
      "--- 2.0287044048309326 seconds ---\n",
      "episode 266, reward -432.0, memory_length 2000, epsilon 0.8754650921087711\n",
      "travel time- 722.0\n",
      "--- 1.9037692546844482 seconds ---\n",
      "episode 267, reward -58.0, memory_length 2000, epsilon 0.8750274689776166\n",
      "travel time- 720.0\n",
      "--- 1.8735928535461426 seconds ---\n",
      "episode 268, reward -83.0, memory_length 2000, epsilon 0.874590064603334\n",
      "travel time- 721.0\n",
      "--- 2.130652904510498 seconds ---\n",
      "episode 269, reward -138.0, memory_length 2000, epsilon 0.8741528788765721\n",
      "travel time- 730.0\n",
      "--- 2.2409868240356445 seconds ---\n",
      "episode 270, reward -302.0, memory_length 2000, epsilon 0.8737159116880344\n",
      "travel time- 727.0\n",
      "--- 2.143749237060547 seconds ---\n",
      "episode 271, reward -529.0, memory_length 2000, epsilon 0.8732791629284792\n",
      "travel time- 723.0\n",
      "--- 1.9148778915405273 seconds ---\n",
      "episode 272, reward -258.0, memory_length 2000, epsilon 0.8728426324887193\n",
      "travel time- 721.0\n",
      "--- 1.8441543579101562 seconds ---\n",
      "episode 273, reward -498.0, memory_length 2000, epsilon 0.8724063202596221\n",
      "travel time- 720.0\n",
      "--- 2.042548179626465 seconds ---\n",
      "episode 274, reward -224.0, memory_length 2000, epsilon 0.8719702261321094\n",
      "travel time- 727.0\n",
      "--- 1.801687479019165 seconds ---\n",
      "episode 275, reward -363.0, memory_length 2000, epsilon 0.8715343499971578\n",
      "travel time- 728.0\n",
      "--- 1.8169891834259033 seconds ---\n",
      "episode 276, reward -159.0, memory_length 2000, epsilon 0.8710986917457983\n",
      "travel time- 723.0\n",
      "--- 1.5244429111480713 seconds ---\n",
      "episode 277, reward -195.0, memory_length 2000, epsilon 0.8706632512691163\n",
      "travel time- 726.0\n",
      "--- 1.9742162227630615 seconds ---\n",
      "episode 278, reward 106.0, memory_length 2000, epsilon 0.8702280284582515\n",
      "travel time- 730.0\n",
      "--- 1.8429975509643555 seconds ---\n",
      "episode 279, reward -319.0, memory_length 2000, epsilon 0.8697930232043986\n",
      "travel time- 723.0\n",
      "--- 1.7363100051879883 seconds ---\n",
      "episode 280, reward 37.0, memory_length 2000, epsilon 0.8693582353988059\n",
      "travel time- 720.0\n",
      "--- 1.921233892440796 seconds ---\n",
      "episode 281, reward -160.0, memory_length 2000, epsilon 0.8689236649327765\n",
      "travel time- 725.0\n",
      "--- 1.6483161449432373 seconds ---\n",
      "episode 282, reward -291.0, memory_length 2000, epsilon 0.8684893116976679\n",
      "travel time- 722.0\n",
      "--- 1.9624838829040527 seconds ---\n",
      "episode 283, reward -404.0, memory_length 2000, epsilon 0.8680551755848918\n",
      "travel time- 724.0\n",
      "--- 1.7563872337341309 seconds ---\n",
      "episode 284, reward -124.0, memory_length 2000, epsilon 0.867621256485914\n",
      "travel time- 722.0\n",
      "--- 1.511251449584961 seconds ---\n",
      "episode 285, reward -37.0, memory_length 2000, epsilon 0.8671875542922549\n",
      "travel time- 720.0\n",
      "--- 1.7859504222869873 seconds ---\n",
      "episode 286, reward -73.0, memory_length 2000, epsilon 0.8667540688954889\n",
      "travel time- 724.0\n",
      "--- 1.7423310279846191 seconds ---\n",
      "episode 287, reward 38.0, memory_length 2000, epsilon 0.8663208001872447\n",
      "travel time- 728.0\n",
      "--- 1.6323442459106445 seconds ---\n",
      "episode 288, reward -295.0, memory_length 2000, epsilon 0.865887748059205\n",
      "travel time- 722.0\n",
      "--- 1.5208275318145752 seconds ---\n",
      "episode 289, reward 19.0, memory_length 2000, epsilon 0.8654549124031069\n",
      "travel time- 725.0\n",
      "--- 1.5242385864257812 seconds ---\n",
      "episode 290, reward -98.0, memory_length 2000, epsilon 0.8650222931107413\n",
      "travel time- 720.0\n",
      "--- 1.7789921760559082 seconds ---\n",
      "episode 291, reward -217.0, memory_length 2000, epsilon 0.8645898900739535\n",
      "travel time- 721.0\n",
      "--- 1.8402304649353027 seconds ---\n",
      "episode 292, reward -154.0, memory_length 2000, epsilon 0.8641577031846428\n",
      "travel time- 725.0\n",
      "--- 1.8066601753234863 seconds ---\n",
      "episode 293, reward -188.0, memory_length 2000, epsilon 0.8637257323347624\n",
      "travel time- 725.0\n",
      "--- 1.8958399295806885 seconds ---\n",
      "episode 294, reward -163.0, memory_length 2000, epsilon 0.8632939774163194\n",
      "travel time- 721.0\n",
      "--- 1.7788290977478027 seconds ---\n",
      "episode 295, reward -187.0, memory_length 2000, epsilon 0.8628624383213754\n",
      "travel time- 733.0\n",
      "--- 1.5901103019714355 seconds ---\n",
      "episode 296, reward 341.0, memory_length 2000, epsilon 0.8624311149420455\n",
      "travel time- 728.0\n",
      "--- 1.5991907119750977 seconds ---\n",
      "episode 297, reward -146.0, memory_length 2000, epsilon 0.8620000071704987\n",
      "travel time- 729.0\n",
      "--- 1.755727767944336 seconds ---\n",
      "episode 298, reward -315.0, memory_length 2000, epsilon 0.8615691148989583\n",
      "travel time- 726.0\n",
      "--- 1.7398536205291748 seconds ---\n",
      "episode 299, reward 36.0, memory_length 2000, epsilon 0.861138438019701\n",
      "travel time- 724.0\n",
      "--- 1.5547831058502197 seconds ---\n",
      "episode 300, reward 146.0, memory_length 2000, epsilon 0.8607079764250578\n",
      "travel time- 721.0\n",
      "--- 1.8326444625854492 seconds ---\n",
      "episode 301, reward -7.0, memory_length 2000, epsilon 0.8602777300074131\n",
      "travel time- 721.0\n",
      "--- 1.691507339477539 seconds ---\n",
      "episode 302, reward 105.0, memory_length 2000, epsilon 0.8598476986592055\n",
      "travel time- 727.0\n",
      "--- 1.4873342514038086 seconds ---\n",
      "episode 303, reward -74.0, memory_length 2000, epsilon 0.8594178822729269\n",
      "travel time- 721.0\n",
      "--- 1.8078334331512451 seconds ---\n",
      "episode 304, reward -80.0, memory_length 2000, epsilon 0.8589882807411234\n",
      "travel time- 723.0\n",
      "--- 1.7287943363189697 seconds ---\n",
      "episode 305, reward -324.0, memory_length 2000, epsilon 0.8585588939563946\n",
      "travel time- 721.0\n",
      "--- 1.7554991245269775 seconds ---\n",
      "episode 306, reward -220.0, memory_length 2000, epsilon 0.8581297218113938\n",
      "travel time- 725.0\n",
      "--- 1.7211768627166748 seconds ---\n",
      "episode 307, reward -339.0, memory_length 2000, epsilon 0.8577007641988279\n",
      "travel time- 720.0\n",
      "--- 1.7150123119354248 seconds ---\n",
      "episode 308, reward -51.0, memory_length 2000, epsilon 0.8572720210114575\n",
      "travel time- 721.0\n",
      "--- 1.7036643028259277 seconds ---\n",
      "episode 309, reward -409.0, memory_length 2000, epsilon 0.8568434921420968\n",
      "travel time- 722.0\n",
      "--- 1.6761417388916016 seconds ---\n",
      "episode 310, reward 16.0, memory_length 2000, epsilon 0.8564151774836135\n",
      "travel time- 723.0\n",
      "--- 1.9894311428070068 seconds ---\n",
      "episode 311, reward -212.0, memory_length 2000, epsilon 0.8559870769289292\n",
      "travel time- 728.0\n",
      "--- 1.7162041664123535 seconds ---\n",
      "episode 312, reward 159.0, memory_length 2000, epsilon 0.8555591903710185\n",
      "travel time- 720.0\n",
      "--- 1.533315896987915 seconds ---\n",
      "episode 313, reward -16.0, memory_length 2000, epsilon 0.8551315177029098\n",
      "travel time- 728.0\n",
      "--- 1.7772293090820312 seconds ---\n",
      "episode 314, reward -590.0, memory_length 2000, epsilon 0.8547040588176851\n",
      "travel time- 726.0\n",
      "--- 1.9228456020355225 seconds ---\n",
      "episode 315, reward -99.0, memory_length 2000, epsilon 0.8542768136084795\n",
      "travel time- 725.0\n",
      "--- 1.6738965511322021 seconds ---\n",
      "episode 316, reward -223.0, memory_length 2000, epsilon 0.8538497819684817\n",
      "travel time- 720.0\n",
      "--- 1.7644445896148682 seconds ---\n",
      "episode 317, reward 78.0, memory_length 2000, epsilon 0.853422963790934\n",
      "travel time- 721.0\n",
      "--- 1.7012383937835693 seconds ---\n",
      "episode 318, reward 217.0, memory_length 2000, epsilon 0.8529963589691315\n",
      "travel time- 723.0\n",
      "--- 1.696070909500122 seconds ---\n",
      "episode 319, reward 55.0, memory_length 2000, epsilon 0.8525699673964233\n",
      "travel time- 722.0\n",
      "--- 1.8427975177764893 seconds ---\n",
      "episode 320, reward -386.0, memory_length 2000, epsilon 0.8521437889662113\n",
      "travel time- 725.0\n",
      "--- 1.6025621891021729 seconds ---\n",
      "episode 321, reward -200.0, memory_length 2000, epsilon 0.851717823571951\n",
      "travel time- 721.0\n",
      "--- 1.9111666679382324 seconds ---\n",
      "episode 322, reward -193.0, memory_length 2000, epsilon 0.8512920711071511\n",
      "travel time- 725.0\n",
      "--- 1.7850313186645508 seconds ---\n",
      "episode 323, reward 28.0, memory_length 2000, epsilon 0.8508665314653734\n",
      "travel time- 724.0\n",
      "--- 1.6291053295135498 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 324, reward -373.0, memory_length 2000, epsilon 0.850441204540233\n",
      "travel time- 720.0\n",
      "--- 1.871164321899414 seconds ---\n",
      "episode 325, reward -110.0, memory_length 2000, epsilon 0.8500160902253981\n",
      "travel time- 725.0\n",
      "--- 1.7193336486816406 seconds ---\n",
      "episode 326, reward -604.0, memory_length 2000, epsilon 0.8495911884145902\n",
      "travel time- 721.0\n",
      "--- 1.961475133895874 seconds ---\n",
      "episode 327, reward -245.0, memory_length 2000, epsilon 0.8491664990015839\n",
      "travel time- 724.0\n",
      "--- 1.7795124053955078 seconds ---\n",
      "episode 328, reward -299.0, memory_length 2000, epsilon 0.8487420218802068\n",
      "travel time- 721.0\n",
      "--- 1.9543447494506836 seconds ---\n",
      "episode 329, reward 124.0, memory_length 2000, epsilon 0.8483177569443394\n",
      "travel time- 724.0\n",
      "--- 1.7125940322875977 seconds ---\n",
      "episode 330, reward -354.0, memory_length 2000, epsilon 0.8478937040879159\n",
      "travel time- 722.0\n",
      "--- 1.7982335090637207 seconds ---\n",
      "episode 331, reward -374.0, memory_length 2000, epsilon 0.8474698632049227\n",
      "travel time- 720.0\n",
      "--- 1.6798193454742432 seconds ---\n",
      "episode 332, reward -67.0, memory_length 2000, epsilon 0.8470462341893996\n",
      "travel time- 720.0\n",
      "--- 1.664017677307129 seconds ---\n",
      "episode 333, reward -98.0, memory_length 2000, epsilon 0.8466228169354396\n",
      "travel time- 720.0\n",
      "--- 1.6875934600830078 seconds ---\n",
      "episode 334, reward -340.0, memory_length 2000, epsilon 0.8461996113371882\n",
      "travel time- 722.0\n",
      "--- 1.8172292709350586 seconds ---\n",
      "episode 335, reward -168.0, memory_length 2000, epsilon 0.8457766172888441\n",
      "travel time- 725.0\n",
      "--- 1.8029522895812988 seconds ---\n",
      "episode 336, reward 72.0, memory_length 2000, epsilon 0.8453538346846587\n",
      "travel time- 722.0\n",
      "--- 1.7156009674072266 seconds ---\n",
      "episode 337, reward -254.0, memory_length 2000, epsilon 0.8449312634189364\n",
      "travel time- 724.0\n",
      "--- 1.753903865814209 seconds ---\n",
      "episode 338, reward 227.0, memory_length 2000, epsilon 0.8445089033860343\n",
      "travel time- 726.0\n",
      "--- 1.5737409591674805 seconds ---\n",
      "episode 339, reward -138.0, memory_length 2000, epsilon 0.8440867544803625\n",
      "travel time- 722.0\n",
      "--- 1.6379573345184326 seconds ---\n",
      "episode 340, reward 219.0, memory_length 2000, epsilon 0.8436648165963837\n",
      "travel time- 720.0\n",
      "--- 1.7018306255340576 seconds ---\n",
      "episode 341, reward -17.0, memory_length 2000, epsilon 0.8432430896286134\n",
      "travel time- 722.0\n",
      "--- 2.134587526321411 seconds ---\n",
      "episode 342, reward 245.0, memory_length 2000, epsilon 0.8428215734716199\n",
      "travel time- 720.0\n",
      "--- 1.848419189453125 seconds ---\n",
      "episode 343, reward -261.0, memory_length 2000, epsilon 0.8424002680200242\n",
      "travel time- 729.0\n",
      "--- 1.7632629871368408 seconds ---\n",
      "episode 344, reward 89.0, memory_length 2000, epsilon 0.8419791731684999\n",
      "travel time- 726.0\n",
      "--- 2.016026496887207 seconds ---\n",
      "episode 345, reward -82.0, memory_length 2000, epsilon 0.8415582888117732\n",
      "travel time- 733.0\n",
      "--- 2.048585891723633 seconds ---\n",
      "episode 346, reward -160.0, memory_length 2000, epsilon 0.8411376148446232\n",
      "travel time- 727.0\n",
      "--- 1.8145654201507568 seconds ---\n",
      "episode 347, reward -103.0, memory_length 2000, epsilon 0.8407171511618812\n",
      "travel time- 723.0\n",
      "--- 1.6858859062194824 seconds ---\n",
      "episode 348, reward -491.0, memory_length 2000, epsilon 0.8402968976584314\n",
      "travel time- 726.0\n",
      "--- 1.6150691509246826 seconds ---\n",
      "episode 349, reward -143.0, memory_length 2000, epsilon 0.8398768542292104\n",
      "travel time- 726.0\n",
      "--- 1.6485965251922607 seconds ---\n",
      "episode 350, reward -36.0, memory_length 2000, epsilon 0.8394570207692074\n",
      "travel time- 721.0\n",
      "--- 1.834416389465332 seconds ---\n",
      "episode 351, reward -389.0, memory_length 2000, epsilon 0.8390373971734638\n",
      "travel time- 720.0\n",
      "--- 1.7568767070770264 seconds ---\n",
      "episode 352, reward -454.0, memory_length 2000, epsilon 0.838617983337074\n",
      "travel time- 730.0\n",
      "--- 1.803542137145996 seconds ---\n",
      "episode 353, reward -64.0, memory_length 2000, epsilon 0.8381987791551844\n",
      "travel time- 723.0\n",
      "--- 1.6738078594207764 seconds ---\n",
      "episode 354, reward 57.0, memory_length 2000, epsilon 0.8377797845229938\n",
      "travel time- 734.0\n",
      "--- 1.401155948638916 seconds ---\n",
      "episode 355, reward -270.0, memory_length 2000, epsilon 0.8373609993357539\n",
      "travel time- 722.0\n",
      "--- 1.8773515224456787 seconds ---\n",
      "episode 356, reward 217.0, memory_length 2000, epsilon 0.8369424234887681\n",
      "travel time- 720.0\n",
      "--- 1.7214927673339844 seconds ---\n",
      "episode 357, reward -115.0, memory_length 2000, epsilon 0.8365240568773925\n",
      "travel time- 728.0\n",
      "--- 1.739457368850708 seconds ---\n",
      "episode 358, reward -214.0, memory_length 2000, epsilon 0.8361058993970355\n",
      "travel time- 723.0\n",
      "--- 1.661238670349121 seconds ---\n",
      "episode 359, reward -212.0, memory_length 2000, epsilon 0.8356879509431577\n",
      "travel time- 731.0\n",
      "--- 1.8552780151367188 seconds ---\n",
      "episode 360, reward -88.0, memory_length 2000, epsilon 0.835270211411272\n",
      "travel time- 731.0\n",
      "--- 1.7136688232421875 seconds ---\n",
      "episode 361, reward -300.0, memory_length 2000, epsilon 0.8348526806969435\n",
      "travel time- 721.0\n",
      "--- 1.7880754470825195 seconds ---\n",
      "episode 362, reward -39.0, memory_length 2000, epsilon 0.8344353586957896\n",
      "travel time- 728.0\n",
      "--- 1.7686183452606201 seconds ---\n",
      "episode 363, reward -214.0, memory_length 2000, epsilon 0.8340182453034796\n",
      "travel time- 725.0\n",
      "--- 1.8665263652801514 seconds ---\n",
      "episode 364, reward -372.0, memory_length 2000, epsilon 0.8336013404157353\n",
      "travel time- 722.0\n",
      "--- 1.804236650466919 seconds ---\n",
      "episode 365, reward -437.0, memory_length 2000, epsilon 0.8331846439283305\n",
      "travel time- 721.0\n",
      "--- 1.6716082096099854 seconds ---\n",
      "episode 366, reward -240.0, memory_length 2000, epsilon 0.832768155737091\n",
      "travel time- 722.0\n",
      "--- 1.7947912216186523 seconds ---\n",
      "episode 367, reward 263.0, memory_length 2000, epsilon 0.8323518757378947\n",
      "travel time- 722.0\n",
      "--- 1.7977030277252197 seconds ---\n",
      "episode 368, reward -280.0, memory_length 2000, epsilon 0.8319358038266718\n",
      "travel time- 720.0\n",
      "--- 1.9703130722045898 seconds ---\n",
      "episode 369, reward -209.0, memory_length 2000, epsilon 0.8315199398994041\n",
      "travel time- 723.0\n",
      "--- 1.7390847206115723 seconds ---\n",
      "episode 370, reward -153.0, memory_length 2000, epsilon 0.8311042838521256\n",
      "travel time- 722.0\n",
      "--- 1.8194897174835205 seconds ---\n",
      "episode 371, reward -72.0, memory_length 2000, epsilon 0.8306888355809225\n",
      "travel time- 722.0\n",
      "--- 1.6462881565093994 seconds ---\n",
      "episode 372, reward -413.0, memory_length 2000, epsilon 0.8302735949819326\n",
      "travel time- 727.0\n",
      "--- 1.934497356414795 seconds ---\n",
      "episode 373, reward 119.0, memory_length 2000, epsilon 0.8298585619513459\n",
      "travel time- 720.0\n",
      "--- 1.4898247718811035 seconds ---\n",
      "episode 374, reward -270.0, memory_length 2000, epsilon 0.8294437363854039\n",
      "travel time- 729.0\n",
      "--- 1.6646695137023926 seconds ---\n",
      "episode 375, reward -161.0, memory_length 2000, epsilon 0.8290291181804004\n",
      "travel time- 723.0\n",
      "--- 1.6814830303192139 seconds ---\n",
      "episode 376, reward -424.0, memory_length 2000, epsilon 0.8286147072326806\n",
      "travel time- 721.0\n",
      "--- 1.7237021923065186 seconds ---\n",
      "episode 377, reward -143.0, memory_length 2000, epsilon 0.828200503438642\n",
      "travel time- 723.0\n",
      "--- 1.5993034839630127 seconds ---\n",
      "episode 378, reward -41.0, memory_length 2000, epsilon 0.8277865066947336\n",
      "travel time- 727.0\n",
      "--- 1.482961654663086 seconds ---\n",
      "episode 379, reward -106.0, memory_length 2000, epsilon 0.8273727168974562\n",
      "travel time- 727.0\n",
      "--- 1.7879300117492676 seconds ---\n",
      "episode 380, reward -197.0, memory_length 2000, epsilon 0.8269591339433623\n",
      "travel time- 724.0\n",
      "--- 1.5115869045257568 seconds ---\n",
      "episode 381, reward -342.0, memory_length 2000, epsilon 0.8265457577290563\n",
      "travel time- 727.0\n",
      "--- 1.672804594039917 seconds ---\n",
      "episode 382, reward -6.0, memory_length 2000, epsilon 0.8261325881511938\n",
      "travel time- 732.0\n",
      "--- 1.5840764045715332 seconds ---\n",
      "episode 383, reward -80.0, memory_length 2000, epsilon 0.8257196251064828\n",
      "travel time- 721.0\n",
      "--- 1.82623291015625 seconds ---\n",
      "episode 384, reward -550.0, memory_length 2000, epsilon 0.8253068684916823\n",
      "travel time- 722.0\n",
      "--- 1.794353723526001 seconds ---\n",
      "episode 385, reward -537.0, memory_length 2000, epsilon 0.8248943182036034\n",
      "travel time- 721.0\n",
      "--- 1.936711311340332 seconds ---\n",
      "episode 386, reward -392.0, memory_length 2000, epsilon 0.8244819741391082\n",
      "travel time- 722.0\n",
      "--- 1.9815406799316406 seconds ---\n",
      "episode 387, reward -62.0, memory_length 2000, epsilon 0.8240698361951109\n",
      "travel time- 720.0\n",
      "--- 1.3839595317840576 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 388, reward -390.0, memory_length 2000, epsilon 0.8236579042685769\n",
      "travel time- 726.0\n",
      "--- 2.074744701385498 seconds ---\n",
      "episode 389, reward 126.0, memory_length 2000, epsilon 0.8232461782565231\n",
      "travel time- 724.0\n",
      "--- 1.6016285419464111 seconds ---\n",
      "episode 390, reward -80.0, memory_length 2000, epsilon 0.8228346580560184\n",
      "travel time- 722.0\n",
      "--- 1.8259944915771484 seconds ---\n",
      "episode 391, reward 91.0, memory_length 2000, epsilon 0.8224233435641823\n",
      "travel time- 723.0\n",
      "--- 1.6348528861999512 seconds ---\n",
      "episode 392, reward -185.0, memory_length 2000, epsilon 0.8220122346781865\n",
      "travel time- 720.0\n",
      "--- 1.8576135635375977 seconds ---\n",
      "episode 393, reward -458.0, memory_length 2000, epsilon 0.8216013312952537\n",
      "travel time- 724.0\n",
      "--- 1.880922555923462 seconds ---\n",
      "episode 394, reward -199.0, memory_length 2000, epsilon 0.821190633312658\n",
      "travel time- 724.0\n",
      "--- 1.6323535442352295 seconds ---\n",
      "episode 395, reward 82.0, memory_length 2000, epsilon 0.8207801406277248\n",
      "travel time- 726.0\n",
      "--- 1.7514097690582275 seconds ---\n",
      "episode 396, reward -29.0, memory_length 2000, epsilon 0.8203698531378311\n",
      "travel time- 724.0\n",
      "--- 1.7788152694702148 seconds ---\n",
      "episode 397, reward -216.0, memory_length 2000, epsilon 0.8199597707404048\n",
      "travel time- 722.0\n",
      "--- 1.7541241645812988 seconds ---\n",
      "episode 398, reward 69.0, memory_length 2000, epsilon 0.8195498933329256\n",
      "travel time- 720.0\n",
      "--- 1.706045389175415 seconds ---\n",
      "episode 399, reward 34.0, memory_length 2000, epsilon 0.819140220812924\n",
      "travel time- 721.0\n",
      "--- 1.6276891231536865 seconds ---\n",
      "episode 400, reward -107.0, memory_length 2000, epsilon 0.8187307530779818\n",
      "travel time- 720.0\n",
      "--- 1.742447853088379 seconds ---\n",
      "episode 401, reward -258.0, memory_length 2000, epsilon 0.8183214900257322\n",
      "travel time- 720.0\n",
      "--- 1.4402689933776855 seconds ---\n",
      "episode 402, reward -56.0, memory_length 2000, epsilon 0.8179124315538594\n",
      "travel time- 722.0\n",
      "--- 1.6176912784576416 seconds ---\n",
      "episode 403, reward -71.0, memory_length 2000, epsilon 0.8175035775600987\n",
      "travel time- 722.0\n",
      "--- 1.5011262893676758 seconds ---\n",
      "episode 404, reward -43.0, memory_length 2000, epsilon 0.8170949279422366\n",
      "travel time- 723.0\n",
      "--- 1.7088444232940674 seconds ---\n",
      "episode 405, reward -128.0, memory_length 2000, epsilon 0.8166864825981108\n",
      "travel time- 720.0\n",
      "--- 1.629798412322998 seconds ---\n",
      "episode 406, reward 224.0, memory_length 2000, epsilon 0.8162782414256099\n",
      "travel time- 731.0\n",
      "--- 1.6541876792907715 seconds ---\n",
      "episode 407, reward -354.0, memory_length 2000, epsilon 0.8158702043226737\n",
      "travel time- 720.0\n",
      "--- 1.8874294757843018 seconds ---\n",
      "episode 408, reward -194.0, memory_length 2000, epsilon 0.8154623711872927\n",
      "travel time- 725.0\n",
      "--- 1.8593316078186035 seconds ---\n",
      "episode 409, reward -9.0, memory_length 2000, epsilon 0.8150547419175087\n",
      "travel time- 725.0\n",
      "--- 1.6745426654815674 seconds ---\n",
      "episode 410, reward -196.0, memory_length 2000, epsilon 0.8146473164114145\n",
      "travel time- 724.0\n",
      "--- 1.6288743019104004 seconds ---\n",
      "episode 411, reward -157.0, memory_length 2000, epsilon 0.8142400945671536\n",
      "travel time- 720.0\n",
      "--- 1.5950403213500977 seconds ---\n",
      "episode 412, reward -200.0, memory_length 2000, epsilon 0.8138330762829207\n",
      "travel time- 723.0\n",
      "--- 1.6708641052246094 seconds ---\n",
      "episode 413, reward 15.0, memory_length 2000, epsilon 0.8134262614569611\n",
      "travel time- 734.0\n",
      "--- 1.655444622039795 seconds ---\n",
      "episode 414, reward -137.0, memory_length 2000, epsilon 0.813019649987571\n",
      "travel time- 721.0\n",
      "--- 1.5976014137268066 seconds ---\n",
      "episode 415, reward 134.0, memory_length 2000, epsilon 0.8126132417730977\n",
      "travel time- 727.0\n",
      "--- 1.2258083820343018 seconds ---\n",
      "episode 416, reward -87.0, memory_length 2000, epsilon 0.812207036711939\n",
      "travel time- 725.0\n",
      "--- 1.9778242111206055 seconds ---\n",
      "episode 417, reward -56.0, memory_length 2000, epsilon 0.8118010347025437\n",
      "travel time- 722.0\n",
      "--- 1.677774429321289 seconds ---\n",
      "episode 418, reward -131.0, memory_length 2000, epsilon 0.8113952356434114\n",
      "travel time- 721.0\n",
      "--- 1.5397167205810547 seconds ---\n",
      "episode 419, reward 51.0, memory_length 2000, epsilon 0.8109896394330922\n",
      "travel time- 728.0\n",
      "--- 1.7814278602600098 seconds ---\n",
      "episode 420, reward -564.0, memory_length 2000, epsilon 0.8105842459701871\n",
      "travel time- 720.0\n",
      "--- 1.6380927562713623 seconds ---\n",
      "episode 421, reward 69.0, memory_length 2000, epsilon 0.8101790551533476\n",
      "travel time- 732.0\n",
      "--- 1.5862228870391846 seconds ---\n",
      "episode 422, reward -235.0, memory_length 2000, epsilon 0.8097740668812763\n",
      "travel time- 723.0\n",
      "--- 1.7140710353851318 seconds ---\n",
      "episode 423, reward -178.0, memory_length 2000, epsilon 0.8093692810527259\n",
      "travel time- 725.0\n",
      "--- 1.634432077407837 seconds ---\n",
      "episode 424, reward -37.0, memory_length 2000, epsilon 0.8089646975664998\n",
      "travel time- 721.0\n",
      "--- 1.7675111293792725 seconds ---\n",
      "episode 425, reward -247.0, memory_length 2000, epsilon 0.8085603163214524\n",
      "travel time- 726.0\n",
      "--- 1.8184728622436523 seconds ---\n",
      "episode 426, reward -346.0, memory_length 2000, epsilon 0.8081561372164884\n",
      "travel time- 723.0\n",
      "--- 1.8985059261322021 seconds ---\n",
      "episode 427, reward -273.0, memory_length 2000, epsilon 0.8077521601505628\n",
      "travel time- 721.0\n",
      "--- 1.9800939559936523 seconds ---\n",
      "episode 428, reward -119.0, memory_length 2000, epsilon 0.8073483850226815\n",
      "travel time- 725.0\n",
      "--- 1.697878360748291 seconds ---\n",
      "episode 429, reward -93.0, memory_length 2000, epsilon 0.8069448117319006\n",
      "travel time- 725.0\n",
      "--- 1.5888912677764893 seconds ---\n",
      "episode 430, reward 20.0, memory_length 2000, epsilon 0.8065414401773269\n",
      "travel time- 725.0\n",
      "--- 1.6914558410644531 seconds ---\n",
      "episode 431, reward -106.0, memory_length 2000, epsilon 0.8061382702581174\n",
      "travel time- 725.0\n",
      "--- 1.8053064346313477 seconds ---\n",
      "episode 432, reward 123.0, memory_length 2000, epsilon 0.8057353018734796\n",
      "travel time- 723.0\n",
      "--- 1.6710822582244873 seconds ---\n",
      "episode 433, reward -148.0, memory_length 2000, epsilon 0.8053325349226717\n",
      "travel time- 722.0\n",
      "--- 1.7800979614257812 seconds ---\n",
      "episode 434, reward -208.0, memory_length 2000, epsilon 0.8049299693050015\n",
      "travel time- 726.0\n",
      "--- 1.594346523284912 seconds ---\n",
      "episode 435, reward -109.0, memory_length 2000, epsilon 0.8045276049198279\n",
      "travel time- 725.0\n",
      "--- 1.7683651447296143 seconds ---\n",
      "episode 436, reward 57.0, memory_length 2000, epsilon 0.8041254416665596\n",
      "travel time- 720.0\n",
      "--- 1.8942430019378662 seconds ---\n",
      "episode 437, reward -220.0, memory_length 2000, epsilon 0.803723479444656\n",
      "travel time- 721.0\n",
      "--- 1.8666133880615234 seconds ---\n",
      "episode 438, reward -111.0, memory_length 2000, epsilon 0.8033217181536265\n",
      "travel time- 724.0\n",
      "--- 1.9561593532562256 seconds ---\n",
      "episode 439, reward -329.0, memory_length 2000, epsilon 0.8029201576930307\n",
      "travel time- 724.0\n",
      "--- 1.9455618858337402 seconds ---\n",
      "episode 440, reward -97.0, memory_length 2000, epsilon 0.8025187979624785\n",
      "travel time- 729.0\n",
      "--- 1.509666919708252 seconds ---\n",
      "episode 441, reward 157.0, memory_length 2000, epsilon 0.8021176388616299\n",
      "travel time- 720.0\n",
      "--- 1.6083974838256836 seconds ---\n",
      "episode 442, reward -69.0, memory_length 2000, epsilon 0.8017166802901953\n",
      "travel time- 723.0\n",
      "--- 1.68202543258667 seconds ---\n",
      "episode 443, reward -448.0, memory_length 2000, epsilon 0.8013159221479349\n",
      "travel time- 725.0\n",
      "--- 1.8553736209869385 seconds ---\n",
      "episode 444, reward -442.0, memory_length 2000, epsilon 0.8009153643346592\n",
      "travel time- 726.0\n",
      "--- 1.7690255641937256 seconds ---\n",
      "episode 445, reward -144.0, memory_length 2000, epsilon 0.8005150067502288\n",
      "travel time- 721.0\n",
      "--- 1.6832969188690186 seconds ---\n",
      "episode 446, reward -2.0, memory_length 2000, epsilon 0.8001148492945541\n",
      "travel time- 720.0\n",
      "--- 1.6421642303466797 seconds ---\n",
      "episode 447, reward -106.0, memory_length 2000, epsilon 0.799714891867596\n",
      "travel time- 722.0\n",
      "--- 1.8529584407806396 seconds ---\n",
      "episode 448, reward -267.0, memory_length 2000, epsilon 0.7993151343693651\n",
      "travel time- 721.0\n",
      "--- 1.7135944366455078 seconds ---\n",
      "episode 449, reward -212.0, memory_length 2000, epsilon 0.7989155766999219\n",
      "travel time- 734.0\n",
      "--- 1.8304669857025146 seconds ---\n",
      "episode 450, reward -182.0, memory_length 2000, epsilon 0.7985162187593771\n",
      "travel time- 724.0\n",
      "--- 1.6384334564208984 seconds ---\n",
      "episode 451, reward -71.0, memory_length 2000, epsilon 0.798117060447891\n",
      "travel time- 729.0\n",
      "--- 1.5560948848724365 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 452, reward -136.0, memory_length 2000, epsilon 0.7977181016656743\n",
      "travel time- 726.0\n",
      "--- 1.8544740676879883 seconds ---\n",
      "episode 453, reward -302.0, memory_length 2000, epsilon 0.7973193423129871\n",
      "travel time- 725.0\n",
      "--- 1.8747327327728271 seconds ---\n",
      "episode 454, reward 10.0, memory_length 2000, epsilon 0.7969207822901396\n",
      "travel time- 729.0\n",
      "--- 1.7242748737335205 seconds ---\n",
      "episode 455, reward -8.0, memory_length 2000, epsilon 0.7965224214974919\n",
      "travel time- 721.0\n",
      "--- 1.7485551834106445 seconds ---\n",
      "episode 456, reward 159.0, memory_length 2000, epsilon 0.7961242598354538\n",
      "travel time- 725.0\n",
      "--- 2.012632131576538 seconds ---\n",
      "episode 457, reward -152.0, memory_length 2000, epsilon 0.7957262972044846\n",
      "travel time- 722.0\n",
      "--- 1.9300141334533691 seconds ---\n",
      "episode 458, reward -163.0, memory_length 2000, epsilon 0.7953285335050939\n",
      "travel time- 720.0\n",
      "--- 1.8360304832458496 seconds ---\n",
      "episode 459, reward -161.0, memory_length 2000, epsilon 0.7949309686378409\n",
      "travel time- 726.0\n",
      "--- 1.8670847415924072 seconds ---\n",
      "episode 460, reward -308.0, memory_length 2000, epsilon 0.794533602503334\n",
      "travel time- 721.0\n",
      "--- 1.775557279586792 seconds ---\n",
      "episode 461, reward -126.0, memory_length 2000, epsilon 0.794136435002232\n",
      "travel time- 730.0\n",
      "--- 1.9700260162353516 seconds ---\n",
      "episode 462, reward -223.0, memory_length 2000, epsilon 0.7937394660352427\n",
      "travel time- 720.0\n",
      "--- 1.8044426441192627 seconds ---\n",
      "episode 463, reward -357.0, memory_length 2000, epsilon 0.7933426955031242\n",
      "travel time- 720.0\n",
      "--- 1.858583927154541 seconds ---\n",
      "episode 464, reward -48.0, memory_length 2000, epsilon 0.7929461233066837\n",
      "travel time- 727.0\n",
      "--- 1.7326927185058594 seconds ---\n",
      "episode 465, reward -537.0, memory_length 2000, epsilon 0.7925497493467781\n",
      "travel time- 726.0\n",
      "--- 1.8606696128845215 seconds ---\n",
      "episode 466, reward -108.0, memory_length 2000, epsilon 0.792153573524314\n",
      "travel time- 720.0\n",
      "--- 1.7409119606018066 seconds ---\n",
      "episode 467, reward -227.0, memory_length 2000, epsilon 0.7917575957402474\n",
      "travel time- 724.0\n",
      "--- 1.6623971462249756 seconds ---\n",
      "episode 468, reward 238.0, memory_length 2000, epsilon 0.7913618158955839\n",
      "travel time- 720.0\n",
      "--- 1.7172479629516602 seconds ---\n",
      "episode 469, reward -177.0, memory_length 2000, epsilon 0.7909662338913784\n",
      "travel time- 722.0\n",
      "--- 1.617957353591919 seconds ---\n",
      "episode 470, reward -64.0, memory_length 2000, epsilon 0.7905708496287356\n",
      "travel time- 722.0\n",
      "--- 1.7123756408691406 seconds ---\n",
      "episode 471, reward -102.0, memory_length 2000, epsilon 0.7901756630088093\n",
      "travel time- 730.0\n",
      "--- 1.6822352409362793 seconds ---\n",
      "episode 472, reward -243.0, memory_length 2000, epsilon 0.7897806739328027\n",
      "travel time- 721.0\n",
      "--- 1.790651559829712 seconds ---\n",
      "episode 473, reward 87.0, memory_length 2000, epsilon 0.7893858823019688\n",
      "travel time- 722.0\n",
      "--- 1.5590753555297852 seconds ---\n",
      "episode 474, reward -391.0, memory_length 2000, epsilon 0.7889912880176096\n",
      "travel time- 728.0\n",
      "--- 1.8764755725860596 seconds ---\n",
      "episode 475, reward -41.0, memory_length 2000, epsilon 0.7885968909810767\n",
      "travel time- 724.0\n",
      "--- 1.9061269760131836 seconds ---\n",
      "episode 476, reward 34.0, memory_length 2000, epsilon 0.7882026910937704\n",
      "travel time- 720.0\n",
      "--- 1.7079739570617676 seconds ---\n",
      "episode 477, reward -78.0, memory_length 2000, epsilon 0.7878086882571411\n",
      "travel time- 725.0\n",
      "--- 1.7247681617736816 seconds ---\n",
      "episode 478, reward -10.0, memory_length 2000, epsilon 0.7874148823726879\n",
      "travel time- 725.0\n",
      "--- 1.7152700424194336 seconds ---\n",
      "episode 479, reward -368.0, memory_length 2000, epsilon 0.7870212733419595\n",
      "travel time- 721.0\n",
      "--- 1.8258976936340332 seconds ---\n",
      "episode 480, reward -40.0, memory_length 2000, epsilon 0.7866278610665535\n",
      "travel time- 723.0\n",
      "--- 1.784921646118164 seconds ---\n",
      "episode 481, reward -104.0, memory_length 2000, epsilon 0.7862346454481167\n",
      "travel time- 725.0\n",
      "--- 1.6724095344543457 seconds ---\n",
      "episode 482, reward -118.0, memory_length 2000, epsilon 0.7858416263883455\n",
      "travel time- 729.0\n",
      "--- 1.5933403968811035 seconds ---\n",
      "episode 483, reward -271.0, memory_length 2000, epsilon 0.785448803788985\n",
      "travel time- 720.0\n",
      "--- 1.8759379386901855 seconds ---\n",
      "episode 484, reward -73.0, memory_length 2000, epsilon 0.7850561775518295\n",
      "travel time- 721.0\n",
      "--- 1.672867774963379 seconds ---\n",
      "episode 485, reward -457.0, memory_length 2000, epsilon 0.7846637475787225\n",
      "travel time- 723.0\n",
      "--- 1.644385814666748 seconds ---\n",
      "episode 486, reward -7.0, memory_length 2000, epsilon 0.7842715137715565\n",
      "travel time- 723.0\n",
      "--- 1.507108449935913 seconds ---\n",
      "episode 487, reward -307.0, memory_length 2000, epsilon 0.7838794760322729\n",
      "travel time- 725.0\n",
      "--- 1.7970607280731201 seconds ---\n",
      "episode 488, reward -141.0, memory_length 2000, epsilon 0.7834876342628625\n",
      "travel time- 734.0\n",
      "--- 1.8387701511383057 seconds ---\n",
      "episode 489, reward 26.0, memory_length 2000, epsilon 0.7830959883653648\n",
      "travel time- 721.0\n",
      "--- 1.626650094985962 seconds ---\n",
      "episode 490, reward 94.0, memory_length 2000, epsilon 0.7827045382418681\n",
      "travel time- 720.0\n",
      "--- 1.4306907653808594 seconds ---\n",
      "episode 491, reward -259.0, memory_length 2000, epsilon 0.7823132837945103\n",
      "travel time- 722.0\n",
      "--- 1.770850419998169 seconds ---\n",
      "episode 492, reward -321.0, memory_length 2000, epsilon 0.7819222249254772\n",
      "travel time- 720.0\n",
      "--- 1.8285071849822998 seconds ---\n",
      "episode 493, reward -204.0, memory_length 2000, epsilon 0.7815313615370046\n",
      "travel time- 722.0\n",
      "--- 1.6225943565368652 seconds ---\n",
      "episode 494, reward 17.0, memory_length 2000, epsilon 0.7811406935313765\n",
      "travel time- 732.0\n",
      "--- 1.6478650569915771 seconds ---\n",
      "episode 495, reward -184.0, memory_length 2000, epsilon 0.7807502208109257\n",
      "travel time- 725.0\n",
      "--- 1.5557703971862793 seconds ---\n",
      "episode 496, reward 133.0, memory_length 2000, epsilon 0.7803599432780343\n",
      "travel time- 726.0\n",
      "--- 1.796121597290039 seconds ---\n",
      "episode 497, reward 46.0, memory_length 2000, epsilon 0.7799698608351326\n",
      "travel time- 720.0\n",
      "--- 1.7089626789093018 seconds ---\n",
      "episode 498, reward -466.0, memory_length 2000, epsilon 0.7795799733847004\n",
      "travel time- 729.0\n",
      "--- 2.0374815464019775 seconds ---\n",
      "episode 499, reward -335.0, memory_length 2000, epsilon 0.7791902808292654\n",
      "travel time- 722.0\n",
      "--- 1.8416130542755127 seconds ---\n",
      "episode 500, reward -44.0, memory_length 2000, epsilon 0.7788007830714049\n",
      "travel time- 722.0\n",
      "--- 1.611388921737671 seconds ---\n",
      "episode 501, reward -1.0, memory_length 2000, epsilon 0.778411480013744\n",
      "travel time- 726.0\n",
      "--- 1.4836499691009521 seconds ---\n",
      "episode 502, reward -158.0, memory_length 2000, epsilon 0.7780223715589573\n",
      "travel time- 727.0\n",
      "--- 1.5528838634490967 seconds ---\n",
      "episode 503, reward -417.0, memory_length 2000, epsilon 0.7776334576097675\n",
      "travel time- 727.0\n",
      "--- 1.6631555557250977 seconds ---\n",
      "episode 504, reward -19.0, memory_length 2000, epsilon 0.7772447380689461\n",
      "travel time- 726.0\n",
      "--- 1.6067171096801758 seconds ---\n",
      "episode 505, reward -136.0, memory_length 2000, epsilon 0.7768562128393134\n",
      "travel time- 721.0\n",
      "--- 1.6446764469146729 seconds ---\n",
      "episode 506, reward 90.0, memory_length 2000, epsilon 0.7764678818237378\n",
      "travel time- 733.0\n",
      "--- 1.8102097511291504 seconds ---\n",
      "episode 507, reward -274.0, memory_length 2000, epsilon 0.7760797449251368\n",
      "travel time- 727.0\n",
      "--- 1.937281608581543 seconds ---\n",
      "episode 508, reward -349.0, memory_length 2000, epsilon 0.775691802046476\n",
      "travel time- 730.0\n",
      "--- 1.7240519523620605 seconds ---\n",
      "episode 509, reward -224.0, memory_length 2000, epsilon 0.7753040530907698\n",
      "travel time- 723.0\n",
      "--- 1.5548038482666016 seconds ---\n",
      "episode 510, reward -297.0, memory_length 2000, epsilon 0.774916497961081\n",
      "travel time- 720.0\n",
      "--- 1.8549017906188965 seconds ---\n",
      "episode 511, reward -347.0, memory_length 2000, epsilon 0.7745291365605206\n",
      "travel time- 728.0\n",
      "--- 1.9457321166992188 seconds ---\n",
      "episode 512, reward -276.0, memory_length 2000, epsilon 0.7741419687922484\n",
      "travel time- 723.0\n",
      "--- 1.6358749866485596 seconds ---\n",
      "episode 513, reward -25.0, memory_length 2000, epsilon 0.7737549945594724\n",
      "travel time- 727.0\n",
      "--- 1.8041954040527344 seconds ---\n",
      "episode 514, reward -389.0, memory_length 2000, epsilon 0.7733682137654491\n",
      "travel time- 721.0\n",
      "--- 1.8363573551177979 seconds ---\n",
      "episode 515, reward -133.0, memory_length 2000, epsilon 0.7729816263134832\n",
      "travel time- 724.0\n",
      "--- 1.7282063961029053 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 516, reward -373.0, memory_length 2000, epsilon 0.772595232106928\n",
      "travel time- 725.0\n",
      "--- 1.745253324508667 seconds ---\n",
      "episode 517, reward -12.0, memory_length 2000, epsilon 0.7722090310491848\n",
      "travel time- 723.0\n",
      "--- 1.4550666809082031 seconds ---\n",
      "episode 518, reward -249.0, memory_length 2000, epsilon 0.7718230230437034\n",
      "travel time- 721.0\n",
      "--- 1.7949731349945068 seconds ---\n",
      "episode 519, reward -205.0, memory_length 2000, epsilon 0.7714372079939819\n",
      "travel time- 723.0\n",
      "--- 1.943981647491455 seconds ---\n",
      "episode 520, reward -186.0, memory_length 2000, epsilon 0.7710515858035663\n",
      "travel time- 725.0\n",
      "--- 1.654547929763794 seconds ---\n",
      "episode 521, reward -34.0, memory_length 2000, epsilon 0.7706661563760512\n",
      "travel time- 724.0\n",
      "--- 2.0035400390625 seconds ---\n",
      "episode 522, reward -219.0, memory_length 2000, epsilon 0.7702809196150792\n",
      "travel time- 722.0\n",
      "--- 1.6472885608673096 seconds ---\n",
      "episode 523, reward -554.0, memory_length 2000, epsilon 0.769895875424341\n",
      "travel time- 727.0\n",
      "--- 2.052804470062256 seconds ---\n",
      "episode 524, reward -129.0, memory_length 2000, epsilon 0.7695110237075758\n",
      "travel time- 720.0\n",
      "--- 1.9473752975463867 seconds ---\n",
      "episode 525, reward -8.0, memory_length 2000, epsilon 0.7691263643685705\n",
      "travel time- 734.0\n",
      "--- 1.6318604946136475 seconds ---\n",
      "episode 526, reward -293.0, memory_length 2000, epsilon 0.7687418973111603\n",
      "travel time- 720.0\n",
      "--- 1.6824047565460205 seconds ---\n",
      "episode 527, reward -95.0, memory_length 2000, epsilon 0.7683576224392284\n",
      "travel time- 721.0\n",
      "--- 1.6646418571472168 seconds ---\n",
      "episode 528, reward 40.0, memory_length 2000, epsilon 0.7679735396567061\n",
      "travel time- 721.0\n",
      "--- 1.6536195278167725 seconds ---\n",
      "episode 529, reward -266.0, memory_length 2000, epsilon 0.7675896488675729\n",
      "travel time- 729.0\n",
      "--- 1.6233265399932861 seconds ---\n",
      "episode 530, reward -61.0, memory_length 2000, epsilon 0.7672059499758557\n",
      "travel time- 724.0\n",
      "--- 1.7149691581726074 seconds ---\n",
      "episode 531, reward 44.0, memory_length 2000, epsilon 0.7668224428856301\n",
      "travel time- 726.0\n",
      "--- 1.6405656337738037 seconds ---\n",
      "episode 532, reward 221.0, memory_length 2000, epsilon 0.7664391275010192\n",
      "travel time- 721.0\n",
      "--- 1.5979421138763428 seconds ---\n",
      "episode 533, reward 339.0, memory_length 2000, epsilon 0.7660560037261941\n",
      "travel time- 721.0\n",
      "--- 1.573561668395996 seconds ---\n",
      "episode 534, reward -117.0, memory_length 2000, epsilon 0.7656730714653739\n",
      "travel time- 726.0\n",
      "--- 1.8352446556091309 seconds ---\n",
      "episode 535, reward 39.0, memory_length 2000, epsilon 0.7652903306228257\n",
      "travel time- 721.0\n",
      "--- 1.7703595161437988 seconds ---\n",
      "episode 536, reward -151.0, memory_length 2000, epsilon 0.764907781102864\n",
      "travel time- 720.0\n",
      "--- 1.752723217010498 seconds ---\n",
      "episode 537, reward -395.0, memory_length 2000, epsilon 0.7645254228098516\n",
      "travel time- 720.0\n",
      "--- 1.7520747184753418 seconds ---\n",
      "episode 538, reward -203.0, memory_length 2000, epsilon 0.764143255648199\n",
      "travel time- 720.0\n",
      "--- 1.519348382949829 seconds ---\n",
      "episode 539, reward -240.0, memory_length 2000, epsilon 0.7637612795223642\n",
      "travel time- 721.0\n",
      "--- 1.6501576900482178 seconds ---\n",
      "episode 540, reward -198.0, memory_length 2000, epsilon 0.7633794943368531\n",
      "travel time- 722.0\n",
      "--- 1.6444895267486572 seconds ---\n",
      "episode 541, reward 255.0, memory_length 2000, epsilon 0.7629978999962198\n",
      "travel time- 720.0\n",
      "--- 1.6375365257263184 seconds ---\n",
      "episode 542, reward -402.0, memory_length 2000, epsilon 0.7626164964050653\n",
      "travel time- 723.0\n",
      "--- 1.5614259243011475 seconds ---\n",
      "episode 543, reward -105.0, memory_length 2000, epsilon 0.762235283468039\n",
      "travel time- 727.0\n",
      "--- 1.846285104751587 seconds ---\n",
      "episode 544, reward -152.0, memory_length 2000, epsilon 0.7618542610898376\n",
      "travel time- 720.0\n",
      "--- 1.7518205642700195 seconds ---\n",
      "episode 545, reward 59.0, memory_length 2000, epsilon 0.7614734291752052\n",
      "travel time- 721.0\n",
      "--- 1.5895543098449707 seconds ---\n",
      "episode 546, reward -402.0, memory_length 2000, epsilon 0.7610927876289343\n",
      "travel time- 723.0\n",
      "--- 1.7193546295166016 seconds ---\n",
      "episode 547, reward -250.0, memory_length 2000, epsilon 0.7607123363558641\n",
      "travel time- 722.0\n",
      "--- 1.751424789428711 seconds ---\n",
      "episode 548, reward -460.0, memory_length 2000, epsilon 0.7603320752608821\n",
      "travel time- 728.0\n",
      "--- 1.8427152633666992 seconds ---\n",
      "episode 549, reward -106.0, memory_length 2000, epsilon 0.7599520042489227\n",
      "travel time- 722.0\n",
      "--- 1.7616636753082275 seconds ---\n",
      "episode 550, reward -289.0, memory_length 2000, epsilon 0.7595721232249685\n",
      "travel time- 725.0\n",
      "--- 1.7574760913848877 seconds ---\n",
      "episode 551, reward -140.0, memory_length 2000, epsilon 0.759192432094049\n",
      "travel time- 725.0\n",
      "--- 1.547093391418457 seconds ---\n",
      "episode 552, reward -127.0, memory_length 2000, epsilon 0.7588129307612413\n",
      "travel time- 721.0\n",
      "--- 1.7928187847137451 seconds ---\n",
      "episode 553, reward -82.0, memory_length 2000, epsilon 0.7584336191316705\n",
      "travel time- 723.0\n",
      "--- 1.651487112045288 seconds ---\n",
      "episode 554, reward -99.0, memory_length 2000, epsilon 0.7580544971105083\n",
      "travel time- 723.0\n",
      "--- 1.7465410232543945 seconds ---\n",
      "episode 555, reward -268.0, memory_length 2000, epsilon 0.7576755646029744\n",
      "travel time- 723.0\n",
      "--- 1.7114911079406738 seconds ---\n",
      "episode 556, reward -367.0, memory_length 2000, epsilon 0.7572968215143355\n",
      "travel time- 723.0\n",
      "--- 1.7778184413909912 seconds ---\n",
      "episode 557, reward -86.0, memory_length 2000, epsilon 0.756918267749906\n",
      "travel time- 725.0\n",
      "--- 1.7683894634246826 seconds ---\n",
      "episode 558, reward -213.0, memory_length 2000, epsilon 0.7565399032150474\n",
      "travel time- 723.0\n",
      "--- 1.6535143852233887 seconds ---\n",
      "episode 559, reward -134.0, memory_length 2000, epsilon 0.7561617278151684\n",
      "travel time- 722.0\n",
      "--- 1.5403873920440674 seconds ---\n",
      "episode 560, reward -104.0, memory_length 2000, epsilon 0.7557837414557255\n",
      "travel time- 727.0\n",
      "--- 1.7143738269805908 seconds ---\n",
      "episode 561, reward -221.0, memory_length 2000, epsilon 0.7554059440422217\n",
      "travel time- 724.0\n",
      "--- 1.6357536315917969 seconds ---\n",
      "episode 562, reward -194.0, memory_length 2000, epsilon 0.755028335480208\n",
      "travel time- 722.0\n",
      "--- 1.5861790180206299 seconds ---\n",
      "episode 563, reward -55.0, memory_length 2000, epsilon 0.754650915675282\n",
      "travel time- 720.0\n",
      "--- 1.516007661819458 seconds ---\n",
      "episode 564, reward 56.0, memory_length 2000, epsilon 0.754273684533089\n",
      "travel time- 721.0\n",
      "--- 1.6812043190002441 seconds ---\n",
      "episode 565, reward 27.0, memory_length 2000, epsilon 0.7538966419593208\n",
      "travel time- 729.0\n",
      "--- 1.3928358554840088 seconds ---\n",
      "episode 566, reward -4.0, memory_length 2000, epsilon 0.7535197878597172\n",
      "travel time- 729.0\n",
      "--- 1.7721507549285889 seconds ---\n",
      "episode 567, reward -472.0, memory_length 2000, epsilon 0.7531431221400645\n",
      "travel time- 723.0\n",
      "--- 1.7705492973327637 seconds ---\n",
      "episode 568, reward -208.0, memory_length 2000, epsilon 0.7527666447061963\n",
      "travel time- 724.0\n",
      "--- 1.7747082710266113 seconds ---\n",
      "episode 569, reward -34.0, memory_length 2000, epsilon 0.752390355463993\n",
      "travel time- 721.0\n",
      "--- 1.5859460830688477 seconds ---\n",
      "episode 570, reward -15.0, memory_length 2000, epsilon 0.7520142543193826\n",
      "travel time- 724.0\n",
      "--- 1.607689619064331 seconds ---\n",
      "episode 571, reward -66.0, memory_length 2000, epsilon 0.7516383411783397\n",
      "travel time- 730.0\n",
      "--- 1.605057716369629 seconds ---\n",
      "episode 572, reward -230.0, memory_length 2000, epsilon 0.751262615946886\n",
      "travel time- 720.0\n",
      "--- 1.658937931060791 seconds ---\n",
      "episode 573, reward 183.0, memory_length 2000, epsilon 0.7508870785310902\n",
      "travel time- 726.0\n",
      "--- 1.6749451160430908 seconds ---\n",
      "episode 574, reward -215.0, memory_length 2000, epsilon 0.750511728837068\n",
      "travel time- 727.0\n",
      "--- 1.7550947666168213 seconds ---\n",
      "episode 575, reward -59.0, memory_length 2000, epsilon 0.7501365667709818\n",
      "travel time- 723.0\n",
      "--- 1.7057113647460938 seconds ---\n",
      "episode 576, reward 43.0, memory_length 2000, epsilon 0.7497615922390413\n",
      "travel time- 720.0\n",
      "--- 1.7826144695281982 seconds ---\n",
      "episode 577, reward -296.0, memory_length 2000, epsilon 0.7493868051475028\n",
      "travel time- 727.0\n",
      "--- 1.6568636894226074 seconds ---\n",
      "episode 578, reward -515.0, memory_length 2000, epsilon 0.7490122054026693\n",
      "travel time- 721.0\n",
      "--- 1.7029964923858643 seconds ---\n",
      "episode 579, reward -524.0, memory_length 2000, epsilon 0.7486377929108913\n",
      "travel time- 721.0\n",
      "--- 2.0994510650634766 seconds ---\n",
      "episode 580, reward -333.0, memory_length 2000, epsilon 0.7482635675785653\n",
      "travel time- 724.0\n",
      "--- 1.8772525787353516 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 581, reward -71.0, memory_length 2000, epsilon 0.747889529312135\n",
      "travel time- 727.0\n",
      "--- 1.8281540870666504 seconds ---\n",
      "episode 582, reward -369.0, memory_length 2000, epsilon 0.747515678018091\n",
      "travel time- 722.0\n",
      "--- 1.838256597518921 seconds ---\n",
      "episode 583, reward -254.0, memory_length 2000, epsilon 0.7471420136029704\n",
      "travel time- 720.0\n",
      "--- 1.792543888092041 seconds ---\n",
      "episode 584, reward 114.0, memory_length 2000, epsilon 0.7467685359733571\n",
      "travel time- 724.0\n",
      "--- 1.5183846950531006 seconds ---\n",
      "episode 585, reward -3.0, memory_length 2000, epsilon 0.7463952450358817\n",
      "travel time- 723.0\n",
      "--- 1.7108111381530762 seconds ---\n",
      "episode 586, reward -460.0, memory_length 2000, epsilon 0.7460221406972215\n",
      "travel time- 724.0\n",
      "--- 1.7648072242736816 seconds ---\n",
      "episode 587, reward -385.0, memory_length 2000, epsilon 0.7456492228641003\n",
      "travel time- 722.0\n",
      "--- 1.706486701965332 seconds ---\n",
      "episode 588, reward -138.0, memory_length 2000, epsilon 0.7452764914432887\n",
      "travel time- 720.0\n",
      "--- 1.7527031898498535 seconds ---\n",
      "episode 589, reward -335.0, memory_length 2000, epsilon 0.7449039463416037\n",
      "travel time- 721.0\n",
      "--- 1.7471601963043213 seconds ---\n",
      "episode 590, reward -22.0, memory_length 2000, epsilon 0.7445315874659094\n",
      "travel time- 731.0\n",
      "--- 1.7061803340911865 seconds ---\n",
      "episode 591, reward -417.0, memory_length 2000, epsilon 0.7441594147231158\n",
      "travel time- 727.0\n",
      "--- 1.675553798675537 seconds ---\n",
      "episode 592, reward -80.0, memory_length 2000, epsilon 0.7437874280201796\n",
      "travel time- 720.0\n",
      "--- 1.7952089309692383 seconds ---\n",
      "episode 593, reward -138.0, memory_length 2000, epsilon 0.7434156272641044\n",
      "travel time- 720.0\n",
      "--- 1.6875331401824951 seconds ---\n",
      "episode 594, reward 344.0, memory_length 2000, epsilon 0.7430440123619398\n",
      "travel time- 727.0\n",
      "--- 1.6335418224334717 seconds ---\n",
      "episode 595, reward -153.0, memory_length 2000, epsilon 0.7426725832207823\n",
      "travel time- 723.0\n",
      "--- 1.8502299785614014 seconds ---\n",
      "episode 596, reward -149.0, memory_length 2000, epsilon 0.7423013397477743\n",
      "travel time- 721.0\n",
      "--- 1.7003061771392822 seconds ---\n",
      "episode 597, reward -131.0, memory_length 2000, epsilon 0.7419302818501052\n",
      "travel time- 727.0\n",
      "--- 1.577784776687622 seconds ---\n",
      "episode 598, reward -412.0, memory_length 2000, epsilon 0.7415594094350105\n",
      "travel time- 723.0\n",
      "--- 1.7989428043365479 seconds ---\n",
      "episode 599, reward -753.0, memory_length 2000, epsilon 0.741188722409772\n",
      "travel time- 723.0\n",
      "--- 1.7805883884429932 seconds ---\n",
      "episode 600, reward -221.0, memory_length 2000, epsilon 0.7408182206817179\n",
      "travel time- 727.0\n",
      "--- 1.9646797180175781 seconds ---\n",
      "episode 601, reward -320.0, memory_length 2000, epsilon 0.7404479041582228\n",
      "travel time- 730.0\n",
      "--- 1.7900400161743164 seconds ---\n",
      "episode 602, reward 68.0, memory_length 2000, epsilon 0.7400777727467076\n",
      "travel time- 725.0\n",
      "--- 1.6116876602172852 seconds ---\n",
      "episode 603, reward -266.0, memory_length 2000, epsilon 0.7397078263546395\n",
      "travel time- 735.0\n",
      "--- 1.4794690608978271 seconds ---\n",
      "episode 604, reward -21.0, memory_length 2000, epsilon 0.7393380648895319\n",
      "travel time- 731.0\n",
      "--- 1.6728341579437256 seconds ---\n",
      "episode 605, reward -71.0, memory_length 2000, epsilon 0.7389684882589442\n",
      "travel time- 720.0\n",
      "--- 1.5924968719482422 seconds ---\n",
      "episode 606, reward -179.0, memory_length 2000, epsilon 0.7385990963704826\n",
      "travel time- 720.0\n",
      "--- 1.8472304344177246 seconds ---\n",
      "episode 607, reward -51.0, memory_length 2000, epsilon 0.7382298891317988\n",
      "travel time- 720.0\n",
      "--- 1.7920420169830322 seconds ---\n",
      "episode 608, reward -107.0, memory_length 2000, epsilon 0.7378608664505911\n",
      "travel time- 720.0\n",
      "--- 1.5372450351715088 seconds ---\n",
      "episode 609, reward -159.0, memory_length 2000, epsilon 0.737492028234604\n",
      "travel time- 729.0\n",
      "--- 1.5842421054840088 seconds ---\n",
      "episode 610, reward -307.0, memory_length 2000, epsilon 0.7371233743916278\n",
      "travel time- 726.0\n",
      "--- 1.6607630252838135 seconds ---\n",
      "episode 611, reward -32.0, memory_length 2000, epsilon 0.7367549048294989\n",
      "travel time- 723.0\n",
      "--- 1.7194676399230957 seconds ---\n",
      "episode 612, reward -257.0, memory_length 2000, epsilon 0.7363866194561001\n",
      "travel time- 723.0\n",
      "--- 1.4972033500671387 seconds ---\n",
      "episode 613, reward -268.0, memory_length 2000, epsilon 0.73601851817936\n",
      "travel time- 724.0\n",
      "--- 1.615349531173706 seconds ---\n",
      "episode 614, reward -260.0, memory_length 2000, epsilon 0.7356506009072533\n",
      "travel time- 729.0\n",
      "--- 1.7727677822113037 seconds ---\n",
      "episode 615, reward -643.0, memory_length 2000, epsilon 0.7352828675478007\n",
      "travel time- 723.0\n",
      "--- 1.7211904525756836 seconds ---\n",
      "episode 616, reward -180.0, memory_length 2000, epsilon 0.7349153180090687\n",
      "travel time- 732.0\n",
      "--- 1.7319250106811523 seconds ---\n",
      "episode 617, reward -28.0, memory_length 2000, epsilon 0.7345479521991701\n",
      "travel time- 730.0\n",
      "--- 1.7656152248382568 seconds ---\n",
      "episode 618, reward -236.0, memory_length 2000, epsilon 0.7341807700262634\n",
      "travel time- 721.0\n",
      "--- 1.9135499000549316 seconds ---\n",
      "episode 619, reward 29.0, memory_length 2000, epsilon 0.733813771398553\n",
      "travel time- 721.0\n",
      "--- 1.8783040046691895 seconds ---\n",
      "episode 620, reward -11.0, memory_length 2000, epsilon 0.7334469562242892\n",
      "travel time- 722.0\n",
      "--- 1.7718312740325928 seconds ---\n",
      "episode 621, reward -156.0, memory_length 2000, epsilon 0.7330803244117684\n",
      "travel time- 723.0\n",
      "--- 1.4811904430389404 seconds ---\n",
      "episode 622, reward -217.0, memory_length 2000, epsilon 0.7327138758693325\n",
      "travel time- 722.0\n",
      "--- 1.6393744945526123 seconds ---\n",
      "episode 623, reward -334.0, memory_length 2000, epsilon 0.7323476105053693\n",
      "travel time- 725.0\n",
      "--- 1.5529828071594238 seconds ---\n",
      "episode 624, reward -444.0, memory_length 2000, epsilon 0.7319815282283126\n",
      "travel time- 722.0\n",
      "--- 1.5633666515350342 seconds ---\n",
      "episode 625, reward -280.0, memory_length 2000, epsilon 0.7316156289466418\n",
      "travel time- 726.0\n",
      "--- 1.7689964771270752 seconds ---\n",
      "episode 626, reward -35.0, memory_length 2000, epsilon 0.731249912568882\n",
      "travel time- 722.0\n",
      "--- 1.7447538375854492 seconds ---\n",
      "episode 627, reward 142.0, memory_length 2000, epsilon 0.7308843790036041\n",
      "travel time- 732.0\n",
      "--- 1.5218641757965088 seconds ---\n",
      "episode 628, reward -244.0, memory_length 2000, epsilon 0.7305190281594249\n",
      "travel time- 720.0\n",
      "--- 1.768627405166626 seconds ---\n",
      "episode 629, reward -356.0, memory_length 2000, epsilon 0.7301538599450065\n",
      "travel time- 720.0\n",
      "--- 1.6809947490692139 seconds ---\n",
      "episode 630, reward 106.0, memory_length 2000, epsilon 0.7297888742690568\n",
      "travel time- 720.0\n",
      "--- 1.7647888660430908 seconds ---\n",
      "episode 631, reward -50.0, memory_length 2000, epsilon 0.7294240710403295\n",
      "travel time- 727.0\n",
      "--- 1.6997945308685303 seconds ---\n",
      "episode 632, reward -217.0, memory_length 2000, epsilon 0.7290594501676237\n",
      "travel time- 721.0\n",
      "--- 1.5890858173370361 seconds ---\n",
      "episode 633, reward 35.0, memory_length 2000, epsilon 0.7286950115597844\n",
      "travel time- 720.0\n",
      "--- 1.6375610828399658 seconds ---\n",
      "episode 634, reward -152.0, memory_length 2000, epsilon 0.7283307551257017\n",
      "travel time- 723.0\n",
      "--- 1.9327502250671387 seconds ---\n",
      "episode 635, reward -449.0, memory_length 2000, epsilon 0.7279666807743116\n",
      "travel time- 720.0\n",
      "--- 2.0917651653289795 seconds ---\n",
      "episode 636, reward -377.0, memory_length 2000, epsilon 0.7276027884145955\n",
      "travel time- 724.0\n",
      "--- 1.5874953269958496 seconds ---\n",
      "episode 637, reward -65.0, memory_length 2000, epsilon 0.7272390779555802\n",
      "travel time- 728.0\n",
      "--- 1.7419989109039307 seconds ---\n",
      "episode 638, reward -219.0, memory_length 2000, epsilon 0.7268755493063382\n",
      "travel time- 720.0\n",
      "--- 1.625061273574829 seconds ---\n",
      "episode 639, reward -88.0, memory_length 2000, epsilon 0.7265122023759873\n",
      "travel time- 730.0\n",
      "--- 1.7155425548553467 seconds ---\n",
      "episode 640, reward -62.0, memory_length 2000, epsilon 0.7261490370736909\n",
      "travel time- 722.0\n",
      "--- 1.6836209297180176 seconds ---\n",
      "episode 641, reward -45.0, memory_length 2000, epsilon 0.7257860533086575\n",
      "travel time- 730.0\n",
      "--- 1.964824914932251 seconds ---\n",
      "episode 642, reward 170.0, memory_length 2000, epsilon 0.7254232509901412\n",
      "travel time- 727.0\n",
      "--- 1.587798833847046 seconds ---\n",
      "episode 643, reward -108.0, memory_length 2000, epsilon 0.7250606300274414\n",
      "travel time- 727.0\n",
      "--- 1.6138887405395508 seconds ---\n",
      "episode 644, reward 23.0, memory_length 2000, epsilon 0.7246981903299029\n",
      "travel time- 728.0\n",
      "--- 1.845780372619629 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 645, reward -405.0, memory_length 2000, epsilon 0.7243359318069157\n",
      "travel time- 720.0\n",
      "--- 1.9071846008300781 seconds ---\n",
      "episode 646, reward -194.0, memory_length 2000, epsilon 0.7239738543679153\n",
      "travel time- 723.0\n",
      "--- 1.582568645477295 seconds ---\n",
      "episode 647, reward -41.0, memory_length 2000, epsilon 0.7236119579223822\n",
      "travel time- 722.0\n",
      "--- 1.7149617671966553 seconds ---\n",
      "episode 648, reward 26.0, memory_length 2000, epsilon 0.7232502423798424\n",
      "travel time- 725.0\n",
      "--- 2.0488193035125732 seconds ---\n",
      "episode 649, reward -139.0, memory_length 2000, epsilon 0.722888707649867\n",
      "travel time- 720.0\n",
      "--- 1.760023593902588 seconds ---\n",
      "episode 650, reward 25.0, memory_length 2000, epsilon 0.7225273536420722\n",
      "travel time- 731.0\n",
      "--- 1.6149091720581055 seconds ---\n",
      "episode 651, reward 73.0, memory_length 2000, epsilon 0.7221661802661196\n",
      "travel time- 722.0\n",
      "--- 1.3951184749603271 seconds ---\n",
      "episode 652, reward -115.0, memory_length 2000, epsilon 0.7218051874317158\n",
      "travel time- 730.0\n",
      "--- 1.9097962379455566 seconds ---\n",
      "episode 653, reward -257.0, memory_length 2000, epsilon 0.7214443750486127\n",
      "travel time- 727.0\n",
      "--- 2.007235527038574 seconds ---\n",
      "episode 654, reward -179.0, memory_length 2000, epsilon 0.721083743026607\n",
      "travel time- 732.0\n",
      "--- 1.6103847026824951 seconds ---\n",
      "episode 655, reward -64.0, memory_length 2000, epsilon 0.7207232912755409\n",
      "travel time- 726.0\n",
      "--- 1.6178343296051025 seconds ---\n",
      "episode 656, reward -485.0, memory_length 2000, epsilon 0.7203630197053014\n",
      "travel time- 726.0\n",
      "--- 1.6301827430725098 seconds ---\n",
      "episode 657, reward -192.0, memory_length 2000, epsilon 0.7200029282258205\n",
      "travel time- 726.0\n",
      "--- 1.7759754657745361 seconds ---\n",
      "episode 658, reward -293.0, memory_length 2000, epsilon 0.7196430167470754\n",
      "travel time- 722.0\n",
      "--- 1.6418745517730713 seconds ---\n",
      "episode 659, reward -84.0, memory_length 2000, epsilon 0.7192832851790882\n",
      "travel time- 721.0\n",
      "--- 1.6123158931732178 seconds ---\n",
      "episode 660, reward -237.0, memory_length 2000, epsilon 0.7189237334319262\n",
      "travel time- 721.0\n",
      "--- 1.8039653301239014 seconds ---\n",
      "episode 661, reward -94.0, memory_length 2000, epsilon 0.7185643614157011\n",
      "travel time- 721.0\n",
      "--- 1.7688705921173096 seconds ---\n",
      "episode 662, reward -528.0, memory_length 2000, epsilon 0.7182051690405703\n",
      "travel time- 724.0\n",
      "--- 1.69150972366333 seconds ---\n",
      "episode 663, reward -425.0, memory_length 2000, epsilon 0.7178461562167354\n",
      "travel time- 722.0\n",
      "--- 1.8224782943725586 seconds ---\n",
      "episode 664, reward -176.0, memory_length 2000, epsilon 0.7174873228544433\n",
      "travel time- 721.0\n",
      "--- 1.8080213069915771 seconds ---\n",
      "episode 665, reward 28.0, memory_length 2000, epsilon 0.7171286688639856\n",
      "travel time- 727.0\n",
      "--- 1.639244556427002 seconds ---\n",
      "episode 666, reward -188.0, memory_length 2000, epsilon 0.716770194155699\n",
      "travel time- 722.0\n",
      "--- 1.8601405620574951 seconds ---\n",
      "episode 667, reward -358.0, memory_length 2000, epsilon 0.7164118986399645\n",
      "travel time- 722.0\n",
      "--- 1.5812475681304932 seconds ---\n",
      "episode 668, reward -84.0, memory_length 2000, epsilon 0.7160537822272085\n",
      "travel time- 723.0\n",
      "--- 1.6739006042480469 seconds ---\n",
      "episode 669, reward -179.0, memory_length 2000, epsilon 0.7156958448279017\n",
      "travel time- 727.0\n",
      "--- 1.6682713031768799 seconds ---\n",
      "episode 670, reward -50.0, memory_length 2000, epsilon 0.7153380863525599\n",
      "travel time- 720.0\n",
      "--- 1.6172912120819092 seconds ---\n",
      "episode 671, reward -68.0, memory_length 2000, epsilon 0.7149805067117434\n",
      "travel time- 729.0\n",
      "--- 1.6900086402893066 seconds ---\n",
      "episode 672, reward -484.0, memory_length 2000, epsilon 0.7146231058160573\n",
      "travel time- 725.0\n",
      "--- 1.7560317516326904 seconds ---\n",
      "episode 673, reward -464.0, memory_length 2000, epsilon 0.7142658835761514\n",
      "travel time- 726.0\n",
      "--- 1.8647119998931885 seconds ---\n",
      "episode 674, reward -85.0, memory_length 2000, epsilon 0.71390883990272\n",
      "travel time- 726.0\n",
      "--- 1.744450569152832 seconds ---\n",
      "episode 675, reward -204.0, memory_length 2000, epsilon 0.7135519747065024\n",
      "travel time- 729.0\n",
      "--- 1.667771816253662 seconds ---\n",
      "episode 676, reward -125.0, memory_length 2000, epsilon 0.7131952878982822\n",
      "travel time- 727.0\n",
      "--- 1.8321669101715088 seconds ---\n",
      "episode 677, reward -178.0, memory_length 2000, epsilon 0.7128387793888877\n",
      "travel time- 724.0\n",
      "--- 1.6567015647888184 seconds ---\n",
      "episode 678, reward -76.0, memory_length 2000, epsilon 0.7124824490891918\n",
      "travel time- 721.0\n",
      "--- 1.67081880569458 seconds ---\n",
      "episode 679, reward -225.0, memory_length 2000, epsilon 0.7121262969101118\n",
      "travel time- 725.0\n",
      "--- 1.8035411834716797 seconds ---\n",
      "episode 680, reward 73.0, memory_length 2000, epsilon 0.7117703227626097\n",
      "travel time- 720.0\n",
      "--- 1.6030311584472656 seconds ---\n",
      "episode 681, reward -319.0, memory_length 2000, epsilon 0.711414526557692\n",
      "travel time- 722.0\n",
      "--- 1.8461575508117676 seconds ---\n",
      "episode 682, reward -147.0, memory_length 2000, epsilon 0.7110589082064097\n",
      "travel time- 720.0\n",
      "--- 1.7052116394042969 seconds ---\n",
      "episode 683, reward -39.0, memory_length 2000, epsilon 0.7107034676198581\n",
      "travel time- 733.0\n",
      "--- 1.789393663406372 seconds ---\n",
      "episode 684, reward -266.0, memory_length 2000, epsilon 0.7103482047091773\n",
      "travel time- 721.0\n",
      "--- 1.7784953117370605 seconds ---\n",
      "episode 685, reward 40.0, memory_length 2000, epsilon 0.7099931193855512\n",
      "travel time- 720.0\n",
      "--- 1.7304139137268066 seconds ---\n",
      "episode 686, reward -413.0, memory_length 2000, epsilon 0.7096382115602087\n",
      "travel time- 720.0\n",
      "--- 1.9088506698608398 seconds ---\n",
      "episode 687, reward -6.0, memory_length 2000, epsilon 0.7092834811444226\n",
      "travel time- 727.0\n",
      "--- 1.7754037380218506 seconds ---\n",
      "episode 688, reward 243.0, memory_length 2000, epsilon 0.7089289280495107\n",
      "travel time- 720.0\n",
      "--- 1.8285739421844482 seconds ---\n",
      "episode 689, reward -242.0, memory_length 2000, epsilon 0.7085745521868345\n",
      "travel time- 726.0\n",
      "--- 1.8382327556610107 seconds ---\n",
      "episode 690, reward 32.0, memory_length 2000, epsilon 0.7082203534678\n",
      "travel time- 728.0\n",
      "--- 1.7151899337768555 seconds ---\n",
      "episode 691, reward -23.0, memory_length 2000, epsilon 0.7078663318038575\n",
      "travel time- 726.0\n",
      "--- 1.6950616836547852 seconds ---\n",
      "episode 692, reward -12.0, memory_length 2000, epsilon 0.7075124871065016\n",
      "travel time- 720.0\n",
      "--- 1.8129446506500244 seconds ---\n",
      "episode 693, reward -90.0, memory_length 2000, epsilon 0.7071588192872713\n",
      "travel time- 723.0\n",
      "--- 1.5146982669830322 seconds ---\n",
      "episode 694, reward -403.0, memory_length 2000, epsilon 0.7068053282577494\n",
      "travel time- 724.0\n",
      "--- 1.746063470840454 seconds ---\n",
      "episode 695, reward -136.0, memory_length 2000, epsilon 0.7064520139295634\n",
      "travel time- 720.0\n",
      "--- 1.6775784492492676 seconds ---\n",
      "episode 696, reward -500.0, memory_length 2000, epsilon 0.7060988762143844\n",
      "travel time- 733.0\n",
      "--- 1.718470811843872 seconds ---\n",
      "episode 697, reward 42.0, memory_length 2000, epsilon 0.7057459150239281\n",
      "travel time- 721.0\n",
      "--- 1.619297981262207 seconds ---\n",
      "episode 698, reward -10.0, memory_length 2000, epsilon 0.7053931302699543\n",
      "travel time- 725.0\n",
      "--- 1.71224045753479 seconds ---\n",
      "episode 699, reward -69.0, memory_length 2000, epsilon 0.7050405218642668\n",
      "travel time- 720.0\n",
      "--- 1.7080271244049072 seconds ---\n",
      "episode 700, reward -231.0, memory_length 2000, epsilon 0.7046880897187134\n",
      "travel time- 727.0\n",
      "--- 1.5683186054229736 seconds ---\n",
      "episode 701, reward 328.0, memory_length 2000, epsilon 0.7043358337451862\n",
      "travel time- 723.0\n",
      "--- 1.8266322612762451 seconds ---\n",
      "episode 702, reward -43.0, memory_length 2000, epsilon 0.703983753855621\n",
      "travel time- 731.0\n",
      "--- 1.7694764137268066 seconds ---\n",
      "episode 703, reward 3.0, memory_length 2000, epsilon 0.7036318499619978\n",
      "travel time- 729.0\n",
      "--- 1.77036452293396 seconds ---\n",
      "episode 704, reward -415.0, memory_length 2000, epsilon 0.7032801219763409\n",
      "travel time- 722.0\n",
      "--- 2.0833468437194824 seconds ---\n",
      "episode 705, reward 44.0, memory_length 2000, epsilon 0.7029285698107182\n",
      "travel time- 723.0\n",
      "--- 1.7780964374542236 seconds ---\n",
      "episode 706, reward -215.0, memory_length 2000, epsilon 0.7025771933772416\n",
      "travel time- 723.0\n",
      "--- 1.8639552593231201 seconds ---\n",
      "episode 707, reward -127.0, memory_length 2000, epsilon 0.7022259925880668\n",
      "travel time- 721.0\n",
      "--- 1.608717441558838 seconds ---\n",
      "episode 708, reward 190.0, memory_length 2000, epsilon 0.701874967355394\n",
      "travel time- 726.0\n",
      "--- 1.797774076461792 seconds ---\n",
      "episode 709, reward -71.0, memory_length 2000, epsilon 0.7015241175914667\n",
      "travel time- 727.0\n",
      "--- 1.6592540740966797 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 710, reward -151.0, memory_length 2000, epsilon 0.7011734432085724\n",
      "travel time- 724.0\n",
      "--- 1.8793566226959229 seconds ---\n",
      "episode 711, reward -270.0, memory_length 2000, epsilon 0.7008229441190426\n",
      "travel time- 726.0\n",
      "--- 1.6879515647888184 seconds ---\n",
      "episode 712, reward -237.0, memory_length 2000, epsilon 0.7004726202352524\n",
      "travel time- 728.0\n",
      "--- 1.6556668281555176 seconds ---\n",
      "episode 713, reward -509.0, memory_length 2000, epsilon 0.7001224714696209\n",
      "travel time- 722.0\n",
      "--- 1.444382905960083 seconds ---\n",
      "episode 714, reward -304.0, memory_length 2000, epsilon 0.699772497734611\n",
      "travel time- 720.0\n",
      "--- 1.6466569900512695 seconds ---\n",
      "episode 715, reward -237.0, memory_length 2000, epsilon 0.6994226989427291\n",
      "travel time- 721.0\n",
      "--- 1.733656644821167 seconds ---\n",
      "episode 716, reward -205.0, memory_length 2000, epsilon 0.6990730750065257\n",
      "travel time- 728.0\n",
      "--- 1.668463945388794 seconds ---\n",
      "episode 717, reward -97.0, memory_length 2000, epsilon 0.6987236258385946\n",
      "travel time- 727.0\n",
      "--- 1.5558183193206787 seconds ---\n",
      "episode 718, reward 33.0, memory_length 2000, epsilon 0.6983743513515736\n",
      "travel time- 720.0\n",
      "--- 1.694645643234253 seconds ---\n",
      "episode 719, reward 55.0, memory_length 2000, epsilon 0.6980252514581441\n",
      "travel time- 720.0\n",
      "--- 1.724442481994629 seconds ---\n",
      "episode 720, reward -175.0, memory_length 2000, epsilon 0.697676326071031\n",
      "travel time- 720.0\n",
      "--- 1.581326961517334 seconds ---\n",
      "episode 721, reward -376.0, memory_length 2000, epsilon 0.6973275751030032\n",
      "travel time- 720.0\n",
      "--- 1.8261642456054688 seconds ---\n",
      "episode 722, reward -22.0, memory_length 2000, epsilon 0.6969789984668727\n",
      "travel time- 723.0\n",
      "--- 1.5149195194244385 seconds ---\n",
      "episode 723, reward -157.0, memory_length 2000, epsilon 0.6966305960754955\n",
      "travel time- 727.0\n",
      "--- 2.1472158432006836 seconds ---\n",
      "episode 724, reward 92.0, memory_length 2000, epsilon 0.696282367841771\n",
      "travel time- 720.0\n",
      "--- 1.5936808586120605 seconds ---\n",
      "episode 725, reward -272.0, memory_length 2000, epsilon 0.695934313678642\n",
      "travel time- 722.0\n",
      "--- 1.538118600845337 seconds ---\n",
      "episode 726, reward -26.0, memory_length 2000, epsilon 0.6955864334990951\n",
      "travel time- 720.0\n",
      "--- 1.7422947883605957 seconds ---\n",
      "episode 727, reward -267.0, memory_length 2000, epsilon 0.6952387272161601\n",
      "travel time- 723.0\n",
      "--- 1.6566357612609863 seconds ---\n",
      "episode 728, reward -244.0, memory_length 2000, epsilon 0.6948911947429106\n",
      "travel time- 727.0\n",
      "--- 1.8301358222961426 seconds ---\n",
      "episode 729, reward -59.0, memory_length 2000, epsilon 0.6945438359924634\n",
      "travel time- 729.0\n",
      "--- 1.8512156009674072 seconds ---\n",
      "episode 730, reward -216.0, memory_length 2000, epsilon 0.6941966508779789\n",
      "travel time- 733.0\n",
      "--- 1.690800428390503 seconds ---\n",
      "episode 731, reward -65.0, memory_length 2000, epsilon 0.6938496393126606\n",
      "travel time- 722.0\n",
      "--- 1.779726266860962 seconds ---\n",
      "episode 732, reward -339.0, memory_length 2000, epsilon 0.6935028012097558\n",
      "travel time- 721.0\n",
      "--- 1.6091749668121338 seconds ---\n",
      "episode 733, reward -84.0, memory_length 2000, epsilon 0.6931561364825549\n",
      "travel time- 721.0\n",
      "--- 1.74102783203125 seconds ---\n",
      "episode 734, reward -292.0, memory_length 2000, epsilon 0.6928096450443917\n",
      "travel time- 723.0\n",
      "--- 1.8301866054534912 seconds ---\n",
      "episode 735, reward -138.0, memory_length 2000, epsilon 0.6924633268086434\n",
      "travel time- 720.0\n",
      "--- 1.8572742938995361 seconds ---\n",
      "episode 736, reward -135.0, memory_length 2000, epsilon 0.6921171816887304\n",
      "travel time- 725.0\n",
      "--- 1.6621999740600586 seconds ---\n",
      "episode 737, reward -278.0, memory_length 2000, epsilon 0.6917712095981164\n",
      "travel time- 724.0\n",
      "--- 1.6609055995941162 seconds ---\n",
      "episode 738, reward -131.0, memory_length 2000, epsilon 0.6914254104503085\n",
      "travel time- 729.0\n",
      "--- 1.7771034240722656 seconds ---\n",
      "episode 739, reward -34.0, memory_length 2000, epsilon 0.6910797841588567\n",
      "travel time- 721.0\n",
      "--- 1.5686771869659424 seconds ---\n",
      "episode 740, reward -229.0, memory_length 2000, epsilon 0.6907343306373547\n",
      "travel time- 720.0\n",
      "--- 1.8340885639190674 seconds ---\n",
      "episode 741, reward -331.0, memory_length 2000, epsilon 0.6903890497994388\n",
      "travel time- 723.0\n",
      "--- 1.6981711387634277 seconds ---\n",
      "episode 742, reward 62.0, memory_length 2000, epsilon 0.690043941558789\n",
      "travel time- 721.0\n",
      "--- 1.522857904434204 seconds ---\n",
      "episode 743, reward -89.0, memory_length 2000, epsilon 0.6896990058291282\n",
      "travel time- 729.0\n",
      "--- 1.616708517074585 seconds ---\n",
      "episode 744, reward -225.0, memory_length 2000, epsilon 0.6893542425242224\n",
      "travel time- 721.0\n",
      "--- 1.7604377269744873 seconds ---\n",
      "episode 745, reward -210.0, memory_length 2000, epsilon 0.6890096515578809\n",
      "travel time- 728.0\n",
      "--- 1.5766761302947998 seconds ---\n",
      "episode 746, reward -261.0, memory_length 2000, epsilon 0.6886652328439558\n",
      "travel time- 726.0\n",
      "--- 1.928361415863037 seconds ---\n",
      "episode 747, reward -376.0, memory_length 2000, epsilon 0.6883209862963425\n",
      "travel time- 723.0\n",
      "--- 1.7468059062957764 seconds ---\n",
      "episode 748, reward -128.0, memory_length 2000, epsilon 0.6879769118289795\n",
      "travel time- 725.0\n",
      "--- 1.727043628692627 seconds ---\n",
      "episode 749, reward 182.0, memory_length 2000, epsilon 0.6876330093558478\n",
      "travel time- 725.0\n",
      "--- 1.7074546813964844 seconds ---\n",
      "episode 750, reward 150.0, memory_length 2000, epsilon 0.6872892787909722\n",
      "travel time- 723.0\n",
      "--- 1.6308534145355225 seconds ---\n",
      "episode 751, reward -244.0, memory_length 2000, epsilon 0.6869457200484198\n",
      "travel time- 723.0\n",
      "--- 1.972170352935791 seconds ---\n",
      "episode 752, reward -320.0, memory_length 2000, epsilon 0.686602333042301\n",
      "travel time- 720.0\n",
      "--- 1.7885568141937256 seconds ---\n",
      "episode 753, reward -93.0, memory_length 2000, epsilon 0.6862591176867691\n",
      "travel time- 729.0\n",
      "--- 1.7667632102966309 seconds ---\n",
      "episode 754, reward -80.0, memory_length 2000, epsilon 0.6859160738960202\n",
      "travel time- 725.0\n",
      "--- 1.9464569091796875 seconds ---\n",
      "episode 755, reward -178.0, memory_length 2000, epsilon 0.6855732015842932\n",
      "travel time- 723.0\n",
      "--- 1.765782356262207 seconds ---\n",
      "episode 756, reward -387.0, memory_length 2000, epsilon 0.6852305006658703\n",
      "travel time- 725.0\n",
      "--- 2.001126289367676 seconds ---\n",
      "episode 757, reward 119.0, memory_length 2000, epsilon 0.684887971055076\n",
      "travel time- 721.0\n",
      "--- 1.6555500030517578 seconds ---\n",
      "episode 758, reward -216.0, memory_length 2000, epsilon 0.6845456126662782\n",
      "travel time- 724.0\n",
      "--- 1.6004347801208496 seconds ---\n",
      "episode 759, reward -12.0, memory_length 2000, epsilon 0.6842034254138871\n",
      "travel time- 723.0\n",
      "--- 1.3945395946502686 seconds ---\n",
      "episode 760, reward 108.0, memory_length 2000, epsilon 0.6838614092123558\n",
      "travel time- 722.0\n",
      "--- 1.9044952392578125 seconds ---\n",
      "episode 761, reward -190.0, memory_length 2000, epsilon 0.6835195639761805\n",
      "travel time- 722.0\n",
      "--- 1.8009049892425537 seconds ---\n",
      "episode 762, reward -261.0, memory_length 2000, epsilon 0.6831778896198997\n",
      "travel time- 725.0\n",
      "--- 1.7183830738067627 seconds ---\n",
      "episode 763, reward -114.0, memory_length 2000, epsilon 0.6828363860580948\n",
      "travel time- 721.0\n",
      "--- 1.6158215999603271 seconds ---\n",
      "episode 764, reward -110.0, memory_length 2000, epsilon 0.6824950532053901\n",
      "travel time- 723.0\n",
      "--- 1.8104255199432373 seconds ---\n",
      "episode 765, reward -201.0, memory_length 2000, epsilon 0.6821538909764522\n",
      "travel time- 720.0\n",
      "--- 1.6669561862945557 seconds ---\n",
      "episode 766, reward -472.0, memory_length 2000, epsilon 0.6818128992859905\n",
      "travel time- 721.0\n",
      "--- 1.7096049785614014 seconds ---\n",
      "episode 767, reward -348.0, memory_length 2000, epsilon 0.6814720780487573\n",
      "travel time- 724.0\n",
      "--- 1.6629021167755127 seconds ---\n",
      "episode 768, reward -181.0, memory_length 2000, epsilon 0.6811314271795471\n",
      "travel time- 726.0\n",
      "--- 1.5404775142669678 seconds ---\n",
      "episode 769, reward -297.0, memory_length 2000, epsilon 0.6807909465931973\n",
      "travel time- 721.0\n",
      "--- 1.545212984085083 seconds ---\n",
      "episode 770, reward -138.0, memory_length 2000, epsilon 0.6804506362045877\n",
      "travel time- 721.0\n",
      "--- 1.685354471206665 seconds ---\n",
      "episode 771, reward -187.0, memory_length 2000, epsilon 0.6801104959286406\n",
      "travel time- 723.0\n",
      "--- 1.8932170867919922 seconds ---\n",
      "episode 772, reward 20.0, memory_length 2000, epsilon 0.679770525680321\n",
      "travel time- 721.0\n",
      "--- 1.54447340965271 seconds ---\n",
      "episode 773, reward -130.0, memory_length 2000, epsilon 0.6794307253746364\n",
      "travel time- 730.0\n",
      "--- 1.6928718090057373 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 774, reward -86.0, memory_length 2000, epsilon 0.6790910949266368\n",
      "travel time- 726.0\n",
      "--- 1.7920432090759277 seconds ---\n",
      "episode 775, reward -217.0, memory_length 2000, epsilon 0.6787516342514144\n",
      "travel time- 721.0\n",
      "--- 1.7799456119537354 seconds ---\n",
      "episode 776, reward -127.0, memory_length 2000, epsilon 0.678412343264104\n",
      "travel time- 727.0\n",
      "--- 1.7335114479064941 seconds ---\n",
      "episode 777, reward 123.0, memory_length 2000, epsilon 0.6780732218798831\n",
      "travel time- 728.0\n",
      "--- 1.7881710529327393 seconds ---\n",
      "episode 778, reward 32.0, memory_length 2000, epsilon 0.6777342700139711\n",
      "travel time- 720.0\n",
      "--- 1.7472543716430664 seconds ---\n",
      "episode 779, reward -46.0, memory_length 2000, epsilon 0.6773954875816302\n",
      "travel time- 726.0\n",
      "--- 1.626112937927246 seconds ---\n",
      "episode 780, reward -282.0, memory_length 2000, epsilon 0.6770568744981647\n",
      "travel time- 728.0\n",
      "--- 1.8730952739715576 seconds ---\n",
      "episode 781, reward 9.0, memory_length 2000, epsilon 0.6767184306789213\n",
      "travel time- 725.0\n",
      "--- 1.4981377124786377 seconds ---\n",
      "episode 782, reward -186.0, memory_length 2000, epsilon 0.6763801560392891\n",
      "travel time- 726.0\n",
      "--- 1.5585861206054688 seconds ---\n",
      "episode 783, reward -138.0, memory_length 2000, epsilon 0.6760420504946996\n",
      "travel time- 721.0\n",
      "--- 1.9778335094451904 seconds ---\n",
      "episode 784, reward 233.0, memory_length 2000, epsilon 0.675704113960626\n",
      "travel time- 729.0\n",
      "--- 1.656388521194458 seconds ---\n",
      "episode 785, reward -51.0, memory_length 2000, epsilon 0.6753663463525845\n",
      "travel time- 722.0\n",
      "--- 1.7553331851959229 seconds ---\n",
      "episode 786, reward -258.0, memory_length 2000, epsilon 0.6750287475861332\n",
      "travel time- 729.0\n",
      "--- 1.8755745887756348 seconds ---\n",
      "episode 787, reward -284.0, memory_length 2000, epsilon 0.6746913175768723\n",
      "travel time- 726.0\n",
      "--- 2.044003963470459 seconds ---\n",
      "episode 788, reward 346.0, memory_length 2000, epsilon 0.6743540562404442\n",
      "travel time- 725.0\n",
      "--- 1.6370015144348145 seconds ---\n",
      "episode 789, reward 1.0, memory_length 2000, epsilon 0.6740169634925337\n",
      "travel time- 721.0\n",
      "--- 1.6945405006408691 seconds ---\n",
      "episode 790, reward -268.0, memory_length 2000, epsilon 0.6736800392488677\n",
      "travel time- 724.0\n",
      "--- 2.2721712589263916 seconds ---\n",
      "episode 791, reward 55.0, memory_length 2000, epsilon 0.6733432834252149\n",
      "travel time- 723.0\n",
      "--- 1.8128015995025635 seconds ---\n",
      "episode 792, reward 120.0, memory_length 2000, epsilon 0.6730066959373864\n",
      "travel time- 722.0\n",
      "--- 1.3553838729858398 seconds ---\n",
      "episode 793, reward -58.0, memory_length 2000, epsilon 0.6726702767012355\n",
      "travel time- 723.0\n",
      "--- 1.708751916885376 seconds ---\n",
      "episode 794, reward 219.0, memory_length 2000, epsilon 0.6723340256326572\n",
      "travel time- 726.0\n",
      "--- 1.5685548782348633 seconds ---\n",
      "episode 795, reward -136.0, memory_length 2000, epsilon 0.6719979426475889\n",
      "travel time- 722.0\n",
      "--- 1.5135505199432373 seconds ---\n",
      "episode 796, reward 125.0, memory_length 2000, epsilon 0.6716620276620098\n",
      "travel time- 727.0\n",
      "--- 1.5394270420074463 seconds ---\n",
      "episode 797, reward -184.0, memory_length 2000, epsilon 0.671326280591941\n",
      "travel time- 721.0\n",
      "--- 1.6867246627807617 seconds ---\n",
      "episode 798, reward -244.0, memory_length 2000, epsilon 0.6709907013534459\n",
      "travel time- 721.0\n",
      "--- 1.8579411506652832 seconds ---\n",
      "episode 799, reward 47.0, memory_length 2000, epsilon 0.6706552898626296\n",
      "travel time- 728.0\n",
      "--- 1.8230631351470947 seconds ---\n",
      "episode 800, reward -116.0, memory_length 2000, epsilon 0.6703200460356393\n",
      "travel time- 721.0\n",
      "--- 1.8903536796569824 seconds ---\n",
      "episode 801, reward -251.0, memory_length 2000, epsilon 0.669984969788664\n",
      "travel time- 721.0\n",
      "--- 2.0244288444519043 seconds ---\n",
      "episode 802, reward 101.0, memory_length 2000, epsilon 0.6696500610379346\n",
      "travel time- 727.0\n",
      "--- 1.8139731884002686 seconds ---\n",
      "episode 803, reward -270.0, memory_length 2000, epsilon 0.6693153196997239\n",
      "travel time- 721.0\n",
      "--- 1.751328945159912 seconds ---\n",
      "episode 804, reward 30.0, memory_length 2000, epsilon 0.6689807456903467\n",
      "travel time- 720.0\n",
      "--- 1.7074754238128662 seconds ---\n",
      "episode 805, reward -107.0, memory_length 2000, epsilon 0.6686463389261594\n",
      "travel time- 734.0\n",
      "--- 1.6184463500976562 seconds ---\n",
      "episode 806, reward 48.0, memory_length 2000, epsilon 0.6683120993235603\n",
      "travel time- 721.0\n",
      "--- 1.5410897731781006 seconds ---\n",
      "episode 807, reward -219.0, memory_length 2000, epsilon 0.6679780267989895\n",
      "travel time- 723.0\n",
      "--- 1.60687255859375 seconds ---\n",
      "episode 808, reward -29.0, memory_length 2000, epsilon 0.6676441212689289\n",
      "travel time- 723.0\n",
      "--- 1.5359268188476562 seconds ---\n",
      "episode 809, reward -173.0, memory_length 2000, epsilon 0.6673103826499021\n",
      "travel time- 722.0\n",
      "--- 1.5905380249023438 seconds ---\n",
      "episode 810, reward 35.0, memory_length 2000, epsilon 0.6669768108584744\n",
      "travel time- 723.0\n",
      "--- 1.7429866790771484 seconds ---\n",
      "episode 811, reward 81.0, memory_length 2000, epsilon 0.6666434058112529\n",
      "travel time- 720.0\n",
      "--- 1.8586692810058594 seconds ---\n",
      "episode 812, reward 110.0, memory_length 2000, epsilon 0.6663101674248864\n",
      "travel time- 727.0\n",
      "--- 1.8805816173553467 seconds ---\n",
      "episode 813, reward -174.0, memory_length 2000, epsilon 0.6659770956160651\n",
      "travel time- 721.0\n",
      "--- 1.796863079071045 seconds ---\n",
      "episode 814, reward 67.0, memory_length 2000, epsilon 0.6656441903015212\n",
      "travel time- 724.0\n",
      "--- 1.8185420036315918 seconds ---\n",
      "episode 815, reward 86.0, memory_length 2000, epsilon 0.6653114513980284\n",
      "travel time- 722.0\n",
      "--- 1.5717387199401855 seconds ---\n",
      "episode 816, reward 54.0, memory_length 2000, epsilon 0.6649788788224019\n",
      "travel time- 726.0\n",
      "--- 1.8187050819396973 seconds ---\n",
      "episode 817, reward -357.0, memory_length 2000, epsilon 0.6646464724914986\n",
      "travel time- 720.0\n",
      "--- 1.621908187866211 seconds ---\n",
      "episode 818, reward -10.0, memory_length 2000, epsilon 0.6643142323222168\n",
      "travel time- 726.0\n",
      "--- 1.6104118824005127 seconds ---\n",
      "episode 819, reward -91.0, memory_length 2000, epsilon 0.6639821582314965\n",
      "travel time- 725.0\n",
      "--- 1.6885786056518555 seconds ---\n",
      "episode 820, reward -65.0, memory_length 2000, epsilon 0.6636502501363194\n",
      "travel time- 721.0\n",
      "--- 1.7138340473175049 seconds ---\n",
      "episode 821, reward -11.0, memory_length 2000, epsilon 0.6633185079537082\n",
      "travel time- 725.0\n",
      "--- 1.5786831378936768 seconds ---\n",
      "episode 822, reward -305.0, memory_length 2000, epsilon 0.6629869316007274\n",
      "travel time- 722.0\n",
      "--- 1.7796411514282227 seconds ---\n",
      "episode 823, reward 73.0, memory_length 2000, epsilon 0.662655520994483\n",
      "travel time- 721.0\n",
      "--- 1.6628990173339844 seconds ---\n",
      "episode 824, reward -91.0, memory_length 2000, epsilon 0.6623242760521222\n",
      "travel time- 733.0\n",
      "--- 1.7611033916473389 seconds ---\n",
      "episode 825, reward 114.0, memory_length 2000, epsilon 0.661993196690834\n",
      "travel time- 721.0\n",
      "--- 1.5976171493530273 seconds ---\n",
      "episode 826, reward -11.0, memory_length 2000, epsilon 0.6616622828278483\n",
      "travel time- 721.0\n",
      "--- 1.5408515930175781 seconds ---\n",
      "episode 827, reward 87.0, memory_length 2000, epsilon 0.6613315343804369\n",
      "travel time- 720.0\n",
      "--- 1.8278074264526367 seconds ---\n",
      "episode 828, reward -398.0, memory_length 2000, epsilon 0.6610009512659124\n",
      "travel time- 727.0\n",
      "--- 1.6881895065307617 seconds ---\n",
      "episode 829, reward -212.0, memory_length 2000, epsilon 0.6606705334016293\n",
      "travel time- 727.0\n",
      "--- 1.6852021217346191 seconds ---\n",
      "episode 830, reward 164.0, memory_length 2000, epsilon 0.6603402807049829\n",
      "travel time- 723.0\n",
      "--- 1.5657317638397217 seconds ---\n",
      "episode 831, reward -139.0, memory_length 2000, epsilon 0.6600101930934101\n",
      "travel time- 723.0\n",
      "--- 1.737299919128418 seconds ---\n",
      "episode 832, reward -180.0, memory_length 2000, epsilon 0.659680270484389\n",
      "travel time- 720.0\n",
      "--- 1.605086326599121 seconds ---\n",
      "episode 833, reward -161.0, memory_length 2000, epsilon 0.6593505127954391\n",
      "travel time- 721.0\n",
      "--- 1.6371428966522217 seconds ---\n",
      "episode 834, reward -94.0, memory_length 2000, epsilon 0.6590209199441207\n",
      "travel time- 720.0\n",
      "--- 1.4716236591339111 seconds ---\n",
      "episode 835, reward -451.0, memory_length 2000, epsilon 0.6586914918480358\n",
      "travel time- 730.0\n",
      "--- 1.6556313037872314 seconds ---\n",
      "episode 836, reward -142.0, memory_length 2000, epsilon 0.6583622284248272\n",
      "travel time- 724.0\n",
      "--- 1.7725105285644531 seconds ---\n",
      "episode 837, reward -115.0, memory_length 2000, epsilon 0.6580331295921792\n",
      "travel time- 725.0\n",
      "--- 1.6619269847869873 seconds ---\n",
      "episode 838, reward -381.0, memory_length 2000, epsilon 0.657704195267817\n",
      "travel time- 721.0\n",
      "--- 1.8001160621643066 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 839, reward -80.0, memory_length 2000, epsilon 0.657375425369507\n",
      "travel time- 721.0\n",
      "--- 1.6878278255462646 seconds ---\n",
      "episode 840, reward -488.0, memory_length 2000, epsilon 0.6570468198150567\n",
      "travel time- 726.0\n",
      "--- 1.7101709842681885 seconds ---\n",
      "episode 841, reward 29.0, memory_length 2000, epsilon 0.656718378522315\n",
      "travel time- 724.0\n",
      "--- 1.755486011505127 seconds ---\n",
      "episode 842, reward -268.0, memory_length 2000, epsilon 0.6563901014091712\n",
      "travel time- 720.0\n",
      "--- 1.873671054840088 seconds ---\n",
      "episode 843, reward -48.0, memory_length 2000, epsilon 0.6560619883935562\n",
      "travel time- 723.0\n",
      "--- 1.6179776191711426 seconds ---\n",
      "episode 844, reward -20.0, memory_length 2000, epsilon 0.6557340393934418\n",
      "travel time- 721.0\n",
      "--- 1.896219253540039 seconds ---\n",
      "episode 845, reward -157.0, memory_length 2000, epsilon 0.6554062543268405\n",
      "travel time- 722.0\n",
      "--- 1.7986762523651123 seconds ---\n",
      "episode 846, reward -114.0, memory_length 2000, epsilon 0.6550786331118063\n",
      "travel time- 727.0\n",
      "--- 1.6475210189819336 seconds ---\n",
      "episode 847, reward -122.0, memory_length 2000, epsilon 0.6547511756664338\n",
      "travel time- 727.0\n",
      "--- 1.7815172672271729 seconds ---\n",
      "episode 848, reward 292.0, memory_length 2000, epsilon 0.6544238819088586\n",
      "travel time- 720.0\n",
      "--- 1.5540814399719238 seconds ---\n",
      "episode 849, reward -209.0, memory_length 2000, epsilon 0.6540967517572572\n",
      "travel time- 722.0\n",
      "--- 1.9318997859954834 seconds ---\n",
      "episode 850, reward -27.0, memory_length 2000, epsilon 0.6537697851298473\n",
      "travel time- 721.0\n",
      "--- 1.6484143733978271 seconds ---\n",
      "episode 851, reward 52.0, memory_length 2000, epsilon 0.653442981944887\n",
      "travel time- 726.0\n",
      "--- 1.7123115062713623 seconds ---\n",
      "episode 852, reward -45.0, memory_length 2000, epsilon 0.6531163421206756\n",
      "travel time- 722.0\n",
      "--- 1.614988088607788 seconds ---\n",
      "episode 853, reward 178.0, memory_length 2000, epsilon 0.6527898655755532\n",
      "travel time- 725.0\n",
      "--- 1.4860949516296387 seconds ---\n",
      "episode 854, reward -242.0, memory_length 2000, epsilon 0.6524635522279004\n",
      "travel time- 724.0\n",
      "--- 1.7012708187103271 seconds ---\n",
      "episode 855, reward -263.0, memory_length 2000, epsilon 0.6521374019961392\n",
      "travel time- 722.0\n",
      "--- 1.4570093154907227 seconds ---\n",
      "episode 856, reward 0.0, memory_length 2000, epsilon 0.651811414798732\n",
      "travel time- 720.0\n",
      "--- 1.6141862869262695 seconds ---\n",
      "episode 857, reward -90.0, memory_length 2000, epsilon 0.6514855905541818\n",
      "travel time- 731.0\n",
      "--- 1.8768706321716309 seconds ---\n",
      "episode 858, reward -94.0, memory_length 2000, epsilon 0.6511599291810325\n",
      "travel time- 722.0\n",
      "--- 1.7622637748718262 seconds ---\n",
      "episode 859, reward -167.0, memory_length 2000, epsilon 0.650834430597869\n",
      "travel time- 730.0\n",
      "--- 1.7103877067565918 seconds ---\n",
      "episode 860, reward 56.0, memory_length 2000, epsilon 0.6505090947233165\n",
      "travel time- 727.0\n",
      "--- 1.4880566596984863 seconds ---\n",
      "episode 861, reward -135.0, memory_length 2000, epsilon 0.6501839214760412\n",
      "travel time- 720.0\n",
      "--- 1.4603114128112793 seconds ---\n",
      "episode 862, reward -57.0, memory_length 2000, epsilon 0.6498589107747496\n",
      "travel time- 721.0\n",
      "--- 1.8138842582702637 seconds ---\n",
      "episode 863, reward -303.0, memory_length 2000, epsilon 0.6495340625381889\n",
      "travel time- 722.0\n",
      "--- 1.6914513111114502 seconds ---\n",
      "episode 864, reward 1.0, memory_length 2000, epsilon 0.6492093766851474\n",
      "travel time- 723.0\n",
      "--- 1.5151026248931885 seconds ---\n",
      "episode 865, reward -394.0, memory_length 2000, epsilon 0.6488848531344534\n",
      "travel time- 732.0\n",
      "--- 1.666919231414795 seconds ---\n",
      "episode 866, reward -164.0, memory_length 2000, epsilon 0.6485604918049761\n",
      "travel time- 726.0\n",
      "--- 1.8483529090881348 seconds ---\n",
      "episode 867, reward -219.0, memory_length 2000, epsilon 0.6482362926156251\n",
      "travel time- 728.0\n",
      "--- 1.816941499710083 seconds ---\n",
      "episode 868, reward -191.0, memory_length 2000, epsilon 0.6479122554853506\n",
      "travel time- 727.0\n",
      "--- 1.4753668308258057 seconds ---\n",
      "episode 869, reward -478.0, memory_length 2000, epsilon 0.6475883803331434\n",
      "travel time- 724.0\n",
      "--- 1.670649766921997 seconds ---\n",
      "episode 870, reward 45.0, memory_length 2000, epsilon 0.6472646670780347\n",
      "travel time- 727.0\n",
      "--- 1.6326735019683838 seconds ---\n",
      "episode 871, reward -347.0, memory_length 2000, epsilon 0.646941115639096\n",
      "travel time- 734.0\n",
      "--- 1.736726999282837 seconds ---\n",
      "episode 872, reward -76.0, memory_length 2000, epsilon 0.6466177259354396\n",
      "travel time- 724.0\n",
      "--- 1.6036901473999023 seconds ---\n",
      "episode 873, reward -432.0, memory_length 2000, epsilon 0.6462944978862182\n",
      "travel time- 720.0\n",
      "--- 1.7720005512237549 seconds ---\n",
      "episode 874, reward 62.0, memory_length 2000, epsilon 0.6459714314106245\n",
      "travel time- 721.0\n",
      "--- 1.6955914497375488 seconds ---\n",
      "episode 875, reward 45.0, memory_length 2000, epsilon 0.645648526427892\n",
      "travel time- 725.0\n",
      "--- 1.7196376323699951 seconds ---\n",
      "episode 876, reward -4.0, memory_length 2000, epsilon 0.6453257828572946\n",
      "travel time- 721.0\n",
      "--- 1.8556370735168457 seconds ---\n",
      "episode 877, reward -229.0, memory_length 2000, epsilon 0.6450032006181462\n",
      "travel time- 729.0\n",
      "--- 1.7531046867370605 seconds ---\n",
      "episode 878, reward -215.0, memory_length 2000, epsilon 0.6446807796298013\n",
      "travel time- 723.0\n",
      "--- 1.6358716487884521 seconds ---\n",
      "episode 879, reward -1.0, memory_length 2000, epsilon 0.6443585198116547\n",
      "travel time- 723.0\n",
      "--- 1.660860538482666 seconds ---\n",
      "episode 880, reward -166.0, memory_length 2000, epsilon 0.6440364210831414\n",
      "travel time- 724.0\n",
      "--- 1.7945573329925537 seconds ---\n",
      "episode 881, reward -46.0, memory_length 2000, epsilon 0.6437144833637367\n",
      "travel time- 721.0\n",
      "--- 1.7024400234222412 seconds ---\n",
      "episode 882, reward -192.0, memory_length 2000, epsilon 0.6433927065729562\n",
      "travel time- 732.0\n",
      "--- 1.8920009136199951 seconds ---\n",
      "episode 883, reward -25.0, memory_length 2000, epsilon 0.6430710906303557\n",
      "travel time- 721.0\n",
      "--- 1.885810375213623 seconds ---\n",
      "episode 884, reward -557.0, memory_length 2000, epsilon 0.6427496354555312\n",
      "travel time- 725.0\n",
      "--- 1.992872714996338 seconds ---\n",
      "episode 885, reward -53.0, memory_length 2000, epsilon 0.642428340968119\n",
      "travel time- 729.0\n",
      "--- 1.6809608936309814 seconds ---\n",
      "episode 886, reward -276.0, memory_length 2000, epsilon 0.6421072070877952\n",
      "travel time- 723.0\n",
      "--- 1.989893913269043 seconds ---\n",
      "episode 887, reward -55.0, memory_length 2000, epsilon 0.6417862337342767\n",
      "travel time- 720.0\n",
      "--- 1.5245883464813232 seconds ---\n",
      "episode 888, reward -304.0, memory_length 2000, epsilon 0.6414654208273198\n",
      "travel time- 720.0\n",
      "--- 1.6168417930603027 seconds ---\n",
      "episode 889, reward 42.0, memory_length 2000, epsilon 0.6411447682867216\n",
      "travel time- 723.0\n",
      "--- 1.6524908542633057 seconds ---\n",
      "episode 890, reward 106.0, memory_length 2000, epsilon 0.6408242760323187\n",
      "travel time- 720.0\n",
      "--- 1.702085018157959 seconds ---\n",
      "episode 891, reward -282.0, memory_length 2000, epsilon 0.6405039439839882\n",
      "travel time- 720.0\n",
      "--- 1.8545787334442139 seconds ---\n",
      "episode 892, reward -277.0, memory_length 2000, epsilon 0.6401837720616471\n",
      "travel time- 722.0\n",
      "--- 1.6535148620605469 seconds ---\n",
      "episode 893, reward -503.0, memory_length 2000, epsilon 0.6398637601852523\n",
      "travel time- 727.0\n",
      "--- 1.9838194847106934 seconds ---\n",
      "episode 894, reward -202.0, memory_length 2000, epsilon 0.6395439082748009\n",
      "travel time- 727.0\n",
      "--- 1.543870210647583 seconds ---\n",
      "episode 895, reward 81.0, memory_length 2000, epsilon 0.6392242162503299\n",
      "travel time- 730.0\n",
      "--- 1.4778788089752197 seconds ---\n",
      "episode 896, reward 25.0, memory_length 2000, epsilon 0.6389046840319162\n",
      "travel time- 726.0\n",
      "--- 1.6316308975219727 seconds ---\n",
      "episode 897, reward 99.0, memory_length 2000, epsilon 0.6385853115396769\n",
      "travel time- 729.0\n",
      "--- 1.5387799739837646 seconds ---\n",
      "episode 898, reward -59.0, memory_length 2000, epsilon 0.6382660986937688\n",
      "travel time- 724.0\n",
      "--- 1.6238272190093994 seconds ---\n",
      "episode 899, reward -159.0, memory_length 2000, epsilon 0.6379470454143887\n",
      "travel time- 721.0\n",
      "--- 1.685896396636963 seconds ---\n",
      "episode 900, reward -200.0, memory_length 2000, epsilon 0.6376281516217733\n",
      "travel time- 727.0\n",
      "--- 1.6225850582122803 seconds ---\n",
      "episode 901, reward -191.0, memory_length 2000, epsilon 0.637309417236199\n",
      "travel time- 721.0\n",
      "--- 1.7871663570404053 seconds ---\n",
      "episode 902, reward -380.0, memory_length 2000, epsilon 0.6369908421779825\n",
      "travel time- 724.0\n",
      "--- 1.681612491607666 seconds ---\n",
      "episode 903, reward -32.0, memory_length 2000, epsilon 0.6366724263674798\n",
      "travel time- 734.0\n",
      "--- 1.6509530544281006 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 904, reward -236.0, memory_length 2000, epsilon 0.6363541697250871\n",
      "travel time- 724.0\n",
      "--- 1.7474868297576904 seconds ---\n",
      "episode 905, reward -153.0, memory_length 2000, epsilon 0.63603607217124\n",
      "travel time- 723.0\n",
      "--- 1.581383228302002 seconds ---\n",
      "episode 906, reward -241.0, memory_length 2000, epsilon 0.6357181336264143\n",
      "travel time- 723.0\n",
      "--- 1.7089974880218506 seconds ---\n",
      "episode 907, reward -101.0, memory_length 2000, epsilon 0.6354003540111253\n",
      "travel time- 724.0\n",
      "--- 1.6802701950073242 seconds ---\n",
      "episode 908, reward -211.0, memory_length 2000, epsilon 0.6350827332459281\n",
      "travel time- 728.0\n",
      "--- 1.6370861530303955 seconds ---\n",
      "episode 909, reward 101.0, memory_length 2000, epsilon 0.6347652712514176\n",
      "travel time- 720.0\n",
      "--- 1.3882005214691162 seconds ---\n",
      "episode 910, reward 79.0, memory_length 2000, epsilon 0.6344479679482282\n",
      "travel time- 721.0\n",
      "--- 1.6760377883911133 seconds ---\n",
      "episode 911, reward -125.0, memory_length 2000, epsilon 0.6341308232570341\n",
      "travel time- 723.0\n",
      "--- 1.7106471061706543 seconds ---\n",
      "episode 912, reward -39.0, memory_length 2000, epsilon 0.633813837098549\n",
      "travel time- 723.0\n",
      "--- 1.4834873676300049 seconds ---\n",
      "episode 913, reward -55.0, memory_length 2000, epsilon 0.6334970093935266\n",
      "travel time- 722.0\n",
      "--- 1.5650732517242432 seconds ---\n",
      "episode 914, reward -245.0, memory_length 2000, epsilon 0.6331803400627598\n",
      "travel time- 728.0\n",
      "--- 1.4464776515960693 seconds ---\n",
      "episode 915, reward -94.0, memory_length 2000, epsilon 0.6328638290270813\n",
      "travel time- 722.0\n",
      "--- 1.5715885162353516 seconds ---\n",
      "episode 916, reward -179.0, memory_length 2000, epsilon 0.6325474762073634\n",
      "travel time- 722.0\n",
      "--- 1.6331851482391357 seconds ---\n",
      "episode 917, reward -45.0, memory_length 2000, epsilon 0.6322312815245178\n",
      "travel time- 728.0\n",
      "--- 1.9064738750457764 seconds ---\n",
      "episode 918, reward -67.0, memory_length 2000, epsilon 0.6319152448994959\n",
      "travel time- 722.0\n",
      "--- 1.6873860359191895 seconds ---\n",
      "episode 919, reward -50.0, memory_length 2000, epsilon 0.6315993662532885\n",
      "travel time- 728.0\n",
      "--- 1.7938761711120605 seconds ---\n",
      "episode 920, reward 73.0, memory_length 2000, epsilon 0.631283645506926\n",
      "travel time- 728.0\n",
      "--- 1.6605570316314697 seconds ---\n",
      "episode 921, reward -198.0, memory_length 2000, epsilon 0.6309680825814781\n",
      "travel time- 726.0\n",
      "--- 1.639514684677124 seconds ---\n",
      "episode 922, reward 164.0, memory_length 2000, epsilon 0.6306526773980542\n",
      "travel time- 737.0\n",
      "--- 1.3908617496490479 seconds ---\n",
      "episode 923, reward 190.0, memory_length 2000, epsilon 0.6303374298778028\n",
      "travel time- 720.0\n",
      "--- 1.532778024673462 seconds ---\n",
      "episode 924, reward -255.0, memory_length 2000, epsilon 0.6300223399419123\n",
      "travel time- 722.0\n",
      "--- 1.5211372375488281 seconds ---\n",
      "episode 925, reward -279.0, memory_length 2000, epsilon 0.62970740751161\n",
      "travel time- 724.0\n",
      "--- 1.9230735301971436 seconds ---\n",
      "episode 926, reward 356.0, memory_length 2000, epsilon 0.6293926325081629\n",
      "travel time- 722.0\n",
      "--- 1.8359923362731934 seconds ---\n",
      "episode 927, reward -58.0, memory_length 2000, epsilon 0.6290780148528772\n",
      "travel time- 724.0\n",
      "--- 1.6095013618469238 seconds ---\n",
      "episode 928, reward 333.0, memory_length 2000, epsilon 0.6287635544670984\n",
      "travel time- 720.0\n",
      "--- 1.587801218032837 seconds ---\n",
      "episode 929, reward -242.0, memory_length 2000, epsilon 0.6284492512722115\n",
      "travel time- 726.0\n",
      "--- 1.6324667930603027 seconds ---\n",
      "episode 930, reward -327.0, memory_length 2000, epsilon 0.6281351051896408\n",
      "travel time- 723.0\n",
      "--- 1.6881916522979736 seconds ---\n",
      "episode 931, reward -83.0, memory_length 2000, epsilon 0.6278211161408496\n",
      "travel time- 728.0\n",
      "--- 1.5148496627807617 seconds ---\n",
      "episode 932, reward -279.0, memory_length 2000, epsilon 0.6275072840473407\n",
      "travel time- 728.0\n",
      "--- 1.8388965129852295 seconds ---\n",
      "episode 933, reward -187.0, memory_length 2000, epsilon 0.6271936088306561\n",
      "travel time- 720.0\n",
      "--- 1.5958707332611084 seconds ---\n",
      "episode 934, reward -287.0, memory_length 2000, epsilon 0.626880090412377\n",
      "travel time- 731.0\n",
      "--- 1.697852611541748 seconds ---\n",
      "episode 935, reward -6.0, memory_length 2000, epsilon 0.6265667287141238\n",
      "travel time- 721.0\n",
      "--- 1.4367117881774902 seconds ---\n",
      "episode 936, reward 181.0, memory_length 2000, epsilon 0.6262535236575559\n",
      "travel time- 721.0\n",
      "--- 1.7416634559631348 seconds ---\n",
      "episode 937, reward 19.0, memory_length 2000, epsilon 0.6259404751643723\n",
      "travel time- 733.0\n",
      "--- 1.6788244247436523 seconds ---\n",
      "episode 938, reward -475.0, memory_length 2000, epsilon 0.6256275831563107\n",
      "travel time- 728.0\n",
      "--- 1.5908124446868896 seconds ---\n",
      "episode 939, reward -153.0, memory_length 2000, epsilon 0.6253148475551482\n",
      "travel time- 721.0\n",
      "--- 1.632509708404541 seconds ---\n",
      "episode 940, reward -353.0, memory_length 2000, epsilon 0.6250022682827008\n",
      "travel time- 722.0\n",
      "--- 1.6278002262115479 seconds ---\n",
      "episode 941, reward 103.0, memory_length 2000, epsilon 0.6246898452608237\n",
      "travel time- 722.0\n",
      "--- 1.4452719688415527 seconds ---\n",
      "episode 942, reward 73.0, memory_length 2000, epsilon 0.6243775784114112\n",
      "travel time- 726.0\n",
      "--- 1.5417726039886475 seconds ---\n",
      "episode 943, reward -97.0, memory_length 2000, epsilon 0.6240654676563966\n",
      "travel time- 720.0\n",
      "--- 1.797888994216919 seconds ---\n",
      "episode 944, reward -352.0, memory_length 2000, epsilon 0.623753512917752\n",
      "travel time- 724.0\n",
      "--- 1.7383544445037842 seconds ---\n",
      "episode 945, reward -145.0, memory_length 2000, epsilon 0.623441714117489\n",
      "travel time- 725.0\n",
      "--- 1.8423526287078857 seconds ---\n",
      "episode 946, reward -197.0, memory_length 2000, epsilon 0.6231300711776578\n",
      "travel time- 720.0\n",
      "--- 1.5537376403808594 seconds ---\n",
      "episode 947, reward -484.0, memory_length 2000, epsilon 0.6228185840203476\n",
      "travel time- 728.0\n",
      "--- 1.5141658782958984 seconds ---\n",
      "episode 948, reward 272.0, memory_length 2000, epsilon 0.6225072525676867\n",
      "travel time- 720.0\n",
      "--- 1.7201206684112549 seconds ---\n",
      "episode 949, reward 165.0, memory_length 2000, epsilon 0.6221960767418422\n",
      "travel time- 724.0\n",
      "--- 1.5710875988006592 seconds ---\n",
      "episode 950, reward -196.0, memory_length 2000, epsilon 0.62188505646502\n",
      "travel time- 723.0\n",
      "--- 1.5327560901641846 seconds ---\n",
      "episode 951, reward -56.0, memory_length 2000, epsilon 0.6215741916594653\n",
      "travel time- 724.0\n",
      "--- 1.6711535453796387 seconds ---\n",
      "episode 952, reward -16.0, memory_length 2000, epsilon 0.6212634822474616\n",
      "travel time- 721.0\n",
      "--- 1.4770429134368896 seconds ---\n",
      "episode 953, reward 247.0, memory_length 2000, epsilon 0.6209529281513319\n",
      "travel time- 722.0\n",
      "--- 1.5410785675048828 seconds ---\n",
      "episode 954, reward 20.0, memory_length 2000, epsilon 0.6206425292934373\n",
      "travel time- 723.0\n",
      "--- 1.684089183807373 seconds ---\n",
      "episode 955, reward 3.0, memory_length 2000, epsilon 0.6203322855961783\n",
      "travel time- 725.0\n",
      "--- 1.4423017501831055 seconds ---\n",
      "episode 956, reward -236.0, memory_length 2000, epsilon 0.6200221969819939\n",
      "travel time- 728.0\n",
      "--- 1.6416985988616943 seconds ---\n",
      "episode 957, reward 355.0, memory_length 2000, epsilon 0.619712263373362\n",
      "travel time- 723.0\n",
      "--- 1.4619929790496826 seconds ---\n",
      "episode 958, reward -191.0, memory_length 2000, epsilon 0.6194024846927992\n",
      "travel time- 727.0\n",
      "--- 1.8331522941589355 seconds ---\n",
      "episode 959, reward 176.0, memory_length 2000, epsilon 0.6190928608628609\n",
      "travel time- 725.0\n",
      "--- 1.4209260940551758 seconds ---\n",
      "episode 960, reward 44.0, memory_length 2000, epsilon 0.6187833918061408\n",
      "travel time- 722.0\n",
      "--- 1.6971819400787354 seconds ---\n",
      "episode 961, reward -72.0, memory_length 2000, epsilon 0.618474077445272\n",
      "travel time- 721.0\n",
      "--- 1.558262825012207 seconds ---\n",
      "episode 962, reward 109.0, memory_length 2000, epsilon 0.6181649177029258\n",
      "travel time- 721.0\n",
      "--- 1.6880409717559814 seconds ---\n",
      "episode 963, reward -186.0, memory_length 2000, epsilon 0.6178559125018123\n",
      "travel time- 720.0\n",
      "--- 1.623054027557373 seconds ---\n",
      "episode 964, reward -206.0, memory_length 2000, epsilon 0.61754706176468\n",
      "travel time- 725.0\n",
      "--- 1.5792360305786133 seconds ---\n",
      "episode 965, reward 22.0, memory_length 2000, epsilon 0.6172383654143164\n",
      "travel time- 729.0\n",
      "--- 1.6934013366699219 seconds ---\n",
      "episode 966, reward 105.0, memory_length 2000, epsilon 0.6169298233735474\n",
      "travel time- 724.0\n",
      "--- 1.462831735610962 seconds ---\n",
      "episode 967, reward 137.0, memory_length 2000, epsilon 0.6166214355652375\n",
      "travel time- 726.0\n",
      "--- 1.4628214836120605 seconds ---\n",
      "episode 968, reward 120.0, memory_length 2000, epsilon 0.6163132019122897\n",
      "travel time- 723.0\n",
      "--- 1.6196510791778564 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 969, reward -104.0, memory_length 2000, epsilon 0.6160051223376455\n",
      "travel time- 727.0\n",
      "--- 1.6939582824707031 seconds ---\n",
      "episode 970, reward -127.0, memory_length 2000, epsilon 0.6156971967642851\n",
      "travel time- 721.0\n",
      "--- 1.5703957080841064 seconds ---\n",
      "episode 971, reward -187.0, memory_length 2000, epsilon 0.6153894251152272\n",
      "travel time- 726.0\n",
      "--- 1.5692412853240967 seconds ---\n",
      "episode 972, reward -306.0, memory_length 2000, epsilon 0.6150818073135287\n",
      "travel time- 724.0\n",
      "--- 1.7904648780822754 seconds ---\n",
      "episode 973, reward -122.0, memory_length 2000, epsilon 0.6147743432822852\n",
      "travel time- 722.0\n",
      "--- 1.8063037395477295 seconds ---\n",
      "episode 974, reward 74.0, memory_length 2000, epsilon 0.6144670329446308\n",
      "travel time- 723.0\n",
      "--- 1.7508623600006104 seconds ---\n",
      "episode 975, reward -232.0, memory_length 2000, epsilon 0.6141598762237378\n",
      "travel time- 727.0\n",
      "--- 1.5213351249694824 seconds ---\n",
      "episode 976, reward -71.0, memory_length 2000, epsilon 0.6138528730428171\n",
      "travel time- 722.0\n",
      "--- 1.6799285411834717 seconds ---\n",
      "episode 977, reward -140.0, memory_length 2000, epsilon 0.6135460233251178\n",
      "travel time- 725.0\n",
      "--- 1.7915418148040771 seconds ---\n",
      "episode 978, reward -409.0, memory_length 2000, epsilon 0.6132393269939275\n",
      "travel time- 721.0\n",
      "--- 1.938284158706665 seconds ---\n",
      "episode 979, reward -293.0, memory_length 2000, epsilon 0.6129327839725722\n",
      "travel time- 728.0\n",
      "--- 1.7703633308410645 seconds ---\n",
      "episode 980, reward -53.0, memory_length 2000, epsilon 0.6126263941844161\n",
      "travel time- 731.0\n",
      "--- 1.480165719985962 seconds ---\n",
      "episode 981, reward -223.0, memory_length 2000, epsilon 0.6123201575528617\n",
      "travel time- 723.0\n",
      "--- 1.5348052978515625 seconds ---\n",
      "episode 982, reward -187.0, memory_length 2000, epsilon 0.6120140740013499\n",
      "travel time- 727.0\n",
      "--- 1.7388043403625488 seconds ---\n",
      "episode 983, reward -185.0, memory_length 2000, epsilon 0.6117081434533598\n",
      "travel time- 721.0\n",
      "--- 1.627234697341919 seconds ---\n",
      "episode 984, reward -72.0, memory_length 2000, epsilon 0.6114023658324087\n",
      "travel time- 725.0\n",
      "--- 1.4363985061645508 seconds ---\n",
      "episode 985, reward -89.0, memory_length 2000, epsilon 0.6110967410620523\n",
      "travel time- 721.0\n",
      "--- 1.8118188381195068 seconds ---\n",
      "episode 986, reward -55.0, memory_length 2000, epsilon 0.6107912690658842\n",
      "travel time- 722.0\n",
      "--- 1.60614013671875 seconds ---\n",
      "episode 987, reward -354.0, memory_length 2000, epsilon 0.6104859497675367\n",
      "travel time- 720.0\n",
      "--- 1.6972057819366455 seconds ---\n",
      "episode 988, reward -308.0, memory_length 2000, epsilon 0.6101807830906798\n",
      "travel time- 722.0\n",
      "--- 1.8104424476623535 seconds ---\n",
      "episode 989, reward -57.0, memory_length 2000, epsilon 0.6098757689590218\n",
      "travel time- 723.0\n",
      "--- 1.6682589054107666 seconds ---\n",
      "episode 990, reward -295.0, memory_length 2000, epsilon 0.6095709072963093\n",
      "travel time- 722.0\n",
      "--- 1.6309194564819336 seconds ---\n",
      "episode 991, reward -437.0, memory_length 2000, epsilon 0.6092661980263268\n",
      "travel time- 720.0\n",
      "--- 1.6748301982879639 seconds ---\n",
      "episode 992, reward -63.0, memory_length 2000, epsilon 0.6089616410728969\n",
      "travel time- 724.0\n",
      "--- 1.4782352447509766 seconds ---\n",
      "episode 993, reward 104.0, memory_length 2000, epsilon 0.6086572363598804\n",
      "travel time- 729.0\n",
      "--- 1.6882908344268799 seconds ---\n",
      "episode 994, reward 285.0, memory_length 2000, epsilon 0.6083529838111763\n",
      "travel time- 722.0\n",
      "--- 1.6410133838653564 seconds ---\n",
      "episode 995, reward -14.0, memory_length 2000, epsilon 0.6080488833507213\n",
      "travel time- 726.0\n",
      "--- 1.9188549518585205 seconds ---\n",
      "episode 996, reward 119.0, memory_length 2000, epsilon 0.6077449349024902\n",
      "travel time- 722.0\n",
      "--- 1.6410627365112305 seconds ---\n",
      "episode 997, reward -68.0, memory_length 2000, epsilon 0.6074411383904961\n",
      "travel time- 736.0\n",
      "--- 1.5329945087432861 seconds ---\n",
      "episode 998, reward -196.0, memory_length 2000, epsilon 0.6071374937387897\n",
      "travel time- 726.0\n",
      "--- 1.529923915863037 seconds ---\n",
      "episode 999, reward -379.0, memory_length 2000, epsilon 0.6068340008714599\n",
      "travel time- 734.0\n",
      "--- 1.9107184410095215 seconds ---\n",
      "episode 1000, reward -32.0, memory_length 2000, epsilon 0.6065306597126334\n",
      "travel time- 720.0\n",
      "--- 1.7217941284179688 seconds ---\n",
      "episode 1001, reward 141.0, memory_length 2000, epsilon 0.606227470186475\n",
      "travel time- 727.0\n",
      "--- 1.8170053958892822 seconds ---\n",
      "episode 1002, reward -218.0, memory_length 2000, epsilon 0.6059244322171875\n",
      "travel time- 722.0\n",
      "--- 1.6856071949005127 seconds ---\n",
      "episode 1003, reward -241.0, memory_length 2000, epsilon 0.6056215457290111\n",
      "travel time- 723.0\n",
      "--- 1.7012815475463867 seconds ---\n",
      "episode 1004, reward -336.0, memory_length 2000, epsilon 0.6053188106462243\n",
      "travel time- 723.0\n",
      "--- 1.7270429134368896 seconds ---\n",
      "episode 1005, reward -121.0, memory_length 2000, epsilon 0.6050162268931432\n",
      "travel time- 723.0\n",
      "--- 1.6793291568756104 seconds ---\n",
      "episode 1006, reward -386.0, memory_length 2000, epsilon 0.6047137943941221\n",
      "travel time- 723.0\n",
      "--- 1.45890474319458 seconds ---\n",
      "episode 1007, reward 45.0, memory_length 2000, epsilon 0.6044115130735527\n",
      "travel time- 726.0\n",
      "--- 1.679976224899292 seconds ---\n",
      "episode 1008, reward -305.0, memory_length 2000, epsilon 0.6041093828558647\n",
      "travel time- 731.0\n",
      "--- 1.8227534294128418 seconds ---\n",
      "episode 1009, reward 20.0, memory_length 2000, epsilon 0.6038074036655255\n",
      "travel time- 722.0\n",
      "--- 1.4401214122772217 seconds ---\n",
      "episode 1010, reward -159.0, memory_length 2000, epsilon 0.6035055754270405\n",
      "travel time- 723.0\n",
      "--- 1.7311291694641113 seconds ---\n",
      "episode 1011, reward -147.0, memory_length 2000, epsilon 0.6032038980649524\n",
      "travel time- 726.0\n",
      "--- 1.6769981384277344 seconds ---\n",
      "episode 1012, reward 141.0, memory_length 2000, epsilon 0.6029023715038421\n",
      "travel time- 720.0\n",
      "--- 1.4813628196716309 seconds ---\n",
      "episode 1013, reward -360.0, memory_length 2000, epsilon 0.6026009956683277\n",
      "travel time- 722.0\n",
      "--- 1.924365758895874 seconds ---\n",
      "episode 1014, reward 142.0, memory_length 2000, epsilon 0.6022997704830654\n",
      "travel time- 724.0\n",
      "--- 1.507488489151001 seconds ---\n",
      "episode 1015, reward 23.0, memory_length 2000, epsilon 0.6019986958727488\n",
      "travel time- 720.0\n",
      "--- 1.4786748886108398 seconds ---\n",
      "episode 1016, reward -40.0, memory_length 2000, epsilon 0.6016977717621094\n",
      "travel time- 728.0\n",
      "--- 1.7198405265808105 seconds ---\n",
      "episode 1017, reward -117.0, memory_length 2000, epsilon 0.601396998075916\n",
      "travel time- 722.0\n",
      "--- 1.5902149677276611 seconds ---\n",
      "episode 1018, reward -217.0, memory_length 2000, epsilon 0.6010963747389753\n",
      "travel time- 720.0\n",
      "--- 1.649608850479126 seconds ---\n",
      "episode 1019, reward -224.0, memory_length 2000, epsilon 0.6007959016761313\n",
      "travel time- 722.0\n",
      "--- 1.8055236339569092 seconds ---\n",
      "episode 1020, reward 100.0, memory_length 2000, epsilon 0.6004955788122659\n",
      "travel time- 727.0\n",
      "--- 1.3989813327789307 seconds ---\n",
      "episode 1021, reward -95.0, memory_length 2000, epsilon 0.6001954060722984\n",
      "travel time- 729.0\n",
      "--- 1.634098768234253 seconds ---\n",
      "episode 1022, reward -533.0, memory_length 2000, epsilon 0.5998953833811855\n",
      "travel time- 721.0\n",
      "--- 1.9108786582946777 seconds ---\n",
      "episode 1023, reward 37.0, memory_length 2000, epsilon 0.5995955106639216\n",
      "travel time- 726.0\n",
      "--- 1.7827916145324707 seconds ---\n",
      "episode 1024, reward -143.0, memory_length 2000, epsilon 0.5992957878455384\n",
      "travel time- 721.0\n",
      "--- 1.4932506084442139 seconds ---\n",
      "episode 1025, reward 10.0, memory_length 2000, epsilon 0.5989962148511054\n",
      "travel time- 724.0\n",
      "--- 1.8278045654296875 seconds ---\n",
      "episode 1026, reward 62.0, memory_length 2000, epsilon 0.5986967916057292\n",
      "travel time- 720.0\n",
      "--- 1.71940279006958 seconds ---\n",
      "episode 1027, reward 96.0, memory_length 2000, epsilon 0.598397518034554\n",
      "travel time- 729.0\n",
      "--- 1.9360871315002441 seconds ---\n",
      "episode 1028, reward -163.0, memory_length 2000, epsilon 0.5980983940627613\n",
      "travel time- 721.0\n",
      "--- 1.640657663345337 seconds ---\n",
      "episode 1029, reward -343.0, memory_length 2000, epsilon 0.5977994196155705\n",
      "travel time- 722.0\n",
      "--- 1.9725325107574463 seconds ---\n",
      "episode 1030, reward -234.0, memory_length 2000, epsilon 0.5975005946182375\n",
      "travel time- 726.0\n",
      "--- 1.810892105102539 seconds ---\n",
      "episode 1031, reward -267.0, memory_length 2000, epsilon 0.5972019189960563\n",
      "travel time- 723.0\n",
      "--- 1.920506238937378 seconds ---\n",
      "episode 1032, reward -301.0, memory_length 2000, epsilon 0.596903392674358\n",
      "travel time- 729.0\n",
      "--- 1.7031304836273193 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1033, reward -391.0, memory_length 2000, epsilon 0.596605015578511\n",
      "travel time- 729.0\n",
      "--- 1.7024950981140137 seconds ---\n",
      "episode 1034, reward -248.0, memory_length 2000, epsilon 0.596306787633921\n",
      "travel time- 721.0\n",
      "--- 1.8332889080047607 seconds ---\n",
      "episode 1035, reward -184.0, memory_length 2000, epsilon 0.596008708766031\n",
      "travel time- 725.0\n",
      "--- 1.4918274879455566 seconds ---\n",
      "episode 1036, reward -229.0, memory_length 2000, epsilon 0.5957107789003212\n",
      "travel time- 722.0\n",
      "--- 1.761284351348877 seconds ---\n",
      "episode 1037, reward -156.0, memory_length 2000, epsilon 0.5954129979623094\n",
      "travel time- 727.0\n",
      "--- 1.5992560386657715 seconds ---\n",
      "episode 1038, reward 186.0, memory_length 2000, epsilon 0.5951153658775501\n",
      "travel time- 720.0\n",
      "--- 1.597217082977295 seconds ---\n",
      "episode 1039, reward -144.0, memory_length 2000, epsilon 0.5948178825716354\n",
      "travel time- 720.0\n",
      "--- 1.638711929321289 seconds ---\n",
      "episode 1040, reward -18.0, memory_length 2000, epsilon 0.5945205479701944\n",
      "travel time- 720.0\n",
      "--- 1.5650269985198975 seconds ---\n",
      "episode 1041, reward 306.0, memory_length 2000, epsilon 0.5942233619988935\n",
      "travel time- 729.0\n",
      "--- 1.6607649326324463 seconds ---\n",
      "episode 1042, reward 64.0, memory_length 2000, epsilon 0.5939263245834361\n",
      "travel time- 722.0\n",
      "--- 1.7576322555541992 seconds ---\n",
      "episode 1043, reward -84.0, memory_length 2000, epsilon 0.593629435649563\n",
      "travel time- 728.0\n",
      "--- 1.6498675346374512 seconds ---\n",
      "episode 1044, reward -290.0, memory_length 2000, epsilon 0.593332695123052\n",
      "travel time- 729.0\n",
      "--- 1.5111184120178223 seconds ---\n",
      "episode 1045, reward 66.0, memory_length 2000, epsilon 0.5930361029297179\n",
      "travel time- 723.0\n",
      "--- 1.5969886779785156 seconds ---\n",
      "episode 1046, reward -300.0, memory_length 2000, epsilon 0.5927396589954125\n",
      "travel time- 720.0\n",
      "--- 1.821760654449463 seconds ---\n",
      "episode 1047, reward -238.0, memory_length 2000, epsilon 0.592443363246025\n",
      "travel time- 721.0\n",
      "--- 1.617544412612915 seconds ---\n",
      "episode 1048, reward 268.0, memory_length 2000, epsilon 0.5921472156074813\n",
      "travel time- 725.0\n",
      "--- 1.8420236110687256 seconds ---\n",
      "episode 1049, reward -337.0, memory_length 2000, epsilon 0.5918512160057446\n",
      "travel time- 722.0\n",
      "--- 1.8923041820526123 seconds ---\n",
      "episode 1050, reward -90.0, memory_length 2000, epsilon 0.5915553643668151\n",
      "travel time- 725.0\n",
      "--- 1.7045307159423828 seconds ---\n",
      "episode 1051, reward 19.0, memory_length 2000, epsilon 0.5912596606167297\n",
      "travel time- 730.0\n",
      "--- 1.7998812198638916 seconds ---\n",
      "episode 1052, reward 268.0, memory_length 2000, epsilon 0.5909641046815626\n",
      "travel time- 725.0\n",
      "--- 1.7069931030273438 seconds ---\n",
      "episode 1053, reward 142.0, memory_length 2000, epsilon 0.5906686964874246\n",
      "travel time- 726.0\n",
      "--- 1.5485072135925293 seconds ---\n",
      "episode 1054, reward 178.0, memory_length 2000, epsilon 0.5903734359604639\n",
      "travel time- 721.0\n",
      "--- 1.6096007823944092 seconds ---\n",
      "episode 1055, reward -146.0, memory_length 2000, epsilon 0.5900783230268652\n",
      "travel time- 720.0\n",
      "--- 1.8556172847747803 seconds ---\n",
      "episode 1056, reward -372.0, memory_length 2000, epsilon 0.5897833576128504\n",
      "travel time- 720.0\n",
      "--- 1.7704548835754395 seconds ---\n",
      "episode 1057, reward -116.0, memory_length 2000, epsilon 0.5894885396446782\n",
      "travel time- 722.0\n",
      "--- 1.5865850448608398 seconds ---\n",
      "episode 1058, reward -256.0, memory_length 2000, epsilon 0.5891938690486437\n",
      "travel time- 721.0\n",
      "--- 1.7421746253967285 seconds ---\n",
      "episode 1059, reward -344.0, memory_length 2000, epsilon 0.5888993457510797\n",
      "travel time- 728.0\n",
      "--- 1.8151159286499023 seconds ---\n",
      "episode 1060, reward -214.0, memory_length 2000, epsilon 0.5886049696783552\n",
      "travel time- 721.0\n",
      "--- 1.6808271408081055 seconds ---\n",
      "episode 1061, reward 128.0, memory_length 2000, epsilon 0.5883107407568762\n",
      "travel time- 720.0\n",
      "--- 1.6282575130462646 seconds ---\n",
      "episode 1062, reward -156.0, memory_length 2000, epsilon 0.5880166589130854\n",
      "travel time- 723.0\n",
      "--- 1.8897898197174072 seconds ---\n",
      "episode 1063, reward 50.0, memory_length 2000, epsilon 0.5877227240734624\n",
      "travel time- 724.0\n",
      "--- 1.5587213039398193 seconds ---\n",
      "episode 1064, reward 49.0, memory_length 2000, epsilon 0.5874289361645234\n",
      "travel time- 725.0\n",
      "--- 1.7700324058532715 seconds ---\n",
      "episode 1065, reward -330.0, memory_length 2000, epsilon 0.5871352951128217\n",
      "travel time- 722.0\n",
      "--- 1.8296523094177246 seconds ---\n",
      "episode 1066, reward -402.0, memory_length 2000, epsilon 0.5868418008449466\n",
      "travel time- 720.0\n",
      "--- 1.7142722606658936 seconds ---\n",
      "episode 1067, reward -19.0, memory_length 2000, epsilon 0.586548453287525\n",
      "travel time- 720.0\n",
      "--- 1.6117174625396729 seconds ---\n",
      "episode 1068, reward 382.0, memory_length 2000, epsilon 0.5862552523672196\n",
      "travel time- 723.0\n",
      "--- 1.7563598155975342 seconds ---\n",
      "episode 1069, reward -235.0, memory_length 2000, epsilon 0.5859621980107305\n",
      "travel time- 722.0\n",
      "--- 1.9392096996307373 seconds ---\n",
      "episode 1070, reward -222.0, memory_length 2000, epsilon 0.5856692901447937\n",
      "travel time- 720.0\n",
      "--- 1.7299792766571045 seconds ---\n",
      "episode 1071, reward -327.0, memory_length 2000, epsilon 0.5853765286961827\n",
      "travel time- 722.0\n",
      "--- 1.9628503322601318 seconds ---\n",
      "episode 1072, reward -161.0, memory_length 2000, epsilon 0.5850839135917069\n",
      "travel time- 721.0\n",
      "--- 1.953599214553833 seconds ---\n",
      "episode 1073, reward -60.0, memory_length 2000, epsilon 0.5847914447582125\n",
      "travel time- 720.0\n",
      "--- 1.7476451396942139 seconds ---\n",
      "episode 1074, reward -115.0, memory_length 2000, epsilon 0.5844991221225824\n",
      "travel time- 720.0\n",
      "--- 1.8927478790283203 seconds ---\n",
      "episode 1075, reward 209.0, memory_length 2000, epsilon 0.5842069456117358\n",
      "travel time- 726.0\n",
      "--- 1.863921880722046 seconds ---\n",
      "episode 1076, reward -208.0, memory_length 2000, epsilon 0.5839149151526287\n",
      "travel time- 721.0\n",
      "--- 1.7029407024383545 seconds ---\n",
      "episode 1077, reward -117.0, memory_length 2000, epsilon 0.5836230306722534\n",
      "travel time- 728.0\n",
      "--- 1.839890480041504 seconds ---\n",
      "episode 1078, reward 96.0, memory_length 2000, epsilon 0.5833312920976388\n",
      "travel time- 720.0\n",
      "--- 1.7479617595672607 seconds ---\n",
      "episode 1079, reward 71.0, memory_length 2000, epsilon 0.5830396993558503\n",
      "travel time- 725.0\n",
      "--- 1.6493239402770996 seconds ---\n",
      "episode 1080, reward -111.0, memory_length 2000, epsilon 0.5827482523739896\n",
      "travel time- 722.0\n",
      "--- 1.720186710357666 seconds ---\n",
      "episode 1081, reward -35.0, memory_length 2000, epsilon 0.5824569510791952\n",
      "travel time- 721.0\n",
      "--- 1.6983544826507568 seconds ---\n",
      "episode 1082, reward -162.0, memory_length 2000, epsilon 0.5821657953986414\n",
      "travel time- 724.0\n",
      "--- 1.6674201488494873 seconds ---\n",
      "episode 1083, reward -470.0, memory_length 2000, epsilon 0.5818747852595396\n",
      "travel time- 724.0\n",
      "--- 1.7787883281707764 seconds ---\n",
      "episode 1084, reward -264.0, memory_length 2000, epsilon 0.5815839205891371\n",
      "travel time- 725.0\n",
      "--- 1.9237630367279053 seconds ---\n",
      "episode 1085, reward 28.0, memory_length 2000, epsilon 0.5812932013147178\n",
      "travel time- 720.0\n",
      "--- 1.611875295639038 seconds ---\n",
      "episode 1086, reward 150.0, memory_length 2000, epsilon 0.5810026273636019\n",
      "travel time- 724.0\n",
      "--- 1.418816089630127 seconds ---\n",
      "episode 1087, reward -65.0, memory_length 2000, epsilon 0.5807121986631457\n",
      "travel time- 722.0\n",
      "--- 1.7190873622894287 seconds ---\n",
      "episode 1088, reward 203.0, memory_length 2000, epsilon 0.5804219151407424\n",
      "travel time- 725.0\n",
      "--- 1.5571577548980713 seconds ---\n",
      "episode 1089, reward -310.0, memory_length 2000, epsilon 0.5801317767238208\n",
      "travel time- 723.0\n",
      "--- 1.752049207687378 seconds ---\n",
      "episode 1090, reward -386.0, memory_length 2000, epsilon 0.5798417833398464\n",
      "travel time- 725.0\n",
      "--- 1.8841478824615479 seconds ---\n",
      "episode 1091, reward -235.0, memory_length 2000, epsilon 0.5795519349163208\n",
      "travel time- 725.0\n",
      "--- 1.6927940845489502 seconds ---\n",
      "episode 1092, reward 45.0, memory_length 2000, epsilon 0.579262231380782\n",
      "travel time- 722.0\n",
      "--- 1.595824956893921 seconds ---\n",
      "episode 1093, reward 212.0, memory_length 2000, epsilon 0.5789726726608041\n",
      "travel time- 724.0\n",
      "--- 1.5886707305908203 seconds ---\n",
      "episode 1094, reward -150.0, memory_length 2000, epsilon 0.5786832586839974\n",
      "travel time- 723.0\n",
      "--- 1.7529373168945312 seconds ---\n",
      "episode 1095, reward 104.0, memory_length 2000, epsilon 0.5783939893780083\n",
      "travel time- 720.0\n",
      "--- 1.6721866130828857 seconds ---\n",
      "episode 1096, reward 100.0, memory_length 2000, epsilon 0.5781048646705196\n",
      "travel time- 722.0\n",
      "--- 1.5766632556915283 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1097, reward 116.0, memory_length 2000, epsilon 0.5778158844892501\n",
      "travel time- 723.0\n",
      "--- 1.7865369319915771 seconds ---\n",
      "episode 1098, reward -330.0, memory_length 2000, epsilon 0.5775270487619547\n",
      "travel time- 720.0\n",
      "--- 1.6882874965667725 seconds ---\n",
      "episode 1099, reward 88.0, memory_length 2000, epsilon 0.5772383574164245\n",
      "travel time- 727.0\n",
      "--- 1.471311330795288 seconds ---\n",
      "episode 1100, reward -159.0, memory_length 2000, epsilon 0.5769498103804866\n",
      "travel time- 726.0\n",
      "--- 1.8617453575134277 seconds ---\n",
      "episode 1101, reward 14.0, memory_length 2000, epsilon 0.5766614075820045\n",
      "travel time- 726.0\n",
      "--- 1.688434362411499 seconds ---\n",
      "episode 1102, reward -108.0, memory_length 2000, epsilon 0.5763731489488771\n",
      "travel time- 722.0\n",
      "--- 1.6727068424224854 seconds ---\n",
      "episode 1103, reward -206.0, memory_length 2000, epsilon 0.57608503440904\n",
      "travel time- 721.0\n",
      "--- 1.7488758563995361 seconds ---\n",
      "episode 1104, reward 167.0, memory_length 2000, epsilon 0.5757970638904645\n",
      "travel time- 722.0\n",
      "--- 1.6042864322662354 seconds ---\n",
      "episode 1105, reward -371.0, memory_length 2000, epsilon 0.575509237321158\n",
      "travel time- 720.0\n",
      "--- 1.800842046737671 seconds ---\n",
      "episode 1106, reward 8.0, memory_length 2000, epsilon 0.5752215546291638\n",
      "travel time- 722.0\n",
      "--- 1.887420892715454 seconds ---\n",
      "episode 1107, reward -145.0, memory_length 2000, epsilon 0.5749340157425613\n",
      "travel time- 722.0\n",
      "--- 1.7468078136444092 seconds ---\n",
      "episode 1108, reward -189.0, memory_length 2000, epsilon 0.5746466205894657\n",
      "travel time- 725.0\n",
      "--- 1.607375144958496 seconds ---\n",
      "episode 1109, reward -167.0, memory_length 2000, epsilon 0.5743593690980282\n",
      "travel time- 721.0\n",
      "--- 1.7261748313903809 seconds ---\n",
      "episode 1110, reward 105.0, memory_length 2000, epsilon 0.574072261196436\n",
      "travel time- 722.0\n",
      "--- 1.8667385578155518 seconds ---\n",
      "episode 1111, reward -175.0, memory_length 2000, epsilon 0.5737852968129121\n",
      "travel time- 722.0\n",
      "--- 1.7787854671478271 seconds ---\n",
      "episode 1112, reward 170.0, memory_length 2000, epsilon 0.5734984758757153\n",
      "travel time- 723.0\n",
      "--- 1.7695050239562988 seconds ---\n",
      "episode 1113, reward -56.0, memory_length 2000, epsilon 0.5732117983131406\n",
      "travel time- 720.0\n",
      "--- 1.6143689155578613 seconds ---\n",
      "episode 1114, reward -498.0, memory_length 2000, epsilon 0.5729252640535184\n",
      "travel time- 721.0\n",
      "--- 1.739332914352417 seconds ---\n",
      "episode 1115, reward -6.0, memory_length 2000, epsilon 0.5726388730252152\n",
      "travel time- 725.0\n",
      "--- 1.5612711906433105 seconds ---\n",
      "episode 1116, reward -343.0, memory_length 2000, epsilon 0.5723526251566332\n",
      "travel time- 726.0\n",
      "--- 1.728100061416626 seconds ---\n",
      "episode 1117, reward -179.0, memory_length 2000, epsilon 0.5720665203762105\n",
      "travel time- 726.0\n",
      "--- 1.8463060855865479 seconds ---\n",
      "episode 1118, reward -128.0, memory_length 2000, epsilon 0.5717805586124209\n",
      "travel time- 726.0\n",
      "--- 1.6260809898376465 seconds ---\n",
      "episode 1119, reward -138.0, memory_length 2000, epsilon 0.571494739793774\n",
      "travel time- 722.0\n",
      "--- 1.6827881336212158 seconds ---\n",
      "episode 1120, reward 27.0, memory_length 2000, epsilon 0.5712090638488149\n",
      "travel time- 723.0\n",
      "--- 1.7510557174682617 seconds ---\n",
      "episode 1121, reward 35.0, memory_length 2000, epsilon 0.5709235307061248\n",
      "travel time- 725.0\n",
      "--- 1.4708759784698486 seconds ---\n",
      "episode 1122, reward 38.0, memory_length 2000, epsilon 0.5706381402943203\n",
      "travel time- 723.0\n",
      "--- 1.6759045124053955 seconds ---\n",
      "episode 1123, reward -24.0, memory_length 2000, epsilon 0.5703528925420539\n",
      "travel time- 729.0\n",
      "--- 1.788863182067871 seconds ---\n",
      "episode 1124, reward 4.0, memory_length 2000, epsilon 0.5700677873780134\n",
      "travel time- 721.0\n",
      "--- 1.3221855163574219 seconds ---\n",
      "episode 1125, reward -318.0, memory_length 2000, epsilon 0.569782824730923\n",
      "travel time- 722.0\n",
      "--- 1.9278268814086914 seconds ---\n",
      "episode 1126, reward -57.0, memory_length 2000, epsilon 0.5694980045295416\n",
      "travel time- 722.0\n",
      "--- 1.8092918395996094 seconds ---\n",
      "episode 1127, reward -164.0, memory_length 2000, epsilon 0.5692133267026643\n",
      "travel time- 722.0\n",
      "--- 1.623143196105957 seconds ---\n",
      "episode 1128, reward 53.0, memory_length 2000, epsilon 0.5689287911791218\n",
      "travel time- 733.0\n",
      "--- 1.6812336444854736 seconds ---\n",
      "episode 1129, reward -353.0, memory_length 2000, epsilon 0.5686443978877799\n",
      "travel time- 724.0\n",
      "--- 1.7625906467437744 seconds ---\n",
      "episode 1130, reward 105.0, memory_length 2000, epsilon 0.5683601467575404\n",
      "travel time- 727.0\n",
      "--- 1.4570398330688477 seconds ---\n",
      "episode 1131, reward -99.0, memory_length 2000, epsilon 0.5680760377173407\n",
      "travel time- 726.0\n",
      "--- 1.5808415412902832 seconds ---\n",
      "episode 1132, reward -147.0, memory_length 2000, epsilon 0.5677920706961532\n",
      "travel time- 721.0\n",
      "--- 1.8152861595153809 seconds ---\n",
      "episode 1133, reward -254.0, memory_length 2000, epsilon 0.5675082456229865\n",
      "travel time- 723.0\n",
      "--- 1.7815263271331787 seconds ---\n",
      "episode 1134, reward -112.0, memory_length 2000, epsilon 0.5672245624268841\n",
      "travel time- 721.0\n",
      "--- 1.7415251731872559 seconds ---\n",
      "episode 1135, reward -476.0, memory_length 2000, epsilon 0.5669410210369252\n",
      "travel time- 731.0\n",
      "--- 1.624706506729126 seconds ---\n",
      "episode 1136, reward -194.0, memory_length 2000, epsilon 0.5666576213822246\n",
      "travel time- 724.0\n",
      "--- 1.9430391788482666 seconds ---\n",
      "episode 1137, reward -137.0, memory_length 2000, epsilon 0.5663743633919324\n",
      "travel time- 720.0\n",
      "--- 1.6245200634002686 seconds ---\n",
      "episode 1138, reward -3.0, memory_length 2000, epsilon 0.5660912469952337\n",
      "travel time- 723.0\n",
      "--- 1.599726915359497 seconds ---\n",
      "episode 1139, reward -212.0, memory_length 2000, epsilon 0.56580827212135\n",
      "travel time- 725.0\n",
      "--- 1.7219061851501465 seconds ---\n",
      "episode 1140, reward -316.0, memory_length 2000, epsilon 0.5655254386995371\n",
      "travel time- 726.0\n",
      "--- 1.5941755771636963 seconds ---\n",
      "episode 1141, reward -502.0, memory_length 2000, epsilon 0.5652427466590868\n",
      "travel time- 722.0\n",
      "--- 1.6671395301818848 seconds ---\n",
      "episode 1142, reward 70.0, memory_length 2000, epsilon 0.5649601959293262\n",
      "travel time- 726.0\n",
      "--- 1.8772234916687012 seconds ---\n",
      "episode 1143, reward -437.0, memory_length 2000, epsilon 0.5646777864396175\n",
      "travel time- 723.0\n",
      "--- 1.8186304569244385 seconds ---\n",
      "episode 1144, reward -414.0, memory_length 2000, epsilon 0.5643955181193583\n",
      "travel time- 724.0\n",
      "--- 1.477407693862915 seconds ---\n",
      "episode 1145, reward -314.0, memory_length 2000, epsilon 0.5641133908979816\n",
      "travel time- 720.0\n",
      "--- 1.8411829471588135 seconds ---\n",
      "episode 1146, reward 28.0, memory_length 2000, epsilon 0.5638314047049556\n",
      "travel time- 724.0\n",
      "--- 1.679121732711792 seconds ---\n",
      "episode 1147, reward -229.0, memory_length 2000, epsilon 0.5635495594697838\n",
      "travel time- 723.0\n",
      "--- 1.4566307067871094 seconds ---\n",
      "episode 1148, reward -336.0, memory_length 2000, epsilon 0.5632678551220046\n",
      "travel time- 722.0\n",
      "--- 1.7591993808746338 seconds ---\n",
      "episode 1149, reward -178.0, memory_length 2000, epsilon 0.5629862915911923\n",
      "travel time- 723.0\n",
      "--- 1.9237308502197266 seconds ---\n",
      "episode 1150, reward -420.0, memory_length 2000, epsilon 0.5627048688069557\n",
      "travel time- 722.0\n",
      "--- 2.030174970626831 seconds ---\n",
      "episode 1151, reward -268.0, memory_length 2000, epsilon 0.5624235866989392\n",
      "travel time- 729.0\n",
      "--- 1.9015748500823975 seconds ---\n",
      "episode 1152, reward 111.0, memory_length 2000, epsilon 0.5621424451968224\n",
      "travel time- 722.0\n",
      "--- 1.776498794555664 seconds ---\n",
      "episode 1153, reward -239.0, memory_length 2000, epsilon 0.5618614442303198\n",
      "travel time- 726.0\n",
      "--- 1.6808743476867676 seconds ---\n",
      "episode 1154, reward -305.0, memory_length 2000, epsilon 0.5615805837291813\n",
      "travel time- 726.0\n",
      "--- 1.6449575424194336 seconds ---\n",
      "episode 1155, reward 330.0, memory_length 2000, epsilon 0.5612998636231915\n",
      "travel time- 725.0\n",
      "--- 1.4289610385894775 seconds ---\n",
      "episode 1156, reward -221.0, memory_length 2000, epsilon 0.5610192838421706\n",
      "travel time- 736.0\n",
      "--- 1.7912311553955078 seconds ---\n",
      "episode 1157, reward -96.0, memory_length 2000, epsilon 0.5607388443159735\n",
      "travel time- 722.0\n",
      "--- 1.766221523284912 seconds ---\n",
      "episode 1158, reward -117.0, memory_length 2000, epsilon 0.5604585449744904\n",
      "travel time- 722.0\n",
      "--- 1.6314265727996826 seconds ---\n",
      "episode 1159, reward -161.0, memory_length 2000, epsilon 0.5601783857476466\n",
      "travel time- 722.0\n",
      "--- 1.6794872283935547 seconds ---\n",
      "episode 1160, reward -72.0, memory_length 2000, epsilon 0.559898366565402\n",
      "travel time- 721.0\n",
      "--- 1.6255519390106201 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1161, reward 171.0, memory_length 2000, epsilon 0.5596184873577521\n",
      "travel time- 722.0\n",
      "--- 1.6062567234039307 seconds ---\n",
      "episode 1162, reward -221.0, memory_length 2000, epsilon 0.5593387480547268\n",
      "travel time- 730.0\n",
      "--- 2.0137643814086914 seconds ---\n",
      "episode 1163, reward -144.0, memory_length 2000, epsilon 0.5590591485863915\n",
      "travel time- 721.0\n",
      "--- 1.7593178749084473 seconds ---\n",
      "episode 1164, reward -428.0, memory_length 2000, epsilon 0.5587796888828463\n",
      "travel time- 724.0\n",
      "--- 1.729475736618042 seconds ---\n",
      "episode 1165, reward -237.0, memory_length 2000, epsilon 0.5585003688742262\n",
      "travel time- 724.0\n",
      "--- 1.8195559978485107 seconds ---\n",
      "episode 1166, reward 86.0, memory_length 2000, epsilon 0.5582211884907012\n",
      "travel time- 727.0\n",
      "--- 1.508382797241211 seconds ---\n",
      "episode 1167, reward -113.0, memory_length 2000, epsilon 0.5579421476624763\n",
      "travel time- 725.0\n",
      "--- 2.0269808769226074 seconds ---\n",
      "episode 1168, reward -183.0, memory_length 2000, epsilon 0.5576632463197913\n",
      "travel time- 721.0\n",
      "--- 1.6754584312438965 seconds ---\n",
      "episode 1169, reward -34.0, memory_length 2000, epsilon 0.5573844843929205\n",
      "travel time- 729.0\n",
      "--- 1.6682980060577393 seconds ---\n",
      "episode 1170, reward 161.0, memory_length 2000, epsilon 0.5571058618121739\n",
      "travel time- 722.0\n",
      "--- 1.7345585823059082 seconds ---\n",
      "episode 1171, reward -242.0, memory_length 2000, epsilon 0.5568273785078957\n",
      "travel time- 723.0\n",
      "--- 1.823659896850586 seconds ---\n",
      "episode 1172, reward -41.0, memory_length 2000, epsilon 0.5565490344104649\n",
      "travel time- 720.0\n",
      "--- 1.8539161682128906 seconds ---\n",
      "episode 1173, reward -55.0, memory_length 2000, epsilon 0.5562708294502956\n",
      "travel time- 721.0\n",
      "--- 1.6463615894317627 seconds ---\n",
      "episode 1174, reward 223.0, memory_length 2000, epsilon 0.5559927635578367\n",
      "travel time- 720.0\n",
      "--- 1.6490590572357178 seconds ---\n",
      "episode 1175, reward -84.0, memory_length 2000, epsilon 0.5557148366635714\n",
      "travel time- 721.0\n",
      "--- 1.7094438076019287 seconds ---\n",
      "episode 1176, reward 92.0, memory_length 2000, epsilon 0.5554370486980182\n",
      "travel time- 721.0\n",
      "--- 1.5967903137207031 seconds ---\n",
      "episode 1177, reward -354.0, memory_length 2000, epsilon 0.5551593995917302\n",
      "travel time- 723.0\n",
      "--- 1.8173186779022217 seconds ---\n",
      "episode 1178, reward -224.0, memory_length 2000, epsilon 0.5548818892752949\n",
      "travel time- 720.0\n",
      "--- 2.0793533325195312 seconds ---\n",
      "episode 1179, reward -125.0, memory_length 2000, epsilon 0.5546045176793348\n",
      "travel time- 728.0\n",
      "--- 1.706150770187378 seconds ---\n",
      "episode 1180, reward -105.0, memory_length 2000, epsilon 0.5543272847345071\n",
      "travel time- 720.0\n",
      "--- 1.6535215377807617 seconds ---\n",
      "episode 1181, reward -65.0, memory_length 2000, epsilon 0.5540501903715033\n",
      "travel time- 728.0\n",
      "--- 1.7421908378601074 seconds ---\n",
      "episode 1182, reward -268.0, memory_length 2000, epsilon 0.5537732345210501\n",
      "travel time- 727.0\n",
      "--- 1.763765811920166 seconds ---\n",
      "episode 1183, reward -35.0, memory_length 2000, epsilon 0.5534964171139084\n",
      "travel time- 724.0\n",
      "--- 1.5722510814666748 seconds ---\n",
      "episode 1184, reward -215.0, memory_length 2000, epsilon 0.5532197380808739\n",
      "travel time- 721.0\n",
      "--- 1.5853383541107178 seconds ---\n",
      "episode 1185, reward -296.0, memory_length 2000, epsilon 0.5529431973527766\n",
      "travel time- 720.0\n",
      "--- 1.657153844833374 seconds ---\n",
      "episode 1186, reward -293.0, memory_length 2000, epsilon 0.5526667948604818\n",
      "travel time- 722.0\n",
      "--- 1.6502604484558105 seconds ---\n",
      "episode 1187, reward -227.0, memory_length 2000, epsilon 0.5523905305348884\n",
      "travel time- 724.0\n",
      "--- 1.7825562953948975 seconds ---\n",
      "episode 1188, reward -221.0, memory_length 2000, epsilon 0.5521144043069306\n",
      "travel time- 720.0\n",
      "--- 1.831075668334961 seconds ---\n",
      "episode 1189, reward -218.0, memory_length 2000, epsilon 0.5518384161075767\n",
      "travel time- 729.0\n",
      "--- 1.8728866577148438 seconds ---\n",
      "episode 1190, reward -113.0, memory_length 2000, epsilon 0.5515625658678298\n",
      "travel time- 733.0\n",
      "--- 1.685171365737915 seconds ---\n",
      "episode 1191, reward -80.0, memory_length 2000, epsilon 0.5512868535187271\n",
      "travel time- 725.0\n",
      "--- 1.8720099925994873 seconds ---\n",
      "episode 1192, reward -102.0, memory_length 2000, epsilon 0.5510112789913407\n",
      "travel time- 732.0\n",
      "--- 1.6403043270111084 seconds ---\n",
      "episode 1193, reward -306.0, memory_length 2000, epsilon 0.550735842216777\n",
      "travel time- 722.0\n",
      "--- 1.8397161960601807 seconds ---\n",
      "episode 1194, reward -142.0, memory_length 2000, epsilon 0.5504605431261766\n",
      "travel time- 720.0\n",
      "--- 1.5710487365722656 seconds ---\n",
      "episode 1195, reward -182.0, memory_length 2000, epsilon 0.550185381650715\n",
      "travel time- 722.0\n",
      "--- 1.675464153289795 seconds ---\n",
      "episode 1196, reward -37.0, memory_length 2000, epsilon 0.5499103577216016\n",
      "travel time- 727.0\n",
      "--- 1.6748430728912354 seconds ---\n",
      "episode 1197, reward 4.0, memory_length 2000, epsilon 0.5496354712700804\n",
      "travel time- 731.0\n",
      "--- 1.5619323253631592 seconds ---\n",
      "episode 1198, reward 11.0, memory_length 2000, epsilon 0.54936072222743\n",
      "travel time- 723.0\n",
      "--- 1.6985366344451904 seconds ---\n",
      "episode 1199, reward 157.0, memory_length 2000, epsilon 0.5490861105249629\n",
      "travel time- 720.0\n",
      "--- 1.5585763454437256 seconds ---\n",
      "episode 1200, reward 171.0, memory_length 2000, epsilon 0.5488116360940264\n",
      "travel time- 720.0\n",
      "--- 1.5445537567138672 seconds ---\n",
      "episode 1201, reward -101.0, memory_length 2000, epsilon 0.5485372988660018\n",
      "travel time- 722.0\n",
      "--- 1.6804592609405518 seconds ---\n",
      "episode 1202, reward -269.0, memory_length 2000, epsilon 0.5482630987723047\n",
      "travel time- 723.0\n",
      "--- 1.6581740379333496 seconds ---\n",
      "episode 1203, reward 185.0, memory_length 2000, epsilon 0.5479890357443852\n",
      "travel time- 728.0\n",
      "--- 1.7344424724578857 seconds ---\n",
      "episode 1204, reward -330.0, memory_length 2000, epsilon 0.5477151097137275\n",
      "travel time- 728.0\n",
      "--- 1.9424357414245605 seconds ---\n",
      "episode 1205, reward -213.0, memory_length 2000, epsilon 0.54744132061185\n",
      "travel time- 726.0\n",
      "--- 1.757606029510498 seconds ---\n",
      "episode 1206, reward -247.0, memory_length 2000, epsilon 0.5471676683703055\n",
      "travel time- 724.0\n",
      "--- 1.7154808044433594 seconds ---\n",
      "episode 1207, reward -44.0, memory_length 2000, epsilon 0.546894152920681\n",
      "travel time- 723.0\n",
      "--- 1.5990102291107178 seconds ---\n",
      "episode 1208, reward 91.0, memory_length 2000, epsilon 0.5466207741945976\n",
      "travel time- 724.0\n",
      "--- 1.7935423851013184 seconds ---\n",
      "episode 1209, reward -51.0, memory_length 2000, epsilon 0.5463475321237106\n",
      "travel time- 722.0\n",
      "--- 1.7515392303466797 seconds ---\n",
      "episode 1210, reward -315.0, memory_length 2000, epsilon 0.5460744266397094\n",
      "travel time- 727.0\n",
      "--- 1.9140288829803467 seconds ---\n",
      "episode 1211, reward -224.0, memory_length 2000, epsilon 0.5458014576743178\n",
      "travel time- 730.0\n",
      "--- 1.728055715560913 seconds ---\n",
      "episode 1212, reward -28.0, memory_length 2000, epsilon 0.5455286251592933\n",
      "travel time- 725.0\n",
      "--- 1.705228567123413 seconds ---\n",
      "episode 1213, reward 165.0, memory_length 2000, epsilon 0.545255929026428\n",
      "travel time- 729.0\n",
      "--- 1.7846465110778809 seconds ---\n",
      "episode 1214, reward -45.0, memory_length 2000, epsilon 0.544983369207548\n",
      "travel time- 727.0\n",
      "--- 1.712871789932251 seconds ---\n",
      "episode 1215, reward 121.0, memory_length 2000, epsilon 0.5447109456345129\n",
      "travel time- 722.0\n",
      "--- 1.7292516231536865 seconds ---\n",
      "episode 1216, reward 150.0, memory_length 2000, epsilon 0.5444386582392171\n",
      "travel time- 720.0\n",
      "--- 1.9041361808776855 seconds ---\n",
      "episode 1217, reward 173.0, memory_length 2000, epsilon 0.5441665069535887\n",
      "travel time- 727.0\n",
      "--- 1.5100505352020264 seconds ---\n",
      "episode 1218, reward -259.0, memory_length 2000, epsilon 0.5438944917095899\n",
      "travel time- 720.0\n",
      "--- 1.6122100353240967 seconds ---\n",
      "episode 1219, reward -90.0, memory_length 2000, epsilon 0.5436226124392168\n",
      "travel time- 725.0\n",
      "--- 1.9497673511505127 seconds ---\n",
      "episode 1220, reward -292.0, memory_length 2000, epsilon 0.5433508690744998\n",
      "travel time- 723.0\n",
      "--- 1.7252869606018066 seconds ---\n",
      "episode 1221, reward -211.0, memory_length 2000, epsilon 0.5430792615475027\n",
      "travel time- 720.0\n",
      "--- 1.637319564819336 seconds ---\n",
      "episode 1222, reward -464.0, memory_length 2000, epsilon 0.542807789790324\n",
      "travel time- 723.0\n",
      "--- 1.4576852321624756 seconds ---\n",
      "episode 1223, reward -261.0, memory_length 2000, epsilon 0.5425364537350954\n",
      "travel time- 721.0\n",
      "--- 1.8780498504638672 seconds ---\n",
      "episode 1224, reward -322.0, memory_length 2000, epsilon 0.5422652533139832\n",
      "travel time- 725.0\n",
      "--- 1.846632719039917 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1225, reward -179.0, memory_length 2000, epsilon 0.5419941884591871\n",
      "travel time- 728.0\n",
      "--- 1.6226565837860107 seconds ---\n",
      "episode 1226, reward 220.0, memory_length 2000, epsilon 0.541723259102941\n",
      "travel time- 736.0\n",
      "--- 1.664597988128662 seconds ---\n",
      "episode 1227, reward -110.0, memory_length 2000, epsilon 0.5414524651775123\n",
      "travel time- 722.0\n",
      "--- 1.55796217918396 seconds ---\n",
      "episode 1228, reward -252.0, memory_length 2000, epsilon 0.5411818066152029\n",
      "travel time- 723.0\n",
      "--- 1.5342776775360107 seconds ---\n",
      "episode 1229, reward -12.0, memory_length 2000, epsilon 0.5409112833483479\n",
      "travel time- 729.0\n",
      "--- 1.6290767192840576 seconds ---\n",
      "episode 1230, reward -356.0, memory_length 2000, epsilon 0.5406408953093166\n",
      "travel time- 720.0\n",
      "--- 1.6660008430480957 seconds ---\n",
      "episode 1231, reward -131.0, memory_length 2000, epsilon 0.5403706424305118\n",
      "travel time- 722.0\n",
      "--- 1.739236831665039 seconds ---\n",
      "episode 1232, reward 216.0, memory_length 2000, epsilon 0.5401005246443706\n",
      "travel time- 726.0\n",
      "--- 1.7481496334075928 seconds ---\n",
      "episode 1233, reward -149.0, memory_length 2000, epsilon 0.5398305418833633\n",
      "travel time- 723.0\n",
      "--- 1.6801261901855469 seconds ---\n",
      "episode 1234, reward -175.0, memory_length 2000, epsilon 0.5395606940799943\n",
      "travel time- 720.0\n",
      "--- 1.74053955078125 seconds ---\n",
      "episode 1235, reward 113.0, memory_length 2000, epsilon 0.5392909811668016\n",
      "travel time- 723.0\n",
      "--- 1.5026535987854004 seconds ---\n",
      "episode 1236, reward -85.0, memory_length 2000, epsilon 0.539021403076357\n",
      "travel time- 722.0\n",
      "--- 1.81410813331604 seconds ---\n",
      "episode 1237, reward 87.0, memory_length 2000, epsilon 0.538751959741266\n",
      "travel time- 720.0\n",
      "--- 1.577768087387085 seconds ---\n",
      "episode 1238, reward 4.0, memory_length 2000, epsilon 0.5384826510941678\n",
      "travel time- 723.0\n",
      "--- 1.793633222579956 seconds ---\n",
      "episode 1239, reward -185.0, memory_length 2000, epsilon 0.538213477067735\n",
      "travel time- 724.0\n",
      "--- 1.6860935688018799 seconds ---\n",
      "episode 1240, reward -6.0, memory_length 2000, epsilon 0.5379444375946745\n",
      "travel time- 723.0\n",
      "--- 1.645296573638916 seconds ---\n",
      "episode 1241, reward -232.0, memory_length 2000, epsilon 0.537675532607726\n",
      "travel time- 720.0\n",
      "--- 1.7323243618011475 seconds ---\n",
      "episode 1242, reward 75.0, memory_length 2000, epsilon 0.5374067620396636\n",
      "travel time- 721.0\n",
      "--- 1.7590389251708984 seconds ---\n",
      "episode 1243, reward -180.0, memory_length 2000, epsilon 0.5371381258232945\n",
      "travel time- 721.0\n",
      "--- 1.775897741317749 seconds ---\n",
      "episode 1244, reward 33.0, memory_length 2000, epsilon 0.5368696238914595\n",
      "travel time- 721.0\n",
      "--- 1.541996955871582 seconds ---\n",
      "episode 1245, reward -320.0, memory_length 2000, epsilon 0.5366012561770334\n",
      "travel time- 727.0\n",
      "--- 1.740741491317749 seconds ---\n",
      "episode 1246, reward 104.0, memory_length 2000, epsilon 0.5363330226129241\n",
      "travel time- 720.0\n",
      "--- 1.6433353424072266 seconds ---\n",
      "episode 1247, reward -273.0, memory_length 2000, epsilon 0.5360649231320733\n",
      "travel time- 730.0\n",
      "--- 1.591033935546875 seconds ---\n",
      "episode 1248, reward 14.0, memory_length 2000, epsilon 0.535796957667456\n",
      "travel time- 732.0\n",
      "--- 1.6666405200958252 seconds ---\n",
      "episode 1249, reward -34.0, memory_length 2000, epsilon 0.5355291261520809\n",
      "travel time- 725.0\n",
      "--- 1.7527220249176025 seconds ---\n",
      "episode 1250, reward -59.0, memory_length 2000, epsilon 0.5352614285189903\n",
      "travel time- 723.0\n",
      "--- 1.7393078804016113 seconds ---\n",
      "episode 1251, reward -137.0, memory_length 2000, epsilon 0.5349938647012594\n",
      "travel time- 720.0\n",
      "--- 1.8523740768432617 seconds ---\n",
      "episode 1252, reward -267.0, memory_length 2000, epsilon 0.5347264346319975\n",
      "travel time- 722.0\n",
      "--- 1.7386069297790527 seconds ---\n",
      "episode 1253, reward -23.0, memory_length 2000, epsilon 0.5344591382443471\n",
      "travel time- 727.0\n",
      "--- 1.6070232391357422 seconds ---\n",
      "episode 1254, reward -238.0, memory_length 2000, epsilon 0.5341919754714841\n",
      "travel time- 720.0\n",
      "--- 1.8593757152557373 seconds ---\n",
      "episode 1255, reward 49.0, memory_length 2000, epsilon 0.5339249462466177\n",
      "travel time- 721.0\n",
      "--- 1.7521088123321533 seconds ---\n",
      "episode 1256, reward -86.0, memory_length 2000, epsilon 0.5336580505029906\n",
      "travel time- 723.0\n",
      "--- 1.6834776401519775 seconds ---\n",
      "episode 1257, reward 49.0, memory_length 2000, epsilon 0.5333912881738789\n",
      "travel time- 723.0\n",
      "--- 1.619957685470581 seconds ---\n",
      "episode 1258, reward 9.0, memory_length 2000, epsilon 0.5331246591925921\n",
      "travel time- 727.0\n",
      "--- 1.7368736267089844 seconds ---\n",
      "episode 1259, reward -495.0, memory_length 2000, epsilon 0.5328581634924728\n",
      "travel time- 727.0\n",
      "--- 1.879544734954834 seconds ---\n",
      "episode 1260, reward -16.0, memory_length 2000, epsilon 0.5325918010068972\n",
      "travel time- 721.0\n",
      "--- 1.812955379486084 seconds ---\n",
      "episode 1261, reward -90.0, memory_length 2000, epsilon 0.5323255716692745\n",
      "travel time- 724.0\n",
      "--- 1.7067627906799316 seconds ---\n",
      "episode 1262, reward -11.0, memory_length 2000, epsilon 0.5320594754130477\n",
      "travel time- 720.0\n",
      "--- 1.8007524013519287 seconds ---\n",
      "episode 1263, reward -157.0, memory_length 2000, epsilon 0.5317935121716924\n",
      "travel time- 721.0\n",
      "--- 1.8678429126739502 seconds ---\n",
      "episode 1264, reward -168.0, memory_length 2000, epsilon 0.5315276818787179\n",
      "travel time- 723.0\n",
      "--- 1.4632747173309326 seconds ---\n",
      "episode 1265, reward -221.0, memory_length 2000, epsilon 0.5312619844676667\n",
      "travel time- 724.0\n",
      "--- 1.6854445934295654 seconds ---\n",
      "episode 1266, reward -208.0, memory_length 2000, epsilon 0.5309964198721143\n",
      "travel time- 727.0\n",
      "--- 1.835219383239746 seconds ---\n",
      "episode 1267, reward -185.0, memory_length 2000, epsilon 0.5307309880256696\n",
      "travel time- 722.0\n",
      "--- 1.6609992980957031 seconds ---\n",
      "episode 1268, reward -137.0, memory_length 2000, epsilon 0.5304656888619749\n",
      "travel time- 726.0\n",
      "--- 1.8021419048309326 seconds ---\n",
      "episode 1269, reward -130.0, memory_length 2000, epsilon 0.5302005223147049\n",
      "travel time- 722.0\n",
      "--- 1.6169872283935547 seconds ---\n",
      "episode 1270, reward -30.0, memory_length 2000, epsilon 0.5299354883175685\n",
      "travel time- 732.0\n",
      "--- 1.788207769393921 seconds ---\n",
      "episode 1271, reward -123.0, memory_length 2000, epsilon 0.5296705868043068\n",
      "travel time- 726.0\n",
      "--- 1.7190208435058594 seconds ---\n",
      "episode 1272, reward -95.0, memory_length 2000, epsilon 0.5294058177086945\n",
      "travel time- 727.0\n",
      "--- 1.6923441886901855 seconds ---\n",
      "episode 1273, reward 60.0, memory_length 2000, epsilon 0.5291411809645395\n",
      "travel time- 721.0\n",
      "--- 1.7637076377868652 seconds ---\n",
      "episode 1274, reward 15.0, memory_length 2000, epsilon 0.5288766765056825\n",
      "travel time- 731.0\n",
      "--- 1.6623661518096924 seconds ---\n",
      "episode 1275, reward -156.0, memory_length 2000, epsilon 0.5286123042659973\n",
      "travel time- 723.0\n",
      "--- 1.8484644889831543 seconds ---\n",
      "episode 1276, reward -64.0, memory_length 2000, epsilon 0.528348064179391\n",
      "travel time- 721.0\n",
      "--- 1.6715447902679443 seconds ---\n",
      "episode 1277, reward 97.0, memory_length 2000, epsilon 0.5280839561798034\n",
      "travel time- 726.0\n",
      "--- 1.7096657752990723 seconds ---\n",
      "episode 1278, reward 195.0, memory_length 2000, epsilon 0.5278199802012077\n",
      "travel time- 723.0\n",
      "--- 1.6632928848266602 seconds ---\n",
      "episode 1279, reward -309.0, memory_length 2000, epsilon 0.5275561361776097\n",
      "travel time- 728.0\n",
      "--- 1.7571446895599365 seconds ---\n",
      "episode 1280, reward -241.0, memory_length 2000, epsilon 0.5272924240430485\n",
      "travel time- 728.0\n",
      "--- 1.557732105255127 seconds ---\n",
      "episode 1281, reward -82.0, memory_length 2000, epsilon 0.5270288437315962\n",
      "travel time- 729.0\n",
      "--- 1.56889009475708 seconds ---\n",
      "episode 1282, reward 113.0, memory_length 2000, epsilon 0.5267653951773574\n",
      "travel time- 721.0\n",
      "--- 1.6424977779388428 seconds ---\n",
      "episode 1283, reward 136.0, memory_length 2000, epsilon 0.5265020783144703\n",
      "travel time- 732.0\n",
      "--- 1.6521165370941162 seconds ---\n",
      "episode 1284, reward 54.0, memory_length 2000, epsilon 0.5262388930771054\n",
      "travel time- 721.0\n",
      "--- 1.6959471702575684 seconds ---\n",
      "episode 1285, reward 155.0, memory_length 2000, epsilon 0.5259758393994666\n",
      "travel time- 722.0\n",
      "--- 1.446972370147705 seconds ---\n",
      "episode 1286, reward 178.0, memory_length 2000, epsilon 0.5257129172157903\n",
      "travel time- 720.0\n",
      "--- 1.5640134811401367 seconds ---\n",
      "episode 1287, reward -231.0, memory_length 2000, epsilon 0.5254501264603461\n",
      "travel time- 723.0\n",
      "--- 2.0253098011016846 seconds ---\n",
      "episode 1288, reward -234.0, memory_length 2000, epsilon 0.5251874670674361\n",
      "travel time- 722.0\n",
      "--- 1.569223165512085 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1289, reward 201.0, memory_length 2000, epsilon 0.5249249389713958\n",
      "travel time- 720.0\n",
      "--- 1.6739394664764404 seconds ---\n",
      "episode 1290, reward 31.0, memory_length 2000, epsilon 0.5246625421065929\n",
      "travel time- 729.0\n",
      "--- 1.660468339920044 seconds ---\n",
      "episode 1291, reward 19.0, memory_length 2000, epsilon 0.5244002764074283\n",
      "travel time- 725.0\n",
      "--- 1.830246925354004 seconds ---\n",
      "episode 1292, reward -152.0, memory_length 2000, epsilon 0.5241381418083354\n",
      "travel time- 721.0\n",
      "--- 1.692603588104248 seconds ---\n",
      "episode 1293, reward 21.0, memory_length 2000, epsilon 0.5238761382437809\n",
      "travel time- 723.0\n",
      "--- 1.6481201648712158 seconds ---\n",
      "episode 1294, reward 234.0, memory_length 2000, epsilon 0.5236142656482635\n",
      "travel time- 729.0\n",
      "--- 1.6785452365875244 seconds ---\n",
      "episode 1295, reward 108.0, memory_length 2000, epsilon 0.5233525239563153\n",
      "travel time- 725.0\n",
      "--- 1.5411083698272705 seconds ---\n",
      "episode 1296, reward 124.0, memory_length 2000, epsilon 0.5230909131025008\n",
      "travel time- 725.0\n",
      "--- 1.654341220855713 seconds ---\n",
      "episode 1297, reward -181.0, memory_length 2000, epsilon 0.5228294330214174\n",
      "travel time- 723.0\n",
      "--- 1.7622478008270264 seconds ---\n",
      "episode 1298, reward 78.0, memory_length 2000, epsilon 0.5225680836476948\n",
      "travel time- 721.0\n",
      "--- 1.6031651496887207 seconds ---\n",
      "episode 1299, reward -196.0, memory_length 2000, epsilon 0.522306864915996\n",
      "travel time- 725.0\n",
      "--- 1.6878700256347656 seconds ---\n",
      "episode 1300, reward 261.0, memory_length 2000, epsilon 0.522045776761016\n",
      "travel time- 727.0\n",
      "--- 1.639657974243164 seconds ---\n",
      "episode 1301, reward 21.0, memory_length 2000, epsilon 0.5217848191174831\n",
      "travel time- 724.0\n",
      "--- 1.6361079216003418 seconds ---\n",
      "episode 1302, reward 80.0, memory_length 2000, epsilon 0.5215239919201575\n",
      "travel time- 722.0\n",
      "--- 1.9175047874450684 seconds ---\n",
      "episode 1303, reward -250.0, memory_length 2000, epsilon 0.5212632951038327\n",
      "travel time- 724.0\n",
      "--- 1.766615629196167 seconds ---\n",
      "episode 1304, reward -475.0, memory_length 2000, epsilon 0.5210027286033344\n",
      "travel time- 730.0\n",
      "--- 1.7503175735473633 seconds ---\n",
      "episode 1305, reward -138.0, memory_length 2000, epsilon 0.520742292353521\n",
      "travel time- 726.0\n",
      "--- 1.6784865856170654 seconds ---\n",
      "episode 1306, reward -84.0, memory_length 2000, epsilon 0.5204819862892832\n",
      "travel time- 720.0\n",
      "--- 1.5480585098266602 seconds ---\n",
      "episode 1307, reward 391.0, memory_length 2000, epsilon 0.5202218103455449\n",
      "travel time- 729.0\n",
      "--- 1.579404592514038 seconds ---\n",
      "episode 1308, reward -89.0, memory_length 2000, epsilon 0.5199617644572618\n",
      "travel time- 726.0\n",
      "--- 1.5736379623413086 seconds ---\n",
      "episode 1309, reward -44.0, memory_length 2000, epsilon 0.5197018485594226\n",
      "travel time- 720.0\n",
      "--- 1.6885197162628174 seconds ---\n",
      "episode 1310, reward -166.0, memory_length 2000, epsilon 0.5194420625870482\n",
      "travel time- 722.0\n",
      "--- 1.7495698928833008 seconds ---\n",
      "episode 1311, reward -51.0, memory_length 2000, epsilon 0.5191824064751921\n",
      "travel time- 733.0\n",
      "--- 1.4713943004608154 seconds ---\n",
      "episode 1312, reward 142.0, memory_length 2000, epsilon 0.5189228801589404\n",
      "travel time- 732.0\n",
      "--- 1.7131133079528809 seconds ---\n",
      "episode 1313, reward -307.0, memory_length 2000, epsilon 0.5186634835734114\n",
      "travel time- 720.0\n",
      "--- 1.7591824531555176 seconds ---\n",
      "episode 1314, reward -8.0, memory_length 2000, epsilon 0.5184042166537559\n",
      "travel time- 730.0\n",
      "--- 1.770768642425537 seconds ---\n",
      "episode 1315, reward 37.0, memory_length 2000, epsilon 0.5181450793351574\n",
      "travel time- 727.0\n",
      "--- 1.5787858963012695 seconds ---\n",
      "episode 1316, reward 31.0, memory_length 2000, epsilon 0.5178860715528314\n",
      "travel time- 721.0\n",
      "--- 1.9840366840362549 seconds ---\n",
      "episode 1317, reward -11.0, memory_length 2000, epsilon 0.517627193242026\n",
      "travel time- 723.0\n",
      "--- 1.5848517417907715 seconds ---\n",
      "episode 1318, reward 22.0, memory_length 2000, epsilon 0.5173684443380216\n",
      "travel time- 724.0\n",
      "--- 1.6886780261993408 seconds ---\n",
      "episode 1319, reward 13.0, memory_length 2000, epsilon 0.517109824776131\n",
      "travel time- 725.0\n",
      "--- 1.5907447338104248 seconds ---\n",
      "episode 1320, reward -187.0, memory_length 2000, epsilon 0.5168513344916992\n",
      "travel time- 721.0\n",
      "--- 1.6928963661193848 seconds ---\n",
      "episode 1321, reward -190.0, memory_length 2000, epsilon 0.5165929734201038\n",
      "travel time- 725.0\n",
      "--- 1.6834368705749512 seconds ---\n",
      "episode 1322, reward 134.0, memory_length 2000, epsilon 0.5163347414967544\n",
      "travel time- 723.0\n",
      "--- 1.505333662033081 seconds ---\n",
      "episode 1323, reward 158.0, memory_length 2000, epsilon 0.5160766386570931\n",
      "travel time- 722.0\n",
      "--- 1.7073743343353271 seconds ---\n",
      "episode 1324, reward 65.0, memory_length 2000, epsilon 0.5158186648365941\n",
      "travel time- 732.0\n",
      "--- 1.8291239738464355 seconds ---\n",
      "episode 1325, reward -13.0, memory_length 2000, epsilon 0.5155608199707641\n",
      "travel time- 722.0\n",
      "--- 1.8521666526794434 seconds ---\n",
      "episode 1326, reward -196.0, memory_length 2000, epsilon 0.5153031039951417\n",
      "travel time- 725.0\n",
      "--- 1.699002981185913 seconds ---\n",
      "episode 1327, reward -83.0, memory_length 2000, epsilon 0.515045516845298\n",
      "travel time- 732.0\n",
      "--- 1.529266595840454 seconds ---\n",
      "episode 1328, reward -329.0, memory_length 2000, epsilon 0.5147880584568362\n",
      "travel time- 723.0\n",
      "--- 1.5848486423492432 seconds ---\n",
      "episode 1329, reward -189.0, memory_length 2000, epsilon 0.5145307287653916\n",
      "travel time- 722.0\n",
      "--- 1.6680433750152588 seconds ---\n",
      "episode 1330, reward -156.0, memory_length 2000, epsilon 0.5142735277066319\n",
      "travel time- 722.0\n",
      "--- 1.8637447357177734 seconds ---\n",
      "episode 1331, reward -250.0, memory_length 2000, epsilon 0.5140164552162569\n",
      "travel time- 727.0\n",
      "--- 1.6520771980285645 seconds ---\n",
      "episode 1332, reward -14.0, memory_length 2000, epsilon 0.5137595112299983\n",
      "travel time- 721.0\n",
      "--- 1.694096326828003 seconds ---\n",
      "episode 1333, reward 231.0, memory_length 2000, epsilon 0.5135026956836203\n",
      "travel time- 731.0\n",
      "--- 1.4794275760650635 seconds ---\n",
      "episode 1334, reward -169.0, memory_length 2000, epsilon 0.5132460085129188\n",
      "travel time- 721.0\n",
      "--- 1.725008249282837 seconds ---\n",
      "episode 1335, reward 5.0, memory_length 2000, epsilon 0.5129894496537222\n",
      "travel time- 723.0\n",
      "--- 1.792003870010376 seconds ---\n",
      "episode 1336, reward -134.0, memory_length 2000, epsilon 0.5127330190418905\n",
      "travel time- 721.0\n",
      "--- 1.6461002826690674 seconds ---\n",
      "episode 1337, reward -132.0, memory_length 2000, epsilon 0.5124767166133164\n",
      "travel time- 723.0\n",
      "--- 1.8410181999206543 seconds ---\n",
      "episode 1338, reward -192.0, memory_length 2000, epsilon 0.512220542303924\n",
      "travel time- 720.0\n",
      "--- 1.6083347797393799 seconds ---\n",
      "episode 1339, reward -551.0, memory_length 2000, epsilon 0.5119644960496699\n",
      "travel time- 724.0\n",
      "--- 1.8321166038513184 seconds ---\n",
      "episode 1340, reward 29.0, memory_length 2000, epsilon 0.5117085777865424\n",
      "travel time- 724.0\n",
      "--- 1.7754905223846436 seconds ---\n",
      "episode 1341, reward 23.0, memory_length 2000, epsilon 0.5114527874505622\n",
      "travel time- 727.0\n",
      "--- 1.5475292205810547 seconds ---\n",
      "episode 1342, reward -293.0, memory_length 2000, epsilon 0.5111971249777814\n",
      "travel time- 723.0\n",
      "--- 1.6860179901123047 seconds ---\n",
      "episode 1343, reward -261.0, memory_length 2000, epsilon 0.5109415903042845\n",
      "travel time- 721.0\n",
      "--- 1.78757643699646 seconds ---\n",
      "episode 1344, reward 130.0, memory_length 2000, epsilon 0.5106861833661879\n",
      "travel time- 729.0\n",
      "--- 1.6904120445251465 seconds ---\n",
      "episode 1345, reward -109.0, memory_length 2000, epsilon 0.5104309040996398\n",
      "travel time- 726.0\n",
      "--- 1.4222002029418945 seconds ---\n",
      "episode 1346, reward 45.0, memory_length 2000, epsilon 0.5101757524408203\n",
      "travel time- 723.0\n",
      "--- 1.5957708358764648 seconds ---\n",
      "episode 1347, reward 32.0, memory_length 2000, epsilon 0.5099207283259416\n",
      "travel time- 723.0\n",
      "--- 1.567676305770874 seconds ---\n",
      "episode 1348, reward -84.0, memory_length 2000, epsilon 0.5096658316912476\n",
      "travel time- 724.0\n",
      "--- 1.5329418182373047 seconds ---\n",
      "episode 1349, reward -256.0, memory_length 2000, epsilon 0.5094110624730143\n",
      "travel time- 723.0\n",
      "--- 1.6879246234893799 seconds ---\n",
      "episode 1350, reward -192.0, memory_length 2000, epsilon 0.5091564206075492\n",
      "travel time- 725.0\n",
      "--- 1.8022546768188477 seconds ---\n",
      "episode 1351, reward -219.0, memory_length 2000, epsilon 0.5089019060311919\n",
      "travel time- 720.0\n",
      "--- 1.9586400985717773 seconds ---\n",
      "episode 1352, reward 12.0, memory_length 2000, epsilon 0.5086475186803137\n",
      "travel time- 725.0\n",
      "--- 1.9569222927093506 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1353, reward 35.0, memory_length 2000, epsilon 0.5083932584913179\n",
      "travel time- 723.0\n",
      "--- 1.6345350742340088 seconds ---\n",
      "episode 1354, reward -82.0, memory_length 2000, epsilon 0.5081391254006393\n",
      "travel time- 724.0\n",
      "--- 1.8307788372039795 seconds ---\n",
      "episode 1355, reward -251.0, memory_length 2000, epsilon 0.5078851193447448\n",
      "travel time- 723.0\n",
      "--- 1.7815327644348145 seconds ---\n",
      "episode 1356, reward -426.0, memory_length 2000, epsilon 0.5076312402601327\n",
      "travel time- 721.0\n",
      "--- 1.64872407913208 seconds ---\n",
      "episode 1357, reward -183.0, memory_length 2000, epsilon 0.5073774880833334\n",
      "travel time- 730.0\n",
      "--- 1.688080072402954 seconds ---\n",
      "episode 1358, reward -97.0, memory_length 2000, epsilon 0.5071238627509086\n",
      "travel time- 721.0\n",
      "--- 1.8940563201904297 seconds ---\n",
      "episode 1359, reward 17.0, memory_length 2000, epsilon 0.5068703641994523\n",
      "travel time- 720.0\n",
      "--- 1.7598178386688232 seconds ---\n",
      "episode 1360, reward 86.0, memory_length 2000, epsilon 0.5066169923655895\n",
      "travel time- 723.0\n",
      "--- 1.5931284427642822 seconds ---\n",
      "episode 1361, reward -109.0, memory_length 2000, epsilon 0.5063637471859777\n",
      "travel time- 726.0\n",
      "--- 1.6011476516723633 seconds ---\n",
      "episode 1362, reward -44.0, memory_length 2000, epsilon 0.5061106285973052\n",
      "travel time- 720.0\n",
      "--- 1.47705078125 seconds ---\n",
      "episode 1363, reward 10.0, memory_length 2000, epsilon 0.5058576365362925\n",
      "travel time- 730.0\n",
      "--- 1.6815571784973145 seconds ---\n",
      "episode 1364, reward -69.0, memory_length 2000, epsilon 0.5056047709396915\n",
      "travel time- 721.0\n",
      "--- 1.536818027496338 seconds ---\n",
      "episode 1365, reward -25.0, memory_length 2000, epsilon 0.5053520317442859\n",
      "travel time- 725.0\n",
      "--- 1.4791233539581299 seconds ---\n",
      "episode 1366, reward -219.0, memory_length 2000, epsilon 0.5050994188868908\n",
      "travel time- 721.0\n",
      "--- 1.700331687927246 seconds ---\n",
      "episode 1367, reward 24.0, memory_length 2000, epsilon 0.5048469323043532\n",
      "travel time- 721.0\n",
      "--- 1.6597940921783447 seconds ---\n",
      "episode 1368, reward 245.0, memory_length 2000, epsilon 0.5045945719335512\n",
      "travel time- 728.0\n",
      "--- 1.5561954975128174 seconds ---\n",
      "episode 1369, reward -148.0, memory_length 2000, epsilon 0.5043423377113948\n",
      "travel time- 721.0\n",
      "--- 1.7139604091644287 seconds ---\n",
      "episode 1370, reward 18.0, memory_length 2000, epsilon 0.5040902295748255\n",
      "travel time- 720.0\n",
      "--- 1.6901392936706543 seconds ---\n",
      "episode 1371, reward -40.0, memory_length 2000, epsilon 0.5038382474608163\n",
      "travel time- 732.0\n",
      "--- 1.47178053855896 seconds ---\n",
      "episode 1372, reward 204.0, memory_length 2000, epsilon 0.5035863913063714\n",
      "travel time- 723.0\n",
      "--- 1.639535903930664 seconds ---\n",
      "episode 1373, reward 166.0, memory_length 2000, epsilon 0.5033346610485271\n",
      "travel time- 727.0\n",
      "--- 1.6707367897033691 seconds ---\n",
      "episode 1374, reward -82.0, memory_length 2000, epsilon 0.5030830566243506\n",
      "travel time- 725.0\n",
      "--- 1.875011920928955 seconds ---\n",
      "episode 1375, reward 20.0, memory_length 2000, epsilon 0.5028315779709409\n",
      "travel time- 720.0\n",
      "--- 1.785245418548584 seconds ---\n",
      "episode 1376, reward 155.0, memory_length 2000, epsilon 0.5025802250254283\n",
      "travel time- 720.0\n",
      "--- 1.6448392868041992 seconds ---\n",
      "episode 1377, reward 107.0, memory_length 2000, epsilon 0.5023289977249746\n",
      "travel time- 726.0\n",
      "--- 1.7133188247680664 seconds ---\n",
      "episode 1378, reward -75.0, memory_length 2000, epsilon 0.502077896006773\n",
      "travel time- 723.0\n",
      "--- 1.927962303161621 seconds ---\n",
      "episode 1379, reward 263.0, memory_length 2000, epsilon 0.501826919808048\n",
      "travel time- 723.0\n",
      "--- 1.6542901992797852 seconds ---\n",
      "episode 1380, reward -168.0, memory_length 2000, epsilon 0.5015760690660555\n",
      "travel time- 720.0\n",
      "--- 1.5662221908569336 seconds ---\n",
      "episode 1381, reward -184.0, memory_length 2000, epsilon 0.5013253437180829\n",
      "travel time- 720.0\n",
      "--- 1.7663977146148682 seconds ---\n",
      "episode 1382, reward -155.0, memory_length 2000, epsilon 0.5010747437014489\n",
      "travel time- 726.0\n",
      "--- 1.5899548530578613 seconds ---\n",
      "episode 1383, reward -301.0, memory_length 2000, epsilon 0.5008242689535034\n",
      "travel time- 721.0\n",
      "--- 1.726088047027588 seconds ---\n",
      "episode 1384, reward -160.0, memory_length 2000, epsilon 0.5005739194116277\n",
      "travel time- 720.0\n",
      "--- 1.807159423828125 seconds ---\n",
      "episode 1385, reward -266.0, memory_length 2000, epsilon 0.5003236950132345\n",
      "travel time- 724.0\n",
      "--- 1.629086971282959 seconds ---\n",
      "episode 1386, reward -200.0, memory_length 2000, epsilon 0.5000735956957676\n",
      "travel time- 722.0\n",
      "--- 1.8304197788238525 seconds ---\n",
      "episode 1387, reward 218.0, memory_length 2000, epsilon 0.49982362139670233\n",
      "travel time- 732.0\n",
      "--- 1.5453250408172607 seconds ---\n",
      "episode 1388, reward 124.0, memory_length 2000, epsilon 0.4995737720535449\n",
      "travel time- 720.0\n",
      "--- 1.628418207168579 seconds ---\n",
      "episode 1389, reward -199.0, memory_length 2000, epsilon 0.4993240476038332\n",
      "travel time- 723.0\n",
      "--- 1.6917757987976074 seconds ---\n",
      "episode 1390, reward -483.0, memory_length 2000, epsilon 0.49907444798513595\n",
      "travel time- 727.0\n",
      "--- 1.7505640983581543 seconds ---\n",
      "episode 1391, reward 105.0, memory_length 2000, epsilon 0.4988249731350533\n",
      "travel time- 721.0\n",
      "--- 1.5209815502166748 seconds ---\n",
      "episode 1392, reward -279.0, memory_length 2000, epsilon 0.4985756229912165\n",
      "travel time- 731.0\n",
      "--- 1.7434186935424805 seconds ---\n",
      "episode 1393, reward -114.0, memory_length 2000, epsilon 0.4983263974912881\n",
      "travel time- 722.0\n",
      "--- 1.6416802406311035 seconds ---\n",
      "episode 1394, reward -192.0, memory_length 2000, epsilon 0.4980772965729616\n",
      "travel time- 725.0\n",
      "--- 1.5985689163208008 seconds ---\n",
      "episode 1395, reward 2.0, memory_length 2000, epsilon 0.49782832017396195\n",
      "travel time- 727.0\n",
      "--- 1.7265973091125488 seconds ---\n",
      "episode 1396, reward 147.0, memory_length 2000, epsilon 0.4975794682320448\n",
      "travel time- 730.0\n",
      "--- 1.4961438179016113 seconds ---\n",
      "episode 1397, reward -346.0, memory_length 2000, epsilon 0.4973307406849974\n",
      "travel time- 720.0\n",
      "--- 1.5648484230041504 seconds ---\n",
      "episode 1398, reward -445.0, memory_length 2000, epsilon 0.4970821374706377\n",
      "travel time- 723.0\n",
      "--- 1.7926967144012451 seconds ---\n",
      "episode 1399, reward -61.0, memory_length 2000, epsilon 0.496833658526815\n",
      "travel time- 720.0\n",
      "--- 1.6334092617034912 seconds ---\n",
      "episode 1400, reward -402.0, memory_length 2000, epsilon 0.49658530379140947\n",
      "travel time- 722.0\n",
      "--- 1.5951533317565918 seconds ---\n",
      "episode 1401, reward -186.0, memory_length 2000, epsilon 0.49633707320233256\n",
      "travel time- 724.0\n",
      "--- 1.6619937419891357 seconds ---\n",
      "episode 1402, reward -165.0, memory_length 2000, epsilon 0.49608896669752645\n",
      "travel time- 726.0\n",
      "--- 1.5179705619812012 seconds ---\n",
      "episode 1403, reward -10.0, memory_length 2000, epsilon 0.49584098421496464\n",
      "travel time- 721.0\n",
      "--- 1.6046414375305176 seconds ---\n",
      "episode 1404, reward 78.0, memory_length 2000, epsilon 0.4955931256926514\n",
      "travel time- 724.0\n",
      "--- 1.7326157093048096 seconds ---\n",
      "episode 1405, reward 202.0, memory_length 2000, epsilon 0.4953453910686223\n",
      "travel time- 728.0\n",
      "--- 1.5366852283477783 seconds ---\n",
      "episode 1406, reward -349.0, memory_length 2000, epsilon 0.4950977802809434\n",
      "travel time- 723.0\n",
      "--- 1.4876086711883545 seconds ---\n",
      "episode 1407, reward -62.0, memory_length 2000, epsilon 0.49485029326771224\n",
      "travel time- 721.0\n",
      "--- 1.6677289009094238 seconds ---\n",
      "episode 1408, reward -125.0, memory_length 2000, epsilon 0.494602929967057\n",
      "travel time- 726.0\n",
      "--- 1.6902596950531006 seconds ---\n",
      "episode 1409, reward -124.0, memory_length 2000, epsilon 0.4943556903171367\n",
      "travel time- 721.0\n",
      "--- 1.730149745941162 seconds ---\n",
      "episode 1410, reward 140.0, memory_length 2000, epsilon 0.4941085742561417\n",
      "travel time- 725.0\n",
      "--- 1.4501080513000488 seconds ---\n",
      "episode 1411, reward -308.0, memory_length 2000, epsilon 0.4938615817222927\n",
      "travel time- 722.0\n",
      "--- 1.7759296894073486 seconds ---\n",
      "episode 1412, reward -387.0, memory_length 2000, epsilon 0.4936147126538418\n",
      "travel time- 721.0\n",
      "--- 1.7580420970916748 seconds ---\n",
      "episode 1413, reward -267.0, memory_length 2000, epsilon 0.49336796698907165\n",
      "travel time- 720.0\n",
      "--- 1.8218681812286377 seconds ---\n",
      "episode 1414, reward -316.0, memory_length 2000, epsilon 0.49312134466629576\n",
      "travel time- 720.0\n",
      "--- 1.823521375656128 seconds ---\n",
      "episode 1415, reward -32.0, memory_length 2000, epsilon 0.4928748456238586\n",
      "travel time- 720.0\n",
      "--- 1.6236062049865723 seconds ---\n",
      "episode 1416, reward 99.0, memory_length 2000, epsilon 0.49262846980013547\n",
      "travel time- 720.0\n",
      "--- 1.4652080535888672 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1417, reward -228.0, memory_length 2000, epsilon 0.4923822171335323\n",
      "travel time- 729.0\n",
      "--- 1.6505131721496582 seconds ---\n",
      "episode 1418, reward -233.0, memory_length 2000, epsilon 0.492136087562486\n",
      "travel time- 730.0\n",
      "--- 1.9090359210968018 seconds ---\n",
      "episode 1419, reward -480.0, memory_length 2000, epsilon 0.4918900810254641\n",
      "travel time- 723.0\n",
      "--- 1.7034556865692139 seconds ---\n",
      "episode 1420, reward -80.0, memory_length 2000, epsilon 0.4916441974609651\n",
      "travel time- 728.0\n",
      "--- 1.5332727432250977 seconds ---\n",
      "episode 1421, reward -78.0, memory_length 2000, epsilon 0.491398436807518\n",
      "travel time- 721.0\n",
      "--- 1.8730065822601318 seconds ---\n",
      "episode 1422, reward 21.0, memory_length 2000, epsilon 0.49115279900368264\n",
      "travel time- 720.0\n",
      "--- 1.721343994140625 seconds ---\n",
      "episode 1423, reward -29.0, memory_length 2000, epsilon 0.4909072839880496\n",
      "travel time- 721.0\n",
      "--- 1.963637351989746 seconds ---\n",
      "episode 1424, reward 44.0, memory_length 2000, epsilon 0.4906618916992401\n",
      "travel time- 722.0\n",
      "--- 1.8229877948760986 seconds ---\n",
      "episode 1425, reward -307.0, memory_length 2000, epsilon 0.49041662207590614\n",
      "travel time- 720.0\n",
      "--- 1.7262041568756104 seconds ---\n",
      "episode 1426, reward -16.0, memory_length 2000, epsilon 0.4901714750567302\n",
      "travel time- 722.0\n",
      "--- 1.7543518543243408 seconds ---\n",
      "episode 1427, reward -369.0, memory_length 2000, epsilon 0.48992645058042555\n",
      "travel time- 722.0\n",
      "--- 1.586033582687378 seconds ---\n",
      "episode 1428, reward -75.0, memory_length 2000, epsilon 0.4896815485857362\n",
      "travel time- 722.0\n",
      "--- 1.715376615524292 seconds ---\n",
      "episode 1429, reward -138.0, memory_length 2000, epsilon 0.48943676901143646\n",
      "travel time- 722.0\n",
      "--- 1.7104291915893555 seconds ---\n",
      "episode 1430, reward 213.0, memory_length 2000, epsilon 0.48919211179633154\n",
      "travel time- 725.0\n",
      "--- 1.4542570114135742 seconds ---\n",
      "episode 1431, reward 105.0, memory_length 2000, epsilon 0.4889475768792571\n",
      "travel time- 723.0\n",
      "--- 1.6261391639709473 seconds ---\n",
      "episode 1432, reward -1.0, memory_length 2000, epsilon 0.4887031641990795\n",
      "travel time- 724.0\n",
      "--- 1.930626630783081 seconds ---\n",
      "episode 1433, reward 96.0, memory_length 2000, epsilon 0.4884588736946954\n",
      "travel time- 734.0\n",
      "--- 1.685833215713501 seconds ---\n",
      "episode 1434, reward -22.0, memory_length 2000, epsilon 0.4882147053050323\n",
      "travel time- 721.0\n",
      "--- 1.6701490879058838 seconds ---\n",
      "episode 1435, reward -103.0, memory_length 2000, epsilon 0.48797065896904807\n",
      "travel time- 720.0\n",
      "--- 1.6897192001342773 seconds ---\n",
      "episode 1436, reward -132.0, memory_length 2000, epsilon 0.4877267346257312\n",
      "travel time- 727.0\n",
      "--- 1.7365868091583252 seconds ---\n",
      "episode 1437, reward 49.0, memory_length 2000, epsilon 0.4874829322141004\n",
      "travel time- 737.0\n",
      "--- 1.5731797218322754 seconds ---\n",
      "episode 1438, reward 70.0, memory_length 2000, epsilon 0.48723925167320525\n",
      "travel time- 720.0\n",
      "--- 1.6715822219848633 seconds ---\n",
      "episode 1439, reward 7.0, memory_length 2000, epsilon 0.4869956929421256\n",
      "travel time- 725.0\n",
      "--- 1.8439979553222656 seconds ---\n",
      "episode 1440, reward -554.0, memory_length 2000, epsilon 0.4867522559599717\n",
      "travel time- 725.0\n",
      "--- 1.7310206890106201 seconds ---\n",
      "episode 1441, reward -231.0, memory_length 2000, epsilon 0.48650894066588424\n",
      "travel time- 723.0\n",
      "--- 1.7189226150512695 seconds ---\n",
      "episode 1442, reward -37.0, memory_length 2000, epsilon 0.4862657469990346\n",
      "travel time- 720.0\n",
      "--- 1.7586839199066162 seconds ---\n",
      "episode 1443, reward 223.0, memory_length 2000, epsilon 0.4860226748986241\n",
      "travel time- 722.0\n",
      "--- 1.576869010925293 seconds ---\n",
      "episode 1444, reward -223.0, memory_length 2000, epsilon 0.485779724303885\n",
      "travel time- 720.0\n",
      "--- 1.6068048477172852 seconds ---\n",
      "episode 1445, reward -329.0, memory_length 2000, epsilon 0.48553689515407944\n",
      "travel time- 721.0\n",
      "--- 1.6284091472625732 seconds ---\n",
      "episode 1446, reward 141.0, memory_length 2000, epsilon 0.4852941873885002\n",
      "travel time- 720.0\n",
      "--- 1.7052288055419922 seconds ---\n",
      "episode 1447, reward -83.0, memory_length 2000, epsilon 0.4850516009464703\n",
      "travel time- 720.0\n",
      "--- 1.6454644203186035 seconds ---\n",
      "episode 1448, reward -301.0, memory_length 2000, epsilon 0.48480913576734325\n",
      "travel time- 720.0\n",
      "--- 1.7010624408721924 seconds ---\n",
      "episode 1449, reward -110.0, memory_length 2000, epsilon 0.4845667917905026\n",
      "travel time- 723.0\n",
      "--- 1.4640250205993652 seconds ---\n",
      "episode 1450, reward 154.0, memory_length 2000, epsilon 0.48432456895536247\n",
      "travel time- 724.0\n",
      "--- 1.7061407566070557 seconds ---\n",
      "episode 1451, reward 10.0, memory_length 2000, epsilon 0.48408246720136705\n",
      "travel time- 725.0\n",
      "--- 1.469994068145752 seconds ---\n",
      "episode 1452, reward -86.0, memory_length 2000, epsilon 0.483840486467991\n",
      "travel time- 728.0\n",
      "--- 1.6320877075195312 seconds ---\n",
      "episode 1453, reward 82.0, memory_length 2000, epsilon 0.483598626694739\n",
      "travel time- 720.0\n",
      "--- 1.8238561153411865 seconds ---\n",
      "episode 1454, reward -336.0, memory_length 2000, epsilon 0.48335688782114633\n",
      "travel time- 727.0\n",
      "--- 1.7864575386047363 seconds ---\n",
      "episode 1455, reward -214.0, memory_length 2000, epsilon 0.48311526978677805\n",
      "travel time- 721.0\n",
      "--- 1.6379976272583008 seconds ---\n",
      "episode 1456, reward 152.0, memory_length 2000, epsilon 0.48287377253122976\n",
      "travel time- 724.0\n",
      "--- 1.628084659576416 seconds ---\n",
      "episode 1457, reward 142.0, memory_length 2000, epsilon 0.48263239599412705\n",
      "travel time- 724.0\n",
      "--- 1.6223275661468506 seconds ---\n",
      "episode 1458, reward -113.0, memory_length 2000, epsilon 0.4823911401151259\n",
      "travel time- 721.0\n",
      "--- 1.6365432739257812 seconds ---\n",
      "episode 1459, reward 249.0, memory_length 2000, epsilon 0.4821500048339123\n",
      "travel time- 721.0\n",
      "--- 1.784930944442749 seconds ---\n",
      "episode 1460, reward -35.0, memory_length 2000, epsilon 0.48190899009020244\n",
      "travel time- 724.0\n",
      "--- 1.7058095932006836 seconds ---\n",
      "episode 1461, reward -165.0, memory_length 2000, epsilon 0.48166809582374254\n",
      "travel time- 722.0\n",
      "--- 1.788982629776001 seconds ---\n",
      "episode 1462, reward 132.0, memory_length 2000, epsilon 0.4814273219743092\n",
      "travel time- 728.0\n",
      "--- 1.8654072284698486 seconds ---\n",
      "episode 1463, reward 76.0, memory_length 2000, epsilon 0.48118666848170877\n",
      "travel time- 723.0\n",
      "--- 1.6796298027038574 seconds ---\n",
      "episode 1464, reward 227.0, memory_length 2000, epsilon 0.480946135285778\n",
      "travel time- 720.0\n",
      "--- 1.5008881092071533 seconds ---\n",
      "episode 1465, reward -49.0, memory_length 2000, epsilon 0.4807057223263836\n",
      "travel time- 723.0\n",
      "--- 1.7191784381866455 seconds ---\n",
      "episode 1466, reward -20.0, memory_length 2000, epsilon 0.48046542954342225\n",
      "travel time- 721.0\n",
      "--- 1.5390191078186035 seconds ---\n",
      "episode 1467, reward 199.0, memory_length 2000, epsilon 0.48022525687682077\n",
      "travel time- 731.0\n",
      "--- 1.702497959136963 seconds ---\n",
      "episode 1468, reward 73.0, memory_length 2000, epsilon 0.479985204266536\n",
      "travel time- 728.0\n",
      "--- 1.611649990081787 seconds ---\n",
      "episode 1469, reward 37.0, memory_length 2000, epsilon 0.4797452716525548\n",
      "travel time- 724.0\n",
      "--- 1.4922974109649658 seconds ---\n",
      "episode 1470, reward -161.0, memory_length 2000, epsilon 0.4795054589748941\n",
      "travel time- 722.0\n",
      "--- 1.5135693550109863 seconds ---\n",
      "episode 1471, reward -409.0, memory_length 2000, epsilon 0.47926576617360056\n",
      "travel time- 723.0\n",
      "--- 1.5307204723358154 seconds ---\n",
      "episode 1472, reward 157.0, memory_length 2000, epsilon 0.4790261931887511\n",
      "travel time- 720.0\n",
      "--- 1.453073263168335 seconds ---\n",
      "episode 1473, reward -57.0, memory_length 2000, epsilon 0.47878673996045235\n",
      "travel time- 727.0\n",
      "--- 1.8730518817901611 seconds ---\n",
      "episode 1474, reward -91.0, memory_length 2000, epsilon 0.4785474064288412\n",
      "travel time- 736.0\n",
      "--- 1.647170066833496 seconds ---\n",
      "episode 1475, reward -189.0, memory_length 2000, epsilon 0.4783081925340841\n",
      "travel time- 723.0\n",
      "--- 1.5926239490509033 seconds ---\n",
      "episode 1476, reward -244.0, memory_length 2000, epsilon 0.4780690982163776\n",
      "travel time- 729.0\n",
      "--- 1.5588252544403076 seconds ---\n",
      "episode 1477, reward -357.0, memory_length 2000, epsilon 0.4778301234159481\n",
      "travel time- 720.0\n",
      "--- 1.9028279781341553 seconds ---\n",
      "episode 1478, reward -171.0, memory_length 2000, epsilon 0.4775912680730521\n",
      "travel time- 725.0\n",
      "--- 1.4457240104675293 seconds ---\n",
      "episode 1479, reward -60.0, memory_length 2000, epsilon 0.47735253212797546\n",
      "travel time- 727.0\n",
      "--- 1.6287686824798584 seconds ---\n",
      "episode 1480, reward 311.0, memory_length 2000, epsilon 0.4771139155210344\n",
      "travel time- 725.0\n",
      "--- 1.6745176315307617 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1481, reward 210.0, memory_length 2000, epsilon 0.4768754181925747\n",
      "travel time- 720.0\n",
      "--- 1.6433167457580566 seconds ---\n",
      "episode 1482, reward 23.0, memory_length 2000, epsilon 0.47663704008297203\n",
      "travel time- 720.0\n",
      "--- 1.5820622444152832 seconds ---\n",
      "episode 1483, reward 126.0, memory_length 2000, epsilon 0.4763987811326318\n",
      "travel time- 729.0\n",
      "--- 1.4461960792541504 seconds ---\n",
      "episode 1484, reward -93.0, memory_length 2000, epsilon 0.4761606412819894\n",
      "travel time- 720.0\n",
      "--- 1.6222734451293945 seconds ---\n",
      "episode 1485, reward 176.0, memory_length 2000, epsilon 0.4759226204715098\n",
      "travel time- 724.0\n",
      "--- 1.544564962387085 seconds ---\n",
      "episode 1486, reward -165.0, memory_length 2000, epsilon 0.4756847186416878\n",
      "travel time- 723.0\n",
      "--- 1.63442063331604 seconds ---\n",
      "episode 1487, reward 115.0, memory_length 2000, epsilon 0.4754469357330479\n",
      "travel time- 721.0\n",
      "--- 1.6492581367492676 seconds ---\n",
      "episode 1488, reward -116.0, memory_length 2000, epsilon 0.47520927168614446\n",
      "travel time- 725.0\n",
      "--- 1.5251338481903076 seconds ---\n",
      "episode 1489, reward 1.0, memory_length 2000, epsilon 0.4749717264415614\n",
      "travel time- 720.0\n",
      "--- 1.6026499271392822 seconds ---\n",
      "episode 1490, reward -454.0, memory_length 2000, epsilon 0.4747342999399124\n",
      "travel time- 725.0\n",
      "--- 1.815535545349121 seconds ---\n",
      "episode 1491, reward 263.0, memory_length 2000, epsilon 0.4744969921218409\n",
      "travel time- 720.0\n",
      "--- 1.565140724182129 seconds ---\n",
      "episode 1492, reward -99.0, memory_length 2000, epsilon 0.4742598029280199\n",
      "travel time- 721.0\n",
      "--- 1.6859688758850098 seconds ---\n",
      "episode 1493, reward 99.0, memory_length 2000, epsilon 0.47402273229915204\n",
      "travel time- 726.0\n",
      "--- 1.8657608032226562 seconds ---\n",
      "episode 1494, reward -305.0, memory_length 2000, epsilon 0.4737857801759698\n",
      "travel time- 723.0\n",
      "--- 1.9344823360443115 seconds ---\n",
      "episode 1495, reward 53.0, memory_length 2000, epsilon 0.47354894649923496\n",
      "travel time- 723.0\n",
      "--- 1.6970419883728027 seconds ---\n",
      "episode 1496, reward 92.0, memory_length 2000, epsilon 0.4733122312097393\n",
      "travel time- 721.0\n",
      "--- 1.3057365417480469 seconds ---\n",
      "episode 1497, reward -366.0, memory_length 2000, epsilon 0.4730756342483039\n",
      "travel time- 720.0\n",
      "--- 1.475142478942871 seconds ---\n",
      "episode 1498, reward -464.0, memory_length 2000, epsilon 0.47283915555577954\n",
      "travel time- 725.0\n",
      "--- 1.6469202041625977 seconds ---\n",
      "episode 1499, reward 136.0, memory_length 2000, epsilon 0.4726027950730465\n",
      "travel time- 728.0\n",
      "--- 1.5300178527832031 seconds ---\n",
      "episode 1500, reward -35.0, memory_length 2000, epsilon 0.4723665527410147\n",
      "travel time- 726.0\n",
      "--- 1.8287363052368164 seconds ---\n",
      "episode 1501, reward -46.0, memory_length 2000, epsilon 0.47213042850062353\n",
      "travel time- 720.0\n",
      "--- 1.525129795074463 seconds ---\n",
      "episode 1502, reward -147.0, memory_length 2000, epsilon 0.471894422292842\n",
      "travel time- 722.0\n",
      "--- 1.8078079223632812 seconds ---\n",
      "episode 1503, reward -394.0, memory_length 2000, epsilon 0.4716585340586684\n",
      "travel time- 729.0\n",
      "--- 1.6528537273406982 seconds ---\n",
      "episode 1504, reward 377.0, memory_length 2000, epsilon 0.4714227637391309\n",
      "travel time- 725.0\n",
      "--- 1.7376415729522705 seconds ---\n",
      "episode 1505, reward 259.0, memory_length 2000, epsilon 0.4711871112752867\n",
      "travel time- 720.0\n",
      "--- 1.707413673400879 seconds ---\n",
      "episode 1506, reward -422.0, memory_length 2000, epsilon 0.4709515766082228\n",
      "travel time- 725.0\n",
      "--- 1.7513236999511719 seconds ---\n",
      "episode 1507, reward 80.0, memory_length 2000, epsilon 0.47071615967905545\n",
      "travel time- 725.0\n",
      "--- 1.5850634574890137 seconds ---\n",
      "episode 1508, reward -191.0, memory_length 2000, epsilon 0.47048086042893056\n",
      "travel time- 724.0\n",
      "--- 1.5523717403411865 seconds ---\n",
      "episode 1509, reward 165.0, memory_length 2000, epsilon 0.4702456787990232\n",
      "travel time- 722.0\n",
      "--- 1.5250742435455322 seconds ---\n",
      "episode 1510, reward -259.0, memory_length 2000, epsilon 0.47001061473053796\n",
      "travel time- 722.0\n",
      "--- 1.7231483459472656 seconds ---\n",
      "episode 1511, reward -129.0, memory_length 2000, epsilon 0.46977566816470884\n",
      "travel time- 722.0\n",
      "--- 1.6379103660583496 seconds ---\n",
      "episode 1512, reward -214.0, memory_length 2000, epsilon 0.46954083904279925\n",
      "travel time- 725.0\n",
      "--- 1.5886852741241455 seconds ---\n",
      "episode 1513, reward 263.0, memory_length 2000, epsilon 0.46930612730610183\n",
      "travel time- 729.0\n",
      "--- 1.475043535232544 seconds ---\n",
      "episode 1514, reward -150.0, memory_length 2000, epsilon 0.4690715328959387\n",
      "travel time- 720.0\n",
      "--- 1.6653945446014404 seconds ---\n",
      "episode 1515, reward 378.0, memory_length 2000, epsilon 0.46883705575366125\n",
      "travel time- 720.0\n",
      "--- 1.551772117614746 seconds ---\n",
      "episode 1516, reward -184.0, memory_length 2000, epsilon 0.46860269582065023\n",
      "travel time- 721.0\n",
      "--- 1.9726314544677734 seconds ---\n",
      "episode 1517, reward -152.0, memory_length 2000, epsilon 0.4683684530383155\n",
      "travel time- 731.0\n",
      "--- 1.7067883014678955 seconds ---\n",
      "episode 1518, reward -64.0, memory_length 2000, epsilon 0.4681343273480965\n",
      "travel time- 727.0\n",
      "--- 1.5661625862121582 seconds ---\n",
      "episode 1519, reward 175.0, memory_length 2000, epsilon 0.4679003186914618\n",
      "travel time- 734.0\n",
      "--- 1.528726577758789 seconds ---\n",
      "episode 1520, reward -333.0, memory_length 2000, epsilon 0.46766642700990924\n",
      "travel time- 721.0\n",
      "--- 1.872225046157837 seconds ---\n",
      "episode 1521, reward 48.0, memory_length 2000, epsilon 0.4674326522449658\n",
      "travel time- 726.0\n",
      "--- 1.5764384269714355 seconds ---\n",
      "episode 1522, reward -187.0, memory_length 2000, epsilon 0.4671989943381879\n",
      "travel time- 731.0\n",
      "--- 1.7218286991119385 seconds ---\n",
      "episode 1523, reward 328.0, memory_length 2000, epsilon 0.46696545323116095\n",
      "travel time- 725.0\n",
      "--- 1.507908582687378 seconds ---\n",
      "episode 1524, reward -156.0, memory_length 2000, epsilon 0.46673202886549986\n",
      "travel time- 726.0\n",
      "--- 1.6630840301513672 seconds ---\n",
      "episode 1525, reward -162.0, memory_length 2000, epsilon 0.4664987211828483\n",
      "travel time- 721.0\n",
      "--- 1.777024269104004 seconds ---\n",
      "episode 1526, reward -31.0, memory_length 2000, epsilon 0.46626553012487953\n",
      "travel time- 723.0\n",
      "--- 1.6677772998809814 seconds ---\n",
      "episode 1527, reward -319.0, memory_length 2000, epsilon 0.4660324556332957\n",
      "travel time- 723.0\n",
      "--- 1.7604331970214844 seconds ---\n",
      "episode 1528, reward -69.0, memory_length 2000, epsilon 0.46579949764982825\n",
      "travel time- 720.0\n",
      "--- 1.610412836074829 seconds ---\n",
      "episode 1529, reward -478.0, memory_length 2000, epsilon 0.46556665611623754\n",
      "travel time- 724.0\n",
      "--- 1.5485787391662598 seconds ---\n",
      "episode 1530, reward -223.0, memory_length 2000, epsilon 0.4653339309743134\n",
      "travel time- 722.0\n",
      "--- 1.6293308734893799 seconds ---\n",
      "episode 1531, reward -432.0, memory_length 2000, epsilon 0.46510132216587435\n",
      "travel time- 721.0\n",
      "--- 1.4064974784851074 seconds ---\n",
      "episode 1532, reward -96.0, memory_length 2000, epsilon 0.46486882963276827\n",
      "travel time- 724.0\n",
      "--- 1.6228535175323486 seconds ---\n",
      "episode 1533, reward -304.0, memory_length 2000, epsilon 0.46463645331687203\n",
      "travel time- 720.0\n",
      "--- 1.7311198711395264 seconds ---\n",
      "episode 1534, reward -199.0, memory_length 2000, epsilon 0.46440419316009157\n",
      "travel time- 720.0\n",
      "--- 1.6655609607696533 seconds ---\n",
      "episode 1535, reward -302.0, memory_length 2000, epsilon 0.4641720491043618\n",
      "travel time- 729.0\n",
      "--- 1.6855676174163818 seconds ---\n",
      "episode 1536, reward -181.0, memory_length 2000, epsilon 0.4639400210916467\n",
      "travel time- 721.0\n",
      "--- 1.5981051921844482 seconds ---\n",
      "episode 1537, reward -126.0, memory_length 2000, epsilon 0.46370810906393933\n",
      "travel time- 725.0\n",
      "--- 1.750373125076294 seconds ---\n",
      "episode 1538, reward -163.0, memory_length 2000, epsilon 0.4634763129632616\n",
      "travel time- 720.0\n",
      "--- 1.8473048210144043 seconds ---\n",
      "episode 1539, reward -69.0, memory_length 2000, epsilon 0.46324463273166455\n",
      "travel time- 720.0\n",
      "--- 1.5372004508972168 seconds ---\n",
      "episode 1540, reward -79.0, memory_length 2000, epsilon 0.46301306831122807\n",
      "travel time- 720.0\n",
      "--- 1.6815364360809326 seconds ---\n",
      "episode 1541, reward -312.0, memory_length 2000, epsilon 0.4627816196440611\n",
      "travel time- 724.0\n",
      "--- 1.7581462860107422 seconds ---\n",
      "episode 1542, reward -91.0, memory_length 2000, epsilon 0.4625502866723014\n",
      "travel time- 725.0\n",
      "--- 1.679053544998169 seconds ---\n",
      "episode 1543, reward -236.0, memory_length 2000, epsilon 0.4623190693381159\n",
      "travel time- 723.0\n",
      "--- 1.6489758491516113 seconds ---\n",
      "episode 1544, reward -74.0, memory_length 2000, epsilon 0.4620879675837\n",
      "travel time- 724.0\n",
      "--- 1.4998807907104492 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1545, reward 53.0, memory_length 2000, epsilon 0.4618569813512785\n",
      "travel time- 723.0\n",
      "--- 1.5623047351837158 seconds ---\n",
      "episode 1546, reward -130.0, memory_length 2000, epsilon 0.4616261105831047\n",
      "travel time- 723.0\n",
      "--- 1.6818721294403076 seconds ---\n",
      "episode 1547, reward -85.0, memory_length 2000, epsilon 0.46139535522146097\n",
      "travel time- 720.0\n",
      "--- 1.7272913455963135 seconds ---\n",
      "episode 1548, reward -194.0, memory_length 2000, epsilon 0.4611647152086584\n",
      "travel time- 725.0\n",
      "--- 1.6588492393493652 seconds ---\n",
      "episode 1549, reward -42.0, memory_length 2000, epsilon 0.46093419048703715\n",
      "travel time- 723.0\n",
      "--- 1.7504031658172607 seconds ---\n",
      "episode 1550, reward 32.0, memory_length 2000, epsilon 0.4607037809989658\n",
      "travel time- 725.0\n",
      "--- 1.6948132514953613 seconds ---\n",
      "episode 1551, reward 188.0, memory_length 2000, epsilon 0.4604734866868422\n",
      "travel time- 720.0\n",
      "--- 1.7005751132965088 seconds ---\n",
      "episode 1552, reward -44.0, memory_length 2000, epsilon 0.46024330749309256\n",
      "travel time- 723.0\n",
      "--- 1.7320408821105957 seconds ---\n",
      "episode 1553, reward -96.0, memory_length 2000, epsilon 0.4600132433601723\n",
      "travel time- 726.0\n",
      "--- 1.6353871822357178 seconds ---\n",
      "episode 1554, reward -175.0, memory_length 2000, epsilon 0.4597832942305652\n",
      "travel time- 722.0\n",
      "--- 1.9028050899505615 seconds ---\n",
      "episode 1555, reward -195.0, memory_length 2000, epsilon 0.4595534600467841\n",
      "travel time- 733.0\n",
      "--- 1.7031621932983398 seconds ---\n",
      "episode 1556, reward 9.0, memory_length 2000, epsilon 0.45932374075137034\n",
      "travel time- 722.0\n",
      "--- 1.6577558517456055 seconds ---\n",
      "episode 1557, reward 46.0, memory_length 2000, epsilon 0.4590941362868942\n",
      "travel time- 723.0\n",
      "--- 1.6130590438842773 seconds ---\n",
      "episode 1558, reward -110.0, memory_length 2000, epsilon 0.4588646465959545\n",
      "travel time- 737.0\n",
      "--- 1.7338294982910156 seconds ---\n",
      "episode 1559, reward -377.0, memory_length 2000, epsilon 0.4586352716211789\n",
      "travel time- 723.0\n",
      "--- 1.6725273132324219 seconds ---\n",
      "episode 1560, reward -7.0, memory_length 2000, epsilon 0.4584060113052235\n",
      "travel time- 722.0\n",
      "--- 1.6529290676116943 seconds ---\n",
      "episode 1561, reward -86.0, memory_length 2000, epsilon 0.4581768655907734\n",
      "travel time- 723.0\n",
      "--- 1.6233739852905273 seconds ---\n",
      "episode 1562, reward -143.0, memory_length 2000, epsilon 0.45794783442054204\n",
      "travel time- 721.0\n",
      "--- 1.806119680404663 seconds ---\n",
      "episode 1563, reward -533.0, memory_length 2000, epsilon 0.45771891773727175\n",
      "travel time- 729.0\n",
      "--- 1.8910045623779297 seconds ---\n",
      "episode 1564, reward -328.0, memory_length 2000, epsilon 0.45749011548373314\n",
      "travel time- 729.0\n",
      "--- 1.6539428234100342 seconds ---\n",
      "episode 1565, reward -92.0, memory_length 2000, epsilon 0.4572614276027259\n",
      "travel time- 724.0\n",
      "--- 1.6522793769836426 seconds ---\n",
      "episode 1566, reward 153.0, memory_length 2000, epsilon 0.4570328540370779\n",
      "travel time- 724.0\n",
      "--- 1.624614953994751 seconds ---\n",
      "episode 1567, reward 53.0, memory_length 2000, epsilon 0.4568043947296458\n",
      "travel time- 721.0\n",
      "--- 1.6238255500793457 seconds ---\n",
      "episode 1568, reward -240.0, memory_length 2000, epsilon 0.4565760496233147\n",
      "travel time- 721.0\n",
      "--- 1.8588988780975342 seconds ---\n",
      "episode 1569, reward 294.0, memory_length 2000, epsilon 0.4563478186609985\n",
      "travel time- 729.0\n",
      "--- 1.5762896537780762 seconds ---\n",
      "episode 1570, reward 206.0, memory_length 2000, epsilon 0.4561197017856392\n",
      "travel time- 722.0\n",
      "--- 1.5935993194580078 seconds ---\n",
      "episode 1571, reward -166.0, memory_length 2000, epsilon 0.45589169894020787\n",
      "travel time- 724.0\n",
      "--- 1.6257197856903076 seconds ---\n",
      "episode 1572, reward -364.0, memory_length 2000, epsilon 0.4556638100677035\n",
      "travel time- 722.0\n",
      "--- 1.8681814670562744 seconds ---\n",
      "episode 1573, reward -93.0, memory_length 2000, epsilon 0.45543603511115416\n",
      "travel time- 722.0\n",
      "--- 1.643052101135254 seconds ---\n",
      "episode 1574, reward 165.0, memory_length 2000, epsilon 0.45520837401361586\n",
      "travel time- 724.0\n",
      "--- 1.6827232837677002 seconds ---\n",
      "episode 1575, reward -566.0, memory_length 2000, epsilon 0.4549808267181735\n",
      "travel time- 721.0\n",
      "--- 1.8286678791046143 seconds ---\n",
      "episode 1576, reward 63.0, memory_length 2000, epsilon 0.45475339316794017\n",
      "travel time- 720.0\n",
      "--- 1.6867609024047852 seconds ---\n",
      "episode 1577, reward -185.0, memory_length 2000, epsilon 0.45452607330605754\n",
      "travel time- 725.0\n",
      "--- 1.716592788696289 seconds ---\n",
      "episode 1578, reward 59.0, memory_length 2000, epsilon 0.4542988670756955\n",
      "travel time- 720.0\n",
      "--- 1.6553096771240234 seconds ---\n",
      "episode 1579, reward 98.0, memory_length 2000, epsilon 0.4540717744200527\n",
      "travel time- 727.0\n",
      "--- 1.6417078971862793 seconds ---\n",
      "episode 1580, reward -61.0, memory_length 2000, epsilon 0.45384479528235583\n",
      "travel time- 722.0\n",
      "--- 1.7030189037322998 seconds ---\n",
      "episode 1581, reward -12.0, memory_length 2000, epsilon 0.45361792960586017\n",
      "travel time- 724.0\n",
      "--- 1.6444618701934814 seconds ---\n",
      "episode 1582, reward -126.0, memory_length 2000, epsilon 0.4533911773338492\n",
      "travel time- 722.0\n",
      "--- 1.7598729133605957 seconds ---\n",
      "episode 1583, reward -118.0, memory_length 2000, epsilon 0.453164538409635\n",
      "travel time- 723.0\n",
      "--- 1.5869677066802979 seconds ---\n",
      "episode 1584, reward 119.0, memory_length 2000, epsilon 0.4529380127765577\n",
      "travel time- 729.0\n",
      "--- 1.6297028064727783 seconds ---\n",
      "episode 1585, reward -458.0, memory_length 2000, epsilon 0.452711600377986\n",
      "travel time- 733.0\n",
      "--- 1.7539775371551514 seconds ---\n",
      "episode 1586, reward -157.0, memory_length 2000, epsilon 0.4524853011573167\n",
      "travel time- 726.0\n",
      "--- 1.6309618949890137 seconds ---\n",
      "episode 1587, reward -190.0, memory_length 2000, epsilon 0.45225911505797517\n",
      "travel time- 727.0\n",
      "--- 1.7137525081634521 seconds ---\n",
      "episode 1588, reward -76.0, memory_length 2000, epsilon 0.45203304202341466\n",
      "travel time- 720.0\n",
      "--- 1.8729119300842285 seconds ---\n",
      "episode 1589, reward 23.0, memory_length 2000, epsilon 0.451807081997117\n",
      "travel time- 721.0\n",
      "--- 1.709059238433838 seconds ---\n",
      "episode 1590, reward -325.0, memory_length 2000, epsilon 0.4515812349225922\n",
      "travel time- 720.0\n",
      "--- 1.6504168510437012 seconds ---\n",
      "episode 1591, reward -210.0, memory_length 2000, epsilon 0.45135550074337855\n",
      "travel time- 727.0\n",
      "--- 1.9857125282287598 seconds ---\n",
      "episode 1592, reward 132.0, memory_length 2000, epsilon 0.45112987940304233\n",
      "travel time- 725.0\n",
      "--- 1.5361621379852295 seconds ---\n",
      "episode 1593, reward 71.0, memory_length 2000, epsilon 0.4509043708451784\n",
      "travel time- 723.0\n",
      "--- 1.6203999519348145 seconds ---\n",
      "episode 1594, reward 119.0, memory_length 2000, epsilon 0.4506789750134095\n",
      "travel time- 720.0\n",
      "--- 1.865645170211792 seconds ---\n",
      "episode 1595, reward -108.0, memory_length 2000, epsilon 0.45045369185138673\n",
      "travel time- 730.0\n",
      "--- 1.7048287391662598 seconds ---\n",
      "episode 1596, reward -607.0, memory_length 2000, epsilon 0.45022852130278923\n",
      "travel time- 722.0\n",
      "--- 1.6680200099945068 seconds ---\n",
      "episode 1597, reward -157.0, memory_length 2000, epsilon 0.4500034633113244\n",
      "travel time- 726.0\n",
      "--- 1.58284330368042 seconds ---\n",
      "episode 1598, reward 388.0, memory_length 2000, epsilon 0.44977851782072775\n",
      "travel time- 734.0\n",
      "--- 1.3957433700561523 seconds ---\n",
      "episode 1599, reward -41.0, memory_length 2000, epsilon 0.44955368477476293\n",
      "travel time- 721.0\n",
      "--- 1.5819401741027832 seconds ---\n",
      "episode 1600, reward 2.0, memory_length 2000, epsilon 0.44932896411722156\n",
      "travel time- 728.0\n",
      "--- 1.7489597797393799 seconds ---\n",
      "episode 1601, reward -80.0, memory_length 2000, epsilon 0.44910435579192365\n",
      "travel time- 722.0\n",
      "--- 1.7035152912139893 seconds ---\n",
      "episode 1602, reward -303.0, memory_length 2000, epsilon 0.448879859742717\n",
      "travel time- 721.0\n",
      "--- 1.7627410888671875 seconds ---\n",
      "episode 1603, reward 173.0, memory_length 2000, epsilon 0.4486554759134776\n",
      "travel time- 721.0\n",
      "--- 1.5549192428588867 seconds ---\n",
      "episode 1604, reward -151.0, memory_length 2000, epsilon 0.4484312042481095\n",
      "travel time- 728.0\n",
      "--- 1.6108126640319824 seconds ---\n",
      "episode 1605, reward 64.0, memory_length 2000, epsilon 0.44820704469054484\n",
      "travel time- 720.0\n",
      "--- 1.406446933746338 seconds ---\n",
      "episode 1606, reward -104.0, memory_length 2000, epsilon 0.44798299718474366\n",
      "travel time- 721.0\n",
      "--- 1.5486674308776855 seconds ---\n",
      "episode 1607, reward 234.0, memory_length 2000, epsilon 0.44775906167469415\n",
      "travel time- 720.0\n",
      "--- 1.5171940326690674 seconds ---\n",
      "episode 1608, reward -286.0, memory_length 2000, epsilon 0.44753523810441237\n",
      "travel time- 727.0\n",
      "--- 1.7008943557739258 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1609, reward -120.0, memory_length 2000, epsilon 0.4473115264179424\n",
      "travel time- 723.0\n",
      "--- 1.5970134735107422 seconds ---\n",
      "episode 1610, reward -282.0, memory_length 2000, epsilon 0.4470879265593564\n",
      "travel time- 720.0\n",
      "--- 1.597163200378418 seconds ---\n",
      "episode 1611, reward -83.0, memory_length 2000, epsilon 0.4468644384727544\n",
      "travel time- 724.0\n",
      "--- 1.6842522621154785 seconds ---\n",
      "episode 1612, reward -287.0, memory_length 2000, epsilon 0.44664106210226434\n",
      "travel time- 722.0\n",
      "--- 1.3361363410949707 seconds ---\n",
      "episode 1613, reward 40.0, memory_length 2000, epsilon 0.4464177973920421\n",
      "travel time- 720.0\n",
      "--- 1.459531545639038 seconds ---\n",
      "episode 1614, reward -26.0, memory_length 2000, epsilon 0.44619464428627154\n",
      "travel time- 725.0\n",
      "--- 1.5521466732025146 seconds ---\n",
      "episode 1615, reward -341.0, memory_length 2000, epsilon 0.4459716027291644\n",
      "travel time- 726.0\n",
      "--- 1.720597505569458 seconds ---\n",
      "episode 1616, reward -48.0, memory_length 2000, epsilon 0.4457486726649602\n",
      "travel time- 720.0\n",
      "--- 1.6091928482055664 seconds ---\n",
      "episode 1617, reward -7.0, memory_length 2000, epsilon 0.44552585403792655\n",
      "travel time- 720.0\n",
      "--- 1.6219770908355713 seconds ---\n",
      "episode 1618, reward 134.0, memory_length 2000, epsilon 0.4453031467923587\n",
      "travel time- 725.0\n",
      "--- 1.8693649768829346 seconds ---\n",
      "episode 1619, reward -113.0, memory_length 2000, epsilon 0.4450805508725799\n",
      "travel time- 720.0\n",
      "--- 1.5058422088623047 seconds ---\n",
      "episode 1620, reward 59.0, memory_length 2000, epsilon 0.4448580662229411\n",
      "travel time- 720.0\n",
      "--- 1.566101312637329 seconds ---\n",
      "episode 1621, reward -196.0, memory_length 2000, epsilon 0.4446356927878212\n",
      "travel time- 720.0\n",
      "--- 1.6296501159667969 seconds ---\n",
      "episode 1622, reward -80.0, memory_length 2000, epsilon 0.4444134305116268\n",
      "travel time- 731.0\n",
      "--- 1.8104279041290283 seconds ---\n",
      "episode 1623, reward -151.0, memory_length 2000, epsilon 0.4441912793387924\n",
      "travel time- 725.0\n",
      "--- 1.7954051494598389 seconds ---\n",
      "episode 1624, reward 144.0, memory_length 2000, epsilon 0.44396923921378006\n",
      "travel time- 720.0\n",
      "--- 1.684152603149414 seconds ---\n",
      "episode 1625, reward -13.0, memory_length 2000, epsilon 0.44374731008107987\n",
      "travel time- 723.0\n",
      "--- 1.8864939212799072 seconds ---\n",
      "episode 1626, reward 93.0, memory_length 2000, epsilon 0.4435254918852095\n",
      "travel time- 728.0\n",
      "--- 1.7356159687042236 seconds ---\n",
      "episode 1627, reward -185.0, memory_length 2000, epsilon 0.44330378457071445\n",
      "travel time- 732.0\n",
      "--- 1.770998477935791 seconds ---\n",
      "episode 1628, reward 222.0, memory_length 2000, epsilon 0.44308218808216776\n",
      "travel time- 721.0\n",
      "--- 1.5675890445709229 seconds ---\n",
      "episode 1629, reward 156.0, memory_length 2000, epsilon 0.4428607023641705\n",
      "travel time- 723.0\n",
      "--- 1.4985694885253906 seconds ---\n",
      "episode 1630, reward -7.0, memory_length 2000, epsilon 0.4426393273613511\n",
      "travel time- 724.0\n",
      "--- 1.4488914012908936 seconds ---\n",
      "episode 1631, reward 169.0, memory_length 2000, epsilon 0.44241806301836584\n",
      "travel time- 727.0\n",
      "--- 1.6760599613189697 seconds ---\n",
      "episode 1632, reward 113.0, memory_length 2000, epsilon 0.44219690927989863\n",
      "travel time- 720.0\n",
      "--- 1.488574504852295 seconds ---\n",
      "episode 1633, reward 309.0, memory_length 2000, epsilon 0.4419758660906611\n",
      "travel time- 727.0\n",
      "--- 1.5862009525299072 seconds ---\n",
      "episode 1634, reward -48.0, memory_length 2000, epsilon 0.4417549333953923\n",
      "travel time- 723.0\n",
      "--- 1.5591022968292236 seconds ---\n",
      "episode 1635, reward -42.0, memory_length 2000, epsilon 0.4415341111388592\n",
      "travel time- 725.0\n",
      "--- 1.6718230247497559 seconds ---\n",
      "episode 1636, reward -369.0, memory_length 2000, epsilon 0.44131339926585617\n",
      "travel time- 728.0\n",
      "--- 1.8166580200195312 seconds ---\n",
      "episode 1637, reward -185.0, memory_length 2000, epsilon 0.4410927977212053\n",
      "travel time- 720.0\n",
      "--- 1.5190038681030273 seconds ---\n",
      "episode 1638, reward -260.0, memory_length 2000, epsilon 0.4408723064497561\n",
      "travel time- 726.0\n",
      "--- 1.626267910003662 seconds ---\n",
      "episode 1639, reward -149.0, memory_length 2000, epsilon 0.44065192539638587\n",
      "travel time- 731.0\n",
      "--- 1.6167192459106445 seconds ---\n",
      "episode 1640, reward -95.0, memory_length 2000, epsilon 0.44043165450599925\n",
      "travel time- 720.0\n",
      "--- 1.5558459758758545 seconds ---\n",
      "episode 1641, reward 386.0, memory_length 2000, epsilon 0.4402114937235286\n",
      "travel time- 720.0\n",
      "--- 1.4123873710632324 seconds ---\n",
      "episode 1642, reward -157.0, memory_length 2000, epsilon 0.43999144299393356\n",
      "travel time- 720.0\n",
      "--- 1.6817963123321533 seconds ---\n",
      "episode 1643, reward 85.0, memory_length 2000, epsilon 0.43977150226220163\n",
      "travel time- 728.0\n",
      "--- 1.6914517879486084 seconds ---\n",
      "episode 1644, reward 56.0, memory_length 2000, epsilon 0.43955167147334756\n",
      "travel time- 720.0\n",
      "--- 1.6547935009002686 seconds ---\n",
      "episode 1645, reward -34.0, memory_length 2000, epsilon 0.43933195057241364\n",
      "travel time- 726.0\n",
      "--- 1.8707256317138672 seconds ---\n",
      "episode 1646, reward -145.0, memory_length 2000, epsilon 0.43911233950446965\n",
      "travel time- 725.0\n",
      "--- 1.903160810470581 seconds ---\n",
      "episode 1647, reward -214.0, memory_length 2000, epsilon 0.43889283821461283\n",
      "travel time- 729.0\n",
      "--- 1.7307209968566895 seconds ---\n",
      "episode 1648, reward -13.0, memory_length 2000, epsilon 0.4386734466479678\n",
      "travel time- 725.0\n",
      "--- 1.6866490840911865 seconds ---\n",
      "episode 1649, reward -343.0, memory_length 2000, epsilon 0.4384541647496868\n",
      "travel time- 726.0\n",
      "--- 1.7315349578857422 seconds ---\n",
      "episode 1650, reward -355.0, memory_length 2000, epsilon 0.4382349924649492\n",
      "travel time- 722.0\n",
      "--- 1.8404090404510498 seconds ---\n",
      "episode 1651, reward -219.0, memory_length 2000, epsilon 0.4380159297389621\n",
      "travel time- 724.0\n",
      "--- 1.6137511730194092 seconds ---\n",
      "episode 1652, reward 15.0, memory_length 2000, epsilon 0.4377969765169596\n",
      "travel time- 721.0\n",
      "--- 1.541914701461792 seconds ---\n",
      "episode 1653, reward -66.0, memory_length 2000, epsilon 0.43757813274420354\n",
      "travel time- 720.0\n",
      "--- 1.6411490440368652 seconds ---\n",
      "episode 1654, reward -107.0, memory_length 2000, epsilon 0.437359398365983\n",
      "travel time- 720.0\n",
      "--- 1.5782337188720703 seconds ---\n",
      "episode 1655, reward 103.0, memory_length 2000, epsilon 0.43714077332761425\n",
      "travel time- 732.0\n",
      "--- 1.6961395740509033 seconds ---\n",
      "episode 1656, reward -31.0, memory_length 2000, epsilon 0.43692225757444114\n",
      "travel time- 729.0\n",
      "--- 1.552131175994873 seconds ---\n",
      "episode 1657, reward -355.0, memory_length 2000, epsilon 0.43670385105183473\n",
      "travel time- 720.0\n",
      "--- 1.7895350456237793 seconds ---\n",
      "episode 1658, reward 44.0, memory_length 2000, epsilon 0.4364855537051933\n",
      "travel time- 729.0\n",
      "--- 1.6080379486083984 seconds ---\n",
      "episode 1659, reward -215.0, memory_length 2000, epsilon 0.43626736547994266\n",
      "travel time- 728.0\n",
      "--- 1.5702612400054932 seconds ---\n",
      "episode 1660, reward -63.0, memory_length 2000, epsilon 0.43604928632153556\n",
      "travel time- 722.0\n",
      "--- 1.677412509918213 seconds ---\n",
      "episode 1661, reward -147.0, memory_length 2000, epsilon 0.4358313161754524\n",
      "travel time- 725.0\n",
      "--- 1.6367824077606201 seconds ---\n",
      "episode 1662, reward -345.0, memory_length 2000, epsilon 0.43561345498720044\n",
      "travel time- 724.0\n",
      "--- 1.8736023902893066 seconds ---\n",
      "episode 1663, reward -317.0, memory_length 2000, epsilon 0.43539570270231465\n",
      "travel time- 720.0\n",
      "--- 1.827014684677124 seconds ---\n",
      "episode 1664, reward 72.0, memory_length 2000, epsilon 0.43517805926635666\n",
      "travel time- 725.0\n",
      "--- 1.5791206359863281 seconds ---\n",
      "episode 1665, reward 80.0, memory_length 2000, epsilon 0.43496052462491586\n",
      "travel time- 723.0\n",
      "--- 1.5354607105255127 seconds ---\n",
      "episode 1666, reward 32.0, memory_length 2000, epsilon 0.43474309872360845\n",
      "travel time- 723.0\n",
      "--- 1.62105393409729 seconds ---\n",
      "episode 1667, reward -92.0, memory_length 2000, epsilon 0.4345257815080779\n",
      "travel time- 721.0\n",
      "--- 1.5433471202850342 seconds ---\n",
      "episode 1668, reward 24.0, memory_length 2000, epsilon 0.4343085729239951\n",
      "travel time- 721.0\n",
      "--- 1.7777385711669922 seconds ---\n",
      "episode 1669, reward 126.0, memory_length 2000, epsilon 0.43409147291705774\n",
      "travel time- 731.0\n",
      "--- 1.6151087284088135 seconds ---\n",
      "episode 1670, reward -85.0, memory_length 2000, epsilon 0.4338744814329909\n",
      "travel time- 722.0\n",
      "--- 1.6806023120880127 seconds ---\n",
      "episode 1671, reward -223.0, memory_length 2000, epsilon 0.43365759841754664\n",
      "travel time- 722.0\n",
      "--- 1.6269607543945312 seconds ---\n",
      "episode 1672, reward 261.0, memory_length 2000, epsilon 0.4334408238165043\n",
      "travel time- 721.0\n",
      "--- 1.4115376472473145 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1673, reward 57.0, memory_length 2000, epsilon 0.4332241575756701\n",
      "travel time- 724.0\n",
      "--- 1.5746846199035645 seconds ---\n",
      "episode 1674, reward -54.0, memory_length 2000, epsilon 0.43300759964087765\n",
      "travel time- 727.0\n",
      "--- 1.7047383785247803 seconds ---\n",
      "episode 1675, reward -132.0, memory_length 2000, epsilon 0.43279114995798723\n",
      "travel time- 723.0\n",
      "--- 1.7571368217468262 seconds ---\n",
      "episode 1676, reward -92.0, memory_length 2000, epsilon 0.43257480847288665\n",
      "travel time- 721.0\n",
      "--- 1.6195931434631348 seconds ---\n",
      "episode 1677, reward 92.0, memory_length 2000, epsilon 0.4323585751314904\n",
      "travel time- 723.0\n",
      "--- 1.7937281131744385 seconds ---\n",
      "episode 1678, reward -129.0, memory_length 2000, epsilon 0.43214244987974026\n",
      "travel time- 731.0\n",
      "--- 1.87868070602417 seconds ---\n",
      "episode 1679, reward -254.0, memory_length 2000, epsilon 0.43192643266360475\n",
      "travel time- 725.0\n",
      "--- 1.71401047706604 seconds ---\n",
      "episode 1680, reward 197.0, memory_length 2000, epsilon 0.43171052342907973\n",
      "travel time- 728.0\n",
      "--- 1.533458948135376 seconds ---\n",
      "episode 1681, reward -224.0, memory_length 2000, epsilon 0.4314947221221877\n",
      "travel time- 723.0\n",
      "--- 1.6180009841918945 seconds ---\n",
      "episode 1682, reward 112.0, memory_length 2000, epsilon 0.43127902868897855\n",
      "travel time- 729.0\n",
      "--- 1.757615566253662 seconds ---\n",
      "episode 1683, reward -214.0, memory_length 2000, epsilon 0.4310634430755288\n",
      "travel time- 728.0\n",
      "--- 1.787074089050293 seconds ---\n",
      "episode 1684, reward 254.0, memory_length 2000, epsilon 0.43084796522794205\n",
      "travel time- 720.0\n",
      "--- 1.7086734771728516 seconds ---\n",
      "episode 1685, reward 308.0, memory_length 2000, epsilon 0.43063259509234886\n",
      "travel time- 725.0\n",
      "--- 1.4574975967407227 seconds ---\n",
      "episode 1686, reward -378.0, memory_length 2000, epsilon 0.43041733261490667\n",
      "travel time- 725.0\n",
      "--- 1.7544670104980469 seconds ---\n",
      "episode 1687, reward -267.0, memory_length 2000, epsilon 0.43020217774179986\n",
      "travel time- 722.0\n",
      "--- 1.772674798965454 seconds ---\n",
      "episode 1688, reward -17.0, memory_length 2000, epsilon 0.4299871304192398\n",
      "travel time- 721.0\n",
      "--- 1.576176643371582 seconds ---\n",
      "episode 1689, reward 274.0, memory_length 2000, epsilon 0.4297721905934645\n",
      "travel time- 728.0\n",
      "--- 1.8648200035095215 seconds ---\n",
      "episode 1690, reward -246.0, memory_length 2000, epsilon 0.42955735821073915\n",
      "travel time- 722.0\n",
      "--- 1.8351147174835205 seconds ---\n",
      "episode 1691, reward 218.0, memory_length 2000, epsilon 0.42934263321735555\n",
      "travel time- 723.0\n",
      "--- 1.5838584899902344 seconds ---\n",
      "episode 1692, reward -39.0, memory_length 2000, epsilon 0.42912801555963254\n",
      "travel time- 721.0\n",
      "--- 1.7720673084259033 seconds ---\n",
      "episode 1693, reward 268.0, memory_length 2000, epsilon 0.4289135051839156\n",
      "travel time- 727.0\n",
      "--- 1.7419919967651367 seconds ---\n",
      "episode 1694, reward 172.0, memory_length 2000, epsilon 0.42869910203657724\n",
      "travel time- 726.0\n",
      "--- 1.7064995765686035 seconds ---\n",
      "episode 1695, reward -465.0, memory_length 2000, epsilon 0.42848480606401657\n",
      "travel time- 723.0\n",
      "--- 1.7305912971496582 seconds ---\n",
      "episode 1696, reward -45.0, memory_length 2000, epsilon 0.4282706172126597\n",
      "travel time- 730.0\n",
      "--- 1.7846412658691406 seconds ---\n",
      "episode 1697, reward -171.0, memory_length 2000, epsilon 0.4280565354289593\n",
      "travel time- 728.0\n",
      "--- 1.8081305027008057 seconds ---\n",
      "episode 1698, reward -129.0, memory_length 2000, epsilon 0.427842560659395\n",
      "travel time- 720.0\n",
      "--- 1.6858556270599365 seconds ---\n",
      "episode 1699, reward -171.0, memory_length 2000, epsilon 0.4276286928504731\n",
      "travel time- 723.0\n",
      "--- 1.6736268997192383 seconds ---\n",
      "episode 1700, reward 54.0, memory_length 2000, epsilon 0.4274149319487267\n",
      "travel time- 721.0\n",
      "--- 1.3683228492736816 seconds ---\n",
      "episode 1701, reward -332.0, memory_length 2000, epsilon 0.42720127790071544\n",
      "travel time- 723.0\n",
      "--- 1.7801711559295654 seconds ---\n",
      "episode 1702, reward -103.0, memory_length 2000, epsilon 0.4269877306530259\n",
      "travel time- 731.0\n",
      "--- 1.6355412006378174 seconds ---\n",
      "episode 1703, reward 127.0, memory_length 2000, epsilon 0.42677429015227125\n",
      "travel time- 725.0\n",
      "--- 1.625459909439087 seconds ---\n",
      "episode 1704, reward 402.0, memory_length 2000, epsilon 0.4265609563450914\n",
      "travel time- 726.0\n",
      "--- 1.6636641025543213 seconds ---\n",
      "episode 1705, reward -156.0, memory_length 2000, epsilon 0.4263477291781528\n",
      "travel time- 733.0\n",
      "--- 1.5804145336151123 seconds ---\n",
      "episode 1706, reward -68.0, memory_length 2000, epsilon 0.4261346085981487\n",
      "travel time- 728.0\n",
      "--- 1.5272881984710693 seconds ---\n",
      "episode 1707, reward -82.0, memory_length 2000, epsilon 0.425921594551799\n",
      "travel time- 731.0\n",
      "--- 1.5558860301971436 seconds ---\n",
      "episode 1708, reward -187.0, memory_length 2000, epsilon 0.4257086869858502\n",
      "travel time- 725.0\n",
      "--- 1.6707508563995361 seconds ---\n",
      "episode 1709, reward -47.0, memory_length 2000, epsilon 0.4254958858470753\n",
      "travel time- 721.0\n",
      "--- 1.6080305576324463 seconds ---\n",
      "episode 1710, reward -76.0, memory_length 2000, epsilon 0.42528319108227414\n",
      "travel time- 723.0\n",
      "--- 1.6226451396942139 seconds ---\n",
      "episode 1711, reward -284.0, memory_length 2000, epsilon 0.4250706026382729\n",
      "travel time- 721.0\n",
      "--- 1.5907659530639648 seconds ---\n",
      "episode 1712, reward -193.0, memory_length 2000, epsilon 0.42485812046192456\n",
      "travel time- 720.0\n",
      "--- 1.777104377746582 seconds ---\n",
      "episode 1713, reward -226.0, memory_length 2000, epsilon 0.42464574450010856\n",
      "travel time- 722.0\n",
      "--- 1.6933701038360596 seconds ---\n",
      "episode 1714, reward -260.0, memory_length 2000, epsilon 0.4244334746997309\n",
      "travel time- 728.0\n",
      "--- 1.7723114490509033 seconds ---\n",
      "episode 1715, reward -336.0, memory_length 2000, epsilon 0.4242213110077241\n",
      "travel time- 722.0\n",
      "--- 1.7147481441497803 seconds ---\n",
      "episode 1716, reward 86.0, memory_length 2000, epsilon 0.4240092533710473\n",
      "travel time- 722.0\n",
      "--- 1.7005362510681152 seconds ---\n",
      "episode 1717, reward -74.0, memory_length 2000, epsilon 0.423797301736686\n",
      "travel time- 729.0\n",
      "--- 1.655059576034546 seconds ---\n",
      "episode 1718, reward -4.0, memory_length 2000, epsilon 0.4235854560516524\n",
      "travel time- 732.0\n",
      "--- 1.4849350452423096 seconds ---\n",
      "episode 1719, reward -156.0, memory_length 2000, epsilon 0.4233737162629849\n",
      "travel time- 729.0\n",
      "--- 1.7458622455596924 seconds ---\n",
      "episode 1720, reward 240.0, memory_length 2000, epsilon 0.4231620823177488\n",
      "travel time- 729.0\n",
      "--- 1.9519436359405518 seconds ---\n",
      "episode 1721, reward -392.0, memory_length 2000, epsilon 0.42295055416303545\n",
      "travel time- 738.0\n",
      "--- 1.619802474975586 seconds ---\n",
      "episode 1722, reward 11.0, memory_length 2000, epsilon 0.42273913174596284\n",
      "travel time- 723.0\n",
      "--- 1.4553875923156738 seconds ---\n",
      "episode 1723, reward 52.0, memory_length 2000, epsilon 0.42252781501367537\n",
      "travel time- 721.0\n",
      "--- 1.5387036800384521 seconds ---\n",
      "episode 1724, reward 61.0, memory_length 2000, epsilon 0.42231660391334386\n",
      "travel time- 724.0\n",
      "--- 1.619342565536499 seconds ---\n",
      "episode 1725, reward -159.0, memory_length 2000, epsilon 0.4221054983921655\n",
      "travel time- 734.0\n",
      "--- 1.7431986331939697 seconds ---\n",
      "episode 1726, reward 81.0, memory_length 2000, epsilon 0.4218944983973639\n",
      "travel time- 724.0\n",
      "--- 1.5517096519470215 seconds ---\n",
      "episode 1727, reward -543.0, memory_length 2000, epsilon 0.4216836038761892\n",
      "travel time- 720.0\n",
      "--- 1.4972171783447266 seconds ---\n",
      "episode 1728, reward -213.0, memory_length 2000, epsilon 0.42147281477591764\n",
      "travel time- 733.0\n",
      "--- 1.8022162914276123 seconds ---\n",
      "episode 1729, reward 26.0, memory_length 2000, epsilon 0.4212621310438519\n",
      "travel time- 729.0\n",
      "--- 1.612572431564331 seconds ---\n",
      "episode 1730, reward -35.0, memory_length 2000, epsilon 0.4210515526273212\n",
      "travel time- 725.0\n",
      "--- 1.6930954456329346 seconds ---\n",
      "episode 1731, reward 25.0, memory_length 2000, epsilon 0.42084107947368077\n",
      "travel time- 732.0\n",
      "--- 1.687659740447998 seconds ---\n",
      "episode 1732, reward -244.0, memory_length 2000, epsilon 0.42063071153031245\n",
      "travel time- 720.0\n",
      "--- 1.7636618614196777 seconds ---\n",
      "episode 1733, reward 62.0, memory_length 2000, epsilon 0.42042044874462414\n",
      "travel time- 728.0\n",
      "--- 1.651578664779663 seconds ---\n",
      "episode 1734, reward 103.0, memory_length 2000, epsilon 0.4202102910640503\n",
      "travel time- 722.0\n",
      "--- 1.8431980609893799 seconds ---\n",
      "episode 1735, reward 114.0, memory_length 2000, epsilon 0.42000023843605133\n",
      "travel time- 720.0\n",
      "--- 1.708503246307373 seconds ---\n",
      "episode 1736, reward -237.0, memory_length 2000, epsilon 0.41979029080811425\n",
      "travel time- 720.0\n",
      "--- 1.736541986465454 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1737, reward 165.0, memory_length 2000, epsilon 0.41958044812775197\n",
      "travel time- 720.0\n",
      "--- 1.5762763023376465 seconds ---\n",
      "episode 1738, reward -169.0, memory_length 2000, epsilon 0.41937071034250395\n",
      "travel time- 721.0\n",
      "--- 1.4490461349487305 seconds ---\n",
      "episode 1739, reward -73.0, memory_length 2000, epsilon 0.4191610773999357\n",
      "travel time- 725.0\n",
      "--- 1.6652166843414307 seconds ---\n",
      "episode 1740, reward -340.0, memory_length 2000, epsilon 0.418951549247639\n",
      "travel time- 725.0\n",
      "--- 1.6757068634033203 seconds ---\n",
      "episode 1741, reward -22.0, memory_length 2000, epsilon 0.4187421258332317\n",
      "travel time- 721.0\n",
      "--- 1.5531396865844727 seconds ---\n",
      "episode 1742, reward -324.0, memory_length 2000, epsilon 0.41853280710435814\n",
      "travel time- 721.0\n",
      "--- 1.478118658065796 seconds ---\n",
      "episode 1743, reward -134.0, memory_length 2000, epsilon 0.4183235930086885\n",
      "travel time- 723.0\n",
      "--- 1.5669937133789062 seconds ---\n",
      "episode 1744, reward -202.0, memory_length 2000, epsilon 0.41811448349391933\n",
      "travel time- 722.0\n",
      "--- 1.9364147186279297 seconds ---\n",
      "episode 1745, reward 46.0, memory_length 2000, epsilon 0.41790547850777315\n",
      "travel time- 730.0\n",
      "--- 1.787177324295044 seconds ---\n",
      "episode 1746, reward 124.0, memory_length 2000, epsilon 0.4176965779979988\n",
      "travel time- 732.0\n",
      "--- 1.592524528503418 seconds ---\n",
      "episode 1747, reward -93.0, memory_length 2000, epsilon 0.4174877819123711\n",
      "travel time- 732.0\n",
      "--- 1.5552539825439453 seconds ---\n",
      "episode 1748, reward -13.0, memory_length 2000, epsilon 0.41727909019869114\n",
      "travel time- 726.0\n",
      "--- 1.8135440349578857 seconds ---\n",
      "episode 1749, reward -161.0, memory_length 2000, epsilon 0.4170705028047858\n",
      "travel time- 721.0\n",
      "--- 1.636751651763916 seconds ---\n",
      "episode 1750, reward 221.0, memory_length 2000, epsilon 0.4168620196785084\n",
      "travel time- 722.0\n",
      "--- 1.612980604171753 seconds ---\n",
      "episode 1751, reward 136.0, memory_length 2000, epsilon 0.41665364076773803\n",
      "travel time- 724.0\n",
      "--- 1.4631969928741455 seconds ---\n",
      "episode 1752, reward -1.0, memory_length 2000, epsilon 0.41644536602038007\n",
      "travel time- 722.0\n",
      "--- 1.6310675144195557 seconds ---\n",
      "episode 1753, reward 226.0, memory_length 2000, epsilon 0.41623719538436577\n",
      "travel time- 725.0\n",
      "--- 1.638054370880127 seconds ---\n",
      "episode 1754, reward -139.0, memory_length 2000, epsilon 0.4160291288076525\n",
      "travel time- 726.0\n",
      "--- 1.5960414409637451 seconds ---\n",
      "episode 1755, reward 52.0, memory_length 2000, epsilon 0.41582116623822357\n",
      "travel time- 727.0\n",
      "--- 1.6389796733856201 seconds ---\n",
      "episode 1756, reward 87.0, memory_length 2000, epsilon 0.4156133076240884\n",
      "travel time- 729.0\n",
      "--- 1.4559476375579834 seconds ---\n",
      "episode 1757, reward -191.0, memory_length 2000, epsilon 0.41540555291328224\n",
      "travel time- 722.0\n",
      "--- 1.762139081954956 seconds ---\n",
      "episode 1758, reward 146.0, memory_length 2000, epsilon 0.4151979020538666\n",
      "travel time- 731.0\n",
      "--- 1.4925079345703125 seconds ---\n",
      "episode 1759, reward -406.0, memory_length 2000, epsilon 0.4149903549939285\n",
      "travel time- 729.0\n",
      "--- 1.7845497131347656 seconds ---\n",
      "episode 1760, reward 26.0, memory_length 2000, epsilon 0.4147829116815814\n",
      "travel time- 728.0\n",
      "--- 1.3782951831817627 seconds ---\n",
      "episode 1761, reward -158.0, memory_length 2000, epsilon 0.41457557206496426\n",
      "travel time- 724.0\n",
      "--- 1.7362220287322998 seconds ---\n",
      "episode 1762, reward -87.0, memory_length 2000, epsilon 0.41436833609224244\n",
      "travel time- 720.0\n",
      "--- 1.649411916732788 seconds ---\n",
      "episode 1763, reward -130.0, memory_length 2000, epsilon 0.4141612037116067\n",
      "travel time- 726.0\n",
      "--- 1.5960326194763184 seconds ---\n",
      "episode 1764, reward -58.0, memory_length 2000, epsilon 0.4139541748712741\n",
      "travel time- 722.0\n",
      "--- 1.7454993724822998 seconds ---\n",
      "episode 1765, reward -348.0, memory_length 2000, epsilon 0.4137472495194873\n",
      "travel time- 720.0\n",
      "--- 1.896125316619873 seconds ---\n",
      "episode 1766, reward -96.0, memory_length 2000, epsilon 0.41354042760451515\n",
      "travel time- 721.0\n",
      "--- 1.5735175609588623 seconds ---\n",
      "episode 1767, reward -133.0, memory_length 2000, epsilon 0.41333370907465194\n",
      "travel time- 721.0\n",
      "--- 1.653052568435669 seconds ---\n",
      "episode 1768, reward -95.0, memory_length 2000, epsilon 0.4131270938782182\n",
      "travel time- 722.0\n",
      "--- 1.6215691566467285 seconds ---\n",
      "episode 1769, reward -169.0, memory_length 2000, epsilon 0.41292058196356013\n",
      "travel time- 723.0\n",
      "--- 1.7291171550750732 seconds ---\n",
      "episode 1770, reward 32.0, memory_length 2000, epsilon 0.41271417327904963\n",
      "travel time- 721.0\n",
      "--- 1.6554288864135742 seconds ---\n",
      "episode 1771, reward 81.0, memory_length 2000, epsilon 0.4125078677730846\n",
      "travel time- 732.0\n",
      "--- 1.6268606185913086 seconds ---\n",
      "episode 1772, reward 322.0, memory_length 2000, epsilon 0.41230166539408875\n",
      "travel time- 720.0\n",
      "--- 1.5759303569793701 seconds ---\n",
      "episode 1773, reward -161.0, memory_length 2000, epsilon 0.4120955660905113\n",
      "travel time- 723.0\n",
      "--- 1.6698129177093506 seconds ---\n",
      "episode 1774, reward -42.0, memory_length 2000, epsilon 0.4118895698108276\n",
      "travel time- 724.0\n",
      "--- 1.5248634815216064 seconds ---\n",
      "episode 1775, reward -450.0, memory_length 2000, epsilon 0.41168367650353843\n",
      "travel time- 722.0\n",
      "--- 1.9670472145080566 seconds ---\n",
      "episode 1776, reward 111.0, memory_length 2000, epsilon 0.41147788611717057\n",
      "travel time- 728.0\n",
      "--- 1.641037940979004 seconds ---\n",
      "episode 1777, reward -337.0, memory_length 2000, epsilon 0.41127219860027636\n",
      "travel time- 724.0\n",
      "--- 1.768460750579834 seconds ---\n",
      "episode 1778, reward 46.0, memory_length 2000, epsilon 0.41106661390143395\n",
      "travel time- 726.0\n",
      "--- 1.6488182544708252 seconds ---\n",
      "episode 1779, reward -39.0, memory_length 2000, epsilon 0.4108611319692471\n",
      "travel time- 726.0\n",
      "--- 1.6138479709625244 seconds ---\n",
      "episode 1780, reward 90.0, memory_length 2000, epsilon 0.4106557527523455\n",
      "travel time- 722.0\n",
      "--- 1.4683375358581543 seconds ---\n",
      "episode 1781, reward 164.0, memory_length 2000, epsilon 0.41045047619938413\n",
      "travel time- 720.0\n",
      "--- 1.503720760345459 seconds ---\n",
      "episode 1782, reward 8.0, memory_length 2000, epsilon 0.410245302259044\n",
      "travel time- 722.0\n",
      "--- 1.5657672882080078 seconds ---\n",
      "episode 1783, reward -473.0, memory_length 2000, epsilon 0.4100402308800315\n",
      "travel time- 720.0\n",
      "--- 1.5871922969818115 seconds ---\n",
      "episode 1784, reward -266.0, memory_length 2000, epsilon 0.40983526201107895\n",
      "travel time- 732.0\n",
      "--- 1.8986701965332031 seconds ---\n",
      "episode 1785, reward 63.0, memory_length 2000, epsilon 0.409630395600944\n",
      "travel time- 728.0\n",
      "--- 1.4283976554870605 seconds ---\n",
      "episode 1786, reward 31.0, memory_length 2000, epsilon 0.40942563159841006\n",
      "travel time- 726.0\n",
      "--- 1.616621971130371 seconds ---\n",
      "episode 1787, reward -33.0, memory_length 2000, epsilon 0.4092209699522862\n",
      "travel time- 731.0\n",
      "--- 1.6778380870819092 seconds ---\n",
      "episode 1788, reward 167.0, memory_length 2000, epsilon 0.4090164106114069\n",
      "travel time- 720.0\n",
      "--- 1.551924467086792 seconds ---\n",
      "episode 1789, reward -249.0, memory_length 2000, epsilon 0.4088119535246324\n",
      "travel time- 720.0\n",
      "--- 1.6064589023590088 seconds ---\n",
      "episode 1790, reward -167.0, memory_length 2000, epsilon 0.40860759864084845\n",
      "travel time- 721.0\n",
      "--- 1.7763686180114746 seconds ---\n",
      "episode 1791, reward 14.0, memory_length 2000, epsilon 0.40840334590896626\n",
      "travel time- 733.0\n",
      "--- 1.6006016731262207 seconds ---\n",
      "episode 1792, reward -29.0, memory_length 2000, epsilon 0.4081991952779227\n",
      "travel time- 721.0\n",
      "--- 1.6066467761993408 seconds ---\n",
      "episode 1793, reward -377.0, memory_length 2000, epsilon 0.4079951466966801\n",
      "travel time- 720.0\n",
      "--- 1.851846694946289 seconds ---\n",
      "episode 1794, reward -200.0, memory_length 2000, epsilon 0.4077912001142262\n",
      "travel time- 721.0\n",
      "--- 1.7252399921417236 seconds ---\n",
      "episode 1795, reward 324.0, memory_length 2000, epsilon 0.40758735547957453\n",
      "travel time- 720.0\n",
      "--- 1.4106876850128174 seconds ---\n",
      "episode 1796, reward -74.0, memory_length 2000, epsilon 0.4073836127417638\n",
      "travel time- 731.0\n",
      "--- 1.7436482906341553 seconds ---\n",
      "episode 1797, reward 17.0, memory_length 2000, epsilon 0.40717997184985844\n",
      "travel time- 729.0\n",
      "--- 1.727733850479126 seconds ---\n",
      "episode 1798, reward 277.0, memory_length 2000, epsilon 0.40697643275294815\n",
      "travel time- 723.0\n",
      "--- 1.355151653289795 seconds ---\n",
      "episode 1799, reward 128.0, memory_length 2000, epsilon 0.40677299540014816\n",
      "travel time- 720.0\n",
      "--- 1.683849573135376 seconds ---\n",
      "episode 1800, reward -42.0, memory_length 2000, epsilon 0.4065696597405991\n",
      "travel time- 726.0\n",
      "--- 1.5428564548492432 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1801, reward -167.0, memory_length 2000, epsilon 0.40636642572346715\n",
      "travel time- 730.0\n",
      "--- 1.6405847072601318 seconds ---\n",
      "episode 1802, reward -243.0, memory_length 2000, epsilon 0.4061632932979437\n",
      "travel time- 722.0\n",
      "--- 1.5197439193725586 seconds ---\n",
      "episode 1803, reward 153.0, memory_length 2000, epsilon 0.40596026241324573\n",
      "travel time- 720.0\n",
      "--- 1.40958833694458 seconds ---\n",
      "episode 1804, reward -23.0, memory_length 2000, epsilon 0.40575733301861544\n",
      "travel time- 722.0\n",
      "--- 1.5723602771759033 seconds ---\n",
      "episode 1805, reward 250.0, memory_length 2000, epsilon 0.4055545050633206\n",
      "travel time- 735.0\n",
      "--- 1.5829119682312012 seconds ---\n",
      "episode 1806, reward 118.0, memory_length 2000, epsilon 0.405351778496654\n",
      "travel time- 721.0\n",
      "--- 1.6407647132873535 seconds ---\n",
      "episode 1807, reward -313.0, memory_length 2000, epsilon 0.40514915326793427\n",
      "travel time- 721.0\n",
      "--- 1.656778335571289 seconds ---\n",
      "episode 1808, reward 40.0, memory_length 2000, epsilon 0.4049466293265049\n",
      "travel time- 725.0\n",
      "--- 1.4877521991729736 seconds ---\n",
      "episode 1809, reward 227.0, memory_length 2000, epsilon 0.404744206621735\n",
      "travel time- 720.0\n",
      "--- 1.72225022315979 seconds ---\n",
      "episode 1810, reward -77.0, memory_length 2000, epsilon 0.4045418851030188\n",
      "travel time- 722.0\n",
      "--- 1.6726484298706055 seconds ---\n",
      "episode 1811, reward 143.0, memory_length 2000, epsilon 0.40433966471977606\n",
      "travel time- 724.0\n",
      "--- 1.7012925148010254 seconds ---\n",
      "episode 1812, reward -145.0, memory_length 2000, epsilon 0.4041375454214515\n",
      "travel time- 720.0\n",
      "--- 1.9325377941131592 seconds ---\n",
      "episode 1813, reward -291.0, memory_length 2000, epsilon 0.4039355271575155\n",
      "travel time- 723.0\n",
      "--- 1.853379249572754 seconds ---\n",
      "episode 1814, reward -49.0, memory_length 2000, epsilon 0.4037336098774634\n",
      "travel time- 721.0\n",
      "--- 1.7051246166229248 seconds ---\n",
      "episode 1815, reward -144.0, memory_length 2000, epsilon 0.4035317935308158\n",
      "travel time- 721.0\n",
      "--- 1.8061432838439941 seconds ---\n",
      "episode 1816, reward -203.0, memory_length 2000, epsilon 0.40333007806711874\n",
      "travel time- 725.0\n",
      "--- 1.72652006149292 seconds ---\n",
      "episode 1817, reward -264.0, memory_length 2000, epsilon 0.4031284634359433\n",
      "travel time- 721.0\n",
      "--- 1.5705997943878174 seconds ---\n",
      "episode 1818, reward -165.0, memory_length 2000, epsilon 0.40292694958688574\n",
      "travel time- 734.0\n",
      "--- 1.4993047714233398 seconds ---\n",
      "episode 1819, reward 60.0, memory_length 2000, epsilon 0.40272553646956777\n",
      "travel time- 723.0\n",
      "--- 1.4537618160247803 seconds ---\n",
      "episode 1820, reward -151.0, memory_length 2000, epsilon 0.40252422403363597\n",
      "travel time- 724.0\n",
      "--- 1.5552279949188232 seconds ---\n",
      "episode 1821, reward -153.0, memory_length 2000, epsilon 0.4023230122287623\n",
      "travel time- 726.0\n",
      "--- 1.60858154296875 seconds ---\n",
      "episode 1822, reward -27.0, memory_length 2000, epsilon 0.40212190100464373\n",
      "travel time- 723.0\n",
      "--- 1.5218729972839355 seconds ---\n",
      "episode 1823, reward 195.0, memory_length 2000, epsilon 0.4019208903110026\n",
      "travel time- 722.0\n",
      "--- 1.660257339477539 seconds ---\n",
      "episode 1824, reward -39.0, memory_length 2000, epsilon 0.401719980097586\n",
      "travel time- 720.0\n",
      "--- 1.5146074295043945 seconds ---\n",
      "episode 1825, reward 52.0, memory_length 2000, epsilon 0.4015191703141667\n",
      "travel time- 724.0\n",
      "--- 1.6138622760772705 seconds ---\n",
      "episode 1826, reward -96.0, memory_length 2000, epsilon 0.4013184609105419\n",
      "travel time- 726.0\n",
      "--- 1.6874170303344727 seconds ---\n",
      "episode 1827, reward -86.0, memory_length 2000, epsilon 0.40111785183653453\n",
      "travel time- 736.0\n",
      "--- 1.6137323379516602 seconds ---\n",
      "episode 1828, reward -1.0, memory_length 2000, epsilon 0.4009173430419921\n",
      "travel time- 725.0\n",
      "--- 1.842695951461792 seconds ---\n",
      "episode 1829, reward 121.0, memory_length 2000, epsilon 0.40071693447678763\n",
      "travel time- 729.0\n",
      "--- 1.5956146717071533 seconds ---\n",
      "episode 1830, reward -75.0, memory_length 2000, epsilon 0.4005166260908188\n",
      "travel time- 720.0\n",
      "--- 1.7822413444519043 seconds ---\n",
      "episode 1831, reward -56.0, memory_length 2000, epsilon 0.4003164178340086\n",
      "travel time- 726.0\n",
      "--- 1.7702357769012451 seconds ---\n",
      "episode 1832, reward -149.0, memory_length 2000, epsilon 0.40011630965630496\n",
      "travel time- 725.0\n",
      "--- 1.9111008644104004 seconds ---\n",
      "episode 1833, reward -416.0, memory_length 2000, epsilon 0.3999163015076808\n",
      "travel time- 721.0\n",
      "--- 1.8286643028259277 seconds ---\n",
      "episode 1834, reward -312.0, memory_length 2000, epsilon 0.3997163933381341\n",
      "travel time- 727.0\n",
      "--- 1.6516659259796143 seconds ---\n",
      "episode 1835, reward 47.0, memory_length 2000, epsilon 0.39951658509768784\n",
      "travel time- 727.0\n",
      "--- 1.4246420860290527 seconds ---\n",
      "episode 1836, reward -2.0, memory_length 2000, epsilon 0.3993168767363899\n",
      "travel time- 720.0\n",
      "--- 1.7245633602142334 seconds ---\n",
      "episode 1837, reward 251.0, memory_length 2000, epsilon 0.3991172682043132\n",
      "travel time- 720.0\n",
      "--- 1.6382153034210205 seconds ---\n",
      "episode 1838, reward 53.0, memory_length 2000, epsilon 0.39891775945155566\n",
      "travel time- 726.0\n",
      "--- 1.5435683727264404 seconds ---\n",
      "episode 1839, reward -172.0, memory_length 2000, epsilon 0.3987183504282401\n",
      "travel time- 727.0\n",
      "--- 1.747532606124878 seconds ---\n",
      "episode 1840, reward -104.0, memory_length 2000, epsilon 0.39851904108451414\n",
      "travel time- 727.0\n",
      "--- 1.624460220336914 seconds ---\n",
      "episode 1841, reward -240.0, memory_length 2000, epsilon 0.3983198313705506\n",
      "travel time- 734.0\n",
      "--- 1.6823978424072266 seconds ---\n",
      "episode 1842, reward -89.0, memory_length 2000, epsilon 0.39812072123654696\n",
      "travel time- 725.0\n",
      "--- 1.4280576705932617 seconds ---\n",
      "episode 1843, reward 170.0, memory_length 2000, epsilon 0.3979217106327257\n",
      "travel time- 727.0\n",
      "--- 1.6673853397369385 seconds ---\n",
      "episode 1844, reward -231.0, memory_length 2000, epsilon 0.39772279950933415\n",
      "travel time- 724.0\n",
      "--- 1.477611780166626 seconds ---\n",
      "episode 1845, reward -74.0, memory_length 2000, epsilon 0.3975239878166446\n",
      "travel time- 725.0\n",
      "--- 1.5085883140563965 seconds ---\n",
      "episode 1846, reward -156.0, memory_length 2000, epsilon 0.397325275504954\n",
      "travel time- 720.0\n",
      "--- 1.683734655380249 seconds ---\n",
      "episode 1847, reward 65.0, memory_length 2000, epsilon 0.3971266625245844\n",
      "travel time- 733.0\n",
      "--- 1.8592100143432617 seconds ---\n",
      "episode 1848, reward -174.0, memory_length 2000, epsilon 0.39692814882588245\n",
      "travel time- 725.0\n",
      "--- 1.6423938274383545 seconds ---\n",
      "episode 1849, reward -332.0, memory_length 2000, epsilon 0.3967297343592199\n",
      "travel time- 731.0\n",
      "--- 1.5587592124938965 seconds ---\n",
      "episode 1850, reward 100.0, memory_length 2000, epsilon 0.39653141907499284\n",
      "travel time- 726.0\n",
      "--- 1.6889078617095947 seconds ---\n",
      "episode 1851, reward -202.0, memory_length 2000, epsilon 0.39633320292362273\n",
      "travel time- 721.0\n",
      "--- 1.8400444984436035 seconds ---\n",
      "episode 1852, reward -341.0, memory_length 2000, epsilon 0.39613508585555535\n",
      "travel time- 727.0\n",
      "--- 1.8516690731048584 seconds ---\n",
      "episode 1853, reward 224.0, memory_length 2000, epsilon 0.39593706782126153\n",
      "travel time- 733.0\n",
      "--- 1.6310784816741943 seconds ---\n",
      "episode 1854, reward -98.0, memory_length 2000, epsilon 0.3957391487712367\n",
      "travel time- 725.0\n",
      "--- 1.705374002456665 seconds ---\n",
      "episode 1855, reward 6.0, memory_length 2000, epsilon 0.39554132865600117\n",
      "travel time- 723.0\n",
      "--- 1.7104911804199219 seconds ---\n",
      "episode 1856, reward -146.0, memory_length 2000, epsilon 0.3953436074260998\n",
      "travel time- 724.0\n",
      "--- 1.6212782859802246 seconds ---\n",
      "episode 1857, reward 80.0, memory_length 2000, epsilon 0.3951459850321024\n",
      "travel time- 722.0\n",
      "--- 1.67340087890625 seconds ---\n",
      "episode 1858, reward -10.0, memory_length 2000, epsilon 0.39494846142460327\n",
      "travel time- 723.0\n",
      "--- 1.5248212814331055 seconds ---\n",
      "episode 1859, reward 155.0, memory_length 2000, epsilon 0.3947510365542216\n",
      "travel time- 722.0\n",
      "--- 1.7773840427398682 seconds ---\n",
      "episode 1860, reward 135.0, memory_length 2000, epsilon 0.3945537103716011\n",
      "travel time- 720.0\n",
      "--- 1.614570140838623 seconds ---\n",
      "episode 1861, reward -101.0, memory_length 2000, epsilon 0.39435648282741026\n",
      "travel time- 728.0\n",
      "--- 1.4642724990844727 seconds ---\n",
      "episode 1862, reward -90.0, memory_length 2000, epsilon 0.3941593538723422\n",
      "travel time- 726.0\n",
      "--- 1.6077985763549805 seconds ---\n",
      "episode 1863, reward 214.0, memory_length 2000, epsilon 0.3939623234571146\n",
      "travel time- 727.0\n",
      "--- 1.784207820892334 seconds ---\n",
      "episode 1864, reward 9.0, memory_length 2000, epsilon 0.39376539153247\n",
      "travel time- 721.0\n",
      "--- 1.723261833190918 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1865, reward 164.0, memory_length 2000, epsilon 0.3935685580491753\n",
      "travel time- 721.0\n",
      "--- 1.690824270248413 seconds ---\n",
      "episode 1866, reward -221.0, memory_length 2000, epsilon 0.3933718229580221\n",
      "travel time- 726.0\n",
      "--- 1.6947689056396484 seconds ---\n",
      "episode 1867, reward 72.0, memory_length 2000, epsilon 0.3931751862098268\n",
      "travel time- 722.0\n",
      "--- 1.837623119354248 seconds ---\n",
      "episode 1868, reward 31.0, memory_length 2000, epsilon 0.39297864775542996\n",
      "travel time- 720.0\n",
      "--- 1.7791738510131836 seconds ---\n",
      "episode 1869, reward 27.0, memory_length 2000, epsilon 0.3927822075456972\n",
      "travel time- 721.0\n",
      "--- 1.6282680034637451 seconds ---\n",
      "episode 1870, reward 91.0, memory_length 2000, epsilon 0.39258586553151836\n",
      "travel time- 723.0\n",
      "--- 1.7834854125976562 seconds ---\n",
      "episode 1871, reward -216.0, memory_length 2000, epsilon 0.392389621663808\n",
      "travel time- 726.0\n",
      "--- 1.6606101989746094 seconds ---\n",
      "episode 1872, reward -178.0, memory_length 2000, epsilon 0.39219347589350495\n",
      "travel time- 720.0\n",
      "--- 1.6853156089782715 seconds ---\n",
      "episode 1873, reward 250.0, memory_length 2000, epsilon 0.39199742817157307\n",
      "travel time- 722.0\n",
      "--- 1.630122184753418 seconds ---\n",
      "episode 1874, reward -99.0, memory_length 2000, epsilon 0.39180147844900015\n",
      "travel time- 724.0\n",
      "--- 1.4591195583343506 seconds ---\n",
      "episode 1875, reward -201.0, memory_length 2000, epsilon 0.391605626676799\n",
      "travel time- 725.0\n",
      "--- 1.6153359413146973 seconds ---\n",
      "episode 1876, reward -16.0, memory_length 2000, epsilon 0.3914098728060065\n",
      "travel time- 721.0\n",
      "--- 1.603989839553833 seconds ---\n",
      "episode 1877, reward -84.0, memory_length 2000, epsilon 0.39121421678768425\n",
      "travel time- 731.0\n",
      "--- 1.594390869140625 seconds ---\n",
      "episode 1878, reward -83.0, memory_length 2000, epsilon 0.3910186585729182\n",
      "travel time- 724.0\n",
      "--- 1.5489516258239746 seconds ---\n",
      "episode 1879, reward -170.0, memory_length 2000, epsilon 0.3908231981128189\n",
      "travel time- 728.0\n",
      "--- 1.7884347438812256 seconds ---\n",
      "episode 1880, reward 164.0, memory_length 2000, epsilon 0.3906278353585211\n",
      "travel time- 728.0\n",
      "--- 1.553556203842163 seconds ---\n",
      "episode 1881, reward -131.0, memory_length 2000, epsilon 0.3904325702611842\n",
      "travel time- 729.0\n",
      "--- 1.8034050464630127 seconds ---\n",
      "episode 1882, reward 72.0, memory_length 2000, epsilon 0.39023740277199187\n",
      "travel time- 727.0\n",
      "--- 1.4988131523132324 seconds ---\n",
      "episode 1883, reward -584.0, memory_length 2000, epsilon 0.39004233284215234\n",
      "travel time- 722.0\n",
      "--- 1.7483315467834473 seconds ---\n",
      "episode 1884, reward 54.0, memory_length 2000, epsilon 0.38984736042289797\n",
      "travel time- 722.0\n",
      "--- 1.8111042976379395 seconds ---\n",
      "episode 1885, reward -22.0, memory_length 2000, epsilon 0.38965248546548575\n",
      "travel time- 720.0\n",
      "--- 1.8147015571594238 seconds ---\n",
      "episode 1886, reward -96.0, memory_length 2000, epsilon 0.38945770792119694\n",
      "travel time- 725.0\n",
      "--- 1.6863141059875488 seconds ---\n",
      "episode 1887, reward -91.0, memory_length 2000, epsilon 0.3892630277413372\n",
      "travel time- 722.0\n",
      "--- 1.7986304759979248 seconds ---\n",
      "episode 1888, reward -224.0, memory_length 2000, epsilon 0.3890684448772363\n",
      "travel time- 725.0\n",
      "--- 1.8117237091064453 seconds ---\n",
      "episode 1889, reward 108.0, memory_length 2000, epsilon 0.38887395928024876\n",
      "travel time- 726.0\n",
      "--- 1.4959194660186768 seconds ---\n",
      "episode 1890, reward -199.0, memory_length 2000, epsilon 0.388679570901753\n",
      "travel time- 722.0\n",
      "--- 1.6092886924743652 seconds ---\n",
      "episode 1891, reward -276.0, memory_length 2000, epsilon 0.388485279693152\n",
      "travel time- 735.0\n",
      "--- 1.7044742107391357 seconds ---\n",
      "episode 1892, reward -78.0, memory_length 2000, epsilon 0.38829108560587294\n",
      "travel time- 731.0\n",
      "--- 1.6718676090240479 seconds ---\n",
      "episode 1893, reward 89.0, memory_length 2000, epsilon 0.3880969885913673\n",
      "travel time- 726.0\n",
      "--- 1.604679822921753 seconds ---\n",
      "episode 1894, reward 287.0, memory_length 2000, epsilon 0.3879029886011109\n",
      "travel time- 726.0\n",
      "--- 1.4704201221466064 seconds ---\n",
      "episode 1895, reward -560.0, memory_length 2000, epsilon 0.3877090855866036\n",
      "travel time- 725.0\n",
      "--- 1.6005947589874268 seconds ---\n",
      "episode 1896, reward -57.0, memory_length 2000, epsilon 0.3875152794993697\n",
      "travel time- 723.0\n",
      "--- 1.7920446395874023 seconds ---\n",
      "episode 1897, reward 39.0, memory_length 2000, epsilon 0.38732157029095776\n",
      "travel time- 730.0\n",
      "--- 1.69089674949646 seconds ---\n",
      "episode 1898, reward -255.0, memory_length 2000, epsilon 0.38712795791294036\n",
      "travel time- 725.0\n",
      "--- 1.6861763000488281 seconds ---\n",
      "episode 1899, reward -180.0, memory_length 2000, epsilon 0.3869344423169145\n",
      "travel time- 730.0\n",
      "--- 1.454953670501709 seconds ---\n",
      "episode 1900, reward 17.0, memory_length 2000, epsilon 0.3867410234545012\n",
      "travel time- 724.0\n",
      "--- 1.6791348457336426 seconds ---\n",
      "episode 1901, reward 206.0, memory_length 2000, epsilon 0.3865477012773458\n",
      "travel time- 721.0\n",
      "--- 1.635802984237671 seconds ---\n",
      "episode 1902, reward -94.0, memory_length 2000, epsilon 0.3863544757371177\n",
      "travel time- 736.0\n",
      "--- 1.538367748260498 seconds ---\n",
      "episode 1903, reward -269.0, memory_length 2000, epsilon 0.38616134678551056\n",
      "travel time- 725.0\n",
      "--- 1.6514713764190674 seconds ---\n",
      "episode 1904, reward -95.0, memory_length 2000, epsilon 0.3859683143742421\n",
      "travel time- 722.0\n",
      "--- 1.8968803882598877 seconds ---\n",
      "episode 1905, reward 70.0, memory_length 2000, epsilon 0.38577537845505433\n",
      "travel time- 720.0\n",
      "--- 1.781280755996704 seconds ---\n",
      "episode 1906, reward 111.0, memory_length 2000, epsilon 0.38558253897971306\n",
      "travel time- 729.0\n",
      "--- 1.642277479171753 seconds ---\n",
      "episode 1907, reward -538.0, memory_length 2000, epsilon 0.38538979590000866\n",
      "travel time- 723.0\n",
      "--- 1.6439733505249023 seconds ---\n",
      "episode 1908, reward -133.0, memory_length 2000, epsilon 0.38519714916775516\n",
      "travel time- 729.0\n",
      "--- 1.521636724472046 seconds ---\n",
      "episode 1909, reward -370.0, memory_length 2000, epsilon 0.38500459873479104\n",
      "travel time- 725.0\n",
      "--- 1.6283104419708252 seconds ---\n",
      "episode 1910, reward 182.0, memory_length 2000, epsilon 0.3848121445529785\n",
      "travel time- 723.0\n",
      "--- 1.597916603088379 seconds ---\n",
      "episode 1911, reward -89.0, memory_length 2000, epsilon 0.3846197865742042\n",
      "travel time- 720.0\n",
      "--- 1.6028563976287842 seconds ---\n",
      "episode 1912, reward 174.0, memory_length 2000, epsilon 0.3844275247503785\n",
      "travel time- 732.0\n",
      "--- 1.491314172744751 seconds ---\n",
      "episode 1913, reward 156.0, memory_length 2000, epsilon 0.38423535903343603\n",
      "travel time- 721.0\n",
      "--- 1.626692771911621 seconds ---\n",
      "episode 1914, reward 208.0, memory_length 2000, epsilon 0.3840432893753352\n",
      "travel time- 724.0\n",
      "--- 1.4046235084533691 seconds ---\n",
      "episode 1915, reward 135.0, memory_length 2000, epsilon 0.38385131572805886\n",
      "travel time- 723.0\n",
      "--- 1.6464054584503174 seconds ---\n",
      "episode 1916, reward -407.0, memory_length 2000, epsilon 0.38365943804361335\n",
      "travel time- 724.0\n",
      "--- 1.7832283973693848 seconds ---\n",
      "episode 1917, reward -206.0, memory_length 2000, epsilon 0.38346765627402946\n",
      "travel time- 722.0\n",
      "--- 1.7628517150878906 seconds ---\n",
      "episode 1918, reward 56.0, memory_length 2000, epsilon 0.3832759703713615\n",
      "travel time- 723.0\n",
      "--- 1.749786615371704 seconds ---\n",
      "episode 1919, reward -110.0, memory_length 2000, epsilon 0.38308438028768826\n",
      "travel time- 727.0\n",
      "--- 1.6029744148254395 seconds ---\n",
      "episode 1920, reward 36.0, memory_length 2000, epsilon 0.38289288597511206\n",
      "travel time- 723.0\n",
      "--- 1.5644745826721191 seconds ---\n",
      "episode 1921, reward 296.0, memory_length 2000, epsilon 0.38270148738575926\n",
      "travel time- 720.0\n",
      "--- 1.3171005249023438 seconds ---\n",
      "episode 1922, reward 82.0, memory_length 2000, epsilon 0.38251018447178037\n",
      "travel time- 722.0\n",
      "--- 1.645728588104248 seconds ---\n",
      "episode 1923, reward 1.0, memory_length 2000, epsilon 0.3823189771853496\n",
      "travel time- 720.0\n",
      "--- 1.6398653984069824 seconds ---\n",
      "episode 1924, reward -345.0, memory_length 2000, epsilon 0.38212786547866506\n",
      "travel time- 727.0\n",
      "--- 1.7831573486328125 seconds ---\n",
      "episode 1925, reward 63.0, memory_length 2000, epsilon 0.3819368493039489\n",
      "travel time- 722.0\n",
      "--- 1.4595961570739746 seconds ---\n",
      "episode 1926, reward 170.0, memory_length 2000, epsilon 0.3817459286134471\n",
      "travel time- 723.0\n",
      "--- 1.8153235912322998 seconds ---\n",
      "episode 1927, reward -187.0, memory_length 2000, epsilon 0.3815551033594294\n",
      "travel time- 723.0\n",
      "--- 1.6399083137512207 seconds ---\n",
      "episode 1928, reward -200.0, memory_length 2000, epsilon 0.38136437349418956\n",
      "travel time- 723.0\n",
      "--- 1.6717324256896973 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1929, reward -90.0, memory_length 2000, epsilon 0.38117373897004503\n",
      "travel time- 723.0\n",
      "--- 1.7333126068115234 seconds ---\n",
      "episode 1930, reward -206.0, memory_length 2000, epsilon 0.38098319973933725\n",
      "travel time- 721.0\n",
      "--- 1.5635907649993896 seconds ---\n",
      "episode 1931, reward 211.0, memory_length 2000, epsilon 0.3807927557544314\n",
      "travel time- 726.0\n",
      "--- 1.670793056488037 seconds ---\n",
      "episode 1932, reward 212.0, memory_length 2000, epsilon 0.38060240696771647\n",
      "travel time- 720.0\n",
      "--- 1.7454569339752197 seconds ---\n",
      "episode 1933, reward -241.0, memory_length 2000, epsilon 0.3804121533316052\n",
      "travel time- 734.0\n",
      "--- 1.6321473121643066 seconds ---\n",
      "episode 1934, reward -73.0, memory_length 2000, epsilon 0.38022199479853436\n",
      "travel time- 720.0\n",
      "--- 1.9126365184783936 seconds ---\n",
      "episode 1935, reward 299.0, memory_length 2000, epsilon 0.3800319313209641\n",
      "travel time- 725.0\n",
      "--- 1.8389685153961182 seconds ---\n",
      "episode 1936, reward 138.0, memory_length 2000, epsilon 0.3798419628513787\n",
      "travel time- 720.0\n",
      "--- 1.7573809623718262 seconds ---\n",
      "episode 1937, reward -184.0, memory_length 2000, epsilon 0.37965208934228595\n",
      "travel time- 730.0\n",
      "--- 1.6390018463134766 seconds ---\n",
      "episode 1938, reward -92.0, memory_length 2000, epsilon 0.37946231074621756\n",
      "travel time- 722.0\n",
      "--- 1.7084596157073975 seconds ---\n",
      "episode 1939, reward -178.0, memory_length 2000, epsilon 0.37927262701572884\n",
      "travel time- 725.0\n",
      "--- 1.5708823204040527 seconds ---\n",
      "episode 1940, reward -169.0, memory_length 2000, epsilon 0.37908303810339883\n",
      "travel time- 724.0\n",
      "--- 1.7510201930999756 seconds ---\n",
      "episode 1941, reward -158.0, memory_length 2000, epsilon 0.3788935439618303\n",
      "travel time- 721.0\n",
      "--- 1.5464322566986084 seconds ---\n",
      "episode 1942, reward -249.0, memory_length 2000, epsilon 0.37870414454364976\n",
      "travel time- 726.0\n",
      "--- 1.6283740997314453 seconds ---\n",
      "episode 1943, reward -360.0, memory_length 2000, epsilon 0.3785148398015073\n",
      "travel time- 721.0\n",
      "--- 1.4947125911712646 seconds ---\n",
      "episode 1944, reward 120.0, memory_length 2000, epsilon 0.3783256296880768\n",
      "travel time- 733.0\n",
      "--- 1.6386997699737549 seconds ---\n",
      "episode 1945, reward -43.0, memory_length 2000, epsilon 0.37813651415605565\n",
      "travel time- 724.0\n",
      "--- 1.819411039352417 seconds ---\n",
      "episode 1946, reward 12.0, memory_length 2000, epsilon 0.37794749315816506\n",
      "travel time- 720.0\n",
      "--- 1.6141438484191895 seconds ---\n",
      "episode 1947, reward -14.0, memory_length 2000, epsilon 0.3777585666471497\n",
      "travel time- 721.0\n",
      "--- 1.7513947486877441 seconds ---\n",
      "episode 1948, reward -224.0, memory_length 2000, epsilon 0.37756973457577797\n",
      "travel time- 720.0\n",
      "--- 1.765453815460205 seconds ---\n",
      "episode 1949, reward -159.0, memory_length 2000, epsilon 0.37738099689684185\n",
      "travel time- 720.0\n",
      "--- 1.7813215255737305 seconds ---\n",
      "episode 1950, reward 151.0, memory_length 2000, epsilon 0.37719235356315695\n",
      "travel time- 721.0\n",
      "--- 1.4434123039245605 seconds ---\n",
      "episode 1951, reward 206.0, memory_length 2000, epsilon 0.3770038045275623\n",
      "travel time- 727.0\n",
      "--- 1.7029986381530762 seconds ---\n",
      "episode 1952, reward -148.0, memory_length 2000, epsilon 0.37681534974292086\n",
      "travel time- 724.0\n",
      "--- 1.555086374282837 seconds ---\n",
      "episode 1953, reward -49.0, memory_length 2000, epsilon 0.3766269891621188\n",
      "travel time- 734.0\n",
      "--- 1.7603662014007568 seconds ---\n",
      "episode 1954, reward -5.0, memory_length 2000, epsilon 0.37643872273806595\n",
      "travel time- 723.0\n",
      "--- 1.676853895187378 seconds ---\n",
      "episode 1955, reward 219.0, memory_length 2000, epsilon 0.37625055042369576\n",
      "travel time- 721.0\n",
      "--- 1.7246637344360352 seconds ---\n",
      "episode 1956, reward -31.0, memory_length 2000, epsilon 0.37606247217196515\n",
      "travel time- 720.0\n",
      "--- 1.769533395767212 seconds ---\n",
      "episode 1957, reward -249.0, memory_length 2000, epsilon 0.37587448793585454\n",
      "travel time- 723.0\n",
      "--- 1.6750049591064453 seconds ---\n",
      "episode 1958, reward 84.0, memory_length 2000, epsilon 0.37568659766836787\n",
      "travel time- 721.0\n",
      "--- 1.791449785232544 seconds ---\n",
      "episode 1959, reward 18.0, memory_length 2000, epsilon 0.37549880132253255\n",
      "travel time- 736.0\n",
      "--- 1.6386404037475586 seconds ---\n",
      "episode 1960, reward -340.0, memory_length 2000, epsilon 0.37531109885139957\n",
      "travel time- 721.0\n",
      "--- 1.6918902397155762 seconds ---\n",
      "episode 1961, reward 30.0, memory_length 2000, epsilon 0.3751234902080432\n",
      "travel time- 734.0\n",
      "--- 1.5743217468261719 seconds ---\n",
      "episode 1962, reward -101.0, memory_length 2000, epsilon 0.37493597534556133\n",
      "travel time- 723.0\n",
      "--- 1.9064812660217285 seconds ---\n",
      "episode 1963, reward 95.0, memory_length 2000, epsilon 0.37474855421707526\n",
      "travel time- 722.0\n",
      "--- 1.6367790699005127 seconds ---\n",
      "episode 1964, reward 221.0, memory_length 2000, epsilon 0.3745612267757298\n",
      "travel time- 730.0\n",
      "--- 1.5830609798431396 seconds ---\n",
      "episode 1965, reward 202.0, memory_length 2000, epsilon 0.3743739929746928\n",
      "travel time- 736.0\n",
      "--- 1.598031759262085 seconds ---\n",
      "episode 1966, reward 137.0, memory_length 2000, epsilon 0.37418685276715613\n",
      "travel time- 725.0\n",
      "--- 1.7867581844329834 seconds ---\n",
      "episode 1967, reward 116.0, memory_length 2000, epsilon 0.37399980610633454\n",
      "travel time- 721.0\n",
      "--- 1.4838104248046875 seconds ---\n",
      "episode 1968, reward -309.0, memory_length 2000, epsilon 0.3738128529454665\n",
      "travel time- 725.0\n",
      "--- 1.9328734874725342 seconds ---\n",
      "episode 1969, reward -161.0, memory_length 2000, epsilon 0.37362599323781354\n",
      "travel time- 721.0\n",
      "--- 1.5758082866668701 seconds ---\n",
      "episode 1970, reward 72.0, memory_length 2000, epsilon 0.37343922693666093\n",
      "travel time- 722.0\n",
      "--- 1.4839887619018555 seconds ---\n",
      "episode 1971, reward -36.0, memory_length 2000, epsilon 0.3732525539953169\n",
      "travel time- 721.0\n",
      "--- 1.472261905670166 seconds ---\n",
      "episode 1972, reward -112.0, memory_length 2000, epsilon 0.3730659743671134\n",
      "travel time- 724.0\n",
      "--- 1.7570698261260986 seconds ---\n",
      "episode 1973, reward 5.0, memory_length 2000, epsilon 0.3728794880054054\n",
      "travel time- 725.0\n",
      "--- 1.4913406372070312 seconds ---\n",
      "episode 1974, reward -66.0, memory_length 2000, epsilon 0.3726930948635714\n",
      "travel time- 723.0\n",
      "--- 1.7261896133422852 seconds ---\n",
      "episode 1975, reward -241.0, memory_length 2000, epsilon 0.3725067948950129\n",
      "travel time- 733.0\n",
      "--- 1.9104554653167725 seconds ---\n",
      "episode 1976, reward -211.0, memory_length 2000, epsilon 0.3723205880531552\n",
      "travel time- 721.0\n",
      "--- 1.5681860446929932 seconds ---\n",
      "episode 1977, reward -69.0, memory_length 2000, epsilon 0.3721344742914464\n",
      "travel time- 721.0\n",
      "--- 1.53993558883667 seconds ---\n",
      "episode 1978, reward -137.0, memory_length 2000, epsilon 0.3719484535633582\n",
      "travel time- 722.0\n",
      "--- 1.721665859222412 seconds ---\n",
      "episode 1979, reward 396.0, memory_length 2000, epsilon 0.3717625258223852\n",
      "travel time- 720.0\n",
      "--- 1.5338270664215088 seconds ---\n",
      "episode 1980, reward -270.0, memory_length 2000, epsilon 0.3715766910220457\n",
      "travel time- 720.0\n",
      "--- 1.6353697776794434 seconds ---\n",
      "episode 1981, reward 77.0, memory_length 2000, epsilon 0.37139094911588083\n",
      "travel time- 723.0\n",
      "--- 1.5379717350006104 seconds ---\n",
      "episode 1982, reward 16.0, memory_length 2000, epsilon 0.37120530005745517\n",
      "travel time- 736.0\n",
      "--- 1.6013386249542236 seconds ---\n",
      "episode 1983, reward -162.0, memory_length 2000, epsilon 0.37101974380035646\n",
      "travel time- 721.0\n",
      "--- 1.7556557655334473 seconds ---\n",
      "episode 1984, reward -329.0, memory_length 2000, epsilon 0.37083428029819565\n",
      "travel time- 720.0\n",
      "--- 1.8695874214172363 seconds ---\n",
      "episode 1985, reward 157.0, memory_length 2000, epsilon 0.3706489095046068\n",
      "travel time- 722.0\n",
      "--- 1.607530117034912 seconds ---\n",
      "episode 1986, reward -39.0, memory_length 2000, epsilon 0.37046363137324734\n",
      "travel time- 723.0\n",
      "--- 1.6791481971740723 seconds ---\n",
      "episode 1987, reward -422.0, memory_length 2000, epsilon 0.3702784458577976\n",
      "travel time- 723.0\n",
      "--- 1.6651957035064697 seconds ---\n",
      "episode 1988, reward 309.0, memory_length 2000, epsilon 0.37009335291196127\n",
      "travel time- 720.0\n",
      "--- 1.6601958274841309 seconds ---\n",
      "episode 1989, reward -137.0, memory_length 2000, epsilon 0.3699083524894651\n",
      "travel time- 727.0\n",
      "--- 1.530496597290039 seconds ---\n",
      "episode 1990, reward -255.0, memory_length 2000, epsilon 0.369723444544059\n",
      "travel time- 726.0\n",
      "--- 1.7565088272094727 seconds ---\n",
      "episode 1991, reward -292.0, memory_length 2000, epsilon 0.3695386290295159\n",
      "travel time- 728.0\n",
      "--- 1.7584447860717773 seconds ---\n",
      "episode 1992, reward -138.0, memory_length 2000, epsilon 0.369353905899632\n",
      "travel time- 720.0\n",
      "--- 1.6483488082885742 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1993, reward -298.0, memory_length 2000, epsilon 0.3691692751082265\n",
      "travel time- 723.0\n",
      "--- 1.6607038974761963 seconds ---\n",
      "episode 1994, reward -3.0, memory_length 2000, epsilon 0.3689847366091418\n",
      "travel time- 723.0\n",
      "--- 1.7244091033935547 seconds ---\n",
      "episode 1995, reward -215.0, memory_length 2000, epsilon 0.368800290356243\n",
      "travel time- 722.0\n",
      "--- 1.6372690200805664 seconds ---\n",
      "episode 1996, reward -56.0, memory_length 2000, epsilon 0.3686159363034188\n",
      "travel time- 724.0\n",
      "--- 1.7456157207489014 seconds ---\n",
      "episode 1997, reward -44.0, memory_length 2000, epsilon 0.3684316744045806\n",
      "travel time- 721.0\n",
      "--- 1.9254779815673828 seconds ---\n",
      "episode 1998, reward 92.0, memory_length 2000, epsilon 0.3682475046136629\n",
      "travel time- 723.0\n",
      "--- 1.8074069023132324 seconds ---\n",
      "episode 1999, reward -151.0, memory_length 2000, epsilon 0.3680634268846233\n",
      "travel time- 721.0\n",
      "--- 1.9216783046722412 seconds ---\n",
      "episode 2000, reward -277.0, memory_length 2000, epsilon 0.36787944117144233\n",
      "travel time- 722.0\n",
      "--- 1.6870698928833008 seconds ---\n",
      "episode 2001, reward -67.0, memory_length 2000, epsilon 0.36769554742812355\n",
      "travel time- 721.0\n",
      "--- 1.7281417846679688 seconds ---\n",
      "episode 2002, reward -286.0, memory_length 2000, epsilon 0.3675117456086935\n",
      "travel time- 723.0\n",
      "--- 2.055436134338379 seconds ---\n",
      "episode 2003, reward 78.0, memory_length 2000, epsilon 0.36732803566720185\n",
      "travel time- 723.0\n",
      "--- 1.7500264644622803 seconds ---\n",
      "episode 2004, reward -128.0, memory_length 2000, epsilon 0.36714441755772104\n",
      "travel time- 730.0\n",
      "--- 1.5654981136322021 seconds ---\n",
      "episode 2005, reward -163.0, memory_length 2000, epsilon 0.3669608912343465\n",
      "travel time- 720.0\n",
      "--- 1.7094862461090088 seconds ---\n",
      "episode 2006, reward 43.0, memory_length 2000, epsilon 0.3667774566511966\n",
      "travel time- 721.0\n",
      "--- 1.4604384899139404 seconds ---\n",
      "episode 2007, reward 135.0, memory_length 2000, epsilon 0.36659411376241285\n",
      "travel time- 725.0\n",
      "--- 1.6465120315551758 seconds ---\n",
      "episode 2008, reward 204.0, memory_length 2000, epsilon 0.3664108625221595\n",
      "travel time- 728.0\n",
      "--- 1.729762077331543 seconds ---\n",
      "episode 2009, reward -32.0, memory_length 2000, epsilon 0.3662277028846236\n",
      "travel time- 724.0\n",
      "--- 1.565896987915039 seconds ---\n",
      "episode 2010, reward 245.0, memory_length 2000, epsilon 0.36604463480401533\n",
      "travel time- 720.0\n",
      "--- 1.6106736660003662 seconds ---\n",
      "episode 2011, reward -304.0, memory_length 2000, epsilon 0.3658616582345677\n",
      "travel time- 723.0\n",
      "--- 1.636326789855957 seconds ---\n",
      "episode 2012, reward -49.0, memory_length 2000, epsilon 0.36567877313053654\n",
      "travel time- 724.0\n",
      "--- 1.803346872329712 seconds ---\n",
      "episode 2013, reward 44.0, memory_length 2000, epsilon 0.3654959794462006\n",
      "travel time- 727.0\n",
      "--- 1.84798264503479 seconds ---\n",
      "episode 2014, reward -258.0, memory_length 2000, epsilon 0.3653132771358613\n",
      "travel time- 721.0\n",
      "--- 1.7901790142059326 seconds ---\n",
      "episode 2015, reward 163.0, memory_length 2000, epsilon 0.3651306661538433\n",
      "travel time- 725.0\n",
      "--- 1.677408218383789 seconds ---\n",
      "episode 2016, reward -28.0, memory_length 2000, epsilon 0.36494814645449375\n",
      "travel time- 721.0\n",
      "--- 1.61224365234375 seconds ---\n",
      "episode 2017, reward -154.0, memory_length 2000, epsilon 0.36476571799218266\n",
      "travel time- 730.0\n",
      "--- 1.7436988353729248 seconds ---\n",
      "episode 2018, reward 257.0, memory_length 2000, epsilon 0.3645833807213029\n",
      "travel time- 726.0\n",
      "--- 1.6603834629058838 seconds ---\n",
      "episode 2019, reward 232.0, memory_length 2000, epsilon 0.3644011345962703\n",
      "travel time- 723.0\n",
      "--- 2.007268190383911 seconds ---\n",
      "episode 2020, reward -156.0, memory_length 2000, epsilon 0.3642189795715233\n",
      "travel time- 728.0\n",
      "--- 1.7496635913848877 seconds ---\n",
      "episode 2021, reward 372.0, memory_length 2000, epsilon 0.36403691560152307\n",
      "travel time- 725.0\n",
      "--- 1.6453306674957275 seconds ---\n",
      "episode 2022, reward -25.0, memory_length 2000, epsilon 0.3638549426407535\n",
      "travel time- 720.0\n",
      "--- 1.686171054840088 seconds ---\n",
      "episode 2023, reward -42.0, memory_length 2000, epsilon 0.3636730606437217\n",
      "travel time- 724.0\n",
      "--- 1.6027090549468994 seconds ---\n",
      "episode 2024, reward -102.0, memory_length 2000, epsilon 0.3634912695649568\n",
      "travel time- 720.0\n",
      "--- 1.6772315502166748 seconds ---\n",
      "episode 2025, reward 261.0, memory_length 2000, epsilon 0.36330956935901126\n",
      "travel time- 734.0\n",
      "--- 1.5613784790039062 seconds ---\n",
      "episode 2026, reward -43.0, memory_length 2000, epsilon 0.3631279599804599\n",
      "travel time- 727.0\n",
      "--- 1.6440536975860596 seconds ---\n",
      "episode 2027, reward -264.0, memory_length 2000, epsilon 0.3629464413839004\n",
      "travel time- 727.0\n",
      "--- 1.554192066192627 seconds ---\n",
      "episode 2028, reward -17.0, memory_length 2000, epsilon 0.36276501352395324\n",
      "travel time- 727.0\n",
      "--- 1.6633872985839844 seconds ---\n",
      "episode 2029, reward 136.0, memory_length 2000, epsilon 0.36258367635526134\n",
      "travel time- 721.0\n",
      "--- 1.6087048053741455 seconds ---\n",
      "episode 2030, reward 190.0, memory_length 2000, epsilon 0.36240242983249027\n",
      "travel time- 726.0\n",
      "--- 1.7047224044799805 seconds ---\n",
      "episode 2031, reward 124.0, memory_length 2000, epsilon 0.36222127391032866\n",
      "travel time- 720.0\n",
      "--- 1.79512357711792 seconds ---\n",
      "episode 2032, reward -71.0, memory_length 2000, epsilon 0.36204020854348745\n",
      "travel time- 736.0\n",
      "--- 1.6706361770629883 seconds ---\n",
      "episode 2033, reward -18.0, memory_length 2000, epsilon 0.36185923368670025\n",
      "travel time- 720.0\n",
      "--- 1.6822426319122314 seconds ---\n",
      "episode 2034, reward -95.0, memory_length 2000, epsilon 0.36167834929472326\n",
      "travel time- 734.0\n",
      "--- 1.5717144012451172 seconds ---\n",
      "episode 2035, reward -86.0, memory_length 2000, epsilon 0.3614975553223355\n",
      "travel time- 724.0\n",
      "--- 1.6229186058044434 seconds ---\n",
      "episode 2036, reward -117.0, memory_length 2000, epsilon 0.36131685172433853\n",
      "travel time- 722.0\n",
      "--- 1.6877553462982178 seconds ---\n",
      "episode 2037, reward 134.0, memory_length 2000, epsilon 0.36113623845555637\n",
      "travel time- 724.0\n",
      "--- 1.6953558921813965 seconds ---\n",
      "episode 2038, reward 236.0, memory_length 2000, epsilon 0.3609557154708356\n",
      "travel time- 727.0\n",
      "--- 1.6838898658752441 seconds ---\n",
      "episode 2039, reward -92.0, memory_length 2000, epsilon 0.36077528272504567\n",
      "travel time- 726.0\n",
      "--- 1.508174180984497 seconds ---\n",
      "episode 2040, reward 6.0, memory_length 2000, epsilon 0.3605949401730783\n",
      "travel time- 722.0\n",
      "--- 1.7231836318969727 seconds ---\n",
      "episode 2041, reward 56.0, memory_length 2000, epsilon 0.36041468776984786\n",
      "travel time- 720.0\n",
      "--- 1.5194456577301025 seconds ---\n",
      "episode 2042, reward 138.0, memory_length 2000, epsilon 0.3602345254702911\n",
      "travel time- 722.0\n",
      "--- 1.5343389511108398 seconds ---\n",
      "episode 2043, reward -190.0, memory_length 2000, epsilon 0.36005445322936774\n",
      "travel time- 723.0\n",
      "--- 1.5789449214935303 seconds ---\n",
      "episode 2044, reward -189.0, memory_length 2000, epsilon 0.35987447100205955\n",
      "travel time- 724.0\n",
      "--- 1.742776870727539 seconds ---\n",
      "episode 2045, reward 17.0, memory_length 2000, epsilon 0.35969457874337096\n",
      "travel time- 724.0\n",
      "--- 1.8788738250732422 seconds ---\n",
      "episode 2046, reward -225.0, memory_length 2000, epsilon 0.35951477640832885\n",
      "travel time- 721.0\n",
      "--- 1.7781476974487305 seconds ---\n",
      "episode 2047, reward 55.0, memory_length 2000, epsilon 0.3593350639519828\n",
      "travel time- 721.0\n",
      "--- 1.7590835094451904 seconds ---\n",
      "episode 2048, reward -85.0, memory_length 2000, epsilon 0.3591554413294046\n",
      "travel time- 734.0\n",
      "--- 1.62420654296875 seconds ---\n",
      "episode 2049, reward -184.0, memory_length 2000, epsilon 0.3589759084956886\n",
      "travel time- 726.0\n",
      "--- 1.9377706050872803 seconds ---\n",
      "episode 2050, reward -262.0, memory_length 2000, epsilon 0.3587964654059516\n",
      "travel time- 730.0\n",
      "--- 1.819122076034546 seconds ---\n",
      "episode 2051, reward -283.0, memory_length 2000, epsilon 0.35861711201533275\n",
      "travel time- 722.0\n",
      "--- 1.6283905506134033 seconds ---\n",
      "episode 2052, reward -8.0, memory_length 2000, epsilon 0.3584378482789939\n",
      "travel time- 723.0\n",
      "--- 1.5124571323394775 seconds ---\n",
      "episode 2053, reward -64.0, memory_length 2000, epsilon 0.3582586741521189\n",
      "travel time- 721.0\n",
      "--- 1.5812675952911377 seconds ---\n",
      "episode 2054, reward 17.0, memory_length 2000, epsilon 0.35807958958991437\n",
      "travel time- 721.0\n",
      "--- 1.6614012718200684 seconds ---\n",
      "episode 2055, reward 143.0, memory_length 2000, epsilon 0.357900594547609\n",
      "travel time- 720.0\n",
      "--- 1.58054518699646 seconds ---\n",
      "episode 2056, reward 53.0, memory_length 2000, epsilon 0.3577216889804542\n",
      "travel time- 723.0\n",
      "--- 1.8124785423278809 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2057, reward 15.0, memory_length 2000, epsilon 0.3575428728437235\n",
      "travel time- 723.0\n",
      "--- 1.656395673751831 seconds ---\n",
      "episode 2058, reward -15.0, memory_length 2000, epsilon 0.3573641460927129\n",
      "travel time- 730.0\n",
      "--- 1.6312839984893799 seconds ---\n",
      "episode 2059, reward -126.0, memory_length 2000, epsilon 0.35718550868274057\n",
      "travel time- 721.0\n",
      "--- 1.7270195484161377 seconds ---\n",
      "episode 2060, reward -192.0, memory_length 2000, epsilon 0.3570069605691474\n",
      "travel time- 721.0\n",
      "--- 1.8140664100646973 seconds ---\n",
      "episode 2061, reward -113.0, memory_length 2000, epsilon 0.3568285017072962\n",
      "travel time- 729.0\n",
      "--- 1.5504133701324463 seconds ---\n",
      "episode 2062, reward 35.0, memory_length 2000, epsilon 0.35665013205257223\n",
      "travel time- 720.0\n",
      "--- 1.6449217796325684 seconds ---\n",
      "episode 2063, reward 34.0, memory_length 2000, epsilon 0.35647185156038314\n",
      "travel time- 721.0\n",
      "--- 1.8914482593536377 seconds ---\n",
      "episode 2064, reward -201.0, memory_length 2000, epsilon 0.3562936601861588\n",
      "travel time- 727.0\n",
      "--- 1.6719894409179688 seconds ---\n",
      "episode 2065, reward 10.0, memory_length 2000, epsilon 0.35611555788535143\n",
      "travel time- 724.0\n",
      "--- 1.7111790180206299 seconds ---\n",
      "episode 2066, reward -23.0, memory_length 2000, epsilon 0.35593754461343535\n",
      "travel time- 720.0\n",
      "--- 1.8068759441375732 seconds ---\n",
      "episode 2067, reward -86.0, memory_length 2000, epsilon 0.35575962032590724\n",
      "travel time- 725.0\n",
      "--- 1.8072917461395264 seconds ---\n",
      "episode 2068, reward -383.0, memory_length 2000, epsilon 0.35558178497828613\n",
      "travel time- 725.0\n",
      "--- 1.7400352954864502 seconds ---\n",
      "episode 2069, reward 25.0, memory_length 2000, epsilon 0.3554040385261131\n",
      "travel time- 724.0\n",
      "--- 1.6729681491851807 seconds ---\n",
      "episode 2070, reward 32.0, memory_length 2000, epsilon 0.3552263809249515\n",
      "travel time- 721.0\n",
      "--- 1.6373858451843262 seconds ---\n",
      "episode 2071, reward -43.0, memory_length 2000, epsilon 0.35504881213038697\n",
      "travel time- 721.0\n",
      "--- 1.6401736736297607 seconds ---\n",
      "episode 2072, reward 211.0, memory_length 2000, epsilon 0.3548713320980274\n",
      "travel time- 724.0\n",
      "--- 1.6468238830566406 seconds ---\n",
      "episode 2073, reward -252.0, memory_length 2000, epsilon 0.3546939407835027\n",
      "travel time- 727.0\n",
      "--- 1.8329393863677979 seconds ---\n",
      "episode 2074, reward 47.0, memory_length 2000, epsilon 0.35451663814246503\n",
      "travel time- 723.0\n",
      "--- 1.5109038352966309 seconds ---\n",
      "episode 2075, reward 141.0, memory_length 2000, epsilon 0.35433942413058866\n",
      "travel time- 729.0\n",
      "--- 1.475836992263794 seconds ---\n",
      "episode 2076, reward -2.0, memory_length 2000, epsilon 0.35416229870357024\n",
      "travel time- 723.0\n",
      "--- 1.5962250232696533 seconds ---\n",
      "episode 2077, reward -114.0, memory_length 2000, epsilon 0.35398526181712836\n",
      "travel time- 727.0\n",
      "--- 1.6994407176971436 seconds ---\n",
      "episode 2078, reward -150.0, memory_length 2000, epsilon 0.35380831342700375\n",
      "travel time- 720.0\n",
      "--- 1.672133207321167 seconds ---\n",
      "episode 2079, reward -98.0, memory_length 2000, epsilon 0.3536314534889593\n",
      "travel time- 724.0\n",
      "--- 1.707477331161499 seconds ---\n",
      "episode 2080, reward 94.0, memory_length 2000, epsilon 0.35345468195878016\n",
      "travel time- 723.0\n",
      "--- 1.7257754802703857 seconds ---\n",
      "episode 2081, reward -247.0, memory_length 2000, epsilon 0.3532779987922733\n",
      "travel time- 721.0\n",
      "--- 1.6004576683044434 seconds ---\n",
      "episode 2082, reward 131.0, memory_length 2000, epsilon 0.353101403945268\n",
      "travel time- 724.0\n",
      "--- 1.69057035446167 seconds ---\n",
      "episode 2083, reward -196.0, memory_length 2000, epsilon 0.35292489737361543\n",
      "travel time- 727.0\n",
      "--- 1.491133689880371 seconds ---\n",
      "episode 2084, reward 148.0, memory_length 2000, epsilon 0.3527484790331891\n",
      "travel time- 721.0\n",
      "--- 1.5260815620422363 seconds ---\n",
      "episode 2085, reward 78.0, memory_length 2000, epsilon 0.3525721488798844\n",
      "travel time- 726.0\n",
      "--- 1.4520363807678223 seconds ---\n",
      "episode 2086, reward -301.0, memory_length 2000, epsilon 0.35239590686961875\n",
      "travel time- 723.0\n",
      "--- 1.6113262176513672 seconds ---\n",
      "episode 2087, reward 90.0, memory_length 2000, epsilon 0.3522197529583316\n",
      "travel time- 726.0\n",
      "--- 1.651036024093628 seconds ---\n",
      "episode 2088, reward 99.0, memory_length 2000, epsilon 0.3520436871019846\n",
      "travel time- 729.0\n",
      "--- 1.5953538417816162 seconds ---\n",
      "episode 2089, reward -136.0, memory_length 2000, epsilon 0.3518677092565612\n",
      "travel time- 720.0\n",
      "--- 1.6991631984710693 seconds ---\n",
      "episode 2090, reward 26.0, memory_length 2000, epsilon 0.3516918193780669\n",
      "travel time- 727.0\n",
      "--- 1.6726500988006592 seconds ---\n",
      "episode 2091, reward -64.0, memory_length 2000, epsilon 0.35151601742252925\n",
      "travel time- 721.0\n",
      "--- 1.6260590553283691 seconds ---\n",
      "episode 2092, reward -34.0, memory_length 2000, epsilon 0.3513403033459978\n",
      "travel time- 720.0\n",
      "--- 1.663762092590332 seconds ---\n",
      "episode 2093, reward -13.0, memory_length 2000, epsilon 0.3511646771045441\n",
      "travel time- 722.0\n",
      "--- 1.722870111465454 seconds ---\n",
      "episode 2094, reward -110.0, memory_length 2000, epsilon 0.35098913865426146\n",
      "travel time- 720.0\n",
      "--- 1.7088770866394043 seconds ---\n",
      "episode 2095, reward 37.0, memory_length 2000, epsilon 0.3508136879512653\n",
      "travel time- 726.0\n",
      "--- 1.5272254943847656 seconds ---\n",
      "episode 2096, reward -115.0, memory_length 2000, epsilon 0.35063832495169295\n",
      "travel time- 728.0\n",
      "--- 1.694218635559082 seconds ---\n",
      "episode 2097, reward -46.0, memory_length 2000, epsilon 0.35046304961170366\n",
      "travel time- 727.0\n",
      "--- 1.5596694946289062 seconds ---\n",
      "episode 2098, reward -23.0, memory_length 2000, epsilon 0.3502878618874786\n",
      "travel time- 720.0\n",
      "--- 1.441072702407837 seconds ---\n",
      "episode 2099, reward -341.0, memory_length 2000, epsilon 0.3501127617352208\n",
      "travel time- 733.0\n",
      "--- 1.622105598449707 seconds ---\n",
      "episode 2100, reward 135.0, memory_length 2000, epsilon 0.3499377491111553\n",
      "travel time- 730.0\n",
      "--- 1.7979366779327393 seconds ---\n",
      "episode 2101, reward -74.0, memory_length 2000, epsilon 0.34976282397152897\n",
      "travel time- 722.0\n",
      "--- 1.6674528121948242 seconds ---\n",
      "episode 2102, reward -278.0, memory_length 2000, epsilon 0.3495879862726104\n",
      "travel time- 727.0\n",
      "--- 1.6332063674926758 seconds ---\n",
      "episode 2103, reward -265.0, memory_length 2000, epsilon 0.34941323597069013\n",
      "travel time- 723.0\n",
      "--- 1.5224087238311768 seconds ---\n",
      "episode 2104, reward 108.0, memory_length 2000, epsilon 0.3492385730220808\n",
      "travel time- 720.0\n",
      "--- 1.5959553718566895 seconds ---\n",
      "episode 2105, reward -207.0, memory_length 2000, epsilon 0.3490639973831165\n",
      "travel time- 720.0\n",
      "--- 1.6144769191741943 seconds ---\n",
      "episode 2106, reward -60.0, memory_length 2000, epsilon 0.34888950901015336\n",
      "travel time- 721.0\n",
      "--- 1.5369923114776611 seconds ---\n",
      "episode 2107, reward 107.0, memory_length 2000, epsilon 0.3487151078595692\n",
      "travel time- 720.0\n",
      "--- 1.6707935333251953 seconds ---\n",
      "episode 2108, reward -53.0, memory_length 2000, epsilon 0.348540793887764\n",
      "travel time- 722.0\n",
      "--- 1.5349323749542236 seconds ---\n",
      "episode 2109, reward -30.0, memory_length 2000, epsilon 0.348366567051159\n",
      "travel time- 726.0\n",
      "--- 1.536696434020996 seconds ---\n",
      "episode 2110, reward -139.0, memory_length 2000, epsilon 0.3481924273061976\n",
      "travel time- 720.0\n",
      "--- 1.3116579055786133 seconds ---\n",
      "episode 2111, reward 71.0, memory_length 2000, epsilon 0.3480183746093447\n",
      "travel time- 730.0\n",
      "--- 1.599266529083252 seconds ---\n",
      "episode 2112, reward -141.0, memory_length 2000, epsilon 0.3478444089170874\n",
      "travel time- 726.0\n",
      "--- 1.587787389755249 seconds ---\n",
      "episode 2113, reward -331.0, memory_length 2000, epsilon 0.34767053018593413\n",
      "travel time- 723.0\n",
      "--- 1.7551751136779785 seconds ---\n",
      "episode 2114, reward -87.0, memory_length 2000, epsilon 0.34749673837241524\n",
      "travel time- 722.0\n",
      "--- 1.6076200008392334 seconds ---\n",
      "episode 2115, reward -304.0, memory_length 2000, epsilon 0.3473230334330827\n",
      "travel time- 724.0\n",
      "--- 1.739633560180664 seconds ---\n",
      "episode 2116, reward -85.0, memory_length 2000, epsilon 0.3471494153245103\n",
      "travel time- 723.0\n",
      "--- 1.6323251724243164 seconds ---\n",
      "episode 2117, reward 11.0, memory_length 2000, epsilon 0.34697588400329366\n",
      "travel time- 720.0\n",
      "--- 1.5631780624389648 seconds ---\n",
      "episode 2118, reward -42.0, memory_length 2000, epsilon 0.34680243942604977\n",
      "travel time- 728.0\n",
      "--- 1.5236411094665527 seconds ---\n",
      "episode 2119, reward -187.0, memory_length 2000, epsilon 0.34662908154941746\n",
      "travel time- 721.0\n",
      "--- 1.6555049419403076 seconds ---\n",
      "episode 2120, reward -69.0, memory_length 2000, epsilon 0.3464558103300574\n",
      "travel time- 727.0\n",
      "--- 1.6333398818969727 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2121, reward -109.0, memory_length 2000, epsilon 0.3462826257246518\n",
      "travel time- 724.0\n",
      "--- 1.6757135391235352 seconds ---\n",
      "episode 2122, reward 214.0, memory_length 2000, epsilon 0.3461095276899044\n",
      "travel time- 720.0\n",
      "--- 1.511659860610962 seconds ---\n",
      "episode 2123, reward 283.0, memory_length 2000, epsilon 0.3459365161825406\n",
      "travel time- 724.0\n",
      "--- 1.6888246536254883 seconds ---\n",
      "episode 2124, reward 281.0, memory_length 2000, epsilon 0.34576359115930777\n",
      "travel time- 727.0\n",
      "--- 1.6769053936004639 seconds ---\n",
      "episode 2125, reward -232.0, memory_length 2000, epsilon 0.3455907525769745\n",
      "travel time- 724.0\n",
      "--- 1.652359962463379 seconds ---\n",
      "episode 2126, reward -157.0, memory_length 2000, epsilon 0.3454180003923312\n",
      "travel time- 733.0\n",
      "--- 1.7091569900512695 seconds ---\n",
      "episode 2127, reward -396.0, memory_length 2000, epsilon 0.34524533456218975\n",
      "travel time- 728.0\n",
      "--- 1.6751065254211426 seconds ---\n",
      "episode 2128, reward 65.0, memory_length 2000, epsilon 0.34507275504338375\n",
      "travel time- 723.0\n",
      "--- 1.5382633209228516 seconds ---\n",
      "episode 2129, reward 220.0, memory_length 2000, epsilon 0.34490026179276834\n",
      "travel time- 721.0\n",
      "--- 1.5666639804840088 seconds ---\n",
      "episode 2130, reward -83.0, memory_length 2000, epsilon 0.3447278547672202\n",
      "travel time- 722.0\n",
      "--- 1.6790900230407715 seconds ---\n",
      "episode 2131, reward -130.0, memory_length 2000, epsilon 0.3445555339236374\n",
      "travel time- 728.0\n",
      "--- 1.8053956031799316 seconds ---\n",
      "episode 2132, reward 36.0, memory_length 2000, epsilon 0.34438329921894\n",
      "travel time- 727.0\n",
      "--- 1.6416051387786865 seconds ---\n",
      "episode 2133, reward 70.0, memory_length 2000, epsilon 0.34421115061006924\n",
      "travel time- 725.0\n",
      "--- 1.6474261283874512 seconds ---\n",
      "episode 2134, reward -390.0, memory_length 2000, epsilon 0.34403908805398786\n",
      "travel time- 720.0\n",
      "--- 1.635638952255249 seconds ---\n",
      "episode 2135, reward -270.0, memory_length 2000, epsilon 0.34386711150768023\n",
      "travel time- 726.0\n",
      "--- 1.5647649765014648 seconds ---\n",
      "episode 2136, reward 97.0, memory_length 2000, epsilon 0.34369522092815236\n",
      "travel time- 723.0\n",
      "--- 1.638777494430542 seconds ---\n",
      "episode 2137, reward -69.0, memory_length 2000, epsilon 0.3435234162724315\n",
      "travel time- 720.0\n",
      "--- 1.822735071182251 seconds ---\n",
      "episode 2138, reward 109.0, memory_length 2000, epsilon 0.3433516974975665\n",
      "travel time- 720.0\n",
      "--- 1.5905687808990479 seconds ---\n",
      "episode 2139, reward -130.0, memory_length 2000, epsilon 0.34318006456062755\n",
      "travel time- 723.0\n",
      "--- 1.484447717666626 seconds ---\n",
      "episode 2140, reward -83.0, memory_length 2000, epsilon 0.34300851741870664\n",
      "travel time- 721.0\n",
      "--- 1.579254388809204 seconds ---\n",
      "episode 2141, reward 311.0, memory_length 2000, epsilon 0.3428370560289169\n",
      "travel time- 722.0\n",
      "--- 1.5698809623718262 seconds ---\n",
      "episode 2142, reward 123.0, memory_length 2000, epsilon 0.3426656803483929\n",
      "travel time- 720.0\n",
      "--- 1.421570062637329 seconds ---\n",
      "episode 2143, reward -50.0, memory_length 2000, epsilon 0.3424943903342907\n",
      "travel time- 724.0\n",
      "--- 1.9155516624450684 seconds ---\n",
      "episode 2144, reward 191.0, memory_length 2000, epsilon 0.34232318594378797\n",
      "travel time- 720.0\n",
      "--- 1.6164205074310303 seconds ---\n",
      "episode 2145, reward 0.0, memory_length 2000, epsilon 0.34215206713408347\n",
      "travel time- 720.0\n",
      "--- 1.8000307083129883 seconds ---\n",
      "episode 2146, reward 9.0, memory_length 2000, epsilon 0.3419810338623976\n",
      "travel time- 724.0\n",
      "--- 1.5488126277923584 seconds ---\n",
      "episode 2147, reward -113.0, memory_length 2000, epsilon 0.34181008608597185\n",
      "travel time- 723.0\n",
      "--- 1.6735570430755615 seconds ---\n",
      "episode 2148, reward 192.0, memory_length 2000, epsilon 0.34163922376206945\n",
      "travel time- 727.0\n",
      "--- 1.6248459815979004 seconds ---\n",
      "episode 2149, reward 58.0, memory_length 2000, epsilon 0.34146844684797484\n",
      "travel time- 727.0\n",
      "--- 1.7156152725219727 seconds ---\n",
      "episode 2150, reward -128.0, memory_length 2000, epsilon 0.3412977553009937\n",
      "travel time- 724.0\n",
      "--- 1.7647528648376465 seconds ---\n",
      "episode 2151, reward 95.0, memory_length 2000, epsilon 0.3411271490784531\n",
      "travel time- 721.0\n",
      "--- 1.5210168361663818 seconds ---\n",
      "episode 2152, reward 172.0, memory_length 2000, epsilon 0.34095662813770156\n",
      "travel time- 730.0\n",
      "--- 1.497316837310791 seconds ---\n",
      "episode 2153, reward 20.0, memory_length 2000, epsilon 0.34078619243610886\n",
      "travel time- 723.0\n",
      "--- 1.558387041091919 seconds ---\n",
      "episode 2154, reward -334.0, memory_length 2000, epsilon 0.3406158419310661\n",
      "travel time- 726.0\n",
      "--- 1.6855769157409668 seconds ---\n",
      "episode 2155, reward -381.0, memory_length 2000, epsilon 0.3404455765799855\n",
      "travel time- 720.0\n",
      "--- 1.7713706493377686 seconds ---\n",
      "episode 2156, reward -218.0, memory_length 2000, epsilon 0.3402753963403008\n",
      "travel time- 727.0\n",
      "--- 1.5629432201385498 seconds ---\n",
      "episode 2157, reward -8.0, memory_length 2000, epsilon 0.340105301169467\n",
      "travel time- 721.0\n",
      "--- 1.604590654373169 seconds ---\n",
      "episode 2158, reward 196.0, memory_length 2000, epsilon 0.33993529102496034\n",
      "travel time- 726.0\n",
      "--- 1.6058287620544434 seconds ---\n",
      "episode 2159, reward -236.0, memory_length 2000, epsilon 0.3397653658642781\n",
      "travel time- 723.0\n",
      "--- 1.6727042198181152 seconds ---\n",
      "episode 2160, reward -13.0, memory_length 2000, epsilon 0.3395955256449391\n",
      "travel time- 721.0\n",
      "--- 1.6347835063934326 seconds ---\n",
      "episode 2161, reward -226.0, memory_length 2000, epsilon 0.33942577032448334\n",
      "travel time- 726.0\n",
      "--- 1.3779668807983398 seconds ---\n",
      "episode 2162, reward -9.0, memory_length 2000, epsilon 0.33925609986047195\n",
      "travel time- 721.0\n",
      "--- 1.533444881439209 seconds ---\n",
      "episode 2163, reward -210.0, memory_length 2000, epsilon 0.3390865142104872\n",
      "travel time- 722.0\n",
      "--- 1.7357251644134521 seconds ---\n",
      "episode 2164, reward -196.0, memory_length 2000, epsilon 0.3389170133321328\n",
      "travel time- 723.0\n",
      "--- 1.596177577972412 seconds ---\n",
      "episode 2165, reward -71.0, memory_length 2000, epsilon 0.33874759718303354\n",
      "travel time- 720.0\n",
      "--- 1.5278701782226562 seconds ---\n",
      "episode 2166, reward -453.0, memory_length 2000, epsilon 0.3385782657208353\n",
      "travel time- 736.0\n",
      "--- 1.7512385845184326 seconds ---\n",
      "episode 2167, reward 81.0, memory_length 2000, epsilon 0.33840901890320524\n",
      "travel time- 731.0\n",
      "--- 1.5183460712432861 seconds ---\n",
      "episode 2168, reward -70.0, memory_length 2000, epsilon 0.3382398566878317\n",
      "travel time- 725.0\n",
      "--- 1.7289977073669434 seconds ---\n",
      "episode 2169, reward -79.0, memory_length 2000, epsilon 0.3380707790324241\n",
      "travel time- 724.0\n",
      "--- 1.7015173435211182 seconds ---\n",
      "episode 2170, reward -408.0, memory_length 2000, epsilon 0.33790178589471304\n",
      "travel time- 727.0\n",
      "--- 1.7203054428100586 seconds ---\n",
      "episode 2171, reward 337.0, memory_length 2000, epsilon 0.3377328772324501\n",
      "travel time- 727.0\n",
      "--- 1.593010663986206 seconds ---\n",
      "episode 2172, reward -146.0, memory_length 2000, epsilon 0.33756405300340836\n",
      "travel time- 720.0\n",
      "--- 1.5268938541412354 seconds ---\n",
      "episode 2173, reward 101.0, memory_length 2000, epsilon 0.33739531316538157\n",
      "travel time- 720.0\n",
      "--- 1.5454204082489014 seconds ---\n",
      "episode 2174, reward -201.0, memory_length 2000, epsilon 0.33722665767618487\n",
      "travel time- 723.0\n",
      "--- 1.7233507633209229 seconds ---\n",
      "episode 2175, reward -234.0, memory_length 2000, epsilon 0.33705808649365426\n",
      "travel time- 723.0\n",
      "--- 1.6531901359558105 seconds ---\n",
      "episode 2176, reward -14.0, memory_length 2000, epsilon 0.33688959957564707\n",
      "travel time- 720.0\n",
      "--- 1.531052827835083 seconds ---\n",
      "episode 2177, reward 5.0, memory_length 2000, epsilon 0.3367211968800416\n",
      "travel time- 721.0\n",
      "--- 1.6328136920928955 seconds ---\n",
      "episode 2178, reward -81.0, memory_length 2000, epsilon 0.336552878364737\n",
      "travel time- 720.0\n",
      "--- 1.542313575744629 seconds ---\n",
      "episode 2179, reward -28.0, memory_length 2000, epsilon 0.33638464398765383\n",
      "travel time- 726.0\n",
      "--- 1.7323706150054932 seconds ---\n",
      "episode 2180, reward 279.0, memory_length 2000, epsilon 0.33621649370673334\n",
      "travel time- 722.0\n",
      "--- 1.4866735935211182 seconds ---\n",
      "episode 2181, reward 154.0, memory_length 2000, epsilon 0.33604842747993807\n",
      "travel time- 724.0\n",
      "--- 1.6086273193359375 seconds ---\n",
      "episode 2182, reward -99.0, memory_length 2000, epsilon 0.3358804452652514\n",
      "travel time- 726.0\n",
      "--- 1.4965214729309082 seconds ---\n",
      "episode 2183, reward 100.0, memory_length 2000, epsilon 0.3357125470206778\n",
      "travel time- 736.0\n",
      "--- 1.596543550491333 seconds ---\n",
      "episode 2184, reward -304.0, memory_length 2000, epsilon 0.3355447327042427\n",
      "travel time- 720.0\n",
      "--- 1.6539225578308105 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2185, reward -232.0, memory_length 2000, epsilon 0.3353770022739925\n",
      "travel time- 721.0\n",
      "--- 1.6715550422668457 seconds ---\n",
      "episode 2186, reward 29.0, memory_length 2000, epsilon 0.33520935568799465\n",
      "travel time- 728.0\n",
      "--- 1.6840968132019043 seconds ---\n",
      "episode 2187, reward 54.0, memory_length 2000, epsilon 0.3350417929043375\n",
      "travel time- 722.0\n",
      "--- 1.9957332611083984 seconds ---\n",
      "episode 2188, reward -41.0, memory_length 2000, epsilon 0.3348743138811302\n",
      "travel time- 724.0\n",
      "--- 1.550480842590332 seconds ---\n",
      "episode 2189, reward 165.0, memory_length 2000, epsilon 0.3347069185765032\n",
      "travel time- 727.0\n",
      "--- 1.7607347965240479 seconds ---\n",
      "episode 2190, reward -298.0, memory_length 2000, epsilon 0.3345396069486076\n",
      "travel time- 720.0\n",
      "--- 1.57759690284729 seconds ---\n",
      "episode 2191, reward -296.0, memory_length 2000, epsilon 0.3343723789556155\n",
      "travel time- 724.0\n",
      "--- 1.6387808322906494 seconds ---\n",
      "episode 2192, reward 40.0, memory_length 2000, epsilon 0.33420523455571977\n",
      "travel time- 728.0\n",
      "--- 1.5681400299072266 seconds ---\n",
      "episode 2193, reward -61.0, memory_length 2000, epsilon 0.3340381737071345\n",
      "travel time- 720.0\n",
      "--- 1.6517770290374756 seconds ---\n",
      "episode 2194, reward -14.0, memory_length 2000, epsilon 0.3338711963680944\n",
      "travel time- 721.0\n",
      "--- 1.3995990753173828 seconds ---\n",
      "episode 2195, reward 64.0, memory_length 2000, epsilon 0.3337043024968552\n",
      "travel time- 723.0\n",
      "--- 1.5233230590820312 seconds ---\n",
      "episode 2196, reward 219.0, memory_length 2000, epsilon 0.3335374920516932\n",
      "travel time- 723.0\n",
      "--- 1.538559913635254 seconds ---\n",
      "episode 2197, reward 46.0, memory_length 2000, epsilon 0.33337076499090607\n",
      "travel time- 732.0\n",
      "--- 1.5650134086608887 seconds ---\n",
      "episode 2198, reward -21.0, memory_length 2000, epsilon 0.33320412127281185\n",
      "travel time- 724.0\n",
      "--- 1.5798442363739014 seconds ---\n",
      "episode 2199, reward 109.0, memory_length 2000, epsilon 0.33303756085574976\n",
      "travel time- 731.0\n",
      "--- 1.6251027584075928 seconds ---\n",
      "episode 2200, reward -69.0, memory_length 2000, epsilon 0.33287108369807955\n",
      "travel time- 725.0\n",
      "--- 1.6912009716033936 seconds ---\n",
      "episode 2201, reward -208.0, memory_length 2000, epsilon 0.332704689758182\n",
      "travel time- 734.0\n",
      "--- 1.6431910991668701 seconds ---\n",
      "episode 2202, reward 1.0, memory_length 2000, epsilon 0.3325383789944587\n",
      "travel time- 722.0\n",
      "--- 1.7219820022583008 seconds ---\n",
      "episode 2203, reward -74.0, memory_length 2000, epsilon 0.3323721513653318\n",
      "travel time- 725.0\n",
      "--- 1.8120734691619873 seconds ---\n",
      "episode 2204, reward -276.0, memory_length 2000, epsilon 0.33220600682924445\n",
      "travel time- 721.0\n",
      "--- 1.7815790176391602 seconds ---\n",
      "episode 2205, reward -13.0, memory_length 2000, epsilon 0.33203994534466064\n",
      "travel time- 725.0\n",
      "--- 1.6184918880462646 seconds ---\n",
      "episode 2206, reward 145.0, memory_length 2000, epsilon 0.3318739668700649\n",
      "travel time- 732.0\n",
      "--- 1.6840407848358154 seconds ---\n",
      "episode 2207, reward -518.0, memory_length 2000, epsilon 0.3317080713639625\n",
      "travel time- 727.0\n",
      "--- 2.086716413497925 seconds ---\n",
      "episode 2208, reward 107.0, memory_length 2000, epsilon 0.3315422587848797\n",
      "travel time- 721.0\n",
      "--- 1.700026273727417 seconds ---\n",
      "episode 2209, reward -109.0, memory_length 2000, epsilon 0.33137652909136334\n",
      "travel time- 724.0\n",
      "--- 1.6912424564361572 seconds ---\n",
      "episode 2210, reward -101.0, memory_length 2000, epsilon 0.331210882241981\n",
      "travel time- 721.0\n",
      "--- 1.518301010131836 seconds ---\n",
      "episode 2211, reward 43.0, memory_length 2000, epsilon 0.33104531819532096\n",
      "travel time- 726.0\n",
      "--- 1.7324202060699463 seconds ---\n",
      "episode 2212, reward 16.0, memory_length 2000, epsilon 0.33087983690999206\n",
      "travel time- 724.0\n",
      "--- 1.5577714443206787 seconds ---\n",
      "episode 2213, reward -234.0, memory_length 2000, epsilon 0.3307144383446243\n",
      "travel time- 724.0\n",
      "--- 1.93646240234375 seconds ---\n",
      "episode 2214, reward -166.0, memory_length 2000, epsilon 0.3305491224578677\n",
      "travel time- 728.0\n",
      "--- 1.5071651935577393 seconds ---\n",
      "episode 2215, reward -129.0, memory_length 2000, epsilon 0.33038388920839357\n",
      "travel time- 720.0\n",
      "--- 1.7572307586669922 seconds ---\n",
      "episode 2216, reward -80.0, memory_length 2000, epsilon 0.3302187385548933\n",
      "travel time- 728.0\n",
      "--- 1.6221022605895996 seconds ---\n",
      "episode 2217, reward 125.0, memory_length 2000, epsilon 0.3300536704560795\n",
      "travel time- 729.0\n",
      "--- 1.5530931949615479 seconds ---\n",
      "episode 2218, reward -89.0, memory_length 2000, epsilon 0.329888684870685\n",
      "travel time- 732.0\n",
      "--- 1.6499931812286377 seconds ---\n",
      "episode 2219, reward -90.0, memory_length 2000, epsilon 0.3297237817574635\n",
      "travel time- 726.0\n",
      "--- 1.6976158618927002 seconds ---\n",
      "episode 2220, reward 12.0, memory_length 2000, epsilon 0.32955896107518906\n",
      "travel time- 725.0\n",
      "--- 1.741955041885376 seconds ---\n",
      "episode 2221, reward -140.0, memory_length 2000, epsilon 0.3293942227826566\n",
      "travel time- 727.0\n",
      "--- 1.6833343505859375 seconds ---\n",
      "episode 2222, reward -286.0, memory_length 2000, epsilon 0.32922956683868165\n",
      "travel time- 723.0\n",
      "--- 1.591045618057251 seconds ---\n",
      "episode 2223, reward -306.0, memory_length 2000, epsilon 0.3290649932021001\n",
      "travel time- 722.0\n",
      "--- 1.8662230968475342 seconds ---\n",
      "episode 2224, reward -290.0, memory_length 2000, epsilon 0.3289005018317685\n",
      "travel time- 723.0\n",
      "--- 1.7107553482055664 seconds ---\n",
      "episode 2225, reward -235.0, memory_length 2000, epsilon 0.3287360926865641\n",
      "travel time- 733.0\n",
      "--- 1.8188502788543701 seconds ---\n",
      "episode 2226, reward 100.0, memory_length 2000, epsilon 0.3285717657253846\n",
      "travel time- 721.0\n",
      "--- 1.5550153255462646 seconds ---\n",
      "episode 2227, reward 187.0, memory_length 2000, epsilon 0.32840752090714825\n",
      "travel time- 727.0\n",
      "--- 1.61720609664917 seconds ---\n",
      "episode 2228, reward -229.0, memory_length 2000, epsilon 0.32824335819079375\n",
      "travel time- 723.0\n",
      "--- 1.6217405796051025 seconds ---\n",
      "episode 2229, reward -141.0, memory_length 2000, epsilon 0.3280792775352806\n",
      "travel time- 727.0\n",
      "--- 1.5531272888183594 seconds ---\n",
      "episode 2230, reward 91.0, memory_length 2000, epsilon 0.32791527889958855\n",
      "travel time- 721.0\n",
      "--- 1.7026875019073486 seconds ---\n",
      "episode 2231, reward 196.0, memory_length 2000, epsilon 0.32775136224271795\n",
      "travel time- 723.0\n",
      "--- 1.6465816497802734 seconds ---\n",
      "episode 2232, reward 79.0, memory_length 2000, epsilon 0.3275875275236895\n",
      "travel time- 722.0\n",
      "--- 1.5321006774902344 seconds ---\n",
      "episode 2233, reward 41.0, memory_length 2000, epsilon 0.3274237747015447\n",
      "travel time- 725.0\n",
      "--- 1.6891875267028809 seconds ---\n",
      "episode 2234, reward 248.0, memory_length 2000, epsilon 0.3272601037353453\n",
      "travel time- 726.0\n",
      "--- 1.727778673171997 seconds ---\n",
      "episode 2235, reward 112.0, memory_length 2000, epsilon 0.3270965145841736\n",
      "travel time- 720.0\n",
      "--- 1.6285319328308105 seconds ---\n",
      "episode 2236, reward 93.0, memory_length 2000, epsilon 0.3269330072071321\n",
      "travel time- 722.0\n",
      "--- 1.8072874546051025 seconds ---\n",
      "episode 2237, reward 12.0, memory_length 2000, epsilon 0.3267695815633442\n",
      "travel time- 727.0\n",
      "--- 1.6407294273376465 seconds ---\n",
      "episode 2238, reward -168.0, memory_length 2000, epsilon 0.3266062376119534\n",
      "travel time- 723.0\n",
      "--- 1.7449114322662354 seconds ---\n",
      "episode 2239, reward -326.0, memory_length 2000, epsilon 0.3264429753121237\n",
      "travel time- 723.0\n",
      "--- 1.7944047451019287 seconds ---\n",
      "episode 2240, reward -146.0, memory_length 2000, epsilon 0.32627979462303947\n",
      "travel time- 725.0\n",
      "--- 1.428767204284668 seconds ---\n",
      "episode 2241, reward -76.0, memory_length 2000, epsilon 0.32611669550390565\n",
      "travel time- 725.0\n",
      "--- 1.6609981060028076 seconds ---\n",
      "episode 2242, reward -107.0, memory_length 2000, epsilon 0.32595367791394736\n",
      "travel time- 720.0\n",
      "--- 1.7031807899475098 seconds ---\n",
      "episode 2243, reward -34.0, memory_length 2000, epsilon 0.3257907418124103\n",
      "travel time- 721.0\n",
      "--- 1.545961618423462 seconds ---\n",
      "episode 2244, reward 129.0, memory_length 2000, epsilon 0.32562788715856034\n",
      "travel time- 727.0\n",
      "--- 1.5136358737945557 seconds ---\n",
      "episode 2245, reward -50.0, memory_length 2000, epsilon 0.32546511391168387\n",
      "travel time- 727.0\n",
      "--- 1.7874102592468262 seconds ---\n",
      "episode 2246, reward 160.0, memory_length 2000, epsilon 0.3253024220310876\n",
      "travel time- 722.0\n",
      "--- 1.6702923774719238 seconds ---\n",
      "episode 2247, reward 257.0, memory_length 2000, epsilon 0.32513981147609855\n",
      "travel time- 726.0\n",
      "--- 1.732520580291748 seconds ---\n",
      "episode 2248, reward 228.0, memory_length 2000, epsilon 0.324977282206064\n",
      "travel time- 723.0\n",
      "--- 1.706885814666748 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2249, reward 17.0, memory_length 2000, epsilon 0.32481483418035173\n",
      "travel time- 725.0\n",
      "--- 1.5230817794799805 seconds ---\n",
      "episode 2250, reward -215.0, memory_length 2000, epsilon 0.32465246735834974\n",
      "travel time- 721.0\n",
      "--- 1.5817921161651611 seconds ---\n",
      "episode 2251, reward -70.0, memory_length 2000, epsilon 0.32449018169946625\n",
      "travel time- 724.0\n",
      "--- 1.5966582298278809 seconds ---\n",
      "episode 2252, reward 112.0, memory_length 2000, epsilon 0.3243279771631298\n",
      "travel time- 720.0\n",
      "--- 1.787792444229126 seconds ---\n",
      "episode 2253, reward -22.0, memory_length 2000, epsilon 0.3241658537087894\n",
      "travel time- 726.0\n",
      "--- 1.605889081954956 seconds ---\n",
      "episode 2254, reward -161.0, memory_length 2000, epsilon 0.32400381129591416\n",
      "travel time- 730.0\n",
      "--- 1.6770572662353516 seconds ---\n",
      "episode 2255, reward 28.0, memory_length 2000, epsilon 0.3238418498839934\n",
      "travel time- 729.0\n",
      "--- 1.7132165431976318 seconds ---\n",
      "episode 2256, reward -90.0, memory_length 2000, epsilon 0.3236799694325367\n",
      "travel time- 721.0\n",
      "--- 1.6671864986419678 seconds ---\n",
      "episode 2257, reward -357.0, memory_length 2000, epsilon 0.3235181699010741\n",
      "travel time- 725.0\n",
      "--- 1.781580924987793 seconds ---\n",
      "episode 2258, reward -437.0, memory_length 2000, epsilon 0.32335645124915574\n",
      "travel time- 720.0\n",
      "--- 1.6535112857818604 seconds ---\n",
      "episode 2259, reward -36.0, memory_length 2000, epsilon 0.3231948134363518\n",
      "travel time- 721.0\n",
      "--- 1.6394846439361572 seconds ---\n",
      "episode 2260, reward 44.0, memory_length 2000, epsilon 0.3230332564222529\n",
      "travel time- 721.0\n",
      "--- 1.554291009902954 seconds ---\n",
      "episode 2261, reward -147.0, memory_length 2000, epsilon 0.32287178016646984\n",
      "travel time- 730.0\n",
      "--- 1.809873342514038 seconds ---\n",
      "episode 2262, reward -23.0, memory_length 2000, epsilon 0.3227103846286335\n",
      "travel time- 720.0\n",
      "--- 1.6885874271392822 seconds ---\n",
      "episode 2263, reward 110.0, memory_length 2000, epsilon 0.322549069768395\n",
      "travel time- 725.0\n",
      "--- 1.5095152854919434 seconds ---\n",
      "episode 2264, reward -291.0, memory_length 2000, epsilon 0.3223878355454255\n",
      "travel time- 720.0\n",
      "--- 1.5974187850952148 seconds ---\n",
      "episode 2265, reward -203.0, memory_length 2000, epsilon 0.32222668191941667\n",
      "travel time- 722.0\n",
      "--- 1.5627837181091309 seconds ---\n",
      "episode 2266, reward -18.0, memory_length 2000, epsilon 0.32206560885008\n",
      "travel time- 724.0\n",
      "--- 1.5644164085388184 seconds ---\n",
      "episode 2267, reward -45.0, memory_length 2000, epsilon 0.32190461629714723\n",
      "travel time- 722.0\n",
      "--- 1.7138915061950684 seconds ---\n",
      "episode 2268, reward -142.0, memory_length 2000, epsilon 0.32174370422037013\n",
      "travel time- 720.0\n",
      "--- 1.5838541984558105 seconds ---\n",
      "episode 2269, reward -17.0, memory_length 2000, epsilon 0.32158287257952084\n",
      "travel time- 726.0\n",
      "--- 1.7036566734313965 seconds ---\n",
      "episode 2270, reward 97.0, memory_length 2000, epsilon 0.32142212133439135\n",
      "travel time- 730.0\n",
      "--- 1.670698642730713 seconds ---\n",
      "episode 2271, reward -4.0, memory_length 2000, epsilon 0.3212614504447939\n",
      "travel time- 722.0\n",
      "--- 1.5799577236175537 seconds ---\n",
      "episode 2272, reward -64.0, memory_length 2000, epsilon 0.32110085987056064\n",
      "travel time- 728.0\n",
      "--- 1.8767595291137695 seconds ---\n",
      "episode 2273, reward -125.0, memory_length 2000, epsilon 0.3209403495715441\n",
      "travel time- 722.0\n",
      "--- 1.8605079650878906 seconds ---\n",
      "episode 2274, reward 89.0, memory_length 2000, epsilon 0.3207799195076166\n",
      "travel time- 722.0\n",
      "--- 1.7798998355865479 seconds ---\n",
      "episode 2275, reward -170.0, memory_length 2000, epsilon 0.32061956963867067\n",
      "travel time- 720.0\n",
      "--- 1.6757748126983643 seconds ---\n",
      "episode 2276, reward -170.0, memory_length 2000, epsilon 0.32045929992461875\n",
      "travel time- 721.0\n",
      "--- 1.6359241008758545 seconds ---\n",
      "episode 2277, reward -189.0, memory_length 2000, epsilon 0.32029911032539354\n",
      "travel time- 721.0\n",
      "--- 1.8657793998718262 seconds ---\n",
      "episode 2278, reward 20.0, memory_length 2000, epsilon 0.3201390008009476\n",
      "travel time- 727.0\n",
      "--- 1.6047794818878174 seconds ---\n",
      "episode 2279, reward -63.0, memory_length 2000, epsilon 0.3199789713112535\n",
      "travel time- 727.0\n",
      "--- 1.6566228866577148 seconds ---\n",
      "episode 2280, reward -58.0, memory_length 2000, epsilon 0.31981902181630384\n",
      "travel time- 722.0\n",
      "--- 1.4914665222167969 seconds ---\n",
      "episode 2281, reward -177.0, memory_length 2000, epsilon 0.31965915227611136\n",
      "travel time- 725.0\n",
      "--- 1.7570953369140625 seconds ---\n",
      "episode 2282, reward 334.0, memory_length 2000, epsilon 0.31949936265070866\n",
      "travel time- 724.0\n",
      "--- 1.4878556728363037 seconds ---\n",
      "episode 2283, reward 33.0, memory_length 2000, epsilon 0.3193396529001482\n",
      "travel time- 720.0\n",
      "--- 1.5199058055877686 seconds ---\n",
      "episode 2284, reward 177.0, memory_length 2000, epsilon 0.31918002298450265\n",
      "travel time- 720.0\n",
      "--- 1.600541591644287 seconds ---\n",
      "episode 2285, reward -246.0, memory_length 2000, epsilon 0.31902047286386453\n",
      "travel time- 726.0\n",
      "--- 1.5748612880706787 seconds ---\n",
      "episode 2286, reward 164.0, memory_length 2000, epsilon 0.3188610024983463\n",
      "travel time- 722.0\n",
      "--- 1.5389204025268555 seconds ---\n",
      "episode 2287, reward -157.0, memory_length 2000, epsilon 0.3187016118480803\n",
      "travel time- 720.0\n",
      "--- 1.5162546634674072 seconds ---\n",
      "episode 2288, reward -132.0, memory_length 2000, epsilon 0.31854230087321894\n",
      "travel time- 720.0\n",
      "--- 1.8188588619232178 seconds ---\n",
      "episode 2289, reward 58.0, memory_length 2000, epsilon 0.31838306953393447\n",
      "travel time- 726.0\n",
      "--- 1.6452155113220215 seconds ---\n",
      "episode 2290, reward 490.0, memory_length 2000, epsilon 0.3182239177904191\n",
      "travel time- 728.0\n",
      "--- 1.5907340049743652 seconds ---\n",
      "episode 2291, reward -115.0, memory_length 2000, epsilon 0.3180648456028848\n",
      "travel time- 723.0\n",
      "--- 1.4750287532806396 seconds ---\n",
      "episode 2292, reward 221.0, memory_length 2000, epsilon 0.3179058529315635\n",
      "travel time- 723.0\n",
      "--- 1.522728443145752 seconds ---\n",
      "episode 2293, reward 106.0, memory_length 2000, epsilon 0.3177469397367071\n",
      "travel time- 720.0\n",
      "--- 1.8246543407440186 seconds ---\n",
      "episode 2294, reward -295.0, memory_length 2000, epsilon 0.31758810597858733\n",
      "travel time- 721.0\n",
      "--- 1.7740318775177002 seconds ---\n",
      "episode 2295, reward 176.0, memory_length 2000, epsilon 0.3174293516174957\n",
      "travel time- 729.0\n",
      "--- 1.5768976211547852 seconds ---\n",
      "episode 2296, reward -187.0, memory_length 2000, epsilon 0.3172706766137436\n",
      "travel time- 724.0\n",
      "--- 1.4668703079223633 seconds ---\n",
      "episode 2297, reward -142.0, memory_length 2000, epsilon 0.3171120809276623\n",
      "travel time- 722.0\n",
      "--- 1.6603004932403564 seconds ---\n",
      "episode 2298, reward 88.0, memory_length 2000, epsilon 0.31695356451960294\n",
      "travel time- 724.0\n",
      "--- 1.3992552757263184 seconds ---\n",
      "episode 2299, reward 7.0, memory_length 2000, epsilon 0.31679512734993637\n",
      "travel time- 727.0\n",
      "--- 1.5513041019439697 seconds ---\n",
      "episode 2300, reward -277.0, memory_length 2000, epsilon 0.31663676937905316\n",
      "travel time- 723.0\n",
      "--- 1.5619747638702393 seconds ---\n",
      "episode 2301, reward 29.0, memory_length 2000, epsilon 0.31647849056736405\n",
      "travel time- 723.0\n",
      "--- 1.423529863357544 seconds ---\n",
      "episode 2302, reward -12.0, memory_length 2000, epsilon 0.3163202908752992\n",
      "travel time- 724.0\n",
      "--- 1.550110101699829 seconds ---\n",
      "episode 2303, reward 151.0, memory_length 2000, epsilon 0.3161621702633088\n",
      "travel time- 722.0\n",
      "--- 1.6320300102233887 seconds ---\n",
      "episode 2304, reward 70.0, memory_length 2000, epsilon 0.31600412869186245\n",
      "travel time- 725.0\n",
      "--- 1.6914644241333008 seconds ---\n",
      "episode 2305, reward -381.0, memory_length 2000, epsilon 0.31584616612145006\n",
      "travel time- 728.0\n",
      "--- 1.8152446746826172 seconds ---\n",
      "episode 2306, reward -69.0, memory_length 2000, epsilon 0.3156882825125808\n",
      "travel time- 724.0\n",
      "--- 1.8384320735931396 seconds ---\n",
      "episode 2307, reward 43.0, memory_length 2000, epsilon 0.3155304778257838\n",
      "travel time- 720.0\n",
      "--- 1.7457377910614014 seconds ---\n",
      "episode 2308, reward -277.0, memory_length 2000, epsilon 0.31537275202160797\n",
      "travel time- 724.0\n",
      "--- 1.752837896347046 seconds ---\n",
      "episode 2309, reward 191.0, memory_length 2000, epsilon 0.31521510506062167\n",
      "travel time- 720.0\n",
      "--- 1.5836448669433594 seconds ---\n",
      "episode 2310, reward 130.0, memory_length 2000, epsilon 0.3150575369034133\n",
      "travel time- 721.0\n",
      "--- 1.2782878875732422 seconds ---\n",
      "episode 2311, reward -30.0, memory_length 2000, epsilon 0.31490004751059086\n",
      "travel time- 727.0\n",
      "--- 1.698122262954712 seconds ---\n",
      "episode 2312, reward -222.0, memory_length 2000, epsilon 0.3147426368427819\n",
      "travel time- 724.0\n",
      "--- 1.6137475967407227 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2313, reward 139.0, memory_length 2000, epsilon 0.3145853048606338\n",
      "travel time- 724.0\n",
      "--- 1.7077088356018066 seconds ---\n",
      "episode 2314, reward -79.0, memory_length 2000, epsilon 0.31442805152481357\n",
      "travel time- 728.0\n",
      "--- 1.6610262393951416 seconds ---\n",
      "episode 2315, reward -457.0, memory_length 2000, epsilon 0.31427087679600785\n",
      "travel time- 722.0\n",
      "--- 1.477473497390747 seconds ---\n",
      "episode 2316, reward -244.0, memory_length 2000, epsilon 0.31411378063492296\n",
      "travel time- 720.0\n",
      "--- 1.8875088691711426 seconds ---\n",
      "episode 2317, reward 139.0, memory_length 2000, epsilon 0.3139567630022848\n",
      "travel time- 720.0\n",
      "--- 1.7052476406097412 seconds ---\n",
      "episode 2318, reward 22.0, memory_length 2000, epsilon 0.3137998238588391\n",
      "travel time- 722.0\n",
      "--- 1.5661900043487549 seconds ---\n",
      "episode 2319, reward 178.0, memory_length 2000, epsilon 0.313642963165351\n",
      "travel time- 720.0\n",
      "--- 1.6712241172790527 seconds ---\n",
      "episode 2320, reward 143.0, memory_length 2000, epsilon 0.3134861808826053\n",
      "travel time- 721.0\n",
      "--- 1.722830057144165 seconds ---\n",
      "episode 2321, reward 56.0, memory_length 2000, epsilon 0.31332947697140645\n",
      "travel time- 726.0\n",
      "--- 1.5480070114135742 seconds ---\n",
      "episode 2322, reward -50.0, memory_length 2000, epsilon 0.3131728513925785\n",
      "travel time- 725.0\n",
      "--- 1.6173815727233887 seconds ---\n",
      "episode 2323, reward -191.0, memory_length 2000, epsilon 0.313016304106965\n",
      "travel time- 727.0\n",
      "--- 1.5836875438690186 seconds ---\n",
      "episode 2324, reward -259.0, memory_length 2000, epsilon 0.3128598350754292\n",
      "travel time- 734.0\n",
      "--- 1.5229573249816895 seconds ---\n",
      "episode 2325, reward 79.0, memory_length 2000, epsilon 0.3127034442588537\n",
      "travel time- 725.0\n",
      "--- 1.7693967819213867 seconds ---\n",
      "episode 2326, reward -110.0, memory_length 2000, epsilon 0.312547131618141\n",
      "travel time- 720.0\n",
      "--- 1.6601080894470215 seconds ---\n",
      "episode 2327, reward 328.0, memory_length 2000, epsilon 0.3123908971142128\n",
      "travel time- 726.0\n",
      "--- 1.5228996276855469 seconds ---\n",
      "episode 2328, reward -448.0, memory_length 2000, epsilon 0.31223474070801055\n",
      "travel time- 724.0\n",
      "--- 1.6784133911132812 seconds ---\n",
      "episode 2329, reward -195.0, memory_length 2000, epsilon 0.31207866236049503\n",
      "travel time- 725.0\n",
      "--- 1.5932106971740723 seconds ---\n",
      "episode 2330, reward -186.0, memory_length 2000, epsilon 0.31192266203264674\n",
      "travel time- 725.0\n",
      "--- 1.5292775630950928 seconds ---\n",
      "episode 2331, reward 193.0, memory_length 2000, epsilon 0.3117667396854656\n",
      "travel time- 724.0\n",
      "--- 1.517401933670044 seconds ---\n",
      "episode 2332, reward 337.0, memory_length 2000, epsilon 0.31161089527997105\n",
      "travel time- 723.0\n",
      "--- 1.7474143505096436 seconds ---\n",
      "episode 2333, reward 118.0, memory_length 2000, epsilon 0.31145512877720183\n",
      "travel time- 723.0\n",
      "--- 1.1705567836761475 seconds ---\n",
      "episode 2334, reward -231.0, memory_length 2000, epsilon 0.3112994401382165\n",
      "travel time- 720.0\n",
      "--- 1.613487958908081 seconds ---\n",
      "episode 2335, reward 190.0, memory_length 2000, epsilon 0.31114382932409285\n",
      "travel time- 721.0\n",
      "--- 1.4544439315795898 seconds ---\n",
      "episode 2336, reward -151.0, memory_length 2000, epsilon 0.3109882962959281\n",
      "travel time- 724.0\n",
      "--- 1.4867546558380127 seconds ---\n",
      "episode 2337, reward 130.0, memory_length 2000, epsilon 0.31083284101483905\n",
      "travel time- 726.0\n",
      "--- 1.6574077606201172 seconds ---\n",
      "episode 2338, reward -502.0, memory_length 2000, epsilon 0.31067746344196184\n",
      "travel time- 731.0\n",
      "--- 1.8622803688049316 seconds ---\n",
      "episode 2339, reward -234.0, memory_length 2000, epsilon 0.3105221635384522\n",
      "travel time- 728.0\n",
      "--- 1.8608624935150146 seconds ---\n",
      "episode 2340, reward -214.0, memory_length 2000, epsilon 0.31036694126548503\n",
      "travel time- 727.0\n",
      "--- 1.6040663719177246 seconds ---\n",
      "episode 2341, reward 61.0, memory_length 2000, epsilon 0.31021179658425474\n",
      "travel time- 724.0\n",
      "--- 1.4968693256378174 seconds ---\n",
      "episode 2342, reward -8.0, memory_length 2000, epsilon 0.31005672945597523\n",
      "travel time- 736.0\n",
      "--- 1.4823527336120605 seconds ---\n",
      "episode 2343, reward -209.0, memory_length 2000, epsilon 0.30990173984187974\n",
      "travel time- 721.0\n",
      "--- 1.459120273590088 seconds ---\n",
      "episode 2344, reward -141.0, memory_length 2000, epsilon 0.3097468277032208\n",
      "travel time- 723.0\n",
      "--- 1.470627784729004 seconds ---\n",
      "episode 2345, reward 21.0, memory_length 2000, epsilon 0.3095919930012704\n",
      "travel time- 721.0\n",
      "--- 1.6228270530700684 seconds ---\n",
      "episode 2346, reward -189.0, memory_length 2000, epsilon 0.30943723569731985\n",
      "travel time- 727.0\n",
      "--- 1.6066162586212158 seconds ---\n",
      "episode 2347, reward 18.0, memory_length 2000, epsilon 0.3092825557526799\n",
      "travel time- 724.0\n",
      "--- 1.6126363277435303 seconds ---\n",
      "episode 2348, reward 240.0, memory_length 2000, epsilon 0.3091279531286804\n",
      "travel time- 724.0\n",
      "--- 1.4926249980926514 seconds ---\n",
      "episode 2349, reward 31.0, memory_length 2000, epsilon 0.3089734277866708\n",
      "travel time- 720.0\n",
      "--- 1.5672314167022705 seconds ---\n",
      "episode 2350, reward -95.0, memory_length 2000, epsilon 0.30881897968801986\n",
      "travel time- 725.0\n",
      "--- 1.9150128364562988 seconds ---\n",
      "episode 2351, reward 13.0, memory_length 2000, epsilon 0.3086646087941154\n",
      "travel time- 732.0\n",
      "--- 1.6798450946807861 seconds ---\n",
      "episode 2352, reward 6.0, memory_length 2000, epsilon 0.3085103150663647\n",
      "travel time- 724.0\n",
      "--- 1.5985326766967773 seconds ---\n",
      "episode 2353, reward 285.0, memory_length 2000, epsilon 0.3083560984661944\n",
      "travel time- 723.0\n",
      "--- 1.4511661529541016 seconds ---\n",
      "episode 2354, reward -21.0, memory_length 2000, epsilon 0.3082019589550503\n",
      "travel time- 722.0\n",
      "--- 1.711913824081421 seconds ---\n",
      "episode 2355, reward 45.0, memory_length 2000, epsilon 0.3080478964943976\n",
      "travel time- 727.0\n",
      "--- 1.5461742877960205 seconds ---\n",
      "episode 2356, reward -39.0, memory_length 2000, epsilon 0.3078939110457206\n",
      "travel time- 726.0\n",
      "--- 1.621994972229004 seconds ---\n",
      "episode 2357, reward 221.0, memory_length 2000, epsilon 0.307740002570523\n",
      "travel time- 729.0\n",
      "--- 1.7015535831451416 seconds ---\n",
      "episode 2358, reward -42.0, memory_length 2000, epsilon 0.3075861710303276\n",
      "travel time- 722.0\n",
      "--- 1.750063180923462 seconds ---\n",
      "episode 2359, reward 255.0, memory_length 2000, epsilon 0.30743241638667657\n",
      "travel time- 722.0\n",
      "--- 1.4652037620544434 seconds ---\n",
      "episode 2360, reward 72.0, memory_length 2000, epsilon 0.30727873860113125\n",
      "travel time- 720.0\n",
      "--- 1.7067177295684814 seconds ---\n",
      "episode 2361, reward 164.0, memory_length 2000, epsilon 0.3071251376352721\n",
      "travel time- 723.0\n",
      "--- 1.3863582611083984 seconds ---\n",
      "episode 2362, reward 315.0, memory_length 2000, epsilon 0.30697161345069907\n",
      "travel time- 721.0\n",
      "--- 1.4636955261230469 seconds ---\n",
      "episode 2363, reward -109.0, memory_length 2000, epsilon 0.306818166009031\n",
      "travel time- 734.0\n",
      "--- 1.4348630905151367 seconds ---\n",
      "episode 2364, reward 3.0, memory_length 2000, epsilon 0.306664795271906\n",
      "travel time- 721.0\n",
      "--- 1.777817964553833 seconds ---\n",
      "episode 2365, reward -180.0, memory_length 2000, epsilon 0.3065115012009813\n",
      "travel time- 728.0\n",
      "--- 1.798708200454712 seconds ---\n",
      "episode 2366, reward -90.0, memory_length 2000, epsilon 0.30635828375793367\n",
      "travel time- 720.0\n",
      "--- 1.6404836177825928 seconds ---\n",
      "episode 2367, reward 294.0, memory_length 2000, epsilon 0.3062051429044585\n",
      "travel time- 722.0\n",
      "--- 1.48685622215271 seconds ---\n",
      "episode 2368, reward -181.0, memory_length 2000, epsilon 0.3060520786022707\n",
      "travel time- 721.0\n",
      "--- 1.5953283309936523 seconds ---\n",
      "episode 2369, reward -44.0, memory_length 2000, epsilon 0.305899090813104\n",
      "travel time- 728.0\n",
      "--- 1.569580316543579 seconds ---\n",
      "episode 2370, reward -175.0, memory_length 2000, epsilon 0.30574617949871175\n",
      "travel time- 722.0\n",
      "--- 1.4301950931549072 seconds ---\n",
      "episode 2371, reward 160.0, memory_length 2000, epsilon 0.3055933446208659\n",
      "travel time- 721.0\n",
      "--- 1.6127183437347412 seconds ---\n",
      "episode 2372, reward -170.0, memory_length 2000, epsilon 0.3054405861413579\n",
      "travel time- 725.0\n",
      "--- 1.7639338970184326 seconds ---\n",
      "episode 2373, reward -205.0, memory_length 2000, epsilon 0.30528790402199785\n",
      "travel time- 725.0\n",
      "--- 1.6087734699249268 seconds ---\n",
      "episode 2374, reward 12.0, memory_length 2000, epsilon 0.3051352982246155\n",
      "travel time- 737.0\n",
      "--- 1.514111042022705 seconds ---\n",
      "episode 2375, reward 0.0, memory_length 2000, epsilon 0.3049827687110593\n",
      "travel time- 725.0\n",
      "--- 1.725973129272461 seconds ---\n",
      "episode 2376, reward 40.0, memory_length 2000, epsilon 0.30483031544319683\n",
      "travel time- 726.0\n",
      "--- 1.6161818504333496 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2377, reward 142.0, memory_length 2000, epsilon 0.3046779383829148\n",
      "travel time- 723.0\n",
      "--- 1.6055655479431152 seconds ---\n",
      "episode 2378, reward 9.0, memory_length 2000, epsilon 0.304525637492119\n",
      "travel time- 732.0\n",
      "--- 1.6804089546203613 seconds ---\n",
      "episode 2379, reward 369.0, memory_length 2000, epsilon 0.30437341273273416\n",
      "travel time- 720.0\n",
      "--- 1.6693017482757568 seconds ---\n",
      "episode 2380, reward -108.0, memory_length 2000, epsilon 0.3042212640667041\n",
      "travel time- 731.0\n",
      "--- 1.673870325088501 seconds ---\n",
      "episode 2381, reward -241.0, memory_length 2000, epsilon 0.30406919145599154\n",
      "travel time- 720.0\n",
      "--- 1.6953167915344238 seconds ---\n",
      "episode 2382, reward 91.0, memory_length 2000, epsilon 0.3039171948625785\n",
      "travel time- 721.0\n",
      "--- 1.537430763244629 seconds ---\n",
      "episode 2383, reward -26.0, memory_length 2000, epsilon 0.3037652742484658\n",
      "travel time- 720.0\n",
      "--- 1.600062370300293 seconds ---\n",
      "episode 2384, reward -326.0, memory_length 2000, epsilon 0.30361342957567317\n",
      "travel time- 725.0\n",
      "--- 1.853687047958374 seconds ---\n",
      "episode 2385, reward -13.0, memory_length 2000, epsilon 0.3034616608062395\n",
      "travel time- 721.0\n",
      "--- 1.5490517616271973 seconds ---\n",
      "episode 2386, reward -288.0, memory_length 2000, epsilon 0.30330996790222264\n",
      "travel time- 722.0\n",
      "--- 1.5844743251800537 seconds ---\n",
      "episode 2387, reward -280.0, memory_length 2000, epsilon 0.30315835082569936\n",
      "travel time- 733.0\n",
      "--- 1.4606091976165771 seconds ---\n",
      "episode 2388, reward 24.0, memory_length 2000, epsilon 0.3030068095387654\n",
      "travel time- 724.0\n",
      "--- 1.4811451435089111 seconds ---\n",
      "episode 2389, reward 68.0, memory_length 2000, epsilon 0.3028553440035353\n",
      "travel time- 732.0\n",
      "--- 1.557530403137207 seconds ---\n",
      "episode 2390, reward -146.0, memory_length 2000, epsilon 0.30270395418214285\n",
      "travel time- 728.0\n",
      "--- 1.587838888168335 seconds ---\n",
      "episode 2391, reward -52.0, memory_length 2000, epsilon 0.30255264003674054\n",
      "travel time- 726.0\n",
      "--- 1.687614917755127 seconds ---\n",
      "episode 2392, reward -125.0, memory_length 2000, epsilon 0.3024014015294998\n",
      "travel time- 721.0\n",
      "--- 1.4728410243988037 seconds ---\n",
      "episode 2393, reward -362.0, memory_length 2000, epsilon 0.3022502386226109\n",
      "travel time- 722.0\n",
      "--- 1.7088367938995361 seconds ---\n",
      "episode 2394, reward -483.0, memory_length 2000, epsilon 0.3020991512782834\n",
      "travel time- 720.0\n",
      "--- 1.7213785648345947 seconds ---\n",
      "episode 2395, reward 162.0, memory_length 2000, epsilon 0.3019481394587452\n",
      "travel time- 725.0\n",
      "--- 1.4152796268463135 seconds ---\n",
      "episode 2396, reward 11.0, memory_length 2000, epsilon 0.3017972031262435\n",
      "travel time- 725.0\n",
      "--- 1.4980485439300537 seconds ---\n",
      "episode 2397, reward -74.0, memory_length 2000, epsilon 0.30164634224304404\n",
      "travel time- 731.0\n",
      "--- 1.6045351028442383 seconds ---\n",
      "episode 2398, reward -29.0, memory_length 2000, epsilon 0.3014955567714318\n",
      "travel time- 721.0\n",
      "--- 1.5633420944213867 seconds ---\n",
      "episode 2399, reward -309.0, memory_length 2000, epsilon 0.30134484667371036\n",
      "travel time- 720.0\n",
      "--- 1.6029736995697021 seconds ---\n",
      "episode 2400, reward -156.0, memory_length 2000, epsilon 0.30119421191220214\n",
      "travel time- 720.0\n",
      "--- 1.7902107238769531 seconds ---\n",
      "episode 2401, reward -150.0, memory_length 2000, epsilon 0.30104365244924836\n",
      "travel time- 724.0\n",
      "--- 1.561091661453247 seconds ---\n",
      "episode 2402, reward -135.0, memory_length 2000, epsilon 0.30089316824720935\n",
      "travel time- 726.0\n",
      "--- 1.391829490661621 seconds ---\n",
      "episode 2403, reward -182.0, memory_length 2000, epsilon 0.30074275926846394\n",
      "travel time- 721.0\n",
      "--- 1.5856728553771973 seconds ---\n",
      "episode 2404, reward 94.0, memory_length 2000, epsilon 0.30059242547541\n",
      "travel time- 727.0\n",
      "--- 1.468113899230957 seconds ---\n",
      "episode 2405, reward 192.0, memory_length 2000, epsilon 0.3004421668304638\n",
      "travel time- 731.0\n",
      "--- 1.651831865310669 seconds ---\n",
      "episode 2406, reward -83.0, memory_length 2000, epsilon 0.30029198329606105\n",
      "travel time- 723.0\n",
      "--- 1.5271546840667725 seconds ---\n",
      "episode 2407, reward -146.0, memory_length 2000, epsilon 0.30014187483465565\n",
      "travel time- 721.0\n",
      "--- 1.6767597198486328 seconds ---\n",
      "episode 2408, reward -221.0, memory_length 2000, epsilon 0.2999918414087205\n",
      "travel time- 720.0\n",
      "--- 1.5007874965667725 seconds ---\n",
      "episode 2409, reward -47.0, memory_length 2000, epsilon 0.2998418829807472\n",
      "travel time- 720.0\n",
      "--- 1.5764195919036865 seconds ---\n",
      "episode 2410, reward 18.0, memory_length 2000, epsilon 0.2996919995132463\n",
      "travel time- 722.0\n",
      "--- 1.5425689220428467 seconds ---\n",
      "episode 2411, reward -69.0, memory_length 2000, epsilon 0.29954219096874685\n",
      "travel time- 730.0\n",
      "--- 1.6180942058563232 seconds ---\n",
      "episode 2412, reward -149.0, memory_length 2000, epsilon 0.2993924573097967\n",
      "travel time- 731.0\n",
      "--- 1.3779916763305664 seconds ---\n",
      "episode 2413, reward 5.0, memory_length 2000, epsilon 0.29924279849896235\n",
      "travel time- 722.0\n",
      "--- 1.5836327075958252 seconds ---\n",
      "episode 2414, reward 122.0, memory_length 2000, epsilon 0.29909321449882925\n",
      "travel time- 722.0\n",
      "--- 1.5711212158203125 seconds ---\n",
      "episode 2415, reward -61.0, memory_length 2000, epsilon 0.2989437052720013\n",
      "travel time- 724.0\n",
      "--- 1.8021759986877441 seconds ---\n",
      "episode 2416, reward -72.0, memory_length 2000, epsilon 0.29879427078110127\n",
      "travel time- 725.0\n",
      "--- 1.6222445964813232 seconds ---\n",
      "episode 2417, reward -348.0, memory_length 2000, epsilon 0.29864491098877044\n",
      "travel time- 720.0\n",
      "--- 1.6242880821228027 seconds ---\n",
      "episode 2418, reward -323.0, memory_length 2000, epsilon 0.2984956258576689\n",
      "travel time- 724.0\n",
      "--- 1.6234381198883057 seconds ---\n",
      "episode 2419, reward 54.0, memory_length 2000, epsilon 0.29834641535047546\n",
      "travel time- 723.0\n",
      "--- 1.4645898342132568 seconds ---\n",
      "episode 2420, reward -228.0, memory_length 2000, epsilon 0.2981972794298874\n",
      "travel time- 720.0\n",
      "--- 1.7039997577667236 seconds ---\n",
      "episode 2421, reward -470.0, memory_length 2000, epsilon 0.29804821805862064\n",
      "travel time- 722.0\n",
      "--- 1.8014342784881592 seconds ---\n",
      "episode 2422, reward -17.0, memory_length 2000, epsilon 0.2978992311994101\n",
      "travel time- 726.0\n",
      "--- 1.6549382209777832 seconds ---\n",
      "episode 2423, reward 126.0, memory_length 2000, epsilon 0.2977503188150088\n",
      "travel time- 721.0\n",
      "--- 1.4359898567199707 seconds ---\n",
      "episode 2424, reward 46.0, memory_length 2000, epsilon 0.29760148086818883\n",
      "travel time- 720.0\n",
      "--- 1.4868760108947754 seconds ---\n",
      "episode 2425, reward 63.0, memory_length 2000, epsilon 0.2974527173217405\n",
      "travel time- 729.0\n",
      "--- 1.609163761138916 seconds ---\n",
      "episode 2426, reward -41.0, memory_length 2000, epsilon 0.2973040281384732\n",
      "travel time- 729.0\n",
      "--- 1.7801353931427002 seconds ---\n",
      "episode 2427, reward 155.0, memory_length 2000, epsilon 0.2971554132812144\n",
      "travel time- 727.0\n",
      "--- 1.6200053691864014 seconds ---\n",
      "episode 2428, reward -64.0, memory_length 2000, epsilon 0.2970068727128105\n",
      "travel time- 724.0\n",
      "--- 1.5748884677886963 seconds ---\n",
      "episode 2429, reward -68.0, memory_length 2000, epsilon 0.29685840639612626\n",
      "travel time- 724.0\n",
      "--- 1.5585405826568604 seconds ---\n",
      "episode 2430, reward -61.0, memory_length 2000, epsilon 0.29671001429404525\n",
      "travel time- 724.0\n",
      "--- 1.485236406326294 seconds ---\n",
      "episode 2431, reward 148.0, memory_length 2000, epsilon 0.2965616963694694\n",
      "travel time- 720.0\n",
      "--- 1.7009267807006836 seconds ---\n",
      "episode 2432, reward -148.0, memory_length 2000, epsilon 0.2964134525853191\n",
      "travel time- 723.0\n",
      "--- 1.735525131225586 seconds ---\n",
      "episode 2433, reward 335.0, memory_length 2000, epsilon 0.2962652829045335\n",
      "travel time- 725.0\n",
      "--- 1.549649715423584 seconds ---\n",
      "episode 2434, reward 145.0, memory_length 2000, epsilon 0.29611718729007014\n",
      "travel time- 725.0\n",
      "--- 1.7176322937011719 seconds ---\n",
      "episode 2435, reward 107.0, memory_length 2000, epsilon 0.29596916570490517\n",
      "travel time- 725.0\n",
      "--- 1.7449140548706055 seconds ---\n",
      "episode 2436, reward 8.0, memory_length 2000, epsilon 0.2958212181120332\n",
      "travel time- 725.0\n",
      "--- 1.565880537033081 seconds ---\n",
      "episode 2437, reward -282.0, memory_length 2000, epsilon 0.2956733444744673\n",
      "travel time- 720.0\n",
      "--- 1.5628161430358887 seconds ---\n",
      "episode 2438, reward 205.0, memory_length 2000, epsilon 0.295525544755239\n",
      "travel time- 727.0\n",
      "--- 1.60115385055542 seconds ---\n",
      "episode 2439, reward -277.0, memory_length 2000, epsilon 0.29537781891739845\n",
      "travel time- 723.0\n",
      "--- 1.6237645149230957 seconds ---\n",
      "episode 2440, reward 408.0, memory_length 2000, epsilon 0.2952301669240142\n",
      "travel time- 730.0\n",
      "--- 1.586151123046875 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2441, reward 8.0, memory_length 2000, epsilon 0.2950825887381732\n",
      "travel time- 721.0\n",
      "--- 1.721930980682373 seconds ---\n",
      "episode 2442, reward -66.0, memory_length 2000, epsilon 0.2949350843229809\n",
      "travel time- 720.0\n",
      "--- 1.626131296157837 seconds ---\n",
      "episode 2443, reward 48.0, memory_length 2000, epsilon 0.29478765364156123\n",
      "travel time- 728.0\n",
      "--- 1.54710054397583 seconds ---\n",
      "episode 2444, reward 155.0, memory_length 2000, epsilon 0.29464029665705654\n",
      "travel time- 723.0\n",
      "--- 1.4282002449035645 seconds ---\n",
      "episode 2445, reward -88.0, memory_length 2000, epsilon 0.29449301333262756\n",
      "travel time- 726.0\n",
      "--- 1.615541696548462 seconds ---\n",
      "episode 2446, reward -541.0, memory_length 2000, epsilon 0.29434580363145335\n",
      "travel time- 726.0\n",
      "--- 1.8412935733795166 seconds ---\n",
      "episode 2447, reward -175.0, memory_length 2000, epsilon 0.2941986675167317\n",
      "travel time- 720.0\n",
      "--- 1.4370439052581787 seconds ---\n",
      "episode 2448, reward 32.0, memory_length 2000, epsilon 0.29405160495167837\n",
      "travel time- 721.0\n",
      "--- 1.5644614696502686 seconds ---\n",
      "episode 2449, reward 0.0, memory_length 2000, epsilon 0.2939046158995279\n",
      "travel time- 724.0\n",
      "--- 1.6741459369659424 seconds ---\n",
      "episode 2450, reward -28.0, memory_length 2000, epsilon 0.29375770032353277\n",
      "travel time- 725.0\n",
      "--- 1.673938274383545 seconds ---\n",
      "episode 2451, reward 29.0, memory_length 2000, epsilon 0.2936108581869644\n",
      "travel time- 720.0\n",
      "--- 1.5924458503723145 seconds ---\n",
      "episode 2452, reward -234.0, memory_length 2000, epsilon 0.2934640894531121\n",
      "travel time- 727.0\n",
      "--- 1.4886589050292969 seconds ---\n",
      "episode 2453, reward 162.0, memory_length 2000, epsilon 0.2933173940852836\n",
      "travel time- 723.0\n",
      "--- 1.6540496349334717 seconds ---\n",
      "episode 2454, reward -293.0, memory_length 2000, epsilon 0.2931707720468052\n",
      "travel time- 722.0\n",
      "--- 1.7536160945892334 seconds ---\n",
      "episode 2455, reward -148.0, memory_length 2000, epsilon 0.29302422330102135\n",
      "travel time- 725.0\n",
      "--- 1.637382984161377 seconds ---\n",
      "episode 2456, reward -81.0, memory_length 2000, epsilon 0.2928777478112949\n",
      "travel time- 728.0\n",
      "--- 1.4642560482025146 seconds ---\n",
      "episode 2457, reward 45.0, memory_length 2000, epsilon 0.2927313455410068\n",
      "travel time- 725.0\n",
      "--- 1.6684534549713135 seconds ---\n",
      "episode 2458, reward -129.0, memory_length 2000, epsilon 0.29258501645355667\n",
      "travel time- 722.0\n",
      "--- 1.4135923385620117 seconds ---\n",
      "episode 2459, reward -189.0, memory_length 2000, epsilon 0.29243876051236223\n",
      "travel time- 729.0\n",
      "--- 1.6571018695831299 seconds ---\n",
      "episode 2460, reward -198.0, memory_length 2000, epsilon 0.2922925776808594\n",
      "travel time- 732.0\n",
      "--- 1.5426490306854248 seconds ---\n",
      "episode 2461, reward 187.0, memory_length 2000, epsilon 0.29214646792250254\n",
      "travel time- 721.0\n",
      "--- 1.6716084480285645 seconds ---\n",
      "episode 2462, reward 60.0, memory_length 2000, epsilon 0.2920004312007641\n",
      "travel time- 723.0\n",
      "--- 1.6681675910949707 seconds ---\n",
      "episode 2463, reward 45.0, memory_length 2000, epsilon 0.29185446747913507\n",
      "travel time- 732.0\n",
      "--- 1.711103916168213 seconds ---\n",
      "episode 2464, reward -246.0, memory_length 2000, epsilon 0.2917085767211244\n",
      "travel time- 728.0\n",
      "--- 1.7861695289611816 seconds ---\n",
      "episode 2465, reward -89.0, memory_length 2000, epsilon 0.29156275889025945\n",
      "travel time- 729.0\n",
      "--- 1.8971247673034668 seconds ---\n",
      "episode 2466, reward -368.0, memory_length 2000, epsilon 0.2914170139500857\n",
      "travel time- 721.0\n",
      "--- 1.4838614463806152 seconds ---\n",
      "episode 2467, reward -102.0, memory_length 2000, epsilon 0.2912713418641669\n",
      "travel time- 731.0\n",
      "--- 1.5764391422271729 seconds ---\n",
      "episode 2468, reward 50.0, memory_length 2000, epsilon 0.2911257425960852\n",
      "travel time- 724.0\n",
      "--- 1.598653793334961 seconds ---\n",
      "episode 2469, reward 142.0, memory_length 2000, epsilon 0.29098021610944064\n",
      "travel time- 722.0\n",
      "--- 1.524853229522705 seconds ---\n",
      "episode 2470, reward 24.0, memory_length 2000, epsilon 0.29083476236785155\n",
      "travel time- 729.0\n",
      "--- 1.570169448852539 seconds ---\n",
      "episode 2471, reward -242.0, memory_length 2000, epsilon 0.29068938133495464\n",
      "travel time- 729.0\n",
      "--- 1.681635856628418 seconds ---\n",
      "episode 2472, reward 324.0, memory_length 2000, epsilon 0.2905440729744046\n",
      "travel time- 722.0\n",
      "--- 1.6685714721679688 seconds ---\n",
      "episode 2473, reward -92.0, memory_length 2000, epsilon 0.29039883724987425\n",
      "travel time- 730.0\n",
      "--- 1.5845341682434082 seconds ---\n",
      "episode 2474, reward -53.0, memory_length 2000, epsilon 0.2902536741250547\n",
      "travel time- 730.0\n",
      "--- 1.497636318206787 seconds ---\n",
      "episode 2475, reward 84.0, memory_length 2000, epsilon 0.29010858356365526\n",
      "travel time- 722.0\n",
      "--- 1.5136208534240723 seconds ---\n",
      "episode 2476, reward 144.0, memory_length 2000, epsilon 0.2899635655294032\n",
      "travel time- 728.0\n",
      "--- 1.4405651092529297 seconds ---\n",
      "episode 2477, reward 248.0, memory_length 2000, epsilon 0.2898186199860441\n",
      "travel time- 720.0\n",
      "--- 1.454613208770752 seconds ---\n",
      "episode 2478, reward 323.0, memory_length 2000, epsilon 0.2896737468973414\n",
      "travel time- 725.0\n",
      "--- 1.4183986186981201 seconds ---\n",
      "episode 2479, reward -1.0, memory_length 2000, epsilon 0.289528946227077\n",
      "travel time- 720.0\n",
      "--- 1.6691312789916992 seconds ---\n",
      "episode 2480, reward 3.0, memory_length 2000, epsilon 0.2893842179390506\n",
      "travel time- 727.0\n",
      "--- 1.6422123908996582 seconds ---\n",
      "episode 2481, reward -226.0, memory_length 2000, epsilon 0.2892395619970803\n",
      "travel time- 726.0\n",
      "--- 1.7068850994110107 seconds ---\n",
      "episode 2482, reward 157.0, memory_length 2000, epsilon 0.28909497836500186\n",
      "travel time- 726.0\n",
      "--- 1.580735206604004 seconds ---\n",
      "episode 2483, reward -120.0, memory_length 2000, epsilon 0.28895046700666965\n",
      "travel time- 720.0\n",
      "--- 1.570387840270996 seconds ---\n",
      "episode 2484, reward -304.0, memory_length 2000, epsilon 0.28880602788595566\n",
      "travel time- 720.0\n",
      "--- 1.6780755519866943 seconds ---\n",
      "episode 2485, reward -318.0, memory_length 2000, epsilon 0.2886616609667501\n",
      "travel time- 729.0\n",
      "--- 1.5450260639190674 seconds ---\n",
      "episode 2486, reward -292.0, memory_length 2000, epsilon 0.2885173662129613\n",
      "travel time- 728.0\n",
      "--- 1.5536210536956787 seconds ---\n",
      "episode 2487, reward -184.0, memory_length 2000, epsilon 0.28837314358851557\n",
      "travel time- 720.0\n",
      "--- 1.4598944187164307 seconds ---\n",
      "episode 2488, reward -232.0, memory_length 2000, epsilon 0.2882289930573573\n",
      "travel time- 720.0\n",
      "--- 1.6079473495483398 seconds ---\n",
      "episode 2489, reward -97.0, memory_length 2000, epsilon 0.2880849145834487\n",
      "travel time- 720.0\n",
      "--- 1.4040861129760742 seconds ---\n",
      "episode 2490, reward 110.0, memory_length 2000, epsilon 0.2879409081307702\n",
      "travel time- 722.0\n",
      "--- 1.6111905574798584 seconds ---\n",
      "episode 2491, reward -241.0, memory_length 2000, epsilon 0.28779697366332035\n",
      "travel time- 726.0\n",
      "--- 1.8166759014129639 seconds ---\n",
      "episode 2492, reward 61.0, memory_length 2000, epsilon 0.2876531111451154\n",
      "travel time- 720.0\n",
      "--- 1.670339822769165 seconds ---\n",
      "episode 2493, reward 50.0, memory_length 2000, epsilon 0.28750932054018974\n",
      "travel time- 724.0\n",
      "--- 1.632455587387085 seconds ---\n",
      "episode 2494, reward 49.0, memory_length 2000, epsilon 0.28736560181259563\n",
      "travel time- 726.0\n",
      "--- 1.3387997150421143 seconds ---\n",
      "episode 2495, reward -123.0, memory_length 2000, epsilon 0.28722195492640357\n",
      "travel time- 729.0\n",
      "--- 1.617100477218628 seconds ---\n",
      "episode 2496, reward -16.0, memory_length 2000, epsilon 0.28707837984570167\n",
      "travel time- 721.0\n",
      "--- 1.565603256225586 seconds ---\n",
      "episode 2497, reward 56.0, memory_length 2000, epsilon 0.28693487653459626\n",
      "travel time- 722.0\n",
      "--- 1.6927077770233154 seconds ---\n",
      "episode 2498, reward -148.0, memory_length 2000, epsilon 0.2867914449572114\n",
      "travel time- 723.0\n",
      "--- 1.6359310150146484 seconds ---\n",
      "episode 2499, reward 226.0, memory_length 2000, epsilon 0.2866480850776894\n",
      "travel time- 726.0\n",
      "--- 1.6018054485321045 seconds ---\n",
      "episode 2500, reward 320.0, memory_length 2000, epsilon 0.2865047968601901\n",
      "travel time- 726.0\n",
      "--- 1.611583948135376 seconds ---\n",
      "episode 2501, reward -53.0, memory_length 2000, epsilon 0.2863615802688915\n",
      "travel time- 728.0\n",
      "--- 1.6290302276611328 seconds ---\n",
      "episode 2502, reward -19.0, memory_length 2000, epsilon 0.28621843526798946\n",
      "travel time- 725.0\n",
      "--- 1.698122501373291 seconds ---\n",
      "episode 2503, reward -66.0, memory_length 2000, epsilon 0.28607536182169774\n",
      "travel time- 723.0\n",
      "--- 1.6552600860595703 seconds ---\n",
      "episode 2504, reward -55.0, memory_length 2000, epsilon 0.285932359894248\n",
      "travel time- 721.0\n",
      "--- 1.684041976928711 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2505, reward -316.0, memory_length 2000, epsilon 0.28578942944988966\n",
      "travel time- 724.0\n",
      "--- 1.7017712593078613 seconds ---\n",
      "episode 2506, reward 188.0, memory_length 2000, epsilon 0.28564657045289016\n",
      "travel time- 726.0\n",
      "--- 1.5006074905395508 seconds ---\n",
      "episode 2507, reward 24.0, memory_length 2000, epsilon 0.2855037828675348\n",
      "travel time- 721.0\n",
      "--- 1.5344672203063965 seconds ---\n",
      "episode 2508, reward 154.0, memory_length 2000, epsilon 0.28536106665812666\n",
      "travel time- 725.0\n",
      "--- 1.7817325592041016 seconds ---\n",
      "episode 2509, reward -215.0, memory_length 2000, epsilon 0.28521842178898665\n",
      "travel time- 721.0\n",
      "--- 1.6234514713287354 seconds ---\n",
      "episode 2510, reward -118.0, memory_length 2000, epsilon 0.28507584822445353\n",
      "travel time- 724.0\n",
      "--- 1.4594371318817139 seconds ---\n",
      "episode 2511, reward -59.0, memory_length 2000, epsilon 0.28493334592888403\n",
      "travel time- 729.0\n",
      "--- 1.676673173904419 seconds ---\n",
      "episode 2512, reward -89.0, memory_length 2000, epsilon 0.2847909148666525\n",
      "travel time- 722.0\n",
      "--- 1.7613229751586914 seconds ---\n",
      "episode 2513, reward 22.0, memory_length 2000, epsilon 0.28464855500215114\n",
      "travel time- 723.0\n",
      "--- 1.5369865894317627 seconds ---\n",
      "episode 2514, reward -81.0, memory_length 2000, epsilon 0.2845062662997899\n",
      "travel time- 726.0\n",
      "--- 1.7089660167694092 seconds ---\n",
      "episode 2515, reward -35.0, memory_length 2000, epsilon 0.28436404872399684\n",
      "travel time- 721.0\n",
      "--- 1.8084042072296143 seconds ---\n",
      "episode 2516, reward 28.0, memory_length 2000, epsilon 0.28422190223921745\n",
      "travel time- 724.0\n",
      "--- 1.6100776195526123 seconds ---\n",
      "episode 2517, reward 81.0, memory_length 2000, epsilon 0.2840798268099151\n",
      "travel time- 722.0\n",
      "--- 1.4550938606262207 seconds ---\n",
      "episode 2518, reward -78.0, memory_length 2000, epsilon 0.28393782240057086\n",
      "travel time- 722.0\n",
      "--- 1.7928147315979004 seconds ---\n",
      "episode 2519, reward -179.0, memory_length 2000, epsilon 0.28379588897568375\n",
      "travel time- 720.0\n",
      "--- 1.543262243270874 seconds ---\n",
      "episode 2520, reward -182.0, memory_length 2000, epsilon 0.2836540264997704\n",
      "travel time- 733.0\n",
      "--- 1.719602108001709 seconds ---\n",
      "episode 2521, reward 109.0, memory_length 2000, epsilon 0.2835122349373651\n",
      "travel time- 724.0\n",
      "--- 1.3798470497131348 seconds ---\n",
      "episode 2522, reward -327.0, memory_length 2000, epsilon 0.28337051425301996\n",
      "travel time- 722.0\n",
      "--- 1.6401066780090332 seconds ---\n",
      "episode 2523, reward -120.0, memory_length 2000, epsilon 0.28322886441130496\n",
      "travel time- 720.0\n",
      "--- 1.6729261875152588 seconds ---\n",
      "episode 2524, reward 110.0, memory_length 2000, epsilon 0.2830872853768075\n",
      "travel time- 721.0\n",
      "--- 1.7382214069366455 seconds ---\n",
      "episode 2525, reward -83.0, memory_length 2000, epsilon 0.2829457771141329\n",
      "travel time- 721.0\n",
      "--- 1.6506764888763428 seconds ---\n",
      "episode 2526, reward 101.0, memory_length 2000, epsilon 0.2828043395879039\n",
      "travel time- 720.0\n",
      "--- 1.5335071086883545 seconds ---\n",
      "episode 2527, reward -127.0, memory_length 2000, epsilon 0.2826629727627614\n",
      "travel time- 722.0\n",
      "--- 1.5350806713104248 seconds ---\n",
      "episode 2528, reward -159.0, memory_length 2000, epsilon 0.2825216766033636\n",
      "travel time- 732.0\n",
      "--- 1.5848503112792969 seconds ---\n",
      "episode 2529, reward -133.0, memory_length 2000, epsilon 0.28238045107438636\n",
      "travel time- 728.0\n",
      "--- 1.5756490230560303 seconds ---\n",
      "episode 2530, reward -63.0, memory_length 2000, epsilon 0.2822392961405233\n",
      "travel time- 731.0\n",
      "--- 1.4206092357635498 seconds ---\n",
      "episode 2531, reward 71.0, memory_length 2000, epsilon 0.2820982117664858\n",
      "travel time- 722.0\n",
      "--- 1.7631518840789795 seconds ---\n",
      "episode 2532, reward -321.0, memory_length 2000, epsilon 0.28195719791700274\n",
      "travel time- 725.0\n",
      "--- 1.9163029193878174 seconds ---\n",
      "episode 2533, reward -143.0, memory_length 2000, epsilon 0.28181625455682063\n",
      "travel time- 721.0\n",
      "--- 1.835866928100586 seconds ---\n",
      "episode 2534, reward 3.0, memory_length 2000, epsilon 0.28167538165070355\n",
      "travel time- 732.0\n",
      "--- 1.7087297439575195 seconds ---\n",
      "episode 2535, reward 10.0, memory_length 2000, epsilon 0.28153457916343344\n",
      "travel time- 720.0\n",
      "--- 1.4558167457580566 seconds ---\n",
      "episode 2536, reward -83.0, memory_length 2000, epsilon 0.2813938470598095\n",
      "travel time- 723.0\n",
      "--- 1.6930348873138428 seconds ---\n",
      "episode 2537, reward -25.0, memory_length 2000, epsilon 0.2812531853046489\n",
      "travel time- 724.0\n",
      "--- 1.6591427326202393 seconds ---\n",
      "episode 2538, reward 100.0, memory_length 2000, epsilon 0.281112593862786\n",
      "travel time- 731.0\n",
      "--- 1.5064201354980469 seconds ---\n",
      "episode 2539, reward 102.0, memory_length 2000, epsilon 0.28097207269907304\n",
      "travel time- 724.0\n",
      "--- 1.5957021713256836 seconds ---\n",
      "episode 2540, reward -69.0, memory_length 2000, epsilon 0.2808316217783798\n",
      "travel time- 729.0\n",
      "--- 1.4322733879089355 seconds ---\n",
      "episode 2541, reward -112.0, memory_length 2000, epsilon 0.2806912410655934\n",
      "travel time- 721.0\n",
      "--- 1.8658430576324463 seconds ---\n",
      "episode 2542, reward -108.0, memory_length 2000, epsilon 0.2805509305256187\n",
      "travel time- 722.0\n",
      "--- 1.5981957912445068 seconds ---\n",
      "episode 2543, reward 86.0, memory_length 2000, epsilon 0.2804106901233781\n",
      "travel time- 722.0\n",
      "--- 1.512300729751587 seconds ---\n",
      "episode 2544, reward -18.0, memory_length 2000, epsilon 0.28027051982381157\n",
      "travel time- 722.0\n",
      "--- 1.6671278476715088 seconds ---\n",
      "episode 2545, reward -503.0, memory_length 2000, epsilon 0.2801304195918764\n",
      "travel time- 729.0\n",
      "--- 1.6693172454833984 seconds ---\n",
      "episode 2546, reward -261.0, memory_length 2000, epsilon 0.27999038939254756\n",
      "travel time- 725.0\n",
      "--- 1.6983788013458252 seconds ---\n",
      "episode 2547, reward 3.0, memory_length 2000, epsilon 0.27985042919081754\n",
      "travel time- 724.0\n",
      "--- 1.625300645828247 seconds ---\n",
      "episode 2548, reward 10.0, memory_length 2000, epsilon 0.27971053895169634\n",
      "travel time- 724.0\n",
      "--- 1.706787347793579 seconds ---\n",
      "episode 2549, reward -57.0, memory_length 2000, epsilon 0.27957071864021127\n",
      "travel time- 725.0\n",
      "--- 1.7205805778503418 seconds ---\n",
      "episode 2550, reward -292.0, memory_length 2000, epsilon 0.2794309682214073\n",
      "travel time- 720.0\n",
      "--- 1.65401291847229 seconds ---\n",
      "episode 2551, reward -97.0, memory_length 2000, epsilon 0.2792912876603469\n",
      "travel time- 728.0\n",
      "--- 1.7701411247253418 seconds ---\n",
      "episode 2552, reward -255.0, memory_length 2000, epsilon 0.27915167692210985\n",
      "travel time- 720.0\n",
      "--- 1.9110996723175049 seconds ---\n",
      "episode 2553, reward -113.0, memory_length 2000, epsilon 0.2790121359717935\n",
      "travel time- 721.0\n",
      "--- 1.6886811256408691 seconds ---\n",
      "episode 2554, reward -44.0, memory_length 2000, epsilon 0.2788726647745125\n",
      "travel time- 724.0\n",
      "--- 1.3278837203979492 seconds ---\n",
      "episode 2555, reward -37.0, memory_length 2000, epsilon 0.27873326329539927\n",
      "travel time- 723.0\n",
      "--- 1.8126049041748047 seconds ---\n",
      "episode 2556, reward -244.0, memory_length 2000, epsilon 0.27859393149960326\n",
      "travel time- 729.0\n",
      "--- 1.605992078781128 seconds ---\n",
      "episode 2557, reward 297.0, memory_length 2000, epsilon 0.2784546693522916\n",
      "travel time- 726.0\n",
      "--- 1.57279634475708 seconds ---\n",
      "episode 2558, reward -104.0, memory_length 2000, epsilon 0.27831547681864865\n",
      "travel time- 722.0\n",
      "--- 1.7891862392425537 seconds ---\n",
      "episode 2559, reward 45.0, memory_length 2000, epsilon 0.27817635386387646\n",
      "travel time- 721.0\n",
      "--- 1.595818281173706 seconds ---\n",
      "episode 2560, reward -196.0, memory_length 2000, epsilon 0.27803730045319414\n",
      "travel time- 721.0\n",
      "--- 1.5067238807678223 seconds ---\n",
      "episode 2561, reward 146.0, memory_length 2000, epsilon 0.2778983165518384\n",
      "travel time- 727.0\n",
      "--- 1.4629936218261719 seconds ---\n",
      "episode 2562, reward -87.0, memory_length 2000, epsilon 0.2777594021250632\n",
      "travel time- 720.0\n",
      "--- 1.6873321533203125 seconds ---\n",
      "episode 2563, reward -41.0, memory_length 2000, epsilon 0.27762055713814\n",
      "travel time- 721.0\n",
      "--- 1.6476871967315674 seconds ---\n",
      "episode 2564, reward -82.0, memory_length 2000, epsilon 0.2774817815563575\n",
      "travel time- 727.0\n",
      "--- 1.5483450889587402 seconds ---\n",
      "episode 2565, reward 105.0, memory_length 2000, epsilon 0.2773430753450219\n",
      "travel time- 726.0\n",
      "--- 1.687638521194458 seconds ---\n",
      "episode 2566, reward 117.0, memory_length 2000, epsilon 0.2772044384694566\n",
      "travel time- 731.0\n",
      "--- 1.4813916683197021 seconds ---\n",
      "episode 2567, reward 169.0, memory_length 2000, epsilon 0.27706587089500223\n",
      "travel time- 725.0\n",
      "--- 1.3581736087799072 seconds ---\n",
      "episode 2568, reward -128.0, memory_length 2000, epsilon 0.2769273725870171\n",
      "travel time- 720.0\n",
      "--- 1.7032470703125 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2569, reward 158.0, memory_length 2000, epsilon 0.27678894351087663\n",
      "travel time- 720.0\n",
      "--- 1.6590566635131836 seconds ---\n",
      "episode 2570, reward 114.0, memory_length 2000, epsilon 0.2766505836319734\n",
      "travel time- 726.0\n",
      "--- 1.645845890045166 seconds ---\n",
      "episode 2571, reward 24.0, memory_length 2000, epsilon 0.2765122929157175\n",
      "travel time- 730.0\n",
      "--- 1.7911152839660645 seconds ---\n",
      "episode 2572, reward -164.0, memory_length 2000, epsilon 0.27637407132753633\n",
      "travel time- 720.0\n",
      "--- 1.7170906066894531 seconds ---\n",
      "episode 2573, reward -145.0, memory_length 2000, epsilon 0.2762359188328744\n",
      "travel time- 722.0\n",
      "--- 1.6270031929016113 seconds ---\n",
      "episode 2574, reward -235.0, memory_length 2000, epsilon 0.2760978353971936\n",
      "travel time- 725.0\n",
      "--- 1.8489177227020264 seconds ---\n",
      "episode 2575, reward 178.0, memory_length 2000, epsilon 0.2759598209859731\n",
      "travel time- 721.0\n",
      "--- 1.539900779724121 seconds ---\n",
      "episode 2576, reward 142.0, memory_length 2000, epsilon 0.27582187556470933\n",
      "travel time- 720.0\n",
      "--- 1.7377753257751465 seconds ---\n",
      "episode 2577, reward 155.0, memory_length 2000, epsilon 0.27568399909891583\n",
      "travel time- 722.0\n",
      "--- 1.5406322479248047 seconds ---\n",
      "episode 2578, reward -422.0, memory_length 2000, epsilon 0.2755461915541236\n",
      "travel time- 729.0\n",
      "--- 2.000091791152954 seconds ---\n",
      "episode 2579, reward -146.0, memory_length 2000, epsilon 0.2754084528958806\n",
      "travel time- 725.0\n",
      "--- 1.78279447555542 seconds ---\n",
      "episode 2580, reward -66.0, memory_length 2000, epsilon 0.27527078308975234\n",
      "travel time- 725.0\n",
      "--- 1.6581661701202393 seconds ---\n",
      "episode 2581, reward -121.0, memory_length 2000, epsilon 0.27513318210132126\n",
      "travel time- 721.0\n",
      "--- 1.7740049362182617 seconds ---\n",
      "episode 2582, reward 145.0, memory_length 2000, epsilon 0.27499564989618713\n",
      "travel time- 726.0\n",
      "--- 1.6405479907989502 seconds ---\n",
      "episode 2583, reward 227.0, memory_length 2000, epsilon 0.2748581864399669\n",
      "travel time- 720.0\n",
      "--- 1.614527940750122 seconds ---\n",
      "episode 2584, reward -23.0, memory_length 2000, epsilon 0.2747207916982947\n",
      "travel time- 727.0\n",
      "--- 1.639286756515503 seconds ---\n",
      "episode 2585, reward 184.0, memory_length 2000, epsilon 0.27458346563682196\n",
      "travel time- 722.0\n",
      "--- 1.6757969856262207 seconds ---\n",
      "episode 2586, reward -146.0, memory_length 2000, epsilon 0.27444620822121696\n",
      "travel time- 723.0\n",
      "--- 1.671184778213501 seconds ---\n",
      "episode 2587, reward -395.0, memory_length 2000, epsilon 0.2743090194171654\n",
      "travel time- 728.0\n",
      "--- 1.5698516368865967 seconds ---\n",
      "episode 2588, reward 69.0, memory_length 2000, epsilon 0.2741718991903702\n",
      "travel time- 721.0\n",
      "--- 1.641582727432251 seconds ---\n",
      "episode 2589, reward 29.0, memory_length 2000, epsilon 0.27403484750655127\n",
      "travel time- 733.0\n",
      "--- 1.4922895431518555 seconds ---\n",
      "episode 2590, reward -107.0, memory_length 2000, epsilon 0.2738978643314456\n",
      "travel time- 728.0\n",
      "--- 1.5970885753631592 seconds ---\n",
      "episode 2591, reward 32.0, memory_length 2000, epsilon 0.2737609496308074\n",
      "travel time- 724.0\n",
      "--- 1.5891902446746826 seconds ---\n",
      "episode 2592, reward 94.0, memory_length 2000, epsilon 0.27362410337040804\n",
      "travel time- 720.0\n",
      "--- 1.688429832458496 seconds ---\n",
      "episode 2593, reward 226.0, memory_length 2000, epsilon 0.273487325516036\n",
      "travel time- 720.0\n",
      "--- 1.3188483715057373 seconds ---\n",
      "episode 2594, reward 102.0, memory_length 2000, epsilon 0.27335061603349675\n",
      "travel time- 730.0\n",
      "--- 1.6692392826080322 seconds ---\n",
      "episode 2595, reward 102.0, memory_length 2000, epsilon 0.2732139748886128\n",
      "travel time- 721.0\n",
      "--- 1.8697810173034668 seconds ---\n",
      "episode 2596, reward 83.0, memory_length 2000, epsilon 0.2730774020472242\n",
      "travel time- 720.0\n",
      "--- 1.6726386547088623 seconds ---\n",
      "episode 2597, reward -211.0, memory_length 2000, epsilon 0.2729408974751874\n",
      "travel time- 733.0\n",
      "--- 1.569383144378662 seconds ---\n",
      "episode 2598, reward -301.0, memory_length 2000, epsilon 0.2728044611383765\n",
      "travel time- 728.0\n",
      "--- 1.7537827491760254 seconds ---\n",
      "episode 2599, reward 248.0, memory_length 2000, epsilon 0.2726680930026822\n",
      "travel time- 722.0\n",
      "--- 1.6276464462280273 seconds ---\n",
      "episode 2600, reward -109.0, memory_length 2000, epsilon 0.2725317930340126\n",
      "travel time- 720.0\n",
      "--- 1.478410243988037 seconds ---\n",
      "episode 2601, reward 49.0, memory_length 2000, epsilon 0.27239556119829267\n",
      "travel time- 720.0\n",
      "--- 1.721125602722168 seconds ---\n",
      "episode 2602, reward 79.0, memory_length 2000, epsilon 0.2722593974614645\n",
      "travel time- 721.0\n",
      "--- 1.6373467445373535 seconds ---\n",
      "episode 2603, reward 176.0, memory_length 2000, epsilon 0.27212330178948707\n",
      "travel time- 722.0\n",
      "--- 1.487281322479248 seconds ---\n",
      "episode 2604, reward -270.0, memory_length 2000, epsilon 0.2719872741483365\n",
      "travel time- 723.0\n",
      "--- 1.644446849822998 seconds ---\n",
      "episode 2605, reward -81.0, memory_length 2000, epsilon 0.27185131450400596\n",
      "travel time- 729.0\n",
      "--- 1.541898250579834 seconds ---\n",
      "episode 2606, reward -95.0, memory_length 2000, epsilon 0.27171542282250544\n",
      "travel time- 728.0\n",
      "--- 1.6781680583953857 seconds ---\n",
      "episode 2607, reward 128.0, memory_length 2000, epsilon 0.27157959906986195\n",
      "travel time- 722.0\n",
      "--- 1.4705748558044434 seconds ---\n",
      "episode 2608, reward -39.0, memory_length 2000, epsilon 0.27144384321211973\n",
      "travel time- 728.0\n",
      "--- 1.6741087436676025 seconds ---\n",
      "episode 2609, reward 10.0, memory_length 2000, epsilon 0.2713081552153397\n",
      "travel time- 720.0\n",
      "--- 1.6979138851165771 seconds ---\n",
      "episode 2610, reward -68.0, memory_length 2000, epsilon 0.2711725350455999\n",
      "travel time- 725.0\n",
      "--- 1.6320116519927979 seconds ---\n",
      "episode 2611, reward -309.0, memory_length 2000, epsilon 0.2710369826689952\n",
      "travel time- 721.0\n",
      "--- 1.7997817993164062 seconds ---\n",
      "episode 2612, reward -283.0, memory_length 2000, epsilon 0.27090149805163766\n",
      "travel time- 723.0\n",
      "--- 1.8704323768615723 seconds ---\n",
      "episode 2613, reward -365.0, memory_length 2000, epsilon 0.270766081159656\n",
      "travel time- 722.0\n",
      "--- 1.7856028079986572 seconds ---\n",
      "episode 2614, reward -156.0, memory_length 2000, epsilon 0.2706307319591961\n",
      "travel time- 731.0\n",
      "--- 1.6484134197235107 seconds ---\n",
      "episode 2615, reward 131.0, memory_length 2000, epsilon 0.27049545041642054\n",
      "travel time- 734.0\n",
      "--- 1.5503008365631104 seconds ---\n",
      "episode 2616, reward 70.0, memory_length 2000, epsilon 0.270360236497509\n",
      "travel time- 721.0\n",
      "--- 1.558422327041626 seconds ---\n",
      "episode 2617, reward 12.0, memory_length 2000, epsilon 0.27022509016865803\n",
      "travel time- 722.0\n",
      "--- 1.5973021984100342 seconds ---\n",
      "episode 2618, reward 64.0, memory_length 2000, epsilon 0.270090011396081\n",
      "travel time- 722.0\n",
      "--- 1.4453670978546143 seconds ---\n",
      "episode 2619, reward -25.0, memory_length 2000, epsilon 0.26995500014600815\n",
      "travel time- 730.0\n",
      "--- 1.4959497451782227 seconds ---\n",
      "episode 2620, reward -100.0, memory_length 2000, epsilon 0.2698200563846868\n",
      "travel time- 720.0\n",
      "--- 1.5433540344238281 seconds ---\n",
      "episode 2621, reward -183.0, memory_length 2000, epsilon 0.269685180078381\n",
      "travel time- 729.0\n",
      "--- 1.7046287059783936 seconds ---\n",
      "episode 2622, reward 109.0, memory_length 2000, epsilon 0.2695503711933716\n",
      "travel time- 725.0\n",
      "--- 1.619539737701416 seconds ---\n",
      "episode 2623, reward -77.0, memory_length 2000, epsilon 0.26941562969595634\n",
      "travel time- 720.0\n",
      "--- 1.6555216312408447 seconds ---\n",
      "episode 2624, reward -24.0, memory_length 2000, epsilon 0.26928095555244996\n",
      "travel time- 720.0\n",
      "--- 1.643805980682373 seconds ---\n",
      "episode 2625, reward 27.0, memory_length 2000, epsilon 0.26914634872918386\n",
      "travel time- 720.0\n",
      "--- 1.5845682621002197 seconds ---\n",
      "episode 2626, reward -151.0, memory_length 2000, epsilon 0.2690118091925064\n",
      "travel time- 722.0\n",
      "--- 1.5310604572296143 seconds ---\n",
      "episode 2627, reward -82.0, memory_length 2000, epsilon 0.2688773369087825\n",
      "travel time- 723.0\n",
      "--- 1.6842279434204102 seconds ---\n",
      "episode 2628, reward -25.0, memory_length 2000, epsilon 0.26874293184439435\n",
      "travel time- 725.0\n",
      "--- 1.5913949012756348 seconds ---\n",
      "episode 2629, reward -82.0, memory_length 2000, epsilon 0.26860859396574055\n",
      "travel time- 721.0\n",
      "--- 1.7692875862121582 seconds ---\n",
      "episode 2630, reward 17.0, memory_length 2000, epsilon 0.2684743232392366\n",
      "travel time- 722.0\n",
      "--- 1.64213228225708 seconds ---\n",
      "episode 2631, reward -121.0, memory_length 2000, epsilon 0.2683401196313148\n",
      "travel time- 722.0\n",
      "--- 1.501321792602539 seconds ---\n",
      "episode 2632, reward -78.0, memory_length 2000, epsilon 0.2682059831084244\n",
      "travel time- 720.0\n",
      "--- 1.619187355041504 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2633, reward -4.0, memory_length 2000, epsilon 0.2680719136370312\n",
      "travel time- 724.0\n",
      "--- 1.3272747993469238 seconds ---\n",
      "episode 2634, reward 511.0, memory_length 2000, epsilon 0.26793791118361776\n",
      "travel time- 720.0\n",
      "--- 1.4706146717071533 seconds ---\n",
      "episode 2635, reward -211.0, memory_length 2000, epsilon 0.26780397571468345\n",
      "travel time- 721.0\n",
      "--- 1.5974407196044922 seconds ---\n",
      "episode 2636, reward -229.0, memory_length 2000, epsilon 0.26767010719674456\n",
      "travel time- 730.0\n",
      "--- 1.6618916988372803 seconds ---\n",
      "episode 2637, reward 95.0, memory_length 2000, epsilon 0.26753630559633385\n",
      "travel time- 729.0\n",
      "--- 1.5858073234558105 seconds ---\n",
      "episode 2638, reward -426.0, memory_length 2000, epsilon 0.2674025708800009\n",
      "travel time- 725.0\n",
      "--- 1.721224069595337 seconds ---\n",
      "episode 2639, reward 58.0, memory_length 2000, epsilon 0.267268903014312\n",
      "travel time- 720.0\n",
      "--- 1.6778581142425537 seconds ---\n",
      "episode 2640, reward 282.0, memory_length 2000, epsilon 0.26713530196585034\n",
      "travel time- 723.0\n",
      "--- 1.6017060279846191 seconds ---\n",
      "episode 2641, reward 111.0, memory_length 2000, epsilon 0.2670017677012156\n",
      "travel time- 720.0\n",
      "--- 1.4824564456939697 seconds ---\n",
      "episode 2642, reward -159.0, memory_length 2000, epsilon 0.2668683001870241\n",
      "travel time- 723.0\n",
      "--- 1.507354736328125 seconds ---\n",
      "episode 2643, reward 84.0, memory_length 2000, epsilon 0.266734899389909\n",
      "travel time- 722.0\n",
      "--- 1.8050713539123535 seconds ---\n",
      "episode 2644, reward -260.0, memory_length 2000, epsilon 0.2666015652765202\n",
      "travel time- 726.0\n",
      "--- 1.714832067489624 seconds ---\n",
      "episode 2645, reward -71.0, memory_length 2000, epsilon 0.2664682978135241\n",
      "travel time- 727.0\n",
      "--- 1.6305482387542725 seconds ---\n",
      "episode 2646, reward 99.0, memory_length 2000, epsilon 0.2663350969676039\n",
      "travel time- 721.0\n",
      "--- 1.5086002349853516 seconds ---\n",
      "episode 2647, reward -100.0, memory_length 2000, epsilon 0.2662019627054592\n",
      "travel time- 730.0\n",
      "--- 1.71309494972229 seconds ---\n",
      "episode 2648, reward -80.0, memory_length 2000, epsilon 0.26606889499380665\n",
      "travel time- 728.0\n",
      "--- 1.5745856761932373 seconds ---\n",
      "episode 2649, reward 128.0, memory_length 2000, epsilon 0.2659358937993792\n",
      "travel time- 721.0\n",
      "--- 1.4121370315551758 seconds ---\n",
      "episode 2650, reward 138.0, memory_length 2000, epsilon 0.2658029590889266\n",
      "travel time- 728.0\n",
      "--- 1.7853834629058838 seconds ---\n",
      "episode 2651, reward -193.0, memory_length 2000, epsilon 0.2656700908292151\n",
      "travel time- 720.0\n",
      "--- 1.717393398284912 seconds ---\n",
      "episode 2652, reward 280.0, memory_length 2000, epsilon 0.2655372889870278\n",
      "travel time- 722.0\n",
      "--- 1.4372622966766357 seconds ---\n",
      "episode 2653, reward 184.0, memory_length 2000, epsilon 0.2654045535291641\n",
      "travel time- 722.0\n",
      "--- 1.4189841747283936 seconds ---\n",
      "episode 2654, reward 47.0, memory_length 2000, epsilon 0.2652718844224401\n",
      "travel time- 724.0\n",
      "--- 1.5565142631530762 seconds ---\n",
      "episode 2655, reward -25.0, memory_length 2000, epsilon 0.2651392816336886\n",
      "travel time- 727.0\n",
      "--- 1.4865846633911133 seconds ---\n",
      "episode 2656, reward -228.0, memory_length 2000, epsilon 0.2650067451297589\n",
      "travel time- 722.0\n",
      "--- 1.833693504333496 seconds ---\n",
      "episode 2657, reward 129.0, memory_length 2000, epsilon 0.2648742748775169\n",
      "travel time- 723.0\n",
      "--- 1.730635404586792 seconds ---\n",
      "episode 2658, reward -200.0, memory_length 2000, epsilon 0.26474187084384504\n",
      "travel time- 720.0\n",
      "--- 1.8110191822052002 seconds ---\n",
      "episode 2659, reward -348.0, memory_length 2000, epsilon 0.26460953299564216\n",
      "travel time- 720.0\n",
      "--- 1.6239948272705078 seconds ---\n",
      "episode 2660, reward 77.0, memory_length 2000, epsilon 0.26447726129982396\n",
      "travel time- 722.0\n",
      "--- 1.769580602645874 seconds ---\n",
      "episode 2661, reward -78.0, memory_length 2000, epsilon 0.26434505572332245\n",
      "travel time- 723.0\n",
      "--- 1.5629010200500488 seconds ---\n",
      "episode 2662, reward 86.0, memory_length 2000, epsilon 0.2642129162330863\n",
      "travel time- 723.0\n",
      "--- 1.631633996963501 seconds ---\n",
      "episode 2663, reward 157.0, memory_length 2000, epsilon 0.26408084279608046\n",
      "travel time- 724.0\n",
      "--- 1.5740573406219482 seconds ---\n",
      "episode 2664, reward -153.0, memory_length 2000, epsilon 0.2639488353792868\n",
      "travel time- 721.0\n",
      "--- 1.6564109325408936 seconds ---\n",
      "episode 2665, reward 110.0, memory_length 2000, epsilon 0.26381689394970337\n",
      "travel time- 728.0\n",
      "--- 1.447624683380127 seconds ---\n",
      "episode 2666, reward -109.0, memory_length 2000, epsilon 0.2636850184743448\n",
      "travel time- 722.0\n",
      "--- 1.4855051040649414 seconds ---\n",
      "episode 2667, reward -234.0, memory_length 2000, epsilon 0.2635532089202421\n",
      "travel time- 723.0\n",
      "--- 1.6982579231262207 seconds ---\n",
      "episode 2668, reward -227.0, memory_length 2000, epsilon 0.2634214652544431\n",
      "travel time- 722.0\n",
      "--- 1.7373311519622803 seconds ---\n",
      "episode 2669, reward 249.0, memory_length 2000, epsilon 0.26328978744401177\n",
      "travel time- 729.0\n",
      "--- 1.6625831127166748 seconds ---\n",
      "episode 2670, reward 189.0, memory_length 2000, epsilon 0.2631581754560287\n",
      "travel time- 720.0\n",
      "--- 1.7296624183654785 seconds ---\n",
      "episode 2671, reward -166.0, memory_length 2000, epsilon 0.2630266292575908\n",
      "travel time- 722.0\n",
      "--- 1.5834786891937256 seconds ---\n",
      "episode 2672, reward -226.0, memory_length 2000, epsilon 0.26289514881581166\n",
      "travel time- 724.0\n",
      "--- 1.4717397689819336 seconds ---\n",
      "episode 2673, reward -116.0, memory_length 2000, epsilon 0.26276373409782106\n",
      "travel time- 724.0\n",
      "--- 1.475193977355957 seconds ---\n",
      "episode 2674, reward 95.0, memory_length 2000, epsilon 0.26263238507076536\n",
      "travel time- 720.0\n",
      "--- 1.7018511295318604 seconds ---\n",
      "episode 2675, reward -31.0, memory_length 2000, epsilon 0.26250110170180724\n",
      "travel time- 724.0\n",
      "--- 1.473742961883545 seconds ---\n",
      "episode 2676, reward -3.0, memory_length 2000, epsilon 0.262369883958126\n",
      "travel time- 721.0\n",
      "--- 1.4526746273040771 seconds ---\n",
      "episode 2677, reward 260.0, memory_length 2000, epsilon 0.2622387318069171\n",
      "travel time- 721.0\n",
      "--- 1.5377776622772217 seconds ---\n",
      "episode 2678, reward -161.0, memory_length 2000, epsilon 0.2621076452153925\n",
      "travel time- 729.0\n",
      "--- 1.6337578296661377 seconds ---\n",
      "episode 2679, reward 124.0, memory_length 2000, epsilon 0.2619766241507805\n",
      "travel time- 722.0\n",
      "--- 1.5852556228637695 seconds ---\n",
      "episode 2680, reward -366.0, memory_length 2000, epsilon 0.261845668580326\n",
      "travel time- 721.0\n",
      "--- 1.7203693389892578 seconds ---\n",
      "episode 2681, reward -230.0, memory_length 2000, epsilon 0.26171477847129\n",
      "travel time- 727.0\n",
      "--- 1.6462681293487549 seconds ---\n",
      "episode 2682, reward 52.0, memory_length 2000, epsilon 0.26158395379094995\n",
      "travel time- 724.0\n",
      "--- 1.5895800590515137 seconds ---\n",
      "episode 2683, reward 185.0, memory_length 2000, epsilon 0.26145319450659965\n",
      "travel time- 733.0\n",
      "--- 1.6245512962341309 seconds ---\n",
      "episode 2684, reward -54.0, memory_length 2000, epsilon 0.2613225005855494\n",
      "travel time- 721.0\n",
      "--- 1.913623332977295 seconds ---\n",
      "episode 2685, reward -352.0, memory_length 2000, epsilon 0.26119187199512567\n",
      "travel time- 727.0\n",
      "--- 1.6092545986175537 seconds ---\n",
      "episode 2686, reward -302.0, memory_length 2000, epsilon 0.2610613087026713\n",
      "travel time- 721.0\n",
      "--- 1.594111442565918 seconds ---\n",
      "episode 2687, reward -254.0, memory_length 2000, epsilon 0.2609308106755454\n",
      "travel time- 734.0\n",
      "--- 1.4348101615905762 seconds ---\n",
      "episode 2688, reward 78.0, memory_length 2000, epsilon 0.26080037788112365\n",
      "travel time- 723.0\n",
      "--- 1.7158164978027344 seconds ---\n",
      "episode 2689, reward -66.0, memory_length 2000, epsilon 0.26067001028679765\n",
      "travel time- 720.0\n",
      "--- 1.6829326152801514 seconds ---\n",
      "episode 2690, reward -279.0, memory_length 2000, epsilon 0.2605397078599756\n",
      "travel time- 728.0\n",
      "--- 1.6697864532470703 seconds ---\n",
      "episode 2691, reward 133.0, memory_length 2000, epsilon 0.2604094705680819\n",
      "travel time- 725.0\n",
      "--- 1.4553749561309814 seconds ---\n",
      "episode 2692, reward -298.0, memory_length 2000, epsilon 0.2602792983785571\n",
      "travel time- 720.0\n",
      "--- 1.5971150398254395 seconds ---\n",
      "episode 2693, reward -201.0, memory_length 2000, epsilon 0.2601491912588583\n",
      "travel time- 724.0\n",
      "--- 1.6617839336395264 seconds ---\n",
      "episode 2694, reward -139.0, memory_length 2000, epsilon 0.26001914917645874\n",
      "travel time- 728.0\n",
      "--- 1.5753059387207031 seconds ---\n",
      "episode 2695, reward 148.0, memory_length 2000, epsilon 0.25988917209884776\n",
      "travel time- 728.0\n",
      "--- 1.6770079135894775 seconds ---\n",
      "episode 2696, reward -83.0, memory_length 2000, epsilon 0.2597592599935311\n",
      "travel time- 722.0\n",
      "--- 1.7012996673583984 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2697, reward 253.0, memory_length 2000, epsilon 0.2596294128280309\n",
      "travel time- 720.0\n",
      "--- 1.477961540222168 seconds ---\n",
      "episode 2698, reward -344.0, memory_length 2000, epsilon 0.25949963056988523\n",
      "travel time- 721.0\n",
      "--- 1.8642909526824951 seconds ---\n",
      "episode 2699, reward 4.0, memory_length 2000, epsilon 0.2593699131866486\n",
      "travel time- 725.0\n",
      "--- 1.372610330581665 seconds ---\n",
      "episode 2700, reward 126.0, memory_length 2000, epsilon 0.2592402606458915\n",
      "travel time- 722.0\n",
      "--- 1.5728740692138672 seconds ---\n",
      "episode 2701, reward -213.0, memory_length 2000, epsilon 0.25911067291520096\n",
      "travel time- 721.0\n",
      "--- 1.5699059963226318 seconds ---\n",
      "episode 2702, reward 88.0, memory_length 2000, epsilon 0.25898114996218\n",
      "travel time- 726.0\n",
      "--- 1.6534233093261719 seconds ---\n",
      "episode 2703, reward 83.0, memory_length 2000, epsilon 0.25885169175444794\n",
      "travel time- 724.0\n",
      "--- 1.6218276023864746 seconds ---\n",
      "episode 2704, reward 97.0, memory_length 2000, epsilon 0.25872229825964005\n",
      "travel time- 721.0\n",
      "--- 1.5395915508270264 seconds ---\n",
      "episode 2705, reward 16.0, memory_length 2000, epsilon 0.25859296944540816\n",
      "travel time- 723.0\n",
      "--- 1.8166570663452148 seconds ---\n",
      "episode 2706, reward -211.0, memory_length 2000, epsilon 0.25846370527942\n",
      "travel time- 722.0\n",
      "--- 1.6030571460723877 seconds ---\n",
      "episode 2707, reward 69.0, memory_length 2000, epsilon 0.25833450572935945\n",
      "travel time- 723.0\n",
      "--- 1.5616753101348877 seconds ---\n",
      "episode 2708, reward -356.0, memory_length 2000, epsilon 0.25820537076292666\n",
      "travel time- 720.0\n",
      "--- 1.857666254043579 seconds ---\n",
      "episode 2709, reward 4.0, memory_length 2000, epsilon 0.25807630034783796\n",
      "travel time- 723.0\n",
      "--- 1.5329787731170654 seconds ---\n",
      "episode 2710, reward -131.0, memory_length 2000, epsilon 0.2579472944518257\n",
      "travel time- 723.0\n",
      "--- 1.826355218887329 seconds ---\n",
      "episode 2711, reward -181.0, memory_length 2000, epsilon 0.25781835304263834\n",
      "travel time- 727.0\n",
      "--- 1.409447431564331 seconds ---\n",
      "episode 2712, reward 87.0, memory_length 2000, epsilon 0.25768947608804055\n",
      "travel time- 720.0\n",
      "--- 1.455336093902588 seconds ---\n",
      "episode 2713, reward -214.0, memory_length 2000, epsilon 0.2575606635558132\n",
      "travel time- 725.0\n",
      "--- 1.7633962631225586 seconds ---\n",
      "episode 2714, reward -107.0, memory_length 2000, epsilon 0.2574319154137531\n",
      "travel time- 725.0\n",
      "--- 1.580822229385376 seconds ---\n",
      "episode 2715, reward -218.0, memory_length 2000, epsilon 0.25730323162967317\n",
      "travel time- 720.0\n",
      "--- 1.8548214435577393 seconds ---\n",
      "episode 2716, reward 225.0, memory_length 2000, epsilon 0.2571746121714024\n",
      "travel time- 722.0\n",
      "--- 1.4503552913665771 seconds ---\n",
      "episode 2717, reward 53.0, memory_length 2000, epsilon 0.2570460570067861\n",
      "travel time- 722.0\n",
      "--- 1.5087716579437256 seconds ---\n",
      "episode 2718, reward 25.0, memory_length 2000, epsilon 0.25691756610368544\n",
      "travel time- 721.0\n",
      "--- 1.6025283336639404 seconds ---\n",
      "episode 2719, reward -13.0, memory_length 2000, epsilon 0.25678913942997755\n",
      "travel time- 722.0\n",
      "--- 1.6632089614868164 seconds ---\n",
      "episode 2720, reward 318.0, memory_length 2000, epsilon 0.2566607769535559\n",
      "travel time- 724.0\n",
      "--- 1.4039297103881836 seconds ---\n",
      "episode 2721, reward 33.0, memory_length 2000, epsilon 0.25653247864232975\n",
      "travel time- 728.0\n",
      "--- 1.4434528350830078 seconds ---\n",
      "episode 2722, reward 54.0, memory_length 2000, epsilon 0.2564042444642247\n",
      "travel time- 724.0\n",
      "--- 1.4325544834136963 seconds ---\n",
      "episode 2723, reward -400.0, memory_length 2000, epsilon 0.2562760743871821\n",
      "travel time- 721.0\n",
      "--- 1.5844645500183105 seconds ---\n",
      "episode 2724, reward 66.0, memory_length 2000, epsilon 0.2561479683791593\n",
      "travel time- 721.0\n",
      "--- 1.6651179790496826 seconds ---\n",
      "episode 2725, reward -16.0, memory_length 2000, epsilon 0.25601992640813004\n",
      "travel time- 723.0\n",
      "--- 1.472611904144287 seconds ---\n",
      "episode 2726, reward -274.0, memory_length 2000, epsilon 0.25589194844208374\n",
      "travel time- 720.0\n",
      "--- 1.5300977230072021 seconds ---\n",
      "episode 2727, reward 169.0, memory_length 2000, epsilon 0.25576403444902585\n",
      "travel time- 723.0\n",
      "--- 1.5602314472198486 seconds ---\n",
      "episode 2728, reward 309.0, memory_length 2000, epsilon 0.25563618439697783\n",
      "travel time- 722.0\n",
      "--- 1.4839105606079102 seconds ---\n",
      "episode 2729, reward -64.0, memory_length 2000, epsilon 0.2555083982539773\n",
      "travel time- 725.0\n",
      "--- 1.6036083698272705 seconds ---\n",
      "episode 2730, reward -365.0, memory_length 2000, epsilon 0.2553806759880777\n",
      "travel time- 723.0\n",
      "--- 1.665196180343628 seconds ---\n",
      "episode 2731, reward -1.0, memory_length 2000, epsilon 0.2552530175673484\n",
      "travel time- 727.0\n",
      "--- 1.5327110290527344 seconds ---\n",
      "episode 2732, reward -117.0, memory_length 2000, epsilon 0.2551254229598748\n",
      "travel time- 720.0\n",
      "--- 1.8035087585449219 seconds ---\n",
      "episode 2733, reward -18.0, memory_length 2000, epsilon 0.2549978921337583\n",
      "travel time- 733.0\n",
      "--- 1.6877732276916504 seconds ---\n",
      "episode 2734, reward 234.0, memory_length 2000, epsilon 0.25487042505711616\n",
      "travel time- 721.0\n",
      "--- 1.3734290599822998 seconds ---\n",
      "episode 2735, reward -21.0, memory_length 2000, epsilon 0.2547430216980816\n",
      "travel time- 724.0\n",
      "--- 1.8157672882080078 seconds ---\n",
      "episode 2736, reward 214.0, memory_length 2000, epsilon 0.2546156820248037\n",
      "travel time- 731.0\n",
      "--- 1.513845682144165 seconds ---\n",
      "episode 2737, reward -128.0, memory_length 2000, epsilon 0.25448840600544775\n",
      "travel time- 732.0\n",
      "--- 1.7782111167907715 seconds ---\n",
      "episode 2738, reward 285.0, memory_length 2000, epsilon 0.25436119360819465\n",
      "travel time- 724.0\n",
      "--- 1.571582555770874 seconds ---\n",
      "episode 2739, reward -26.0, memory_length 2000, epsilon 0.25423404480124123\n",
      "travel time- 721.0\n",
      "--- 1.5869855880737305 seconds ---\n",
      "episode 2740, reward 93.0, memory_length 2000, epsilon 0.25410695955280027\n",
      "travel time- 721.0\n",
      "--- 1.5504491329193115 seconds ---\n",
      "episode 2741, reward 193.0, memory_length 2000, epsilon 0.2539799378311006\n",
      "travel time- 723.0\n",
      "--- 1.7485098838806152 seconds ---\n",
      "episode 2742, reward -139.0, memory_length 2000, epsilon 0.2538529796043867\n",
      "travel time- 723.0\n",
      "--- 1.7449665069580078 seconds ---\n",
      "episode 2743, reward 215.0, memory_length 2000, epsilon 0.253726084840919\n",
      "travel time- 724.0\n",
      "--- 1.675318956375122 seconds ---\n",
      "episode 2744, reward 75.0, memory_length 2000, epsilon 0.25359925350897383\n",
      "travel time- 729.0\n",
      "--- 1.6529853343963623 seconds ---\n",
      "episode 2745, reward -144.0, memory_length 2000, epsilon 0.2534724855768434\n",
      "travel time- 721.0\n",
      "--- 1.6023640632629395 seconds ---\n",
      "episode 2746, reward -82.0, memory_length 2000, epsilon 0.25334578101283567\n",
      "travel time- 725.0\n",
      "--- 1.8258707523345947 seconds ---\n",
      "episode 2747, reward 155.0, memory_length 2000, epsilon 0.2532191397852745\n",
      "travel time- 726.0\n",
      "--- 1.5629093647003174 seconds ---\n",
      "episode 2748, reward -386.0, memory_length 2000, epsilon 0.25309256186249957\n",
      "travel time- 728.0\n",
      "--- 1.6396327018737793 seconds ---\n",
      "episode 2749, reward -158.0, memory_length 2000, epsilon 0.2529660472128665\n",
      "travel time- 720.0\n",
      "--- 1.358076810836792 seconds ---\n",
      "episode 2750, reward -252.0, memory_length 2000, epsilon 0.25283959580474646\n",
      "travel time- 722.0\n",
      "--- 1.5465407371520996 seconds ---\n",
      "episode 2751, reward -12.0, memory_length 2000, epsilon 0.25271320760652677\n",
      "travel time- 720.0\n",
      "--- 1.744722604751587 seconds ---\n",
      "episode 2752, reward 92.0, memory_length 2000, epsilon 0.2525868825866102\n",
      "travel time- 724.0\n",
      "--- 1.7035768032073975 seconds ---\n",
      "episode 2753, reward -131.0, memory_length 2000, epsilon 0.2524606207134157\n",
      "travel time- 722.0\n",
      "--- 1.7030448913574219 seconds ---\n",
      "episode 2754, reward -27.0, memory_length 2000, epsilon 0.25233442195537764\n",
      "travel time- 723.0\n",
      "--- 1.5867927074432373 seconds ---\n",
      "episode 2755, reward -252.0, memory_length 2000, epsilon 0.2522082862809464\n",
      "travel time- 727.0\n",
      "--- 1.6129851341247559 seconds ---\n",
      "episode 2756, reward -268.0, memory_length 2000, epsilon 0.25208221365858796\n",
      "travel time- 726.0\n",
      "--- 1.64400315284729 seconds ---\n",
      "episode 2757, reward -211.0, memory_length 2000, epsilon 0.2519562040567843\n",
      "travel time- 721.0\n",
      "--- 1.634214162826538 seconds ---\n",
      "episode 2758, reward 85.0, memory_length 2000, epsilon 0.25183025744403303\n",
      "travel time- 728.0\n",
      "--- 1.3480217456817627 seconds ---\n",
      "episode 2759, reward -251.0, memory_length 2000, epsilon 0.2517043737888474\n",
      "travel time- 721.0\n",
      "--- 1.918339490890503 seconds ---\n",
      "episode 2760, reward 146.0, memory_length 2000, epsilon 0.25157855305975646\n",
      "travel time- 725.0\n",
      "--- 1.7455930709838867 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2761, reward -194.0, memory_length 2000, epsilon 0.25145279522530517\n",
      "travel time- 722.0\n",
      "--- 1.5657079219818115 seconds ---\n",
      "episode 2762, reward 200.0, memory_length 2000, epsilon 0.251327100254054\n",
      "travel time- 731.0\n",
      "--- 1.7688875198364258 seconds ---\n",
      "episode 2763, reward -97.0, memory_length 2000, epsilon 0.2512014681145792\n",
      "travel time- 724.0\n",
      "--- 1.7396328449249268 seconds ---\n",
      "episode 2764, reward 47.0, memory_length 2000, epsilon 0.25107589877547265\n",
      "travel time- 720.0\n",
      "--- 1.4196255207061768 seconds ---\n",
      "episode 2765, reward 58.0, memory_length 2000, epsilon 0.2509503922053422\n",
      "travel time- 726.0\n",
      "--- 1.7762856483459473 seconds ---\n",
      "episode 2766, reward -156.0, memory_length 2000, epsilon 0.2508249483728111\n",
      "travel time- 725.0\n",
      "--- 1.7752039432525635 seconds ---\n",
      "episode 2767, reward 125.0, memory_length 2000, epsilon 0.2506995672465184\n",
      "travel time- 727.0\n",
      "--- 1.6066689491271973 seconds ---\n",
      "episode 2768, reward 193.0, memory_length 2000, epsilon 0.25057424879511875\n",
      "travel time- 729.0\n",
      "--- 1.6424336433410645 seconds ---\n",
      "episode 2769, reward 16.0, memory_length 2000, epsilon 0.2504489929872826\n",
      "travel time- 730.0\n",
      "--- 1.6495060920715332 seconds ---\n",
      "episode 2770, reward -70.0, memory_length 2000, epsilon 0.2503237997916961\n",
      "travel time- 729.0\n",
      "--- 1.5540597438812256 seconds ---\n",
      "episode 2771, reward 165.0, memory_length 2000, epsilon 0.2501986691770608\n",
      "travel time- 720.0\n",
      "--- 1.6176769733428955 seconds ---\n",
      "episode 2772, reward -105.0, memory_length 2000, epsilon 0.2500736011120941\n",
      "travel time- 721.0\n",
      "--- 1.5045173168182373 seconds ---\n",
      "episode 2773, reward -304.0, memory_length 2000, epsilon 0.24994859556552895\n",
      "travel time- 731.0\n",
      "--- 1.6826176643371582 seconds ---\n",
      "episode 2774, reward 209.0, memory_length 2000, epsilon 0.24982365250611405\n",
      "travel time- 727.0\n",
      "--- 1.5505919456481934 seconds ---\n",
      "episode 2775, reward -66.0, memory_length 2000, epsilon 0.24969877190261355\n",
      "travel time- 726.0\n",
      "--- 1.7938039302825928 seconds ---\n",
      "episode 2776, reward 179.0, memory_length 2000, epsilon 0.24957395372380728\n",
      "travel time- 720.0\n",
      "--- 1.389887809753418 seconds ---\n",
      "episode 2777, reward 216.0, memory_length 2000, epsilon 0.2494491979384908\n",
      "travel time- 720.0\n",
      "--- 1.6456432342529297 seconds ---\n",
      "episode 2778, reward -154.0, memory_length 2000, epsilon 0.2493245045154751\n",
      "travel time- 728.0\n",
      "--- 1.5679402351379395 seconds ---\n",
      "episode 2779, reward -102.0, memory_length 2000, epsilon 0.24919987342358682\n",
      "travel time- 723.0\n",
      "--- 1.6975553035736084 seconds ---\n",
      "episode 2780, reward 5.0, memory_length 2000, epsilon 0.24907530463166816\n",
      "travel time- 722.0\n",
      "--- 1.7024743556976318 seconds ---\n",
      "episode 2781, reward 223.0, memory_length 2000, epsilon 0.24895079810857698\n",
      "travel time- 725.0\n",
      "--- 1.7310762405395508 seconds ---\n",
      "episode 2782, reward 152.0, memory_length 2000, epsilon 0.24882635382318666\n",
      "travel time- 729.0\n",
      "--- 1.702502965927124 seconds ---\n",
      "episode 2783, reward -13.0, memory_length 2000, epsilon 0.24870197174438607\n",
      "travel time- 724.0\n",
      "--- 1.6084606647491455 seconds ---\n",
      "episode 2784, reward 27.0, memory_length 2000, epsilon 0.24857765184107966\n",
      "travel time- 721.0\n",
      "--- 1.3176822662353516 seconds ---\n",
      "episode 2785, reward -104.0, memory_length 2000, epsilon 0.24845339408218756\n",
      "travel time- 720.0\n",
      "--- 1.514047622680664 seconds ---\n",
      "episode 2786, reward -70.0, memory_length 2000, epsilon 0.24832919843664528\n",
      "travel time- 726.0\n",
      "--- 1.614659309387207 seconds ---\n",
      "episode 2787, reward -309.0, memory_length 2000, epsilon 0.24820506487340388\n",
      "travel time- 723.0\n",
      "--- 1.452538251876831 seconds ---\n",
      "episode 2788, reward 27.0, memory_length 2000, epsilon 0.24808099336142997\n",
      "travel time- 722.0\n",
      "--- 1.4909284114837646 seconds ---\n",
      "episode 2789, reward -175.0, memory_length 2000, epsilon 0.24795698386970572\n",
      "travel time- 721.0\n",
      "--- 1.7827892303466797 seconds ---\n",
      "episode 2790, reward 33.0, memory_length 2000, epsilon 0.24783303636722875\n",
      "travel time- 720.0\n",
      "--- 1.5839192867279053 seconds ---\n",
      "episode 2791, reward 112.0, memory_length 2000, epsilon 0.24770915082301215\n",
      "travel time- 724.0\n",
      "--- 1.4972918033599854 seconds ---\n",
      "episode 2792, reward 48.0, memory_length 2000, epsilon 0.2475853272060845\n",
      "travel time- 723.0\n",
      "--- 1.5636317729949951 seconds ---\n",
      "episode 2793, reward -217.0, memory_length 2000, epsilon 0.24746156548548998\n",
      "travel time- 728.0\n",
      "--- 1.7005503177642822 seconds ---\n",
      "episode 2794, reward 340.0, memory_length 2000, epsilon 0.24733786563028812\n",
      "travel time- 722.0\n",
      "--- 1.5163652896881104 seconds ---\n",
      "episode 2795, reward -44.0, memory_length 2000, epsilon 0.24721422760955397\n",
      "travel time- 727.0\n",
      "--- 1.4960544109344482 seconds ---\n",
      "episode 2796, reward -134.0, memory_length 2000, epsilon 0.24709065139237796\n",
      "travel time- 721.0\n",
      "--- 1.640397548675537 seconds ---\n",
      "episode 2797, reward 58.0, memory_length 2000, epsilon 0.24696713694786612\n",
      "travel time- 724.0\n",
      "--- 1.6474864482879639 seconds ---\n",
      "episode 2798, reward 76.0, memory_length 2000, epsilon 0.24684368424513983\n",
      "travel time- 724.0\n",
      "--- 1.4132812023162842 seconds ---\n",
      "episode 2799, reward -246.0, memory_length 2000, epsilon 0.24672029325333586\n",
      "travel time- 721.0\n",
      "--- 1.5202925205230713 seconds ---\n",
      "episode 2800, reward 123.0, memory_length 2000, epsilon 0.24659696394160643\n",
      "travel time- 729.0\n",
      "--- 1.5978929996490479 seconds ---\n",
      "episode 2801, reward -145.0, memory_length 2000, epsilon 0.24647369627911936\n",
      "travel time- 722.0\n",
      "--- 1.4088020324707031 seconds ---\n",
      "episode 2802, reward -140.0, memory_length 2000, epsilon 0.24635049023505762\n",
      "travel time- 728.0\n",
      "--- 1.4490816593170166 seconds ---\n",
      "episode 2803, reward 48.0, memory_length 2000, epsilon 0.2462273457786197\n",
      "travel time- 723.0\n",
      "--- 1.6269474029541016 seconds ---\n",
      "episode 2804, reward -3.0, memory_length 2000, epsilon 0.2461042628790195\n",
      "travel time- 725.0\n",
      "--- 1.7905526161193848 seconds ---\n",
      "episode 2805, reward -101.0, memory_length 2000, epsilon 0.24598124150548634\n",
      "travel time- 725.0\n",
      "--- 1.5560531616210938 seconds ---\n",
      "episode 2806, reward -266.0, memory_length 2000, epsilon 0.2458582816272648\n",
      "travel time- 727.0\n",
      "--- 1.7033426761627197 seconds ---\n",
      "episode 2807, reward -34.0, memory_length 2000, epsilon 0.245735383213615\n",
      "travel time- 722.0\n",
      "--- 1.6483581066131592 seconds ---\n",
      "episode 2808, reward -85.0, memory_length 2000, epsilon 0.2456125462338122\n",
      "travel time- 732.0\n",
      "--- 1.4769039154052734 seconds ---\n",
      "episode 2809, reward 92.0, memory_length 2000, epsilon 0.2454897706571473\n",
      "travel time- 722.0\n",
      "--- 1.5462744235992432 seconds ---\n",
      "episode 2810, reward -178.0, memory_length 2000, epsilon 0.24536705645292634\n",
      "travel time- 725.0\n",
      "--- 1.5345306396484375 seconds ---\n",
      "episode 2811, reward 30.0, memory_length 2000, epsilon 0.24524440359047078\n",
      "travel time- 727.0\n",
      "--- 1.4809746742248535 seconds ---\n",
      "episode 2812, reward 101.0, memory_length 2000, epsilon 0.24512181203911731\n",
      "travel time- 722.0\n",
      "--- 1.6019604206085205 seconds ---\n",
      "episode 2813, reward -76.0, memory_length 2000, epsilon 0.24499928176821822\n",
      "travel time- 723.0\n",
      "--- 1.6485121250152588 seconds ---\n",
      "episode 2814, reward -8.0, memory_length 2000, epsilon 0.24487681274714082\n",
      "travel time- 723.0\n",
      "--- 1.601649284362793 seconds ---\n",
      "episode 2815, reward 135.0, memory_length 2000, epsilon 0.2447544049452679\n",
      "travel time- 727.0\n",
      "--- 1.480255126953125 seconds ---\n",
      "episode 2816, reward 59.0, memory_length 2000, epsilon 0.2446320583319975\n",
      "travel time- 724.0\n",
      "--- 1.518935203552246 seconds ---\n",
      "episode 2817, reward -216.0, memory_length 2000, epsilon 0.2445097728767429\n",
      "travel time- 728.0\n",
      "--- 1.3817291259765625 seconds ---\n",
      "episode 2818, reward -80.0, memory_length 2000, epsilon 0.2443875485489328\n",
      "travel time- 723.0\n",
      "--- 1.626236915588379 seconds ---\n",
      "episode 2819, reward -367.0, memory_length 2000, epsilon 0.24426538531801115\n",
      "travel time- 733.0\n",
      "--- 1.4736137390136719 seconds ---\n",
      "episode 2820, reward 15.0, memory_length 2000, epsilon 0.2441432831534371\n",
      "travel time- 722.0\n",
      "--- 1.725417137145996 seconds ---\n",
      "episode 2821, reward 106.0, memory_length 2000, epsilon 0.24402124202468506\n",
      "travel time- 728.0\n",
      "--- 1.575314998626709 seconds ---\n",
      "episode 2822, reward 22.0, memory_length 2000, epsilon 0.24389926190124483\n",
      "travel time- 727.0\n",
      "--- 1.566220760345459 seconds ---\n",
      "episode 2823, reward 22.0, memory_length 2000, epsilon 0.24377734275262136\n",
      "travel time- 727.0\n",
      "--- 1.4628520011901855 seconds ---\n",
      "episode 2824, reward 49.0, memory_length 2000, epsilon 0.24365548454833486\n",
      "travel time- 721.0\n",
      "--- 1.5643749237060547 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2825, reward 252.0, memory_length 2000, epsilon 0.24353368725792068\n",
      "travel time- 723.0\n",
      "--- 1.7038195133209229 seconds ---\n",
      "episode 2826, reward -24.0, memory_length 2000, epsilon 0.24341195085092968\n",
      "travel time- 720.0\n",
      "--- 1.4492673873901367 seconds ---\n",
      "episode 2827, reward -97.0, memory_length 2000, epsilon 0.24329027529692762\n",
      "travel time- 724.0\n",
      "--- 1.6118156909942627 seconds ---\n",
      "episode 2828, reward -71.0, memory_length 2000, epsilon 0.24316866056549566\n",
      "travel time- 721.0\n",
      "--- 1.71669602394104 seconds ---\n",
      "episode 2829, reward 20.0, memory_length 2000, epsilon 0.24304710662623008\n",
      "travel time- 724.0\n",
      "--- 1.84751296043396 seconds ---\n",
      "episode 2830, reward 34.0, memory_length 2000, epsilon 0.24292561344874244\n",
      "travel time- 722.0\n",
      "--- 1.7887756824493408 seconds ---\n",
      "episode 2831, reward -234.0, memory_length 2000, epsilon 0.24280418100265946\n",
      "travel time- 726.0\n",
      "--- 1.6706535816192627 seconds ---\n",
      "episode 2832, reward 62.0, memory_length 2000, epsilon 0.24268280925762298\n",
      "travel time- 726.0\n",
      "--- 1.6649169921875 seconds ---\n",
      "episode 2833, reward 220.0, memory_length 2000, epsilon 0.24256149818329004\n",
      "travel time- 725.0\n",
      "--- 1.6234710216522217 seconds ---\n",
      "episode 2834, reward 95.0, memory_length 2000, epsilon 0.24244024774933293\n",
      "travel time- 724.0\n",
      "--- 1.7390668392181396 seconds ---\n",
      "episode 2835, reward 361.0, memory_length 2000, epsilon 0.24231905792543904\n",
      "travel time- 731.0\n",
      "--- 1.4702301025390625 seconds ---\n",
      "episode 2836, reward 118.0, memory_length 2000, epsilon 0.2421979286813109\n",
      "travel time- 726.0\n",
      "--- 1.427809238433838 seconds ---\n",
      "episode 2837, reward -45.0, memory_length 2000, epsilon 0.24207685998666612\n",
      "travel time- 721.0\n",
      "--- 1.4312143325805664 seconds ---\n",
      "episode 2838, reward -76.0, memory_length 2000, epsilon 0.24195585181123766\n",
      "travel time- 720.0\n",
      "--- 1.772190809249878 seconds ---\n",
      "episode 2839, reward -115.0, memory_length 2000, epsilon 0.2418349041247734\n",
      "travel time- 730.0\n",
      "--- 1.3818745613098145 seconds ---\n",
      "episode 2840, reward 36.0, memory_length 2000, epsilon 0.24171401689703645\n",
      "travel time- 722.0\n",
      "--- 1.648634433746338 seconds ---\n",
      "episode 2841, reward 203.0, memory_length 2000, epsilon 0.24159319009780494\n",
      "travel time- 727.0\n",
      "--- 1.6991832256317139 seconds ---\n",
      "episode 2842, reward -171.0, memory_length 2000, epsilon 0.24147242369687225\n",
      "travel time- 722.0\n",
      "--- 1.6897644996643066 seconds ---\n",
      "episode 2843, reward 44.0, memory_length 2000, epsilon 0.24135171766404673\n",
      "travel time- 722.0\n",
      "--- 1.7226312160491943 seconds ---\n",
      "episode 2844, reward -144.0, memory_length 2000, epsilon 0.24123107196915192\n",
      "travel time- 720.0\n",
      "--- 1.6653108596801758 seconds ---\n",
      "episode 2845, reward -117.0, memory_length 2000, epsilon 0.24111048658202627\n",
      "travel time- 724.0\n",
      "--- 1.5569393634796143 seconds ---\n",
      "episode 2846, reward -127.0, memory_length 2000, epsilon 0.24098996147252358\n",
      "travel time- 723.0\n",
      "--- 1.511378526687622 seconds ---\n",
      "episode 2847, reward 206.0, memory_length 2000, epsilon 0.24086949661051252\n",
      "travel time- 720.0\n",
      "--- 1.3534934520721436 seconds ---\n",
      "episode 2848, reward -281.0, memory_length 2000, epsilon 0.24074909196587688\n",
      "travel time- 722.0\n",
      "--- 1.5498852729797363 seconds ---\n",
      "episode 2849, reward 49.0, memory_length 2000, epsilon 0.2406287475085154\n",
      "travel time- 724.0\n",
      "--- 1.4770331382751465 seconds ---\n",
      "episode 2850, reward 26.0, memory_length 2000, epsilon 0.24050846320834213\n",
      "travel time- 722.0\n",
      "--- 1.436575174331665 seconds ---\n",
      "episode 2851, reward -198.0, memory_length 2000, epsilon 0.2403882390352859\n",
      "travel time- 720.0\n",
      "--- 1.7605986595153809 seconds ---\n",
      "episode 2852, reward 70.0, memory_length 2000, epsilon 0.2402680749592907\n",
      "travel time- 721.0\n",
      "--- 1.6077923774719238 seconds ---\n",
      "episode 2853, reward 145.0, memory_length 2000, epsilon 0.24014797095031543\n",
      "travel time- 727.0\n",
      "--- 1.6688952445983887 seconds ---\n",
      "episode 2854, reward -101.0, memory_length 2000, epsilon 0.2400279269783342\n",
      "travel time- 721.0\n",
      "--- 1.6368191242218018 seconds ---\n",
      "episode 2855, reward 111.0, memory_length 2000, epsilon 0.23990794301333596\n",
      "travel time- 723.0\n",
      "--- 1.382781982421875 seconds ---\n",
      "episode 2856, reward 54.0, memory_length 2000, epsilon 0.2397880190253247\n",
      "travel time- 735.0\n",
      "--- 1.7426397800445557 seconds ---\n",
      "episode 2857, reward -312.0, memory_length 2000, epsilon 0.23966815498431943\n",
      "travel time- 728.0\n",
      "--- 1.7085785865783691 seconds ---\n",
      "episode 2858, reward 85.0, memory_length 2000, epsilon 0.2395483508603542\n",
      "travel time- 722.0\n",
      "--- 1.6681804656982422 seconds ---\n",
      "episode 2859, reward -43.0, memory_length 2000, epsilon 0.23942860662347792\n",
      "travel time- 723.0\n",
      "--- 1.6314709186553955 seconds ---\n",
      "episode 2860, reward -303.0, memory_length 2000, epsilon 0.23930892224375455\n",
      "travel time- 725.0\n",
      "--- 1.6531150341033936 seconds ---\n",
      "episode 2861, reward 52.0, memory_length 2000, epsilon 0.23918929769126293\n",
      "travel time- 722.0\n",
      "--- 1.7054762840270996 seconds ---\n",
      "episode 2862, reward -137.0, memory_length 2000, epsilon 0.23906973293609704\n",
      "travel time- 721.0\n",
      "--- 1.7550573348999023 seconds ---\n",
      "episode 2863, reward -103.0, memory_length 2000, epsilon 0.23895022794836562\n",
      "travel time- 721.0\n",
      "--- 1.5792956352233887 seconds ---\n",
      "episode 2864, reward 13.0, memory_length 2000, epsilon 0.23883078269819244\n",
      "travel time- 723.0\n",
      "--- 1.5779399871826172 seconds ---\n",
      "episode 2865, reward 229.0, memory_length 2000, epsilon 0.23871139715571613\n",
      "travel time- 725.0\n",
      "--- 1.4590058326721191 seconds ---\n",
      "episode 2866, reward -117.0, memory_length 2000, epsilon 0.2385920712910904\n",
      "travel time- 727.0\n",
      "--- 1.596625566482544 seconds ---\n",
      "episode 2867, reward -253.0, memory_length 2000, epsilon 0.2384728050744837\n",
      "travel time- 725.0\n",
      "--- 1.6117193698883057 seconds ---\n",
      "episode 2868, reward -16.0, memory_length 2000, epsilon 0.23835359847607956\n",
      "travel time- 720.0\n",
      "--- 1.571964979171753 seconds ---\n",
      "episode 2869, reward -41.0, memory_length 2000, epsilon 0.23823445146607622\n",
      "travel time- 725.0\n",
      "--- 1.5452382564544678 seconds ---\n",
      "episode 2870, reward -316.0, memory_length 2000, epsilon 0.23811536401468703\n",
      "travel time- 720.0\n",
      "--- 1.5439834594726562 seconds ---\n",
      "episode 2871, reward -215.0, memory_length 2000, epsilon 0.23799633609214008\n",
      "travel time- 722.0\n",
      "--- 1.5307583808898926 seconds ---\n",
      "episode 2872, reward 175.0, memory_length 2000, epsilon 0.2378773676686784\n",
      "travel time- 722.0\n",
      "--- 1.573167324066162 seconds ---\n",
      "episode 2873, reward -139.0, memory_length 2000, epsilon 0.2377584587145598\n",
      "travel time- 723.0\n",
      "--- 1.4035303592681885 seconds ---\n",
      "episode 2874, reward -227.0, memory_length 2000, epsilon 0.2376396092000572\n",
      "travel time- 725.0\n",
      "--- 1.719146490097046 seconds ---\n",
      "episode 2875, reward 80.0, memory_length 2000, epsilon 0.23752081909545814\n",
      "travel time- 720.0\n",
      "--- 1.5972301959991455 seconds ---\n",
      "episode 2876, reward 27.0, memory_length 2000, epsilon 0.23740208837106508\n",
      "travel time- 725.0\n",
      "--- 1.6586863994598389 seconds ---\n",
      "episode 2877, reward 0.0, memory_length 2000, epsilon 0.2372834169971953\n",
      "travel time- 721.0\n",
      "--- 1.6388015747070312 seconds ---\n",
      "episode 2878, reward 146.0, memory_length 2000, epsilon 0.23716480494418105\n",
      "travel time- 724.0\n",
      "--- 1.3732469081878662 seconds ---\n",
      "episode 2879, reward -29.0, memory_length 2000, epsilon 0.23704625218236927\n",
      "travel time- 720.0\n",
      "--- 1.6740696430206299 seconds ---\n",
      "episode 2880, reward 267.0, memory_length 2000, epsilon 0.23692775868212176\n",
      "travel time- 721.0\n",
      "--- 1.584479808807373 seconds ---\n",
      "episode 2881, reward -263.0, memory_length 2000, epsilon 0.23680932441381514\n",
      "travel time- 721.0\n",
      "--- 1.3951983451843262 seconds ---\n",
      "episode 2882, reward 6.0, memory_length 2000, epsilon 0.23669094934784088\n",
      "travel time- 722.0\n",
      "--- 1.6173417568206787 seconds ---\n",
      "episode 2883, reward -68.0, memory_length 2000, epsilon 0.2365726334546052\n",
      "travel time- 721.0\n",
      "--- 1.4594645500183105 seconds ---\n",
      "episode 2884, reward -123.0, memory_length 2000, epsilon 0.2364543767045291\n",
      "travel time- 727.0\n",
      "--- 1.7933576107025146 seconds ---\n",
      "episode 2885, reward -94.0, memory_length 2000, epsilon 0.23633617906804838\n",
      "travel time- 720.0\n",
      "--- 1.529874324798584 seconds ---\n",
      "episode 2886, reward 46.0, memory_length 2000, epsilon 0.23621804051561368\n",
      "travel time- 727.0\n",
      "--- 1.4343092441558838 seconds ---\n",
      "episode 2887, reward 0.0, memory_length 2000, epsilon 0.23609996101769037\n",
      "travel time- 729.0\n",
      "--- 1.5914788246154785 seconds ---\n",
      "episode 2888, reward 237.0, memory_length 2000, epsilon 0.23598194054475852\n",
      "travel time- 725.0\n",
      "--- 1.6137073040008545 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2889, reward -335.0, memory_length 2000, epsilon 0.235863979067313\n",
      "travel time- 722.0\n",
      "--- 1.7874500751495361 seconds ---\n",
      "episode 2890, reward -133.0, memory_length 2000, epsilon 0.23574607655586352\n",
      "travel time- 722.0\n",
      "--- 1.5858285427093506 seconds ---\n",
      "episode 2891, reward 75.0, memory_length 2000, epsilon 0.2356282329809344\n",
      "travel time- 727.0\n",
      "--- 1.6096458435058594 seconds ---\n",
      "episode 2892, reward -321.0, memory_length 2000, epsilon 0.23551044831306475\n",
      "travel time- 727.0\n",
      "--- 1.4524075984954834 seconds ---\n",
      "episode 2893, reward -132.0, memory_length 2000, epsilon 0.23539272252280838\n",
      "travel time- 722.0\n",
      "--- 1.6853249073028564 seconds ---\n",
      "episode 2894, reward -21.0, memory_length 2000, epsilon 0.2352750555807339\n",
      "travel time- 730.0\n",
      "--- 1.5814735889434814 seconds ---\n",
      "episode 2895, reward -63.0, memory_length 2000, epsilon 0.23515744745742453\n",
      "travel time- 729.0\n",
      "--- 1.6436362266540527 seconds ---\n",
      "episode 2896, reward 235.0, memory_length 2000, epsilon 0.23503989812347828\n",
      "travel time- 725.0\n",
      "--- 1.427767038345337 seconds ---\n",
      "episode 2897, reward -483.0, memory_length 2000, epsilon 0.23492240754950772\n",
      "travel time- 720.0\n",
      "--- 1.5079095363616943 seconds ---\n",
      "episode 2898, reward -92.0, memory_length 2000, epsilon 0.2348049757061403\n",
      "travel time- 721.0\n",
      "--- 1.7097506523132324 seconds ---\n",
      "episode 2899, reward -2.0, memory_length 2000, epsilon 0.23468760256401805\n",
      "travel time- 722.0\n",
      "--- 1.5580191612243652 seconds ---\n",
      "episode 2900, reward -111.0, memory_length 2000, epsilon 0.23457028809379765\n",
      "travel time- 723.0\n",
      "--- 1.6579267978668213 seconds ---\n",
      "episode 2901, reward -126.0, memory_length 2000, epsilon 0.23445303226615047\n",
      "travel time- 721.0\n",
      "--- 1.7299559116363525 seconds ---\n",
      "episode 2902, reward 79.0, memory_length 2000, epsilon 0.23433583505176261\n",
      "travel time- 721.0\n",
      "--- 1.503770351409912 seconds ---\n",
      "episode 2903, reward -148.0, memory_length 2000, epsilon 0.23421869642133475\n",
      "travel time- 720.0\n",
      "--- 1.7219698429107666 seconds ---\n",
      "episode 2904, reward -210.0, memory_length 2000, epsilon 0.2341016163455822\n",
      "travel time- 722.0\n",
      "--- 1.7352607250213623 seconds ---\n",
      "episode 2905, reward 188.0, memory_length 2000, epsilon 0.2339845947952349\n",
      "travel time- 724.0\n",
      "--- 1.6067492961883545 seconds ---\n",
      "episode 2906, reward -6.0, memory_length 2000, epsilon 0.23386763174103756\n",
      "travel time- 729.0\n",
      "--- 1.4997687339782715 seconds ---\n",
      "episode 2907, reward 135.0, memory_length 2000, epsilon 0.2337507271537494\n",
      "travel time- 725.0\n",
      "--- 1.6487629413604736 seconds ---\n",
      "episode 2908, reward -206.0, memory_length 2000, epsilon 0.23363388100414423\n",
      "travel time- 727.0\n",
      "--- 1.4511501789093018 seconds ---\n",
      "episode 2909, reward -55.0, memory_length 2000, epsilon 0.23351709326301048\n",
      "travel time- 723.0\n",
      "--- 1.6592872142791748 seconds ---\n",
      "episode 2910, reward -18.0, memory_length 2000, epsilon 0.23340036390115132\n",
      "travel time- 721.0\n",
      "--- 1.601548194885254 seconds ---\n",
      "episode 2911, reward -397.0, memory_length 2000, epsilon 0.23328369288938433\n",
      "travel time- 725.0\n",
      "--- 1.8944778442382812 seconds ---\n",
      "episode 2912, reward 152.0, memory_length 2000, epsilon 0.2331670801985418\n",
      "travel time- 726.0\n",
      "--- 1.559314489364624 seconds ---\n",
      "episode 2913, reward -101.0, memory_length 2000, epsilon 0.23305052579947047\n",
      "travel time- 720.0\n",
      "--- 1.6122183799743652 seconds ---\n",
      "episode 2914, reward -134.0, memory_length 2000, epsilon 0.23293402966303187\n",
      "travel time- 722.0\n",
      "--- 1.6617059707641602 seconds ---\n",
      "episode 2915, reward -248.0, memory_length 2000, epsilon 0.2328175917601019\n",
      "travel time- 731.0\n",
      "--- 1.6163575649261475 seconds ---\n",
      "episode 2916, reward -125.0, memory_length 2000, epsilon 0.23270121206157107\n",
      "travel time- 720.0\n",
      "--- 1.8002557754516602 seconds ---\n",
      "episode 2917, reward 296.0, memory_length 2000, epsilon 0.2325848905383444\n",
      "travel time- 720.0\n",
      "--- 1.6716115474700928 seconds ---\n",
      "episode 2918, reward 175.0, memory_length 2000, epsilon 0.23246862716134165\n",
      "travel time- 720.0\n",
      "--- 1.4803271293640137 seconds ---\n",
      "episode 2919, reward -248.0, memory_length 2000, epsilon 0.2323524219014969\n",
      "travel time- 731.0\n",
      "--- 1.5994117259979248 seconds ---\n",
      "episode 2920, reward -112.0, memory_length 2000, epsilon 0.23223627472975883\n",
      "travel time- 728.0\n",
      "--- 1.663301706314087 seconds ---\n",
      "episode 2921, reward -221.0, memory_length 2000, epsilon 0.2321201856170906\n",
      "travel time- 722.0\n",
      "--- 1.654630422592163 seconds ---\n",
      "episode 2922, reward -238.0, memory_length 2000, epsilon 0.23200415453447004\n",
      "travel time- 721.0\n",
      "--- 1.6013939380645752 seconds ---\n",
      "episode 2923, reward -41.0, memory_length 2000, epsilon 0.2318881814528893\n",
      "travel time- 724.0\n",
      "--- 1.66243314743042 seconds ---\n",
      "episode 2924, reward -105.0, memory_length 2000, epsilon 0.23177226634335515\n",
      "travel time- 723.0\n",
      "--- 1.6867051124572754 seconds ---\n",
      "episode 2925, reward -52.0, memory_length 2000, epsilon 0.23165640917688876\n",
      "travel time- 720.0\n",
      "--- 1.5805611610412598 seconds ---\n",
      "episode 2926, reward 111.0, memory_length 2000, epsilon 0.2315406099245259\n",
      "travel time- 727.0\n",
      "--- 1.6458227634429932 seconds ---\n",
      "episode 2927, reward 190.0, memory_length 2000, epsilon 0.23142486855731673\n",
      "travel time- 728.0\n",
      "--- 1.6818056106567383 seconds ---\n",
      "episode 2928, reward -71.0, memory_length 2000, epsilon 0.23130918504632592\n",
      "travel time- 721.0\n",
      "--- 1.748943567276001 seconds ---\n",
      "episode 2929, reward 72.0, memory_length 2000, epsilon 0.2311935593626325\n",
      "travel time- 729.0\n",
      "--- 1.5771222114562988 seconds ---\n",
      "episode 2930, reward 61.0, memory_length 2000, epsilon 0.23107799147733019\n",
      "travel time- 723.0\n",
      "--- 1.7161316871643066 seconds ---\n",
      "episode 2931, reward -15.0, memory_length 2000, epsilon 0.23096248136152694\n",
      "travel time- 720.0\n",
      "--- 1.669419288635254 seconds ---\n",
      "episode 2932, reward 33.0, memory_length 2000, epsilon 0.23084702898634524\n",
      "travel time- 728.0\n",
      "--- 1.8582780361175537 seconds ---\n",
      "episode 2933, reward -323.0, memory_length 2000, epsilon 0.23073163432292196\n",
      "travel time- 725.0\n",
      "--- 1.689652919769287 seconds ---\n",
      "episode 2934, reward -60.0, memory_length 2000, epsilon 0.2306162973424085\n",
      "travel time- 725.0\n",
      "--- 1.6164460182189941 seconds ---\n",
      "episode 2935, reward 54.0, memory_length 2000, epsilon 0.23050101801597056\n",
      "travel time- 722.0\n",
      "--- 1.5655591487884521 seconds ---\n",
      "episode 2936, reward -28.0, memory_length 2000, epsilon 0.23038579631478834\n",
      "travel time- 720.0\n",
      "--- 1.8352751731872559 seconds ---\n",
      "episode 2937, reward -50.0, memory_length 2000, epsilon 0.23027063221005634\n",
      "travel time- 721.0\n",
      "--- 1.673530101776123 seconds ---\n",
      "episode 2938, reward -163.0, memory_length 2000, epsilon 0.23015552567298364\n",
      "travel time- 722.0\n",
      "--- 1.746819257736206 seconds ---\n",
      "episode 2939, reward -317.0, memory_length 2000, epsilon 0.23004047667479355\n",
      "travel time- 721.0\n",
      "--- 1.6756162643432617 seconds ---\n",
      "episode 2940, reward -313.0, memory_length 2000, epsilon 0.22992548518672384\n",
      "travel time- 729.0\n",
      "--- 1.4416415691375732 seconds ---\n",
      "episode 2941, reward -146.0, memory_length 2000, epsilon 0.22981055118002658\n",
      "travel time- 723.0\n",
      "--- 1.5304722785949707 seconds ---\n",
      "episode 2942, reward -81.0, memory_length 2000, epsilon 0.22969567462596835\n",
      "travel time- 726.0\n",
      "--- 1.8631441593170166 seconds ---\n",
      "episode 2943, reward 0.0, memory_length 2000, epsilon 0.22958085549583\n",
      "travel time- 721.0\n",
      "--- 1.6288630962371826 seconds ---\n",
      "episode 2944, reward 151.0, memory_length 2000, epsilon 0.22946609376090668\n",
      "travel time- 720.0\n",
      "--- 1.6155388355255127 seconds ---\n",
      "episode 2945, reward 45.0, memory_length 2000, epsilon 0.22935138939250801\n",
      "travel time- 720.0\n",
      "--- 1.5670182704925537 seconds ---\n",
      "episode 2946, reward 83.0, memory_length 2000, epsilon 0.22923674236195785\n",
      "travel time- 728.0\n",
      "--- 1.6396100521087646 seconds ---\n",
      "episode 2947, reward 69.0, memory_length 2000, epsilon 0.2291221526405945\n",
      "travel time- 720.0\n",
      "--- 1.6606321334838867 seconds ---\n",
      "episode 2948, reward 189.0, memory_length 2000, epsilon 0.2290076201997705\n",
      "travel time- 733.0\n",
      "--- 1.7952122688293457 seconds ---\n",
      "episode 2949, reward -52.0, memory_length 2000, epsilon 0.22889314501085276\n",
      "travel time- 732.0\n",
      "--- 1.7104103565216064 seconds ---\n",
      "episode 2950, reward -161.0, memory_length 2000, epsilon 0.22877872704522242\n",
      "travel time- 722.0\n",
      "--- 1.5815846920013428 seconds ---\n",
      "episode 2951, reward 71.0, memory_length 2000, epsilon 0.22866436627427508\n",
      "travel time- 728.0\n",
      "--- 1.6013267040252686 seconds ---\n",
      "episode 2952, reward 78.0, memory_length 2000, epsilon 0.2285500626694205\n",
      "travel time- 722.0\n",
      "--- 1.5013818740844727 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2953, reward -27.0, memory_length 2000, epsilon 0.22843581620208275\n",
      "travel time- 733.0\n",
      "--- 1.7811660766601562 seconds ---\n",
      "episode 2954, reward -317.0, memory_length 2000, epsilon 0.22832162684370022\n",
      "travel time- 721.0\n",
      "--- 1.828479528427124 seconds ---\n",
      "episode 2955, reward -227.0, memory_length 2000, epsilon 0.22820749456572564\n",
      "travel time- 725.0\n",
      "--- 1.8608877658843994 seconds ---\n",
      "episode 2956, reward -109.0, memory_length 2000, epsilon 0.22809341933962587\n",
      "travel time- 725.0\n",
      "--- 1.5798749923706055 seconds ---\n",
      "episode 2957, reward 294.0, memory_length 2000, epsilon 0.22797940113688214\n",
      "travel time- 733.0\n",
      "--- 1.5466539859771729 seconds ---\n",
      "episode 2958, reward 92.0, memory_length 2000, epsilon 0.22786543992898983\n",
      "travel time- 728.0\n",
      "--- 1.7947313785552979 seconds ---\n",
      "episode 2959, reward -174.0, memory_length 2000, epsilon 0.22775153568745873\n",
      "travel time- 729.0\n",
      "--- 1.8241305351257324 seconds ---\n",
      "episode 2960, reward 23.0, memory_length 2000, epsilon 0.22763768838381274\n",
      "travel time- 725.0\n",
      "--- 1.6860535144805908 seconds ---\n",
      "episode 2961, reward 237.0, memory_length 2000, epsilon 0.22752389798959005\n",
      "travel time- 724.0\n",
      "--- 1.6264371871948242 seconds ---\n",
      "episode 2962, reward -55.0, memory_length 2000, epsilon 0.22741016447634296\n",
      "travel time- 726.0\n",
      "--- 1.5326952934265137 seconds ---\n",
      "episode 2963, reward -9.0, memory_length 2000, epsilon 0.22729648781563824\n",
      "travel time- 722.0\n",
      "--- 1.7126424312591553 seconds ---\n",
      "episode 2964, reward 15.0, memory_length 2000, epsilon 0.22718286797905665\n",
      "travel time- 722.0\n",
      "--- 1.630392074584961 seconds ---\n",
      "episode 2965, reward 81.0, memory_length 2000, epsilon 0.22706930493819327\n",
      "travel time- 728.0\n",
      "--- 1.5919108390808105 seconds ---\n",
      "episode 2966, reward -75.0, memory_length 2000, epsilon 0.22695579866465723\n",
      "travel time- 726.0\n",
      "--- 1.6191835403442383 seconds ---\n",
      "episode 2967, reward -164.0, memory_length 2000, epsilon 0.2268423491300721\n",
      "travel time- 729.0\n",
      "--- 1.6429204940795898 seconds ---\n",
      "episode 2968, reward -283.0, memory_length 2000, epsilon 0.22672895630607542\n",
      "travel time- 726.0\n",
      "--- 1.615616798400879 seconds ---\n",
      "episode 2969, reward 167.0, memory_length 2000, epsilon 0.226615620164319\n",
      "travel time- 721.0\n",
      "--- 1.6407043933868408 seconds ---\n",
      "episode 2970, reward 216.0, memory_length 2000, epsilon 0.22650234067646874\n",
      "travel time- 724.0\n",
      "--- 1.68798828125 seconds ---\n",
      "episode 2971, reward -120.0, memory_length 2000, epsilon 0.2263891178142049\n",
      "travel time- 720.0\n",
      "--- 1.5713212490081787 seconds ---\n",
      "episode 2972, reward 186.0, memory_length 2000, epsilon 0.2262759515492217\n",
      "travel time- 725.0\n",
      "--- 1.7141578197479248 seconds ---\n",
      "episode 2973, reward 88.0, memory_length 2000, epsilon 0.22616284185322755\n",
      "travel time- 727.0\n",
      "--- 1.7160453796386719 seconds ---\n",
      "episode 2974, reward -308.0, memory_length 2000, epsilon 0.22604978869794498\n",
      "travel time- 720.0\n",
      "--- 1.6036369800567627 seconds ---\n",
      "episode 2975, reward 14.0, memory_length 2000, epsilon 0.22593679205511083\n",
      "travel time- 721.0\n",
      "--- 1.82206130027771 seconds ---\n",
      "episode 2976, reward -231.0, memory_length 2000, epsilon 0.22582385189647586\n",
      "travel time- 721.0\n",
      "--- 1.8094677925109863 seconds ---\n",
      "episode 2977, reward -179.0, memory_length 2000, epsilon 0.22571096819380504\n",
      "travel time- 721.0\n",
      "--- 1.710033655166626 seconds ---\n",
      "episode 2978, reward 91.0, memory_length 2000, epsilon 0.22559814091887742\n",
      "travel time- 723.0\n",
      "--- 1.65501070022583 seconds ---\n",
      "episode 2979, reward -88.0, memory_length 2000, epsilon 0.22548537004348623\n",
      "travel time- 727.0\n",
      "--- 1.5743319988250732 seconds ---\n",
      "episode 2980, reward -75.0, memory_length 2000, epsilon 0.22537265553943872\n",
      "travel time- 724.0\n",
      "--- 1.6908693313598633 seconds ---\n",
      "episode 2981, reward 163.0, memory_length 2000, epsilon 0.2252599973785563\n",
      "travel time- 722.0\n",
      "--- 1.4053399562835693 seconds ---\n",
      "episode 2982, reward 22.0, memory_length 2000, epsilon 0.22514739553267432\n",
      "travel time- 726.0\n",
      "--- 1.4882514476776123 seconds ---\n",
      "episode 2983, reward -320.0, memory_length 2000, epsilon 0.22503484997364245\n",
      "travel time- 729.0\n",
      "--- 1.6335468292236328 seconds ---\n",
      "episode 2984, reward 25.0, memory_length 2000, epsilon 0.22492236067332425\n",
      "travel time- 720.0\n",
      "--- 1.4752147197723389 seconds ---\n",
      "episode 2985, reward 8.0, memory_length 2000, epsilon 0.2248099276035974\n",
      "travel time- 723.0\n",
      "--- 1.487769603729248 seconds ---\n",
      "episode 2986, reward -95.0, memory_length 2000, epsilon 0.22469755073635353\n",
      "travel time- 720.0\n",
      "--- 1.6233251094818115 seconds ---\n",
      "episode 2987, reward -43.0, memory_length 2000, epsilon 0.2245852300434986\n",
      "travel time- 721.0\n",
      "--- 1.6417527198791504 seconds ---\n",
      "episode 2988, reward -114.0, memory_length 2000, epsilon 0.22447296549695234\n",
      "travel time- 721.0\n",
      "--- 1.7573950290679932 seconds ---\n",
      "episode 2989, reward -184.0, memory_length 2000, epsilon 0.22436075706864864\n",
      "travel time- 721.0\n",
      "--- 1.6152501106262207 seconds ---\n",
      "episode 2990, reward 61.0, memory_length 2000, epsilon 0.22424860473053532\n",
      "travel time- 720.0\n",
      "--- 1.5723955631256104 seconds ---\n",
      "episode 2991, reward 165.0, memory_length 2000, epsilon 0.2241365084545744\n",
      "travel time- 726.0\n",
      "--- 1.4368641376495361 seconds ---\n",
      "episode 2992, reward 15.0, memory_length 2000, epsilon 0.22402446821274175\n",
      "travel time- 726.0\n",
      "--- 1.7224326133728027 seconds ---\n",
      "episode 2993, reward -63.0, memory_length 2000, epsilon 0.22391248397702732\n",
      "travel time- 728.0\n",
      "--- 1.8022372722625732 seconds ---\n",
      "episode 2994, reward 54.0, memory_length 2000, epsilon 0.223800555719435\n",
      "travel time- 722.0\n",
      "--- 1.5966546535491943 seconds ---\n",
      "episode 2995, reward -157.0, memory_length 2000, epsilon 0.22368868341198284\n",
      "travel time- 725.0\n",
      "--- 1.581437587738037 seconds ---\n",
      "episode 2996, reward -10.0, memory_length 2000, epsilon 0.22357686702670268\n",
      "travel time- 721.0\n",
      "--- 1.5482492446899414 seconds ---\n",
      "episode 2997, reward -19.0, memory_length 2000, epsilon 0.22346510653564045\n",
      "travel time- 722.0\n",
      "--- 1.6583893299102783 seconds ---\n",
      "episode 2998, reward 327.0, memory_length 2000, epsilon 0.22335340191085598\n",
      "travel time- 732.0\n",
      "--- 1.6968882083892822 seconds ---\n",
      "episode 2999, reward -139.0, memory_length 2000, epsilon 0.22324175312442318\n",
      "travel time- 720.0\n",
      "--- 1.6522424221038818 seconds ---\n",
      "episode 3000, reward 10.0, memory_length 2000, epsilon 0.22313016014842982\n",
      "travel time- 727.0\n",
      "--- 1.5086746215820312 seconds ---\n",
      "episode 3001, reward -82.0, memory_length 2000, epsilon 0.22301862295497768\n",
      "travel time- 729.0\n",
      "--- 1.732710838317871 seconds ---\n",
      "episode 3002, reward 34.0, memory_length 2000, epsilon 0.22290714151618238\n",
      "travel time- 727.0\n",
      "--- 1.7477214336395264 seconds ---\n",
      "episode 3003, reward -135.0, memory_length 2000, epsilon 0.22279571580417368\n",
      "travel time- 735.0\n",
      "--- 1.8360331058502197 seconds ---\n",
      "episode 3004, reward 50.0, memory_length 2000, epsilon 0.22268434579109508\n",
      "travel time- 721.0\n",
      "--- 1.4062838554382324 seconds ---\n",
      "episode 3005, reward -318.0, memory_length 2000, epsilon 0.2225730314491041\n",
      "travel time- 728.0\n",
      "--- 1.6720831394195557 seconds ---\n",
      "episode 3006, reward -186.0, memory_length 2000, epsilon 0.22246177275037207\n",
      "travel time- 723.0\n",
      "--- 1.8063697814941406 seconds ---\n",
      "episode 3007, reward -119.0, memory_length 2000, epsilon 0.22235056966708444\n",
      "travel time- 729.0\n",
      "--- 1.8575472831726074 seconds ---\n",
      "episode 3008, reward -341.0, memory_length 2000, epsilon 0.2222394221714404\n",
      "travel time- 729.0\n",
      "--- 1.762836217880249 seconds ---\n",
      "episode 3009, reward 57.0, memory_length 2000, epsilon 0.22212833023565307\n",
      "travel time- 720.0\n",
      "--- 1.5382413864135742 seconds ---\n",
      "episode 3010, reward -208.0, memory_length 2000, epsilon 0.22201729383194937\n",
      "travel time- 724.0\n",
      "--- 1.6227688789367676 seconds ---\n",
      "episode 3011, reward -159.0, memory_length 2000, epsilon 0.22190631293257038\n",
      "travel time- 722.0\n",
      "--- 1.6249940395355225 seconds ---\n",
      "episode 3012, reward 104.0, memory_length 2000, epsilon 0.22179538750977074\n",
      "travel time- 725.0\n",
      "--- 1.5590357780456543 seconds ---\n",
      "episode 3013, reward -302.0, memory_length 2000, epsilon 0.22168451753581914\n",
      "travel time- 727.0\n",
      "--- 1.849519968032837 seconds ---\n",
      "episode 3014, reward 59.0, memory_length 2000, epsilon 0.22157370298299803\n",
      "travel time- 723.0\n",
      "--- 1.7261576652526855 seconds ---\n",
      "episode 3015, reward -174.0, memory_length 2000, epsilon 0.22146294382360387\n",
      "travel time- 722.0\n",
      "--- 1.7475433349609375 seconds ---\n",
      "episode 3016, reward 33.0, memory_length 2000, epsilon 0.22135224002994683\n",
      "travel time- 730.0\n",
      "--- 1.7876100540161133 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3017, reward 94.0, memory_length 2000, epsilon 0.22124159157435094\n",
      "travel time- 727.0\n",
      "--- 1.5958974361419678 seconds ---\n",
      "episode 3018, reward -245.0, memory_length 2000, epsilon 0.22113099842915407\n",
      "travel time- 722.0\n",
      "--- 1.5864942073822021 seconds ---\n",
      "episode 3019, reward -155.0, memory_length 2000, epsilon 0.221020460566708\n",
      "travel time- 722.0\n",
      "--- 1.924797534942627 seconds ---\n",
      "episode 3020, reward -71.0, memory_length 2000, epsilon 0.2209099779593782\n",
      "travel time- 723.0\n",
      "--- 1.566549301147461 seconds ---\n",
      "episode 3021, reward 191.0, memory_length 2000, epsilon 0.22079955057954403\n",
      "travel time- 722.0\n",
      "--- 1.6551883220672607 seconds ---\n",
      "episode 3022, reward -223.0, memory_length 2000, epsilon 0.22068917839959865\n",
      "travel time- 726.0\n",
      "--- 1.54341459274292 seconds ---\n",
      "episode 3023, reward 58.0, memory_length 2000, epsilon 0.22057886139194904\n",
      "travel time- 722.0\n",
      "--- 1.707869291305542 seconds ---\n",
      "episode 3024, reward 73.0, memory_length 2000, epsilon 0.22046859952901593\n",
      "travel time- 723.0\n",
      "--- 1.695098876953125 seconds ---\n",
      "episode 3025, reward -270.0, memory_length 2000, epsilon 0.22035839278323385\n",
      "travel time- 725.0\n",
      "--- 1.6597094535827637 seconds ---\n",
      "episode 3026, reward 127.0, memory_length 2000, epsilon 0.22024824112705108\n",
      "travel time- 721.0\n",
      "--- 1.535982608795166 seconds ---\n",
      "episode 3027, reward -135.0, memory_length 2000, epsilon 0.22013814453292976\n",
      "travel time- 729.0\n",
      "--- 1.6948060989379883 seconds ---\n",
      "episode 3028, reward -64.0, memory_length 2000, epsilon 0.22002810297334574\n",
      "travel time- 729.0\n",
      "--- 1.9601104259490967 seconds ---\n",
      "episode 3029, reward -162.0, memory_length 2000, epsilon 0.21991811642078862\n",
      "travel time- 722.0\n",
      "--- 1.7800109386444092 seconds ---\n",
      "episode 3030, reward 16.0, memory_length 2000, epsilon 0.21980818484776168\n",
      "travel time- 724.0\n",
      "--- 1.5579516887664795 seconds ---\n",
      "episode 3031, reward -14.0, memory_length 2000, epsilon 0.21969830822678216\n",
      "travel time- 724.0\n",
      "--- 1.5587730407714844 seconds ---\n",
      "episode 3032, reward 235.0, memory_length 2000, epsilon 0.21958848653038082\n",
      "travel time- 722.0\n",
      "--- 1.6875247955322266 seconds ---\n",
      "episode 3033, reward -89.0, memory_length 2000, epsilon 0.21947871973110228\n",
      "travel time- 726.0\n",
      "--- 1.7628147602081299 seconds ---\n",
      "episode 3034, reward 18.0, memory_length 2000, epsilon 0.21936900780150476\n",
      "travel time- 720.0\n",
      "--- 1.6646738052368164 seconds ---\n",
      "episode 3035, reward -202.0, memory_length 2000, epsilon 0.21925935071416036\n",
      "travel time- 731.0\n",
      "--- 1.7906200885772705 seconds ---\n",
      "episode 3036, reward -48.0, memory_length 2000, epsilon 0.2191497484416548\n",
      "travel time- 724.0\n",
      "--- 1.7944843769073486 seconds ---\n",
      "episode 3037, reward -262.0, memory_length 2000, epsilon 0.2190402009565875\n",
      "travel time- 721.0\n",
      "--- 1.74006986618042 seconds ---\n",
      "episode 3038, reward 144.0, memory_length 2000, epsilon 0.2189307082315715\n",
      "travel time- 726.0\n",
      "--- 1.6591944694519043 seconds ---\n",
      "episode 3039, reward 23.0, memory_length 2000, epsilon 0.21882127023923378\n",
      "travel time- 721.0\n",
      "--- 1.8785853385925293 seconds ---\n",
      "episode 3040, reward 34.0, memory_length 2000, epsilon 0.21871188695221475\n",
      "travel time- 724.0\n",
      "--- 1.6416957378387451 seconds ---\n",
      "episode 3041, reward -128.0, memory_length 2000, epsilon 0.2186025583431686\n",
      "travel time- 723.0\n",
      "--- 1.7468199729919434 seconds ---\n",
      "episode 3042, reward 116.0, memory_length 2000, epsilon 0.21849328438476312\n",
      "travel time- 725.0\n",
      "--- 1.3981561660766602 seconds ---\n",
      "episode 3043, reward -25.0, memory_length 2000, epsilon 0.21838406504967992\n",
      "travel time- 722.0\n",
      "--- 1.506718397140503 seconds ---\n",
      "episode 3044, reward -14.0, memory_length 2000, epsilon 0.21827490031061414\n",
      "travel time- 724.0\n",
      "--- 1.7944447994232178 seconds ---\n",
      "episode 3045, reward -334.0, memory_length 2000, epsilon 0.21816579014027454\n",
      "travel time- 724.0\n",
      "--- 1.5349016189575195 seconds ---\n",
      "episode 3046, reward -201.0, memory_length 2000, epsilon 0.2180567345113836\n",
      "travel time- 723.0\n",
      "--- 1.6672492027282715 seconds ---\n",
      "episode 3047, reward -212.0, memory_length 2000, epsilon 0.21794773339667745\n",
      "travel time- 721.0\n",
      "--- 1.71378755569458 seconds ---\n",
      "episode 3048, reward -60.0, memory_length 2000, epsilon 0.21783878676890578\n",
      "travel time- 732.0\n",
      "--- 1.6211321353912354 seconds ---\n",
      "episode 3049, reward 246.0, memory_length 2000, epsilon 0.21772989460083195\n",
      "travel time- 720.0\n",
      "--- 1.6995782852172852 seconds ---\n",
      "episode 3050, reward -196.0, memory_length 2000, epsilon 0.21762105686523284\n",
      "travel time- 721.0\n",
      "--- 1.5215647220611572 seconds ---\n",
      "episode 3051, reward 331.0, memory_length 2000, epsilon 0.21751227353489916\n",
      "travel time- 722.0\n",
      "--- 1.867316722869873 seconds ---\n",
      "episode 3052, reward -302.0, memory_length 2000, epsilon 0.21740354458263497\n",
      "travel time- 724.0\n",
      "--- 1.8438670635223389 seconds ---\n",
      "episode 3053, reward -230.0, memory_length 2000, epsilon 0.21729486998125805\n",
      "travel time- 726.0\n",
      "--- 1.6458606719970703 seconds ---\n",
      "episode 3054, reward -289.0, memory_length 2000, epsilon 0.21718624970359973\n",
      "travel time- 724.0\n",
      "--- 1.6090657711029053 seconds ---\n",
      "episode 3055, reward 229.0, memory_length 2000, epsilon 0.217077683722505\n",
      "travel time- 737.0\n",
      "--- 1.9524083137512207 seconds ---\n",
      "episode 3056, reward -53.0, memory_length 2000, epsilon 0.21696917201083235\n",
      "travel time- 720.0\n",
      "--- 1.8147239685058594 seconds ---\n",
      "episode 3057, reward -154.0, memory_length 2000, epsilon 0.2168607145414538\n",
      "travel time- 722.0\n",
      "--- 1.743877649307251 seconds ---\n",
      "episode 3058, reward -88.0, memory_length 2000, epsilon 0.216752311287255\n",
      "travel time- 725.0\n",
      "--- 1.579901933670044 seconds ---\n",
      "episode 3059, reward -159.0, memory_length 2000, epsilon 0.2166439622211352\n",
      "travel time- 724.0\n",
      "--- 1.8472034931182861 seconds ---\n",
      "episode 3060, reward -162.0, memory_length 2000, epsilon 0.21653566731600707\n",
      "travel time- 723.0\n",
      "--- 1.6717751026153564 seconds ---\n",
      "episode 3061, reward -107.0, memory_length 2000, epsilon 0.21642742654479688\n",
      "travel time- 721.0\n",
      "--- 1.5227506160736084 seconds ---\n",
      "episode 3062, reward 115.0, memory_length 2000, epsilon 0.21631923988044444\n",
      "travel time- 724.0\n",
      "--- 1.8040895462036133 seconds ---\n",
      "episode 3063, reward -115.0, memory_length 2000, epsilon 0.21621110729590312\n",
      "travel time- 722.0\n",
      "--- 1.4804012775421143 seconds ---\n",
      "episode 3064, reward 29.0, memory_length 2000, epsilon 0.21610302876413975\n",
      "travel time- 725.0\n",
      "--- 1.7642254829406738 seconds ---\n",
      "episode 3065, reward -120.0, memory_length 2000, epsilon 0.2159950042581347\n",
      "travel time- 733.0\n",
      "--- 1.923588514328003 seconds ---\n",
      "episode 3066, reward -208.0, memory_length 2000, epsilon 0.2158870337508818\n",
      "travel time- 729.0\n",
      "--- 1.7643165588378906 seconds ---\n",
      "episode 3067, reward -73.0, memory_length 2000, epsilon 0.2157791172153885\n",
      "travel time- 729.0\n",
      "--- 1.6800081729888916 seconds ---\n",
      "episode 3068, reward -95.0, memory_length 2000, epsilon 0.21567125462467565\n",
      "travel time- 725.0\n",
      "--- 1.6529254913330078 seconds ---\n",
      "episode 3069, reward -72.0, memory_length 2000, epsilon 0.21556344595177754\n",
      "travel time- 724.0\n",
      "--- 1.9247691631317139 seconds ---\n",
      "episode 3070, reward -109.0, memory_length 2000, epsilon 0.21545569116974203\n",
      "travel time- 720.0\n",
      "--- 1.609311580657959 seconds ---\n",
      "episode 3071, reward 225.0, memory_length 2000, epsilon 0.21534799025163046\n",
      "travel time- 722.0\n",
      "--- 1.7071974277496338 seconds ---\n",
      "episode 3072, reward 25.0, memory_length 2000, epsilon 0.21524034317051757\n",
      "travel time- 721.0\n",
      "--- 1.8050501346588135 seconds ---\n",
      "episode 3073, reward -164.0, memory_length 2000, epsilon 0.21513274989949163\n",
      "travel time- 727.0\n",
      "--- 1.6854603290557861 seconds ---\n",
      "episode 3074, reward -53.0, memory_length 2000, epsilon 0.21502521041165426\n",
      "travel time- 724.0\n",
      "--- 1.7110795974731445 seconds ---\n",
      "episode 3075, reward 150.0, memory_length 2000, epsilon 0.21491772468012055\n",
      "travel time- 720.0\n",
      "--- 1.7735857963562012 seconds ---\n",
      "episode 3076, reward 9.0, memory_length 2000, epsilon 0.2148102926780192\n",
      "travel time- 722.0\n",
      "--- 1.7223560810089111 seconds ---\n",
      "episode 3077, reward -11.0, memory_length 2000, epsilon 0.21470291437849215\n",
      "travel time- 724.0\n",
      "--- 1.7868907451629639 seconds ---\n",
      "episode 3078, reward -383.0, memory_length 2000, epsilon 0.21459558975469478\n",
      "travel time- 726.0\n",
      "--- 1.5725252628326416 seconds ---\n",
      "episode 3079, reward 163.0, memory_length 2000, epsilon 0.21448831877979593\n",
      "travel time- 731.0\n",
      "--- 1.6457853317260742 seconds ---\n",
      "episode 3080, reward -36.0, memory_length 2000, epsilon 0.21438110142697794\n",
      "travel time- 724.0\n",
      "--- 1.5109186172485352 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3081, reward -236.0, memory_length 2000, epsilon 0.21427393766943642\n",
      "travel time- 720.0\n",
      "--- 1.6321380138397217 seconds ---\n",
      "episode 3082, reward -190.0, memory_length 2000, epsilon 0.21416682748038046\n",
      "travel time- 720.0\n",
      "--- 1.6131246089935303 seconds ---\n",
      "episode 3083, reward 50.0, memory_length 2000, epsilon 0.2140597708330324\n",
      "travel time- 721.0\n",
      "--- 1.4195773601531982 seconds ---\n",
      "episode 3084, reward -128.0, memory_length 2000, epsilon 0.21395276770062824\n",
      "travel time- 723.0\n",
      "--- 1.6372325420379639 seconds ---\n",
      "episode 3085, reward 43.0, memory_length 2000, epsilon 0.21384581805641711\n",
      "travel time- 724.0\n",
      "--- 1.534623384475708 seconds ---\n",
      "episode 3086, reward 189.0, memory_length 2000, epsilon 0.2137389218736616\n",
      "travel time- 726.0\n",
      "--- 1.5912203788757324 seconds ---\n",
      "episode 3087, reward -136.0, memory_length 2000, epsilon 0.21363207912563764\n",
      "travel time- 727.0\n",
      "--- 1.6939630508422852 seconds ---\n",
      "episode 3088, reward 400.0, memory_length 2000, epsilon 0.2135252897856346\n",
      "travel time- 723.0\n",
      "--- 1.3981366157531738 seconds ---\n",
      "episode 3089, reward 90.0, memory_length 2000, epsilon 0.21341855382695513\n",
      "travel time- 731.0\n",
      "--- 1.5572853088378906 seconds ---\n",
      "episode 3090, reward -172.0, memory_length 2000, epsilon 0.21331187122291523\n",
      "travel time- 727.0\n",
      "--- 1.6718919277191162 seconds ---\n",
      "episode 3091, reward -50.0, memory_length 2000, epsilon 0.2132052419468442\n",
      "travel time- 722.0\n",
      "--- 1.7986564636230469 seconds ---\n",
      "episode 3092, reward 261.0, memory_length 2000, epsilon 0.21309866597208482\n",
      "travel time- 723.0\n",
      "--- 1.4050250053405762 seconds ---\n",
      "episode 3093, reward -455.0, memory_length 2000, epsilon 0.21299214327199303\n",
      "travel time- 726.0\n",
      "--- 1.6551282405853271 seconds ---\n",
      "episode 3094, reward -85.0, memory_length 2000, epsilon 0.21288567381993817\n",
      "travel time- 730.0\n",
      "--- 1.755547046661377 seconds ---\n",
      "episode 3095, reward 197.0, memory_length 2000, epsilon 0.21277925758930283\n",
      "travel time- 723.0\n",
      "--- 1.8281855583190918 seconds ---\n",
      "episode 3096, reward 109.0, memory_length 2000, epsilon 0.21267289455348304\n",
      "travel time- 721.0\n",
      "--- 1.571777105331421 seconds ---\n",
      "episode 3097, reward -88.0, memory_length 2000, epsilon 0.212566584685888\n",
      "travel time- 722.0\n",
      "--- 1.6081559658050537 seconds ---\n",
      "episode 3098, reward -81.0, memory_length 2000, epsilon 0.21246032795994024\n",
      "travel time- 726.0\n",
      "--- 1.5795516967773438 seconds ---\n",
      "episode 3099, reward -351.0, memory_length 2000, epsilon 0.21235412434907552\n",
      "travel time- 720.0\n",
      "--- 1.955965518951416 seconds ---\n",
      "episode 3100, reward -186.0, memory_length 2000, epsilon 0.21224797382674304\n",
      "travel time- 727.0\n",
      "--- 1.765831470489502 seconds ---\n",
      "episode 3101, reward -15.0, memory_length 2000, epsilon 0.21214187636640514\n",
      "travel time- 722.0\n",
      "--- 1.5616178512573242 seconds ---\n",
      "episode 3102, reward -268.0, memory_length 2000, epsilon 0.2120358319415374\n",
      "travel time- 725.0\n",
      "--- 1.6902706623077393 seconds ---\n",
      "episode 3103, reward 33.0, memory_length 2000, epsilon 0.21192984052562874\n",
      "travel time- 723.0\n",
      "--- 1.7863245010375977 seconds ---\n",
      "episode 3104, reward 101.0, memory_length 2000, epsilon 0.21182390209218135\n",
      "travel time- 721.0\n",
      "--- 1.5973260402679443 seconds ---\n",
      "episode 3105, reward 28.0, memory_length 2000, epsilon 0.2117180166147106\n",
      "travel time- 728.0\n",
      "--- 1.7660486698150635 seconds ---\n",
      "episode 3106, reward -88.0, memory_length 2000, epsilon 0.2116121840667451\n",
      "travel time- 728.0\n",
      "--- 1.9151856899261475 seconds ---\n",
      "episode 3107, reward -126.0, memory_length 2000, epsilon 0.21150640442182664\n",
      "travel time- 721.0\n",
      "--- 1.8106999397277832 seconds ---\n",
      "episode 3108, reward -160.0, memory_length 2000, epsilon 0.21140067765351048\n",
      "travel time- 723.0\n",
      "--- 1.6268343925476074 seconds ---\n",
      "episode 3109, reward 14.0, memory_length 2000, epsilon 0.2112950037353648\n",
      "travel time- 722.0\n",
      "--- 1.7577481269836426 seconds ---\n",
      "episode 3110, reward -178.0, memory_length 2000, epsilon 0.21118938264097117\n",
      "travel time- 727.0\n",
      "--- 1.8541369438171387 seconds ---\n",
      "episode 3111, reward -64.0, memory_length 2000, epsilon 0.21108381434392426\n",
      "travel time- 723.0\n",
      "--- 1.5146236419677734 seconds ---\n",
      "episode 3112, reward 460.0, memory_length 2000, epsilon 0.21097829881783206\n",
      "travel time- 728.0\n",
      "--- 1.722170114517212 seconds ---\n",
      "episode 3113, reward -7.0, memory_length 2000, epsilon 0.21087283603631568\n",
      "travel time- 725.0\n",
      "--- 1.6260790824890137 seconds ---\n",
      "episode 3114, reward -180.0, memory_length 2000, epsilon 0.2107674259730094\n",
      "travel time- 731.0\n",
      "--- 1.7476341724395752 seconds ---\n",
      "episode 3115, reward -4.0, memory_length 2000, epsilon 0.21066206860156067\n",
      "travel time- 732.0\n",
      "--- 1.6878538131713867 seconds ---\n",
      "episode 3116, reward -92.0, memory_length 2000, epsilon 0.21055676389563024\n",
      "travel time- 721.0\n",
      "--- 1.8993628025054932 seconds ---\n",
      "episode 3117, reward 108.0, memory_length 2000, epsilon 0.21045151182889185\n",
      "travel time- 726.0\n",
      "--- 1.678140640258789 seconds ---\n",
      "episode 3118, reward -120.0, memory_length 2000, epsilon 0.21034631237503254\n",
      "travel time- 723.0\n",
      "--- 1.6084480285644531 seconds ---\n",
      "episode 3119, reward 327.0, memory_length 2000, epsilon 0.21024116550775238\n",
      "travel time- 722.0\n",
      "--- 1.5981864929199219 seconds ---\n",
      "episode 3120, reward -119.0, memory_length 2000, epsilon 0.21013607120076472\n",
      "travel time- 725.0\n",
      "--- 1.6088032722473145 seconds ---\n",
      "episode 3121, reward 48.0, memory_length 2000, epsilon 0.21003102942779597\n",
      "travel time- 720.0\n",
      "--- 1.4487175941467285 seconds ---\n",
      "episode 3122, reward 65.0, memory_length 2000, epsilon 0.20992604016258565\n",
      "travel time- 720.0\n",
      "--- 1.662384271621704 seconds ---\n",
      "episode 3123, reward 64.0, memory_length 2000, epsilon 0.20982110337888643\n",
      "travel time- 723.0\n",
      "--- 1.8200781345367432 seconds ---\n",
      "episode 3124, reward -77.0, memory_length 2000, epsilon 0.2097162190504642\n",
      "travel time- 730.0\n",
      "--- 1.763990879058838 seconds ---\n",
      "episode 3125, reward -182.0, memory_length 2000, epsilon 0.2096113871510978\n",
      "travel time- 722.0\n",
      "--- 1.5876123905181885 seconds ---\n",
      "episode 3126, reward 37.0, memory_length 2000, epsilon 0.20950660765457932\n",
      "travel time- 729.0\n",
      "--- 1.8064789772033691 seconds ---\n",
      "episode 3127, reward 71.0, memory_length 2000, epsilon 0.20940188053471379\n",
      "travel time- 720.0\n",
      "--- 1.6950483322143555 seconds ---\n",
      "episode 3128, reward -79.0, memory_length 2000, epsilon 0.20929720576531952\n",
      "travel time- 730.0\n",
      "--- 1.781358242034912 seconds ---\n",
      "episode 3129, reward 50.0, memory_length 2000, epsilon 0.20919258332022778\n",
      "travel time- 722.0\n",
      "--- 1.8562817573547363 seconds ---\n",
      "episode 3130, reward 211.0, memory_length 2000, epsilon 0.20908801317328293\n",
      "travel time- 725.0\n",
      "--- 1.8395795822143555 seconds ---\n",
      "episode 3131, reward 256.0, memory_length 2000, epsilon 0.20898349529834245\n",
      "travel time- 727.0\n",
      "--- 1.7441394329071045 seconds ---\n",
      "episode 3132, reward 43.0, memory_length 2000, epsilon 0.20887902966927693\n",
      "travel time- 720.0\n",
      "--- 1.5981135368347168 seconds ---\n",
      "episode 3133, reward -133.0, memory_length 2000, epsilon 0.2087746162599699\n",
      "travel time- 723.0\n",
      "--- 1.4962763786315918 seconds ---\n",
      "episode 3134, reward -137.0, memory_length 2000, epsilon 0.20867025504431805\n",
      "travel time- 725.0\n",
      "--- 1.7989232540130615 seconds ---\n",
      "episode 3135, reward 108.0, memory_length 2000, epsilon 0.20856594599623096\n",
      "travel time- 722.0\n",
      "--- 1.577587604522705 seconds ---\n",
      "episode 3136, reward 85.0, memory_length 2000, epsilon 0.20846168908963153\n",
      "travel time- 728.0\n",
      "--- 1.7752265930175781 seconds ---\n",
      "episode 3137, reward 110.0, memory_length 2000, epsilon 0.20835748429845546\n",
      "travel time- 729.0\n",
      "--- 1.6442227363586426 seconds ---\n",
      "episode 3138, reward -224.0, memory_length 2000, epsilon 0.20825333159665155\n",
      "travel time- 720.0\n",
      "--- 1.641369104385376 seconds ---\n",
      "episode 3139, reward 36.0, memory_length 2000, epsilon 0.20814923095818155\n",
      "travel time- 720.0\n",
      "--- 1.6605072021484375 seconds ---\n",
      "episode 3140, reward -313.0, memory_length 2000, epsilon 0.20804518235702046\n",
      "travel time- 724.0\n",
      "--- 1.803145170211792 seconds ---\n",
      "episode 3141, reward 352.0, memory_length 2000, epsilon 0.207941185767156\n",
      "travel time- 727.0\n",
      "--- 1.6895387172698975 seconds ---\n",
      "episode 3142, reward -24.0, memory_length 2000, epsilon 0.20783724116258911\n",
      "travel time- 729.0\n",
      "--- 1.6543290615081787 seconds ---\n",
      "episode 3143, reward 238.0, memory_length 2000, epsilon 0.20773334851733352\n",
      "travel time- 722.0\n",
      "--- 1.9336671829223633 seconds ---\n",
      "episode 3144, reward -50.0, memory_length 2000, epsilon 0.2076295078054162\n",
      "travel time- 731.0\n",
      "--- 1.7926888465881348 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3145, reward -248.0, memory_length 2000, epsilon 0.2075257190008769\n",
      "travel time- 721.0\n",
      "--- 1.6295204162597656 seconds ---\n",
      "episode 3146, reward 12.0, memory_length 2000, epsilon 0.20742198207776844\n",
      "travel time- 726.0\n",
      "--- 1.8503990173339844 seconds ---\n",
      "episode 3147, reward 41.0, memory_length 2000, epsilon 0.20731829701015653\n",
      "travel time- 724.0\n",
      "--- 1.5924525260925293 seconds ---\n",
      "episode 3148, reward 266.0, memory_length 2000, epsilon 0.20721466377212\n",
      "travel time- 720.0\n",
      "--- 1.870462417602539 seconds ---\n",
      "episode 3149, reward -119.0, memory_length 2000, epsilon 0.20711108233775047\n",
      "travel time- 720.0\n",
      "--- 1.4647037982940674 seconds ---\n",
      "episode 3150, reward 83.0, memory_length 2000, epsilon 0.20700755268115265\n",
      "travel time- 723.0\n",
      "--- 1.5759527683258057 seconds ---\n",
      "episode 3151, reward -18.0, memory_length 2000, epsilon 0.20690407477644399\n",
      "travel time- 722.0\n",
      "--- 1.791680097579956 seconds ---\n",
      "episode 3152, reward 292.0, memory_length 2000, epsilon 0.20680064859775515\n",
      "travel time- 725.0\n",
      "--- 1.6021075248718262 seconds ---\n",
      "episode 3153, reward -238.0, memory_length 2000, epsilon 0.20669727411922956\n",
      "travel time- 726.0\n",
      "--- 1.4633986949920654 seconds ---\n",
      "episode 3154, reward 212.0, memory_length 2000, epsilon 0.20659395131502356\n",
      "travel time- 725.0\n",
      "--- 1.5382895469665527 seconds ---\n",
      "episode 3155, reward 118.0, memory_length 2000, epsilon 0.20649068015930644\n",
      "travel time- 724.0\n",
      "--- 1.507059097290039 seconds ---\n",
      "episode 3156, reward 205.0, memory_length 2000, epsilon 0.20638746062626045\n",
      "travel time- 720.0\n",
      "--- 1.4868905544281006 seconds ---\n",
      "episode 3157, reward 3.0, memory_length 2000, epsilon 0.20628429269008072\n",
      "travel time- 732.0\n",
      "--- 1.5672423839569092 seconds ---\n",
      "episode 3158, reward -525.0, memory_length 2000, epsilon 0.20618117632497523\n",
      "travel time- 726.0\n",
      "--- 1.7409083843231201 seconds ---\n",
      "episode 3159, reward -100.0, memory_length 2000, epsilon 0.20607811150516483\n",
      "travel time- 723.0\n",
      "--- 1.5979232788085938 seconds ---\n",
      "episode 3160, reward -233.0, memory_length 2000, epsilon 0.20597509820488344\n",
      "travel time- 726.0\n",
      "--- 1.8701355457305908 seconds ---\n",
      "episode 3161, reward -324.0, memory_length 2000, epsilon 0.20587213639837768\n",
      "travel time- 728.0\n",
      "--- 1.8993000984191895 seconds ---\n",
      "episode 3162, reward -130.0, memory_length 2000, epsilon 0.20576922605990708\n",
      "travel time- 723.0\n",
      "--- 1.7931857109069824 seconds ---\n",
      "episode 3163, reward 209.0, memory_length 2000, epsilon 0.20566636716374403\n",
      "travel time- 730.0\n",
      "--- 1.7754840850830078 seconds ---\n",
      "episode 3164, reward 94.0, memory_length 2000, epsilon 0.2055635596841739\n",
      "travel time- 733.0\n",
      "--- 1.4807276725769043 seconds ---\n",
      "episode 3165, reward -39.0, memory_length 2000, epsilon 0.20546080359549473\n",
      "travel time- 721.0\n",
      "--- 1.4766736030578613 seconds ---\n",
      "episode 3166, reward 51.0, memory_length 2000, epsilon 0.20535809887201756\n",
      "travel time- 727.0\n",
      "--- 1.7408645153045654 seconds ---\n",
      "episode 3167, reward 170.0, memory_length 2000, epsilon 0.2052554454880661\n",
      "travel time- 725.0\n",
      "--- 1.7218732833862305 seconds ---\n",
      "episode 3168, reward -59.0, memory_length 2000, epsilon 0.20515284341797715\n",
      "travel time- 725.0\n",
      "--- 1.8353123664855957 seconds ---\n",
      "episode 3169, reward 302.0, memory_length 2000, epsilon 0.2050502926361001\n",
      "travel time- 726.0\n",
      "--- 1.4555540084838867 seconds ---\n",
      "episode 3170, reward 26.0, memory_length 2000, epsilon 0.2049477931167973\n",
      "travel time- 722.0\n",
      "--- 1.546741008758545 seconds ---\n",
      "episode 3171, reward 118.0, memory_length 2000, epsilon 0.2048453448344438\n",
      "travel time- 727.0\n",
      "--- 1.5283453464508057 seconds ---\n",
      "episode 3172, reward 154.0, memory_length 2000, epsilon 0.20474294776342764\n",
      "travel time- 731.0\n",
      "--- 1.7865667343139648 seconds ---\n",
      "episode 3173, reward 67.0, memory_length 2000, epsilon 0.20464060187814945\n",
      "travel time- 734.0\n",
      "--- 1.5880589485168457 seconds ---\n",
      "episode 3174, reward -65.0, memory_length 2000, epsilon 0.2045383071530228\n",
      "travel time- 721.0\n",
      "--- 1.7513129711151123 seconds ---\n",
      "episode 3175, reward 65.0, memory_length 2000, epsilon 0.20443606356247396\n",
      "travel time- 727.0\n",
      "--- 1.60164475440979 seconds ---\n",
      "episode 3176, reward -188.0, memory_length 2000, epsilon 0.20433387108094214\n",
      "travel time- 720.0\n",
      "--- 1.7737116813659668 seconds ---\n",
      "episode 3177, reward -125.0, memory_length 2000, epsilon 0.20423172968287914\n",
      "travel time- 723.0\n",
      "--- 1.6585934162139893 seconds ---\n",
      "episode 3178, reward -495.0, memory_length 2000, epsilon 0.20412963934274964\n",
      "travel time- 720.0\n",
      "--- 1.6997220516204834 seconds ---\n",
      "episode 3179, reward 150.0, memory_length 2000, epsilon 0.20402760003503095\n",
      "travel time- 723.0\n",
      "--- 1.6974859237670898 seconds ---\n",
      "episode 3180, reward -146.0, memory_length 2000, epsilon 0.20392561173421342\n",
      "travel time- 729.0\n",
      "--- 1.6777243614196777 seconds ---\n",
      "episode 3181, reward 276.0, memory_length 2000, epsilon 0.20382367441479987\n",
      "travel time- 720.0\n",
      "--- 1.6026840209960938 seconds ---\n",
      "episode 3182, reward -111.0, memory_length 2000, epsilon 0.203721788051306\n",
      "travel time- 722.0\n",
      "--- 1.7344322204589844 seconds ---\n",
      "episode 3183, reward -162.0, memory_length 2000, epsilon 0.20361995261826013\n",
      "travel time- 730.0\n",
      "--- 1.7194502353668213 seconds ---\n",
      "episode 3184, reward 14.0, memory_length 2000, epsilon 0.20351816809020354\n",
      "travel time- 721.0\n",
      "--- 1.6508300304412842 seconds ---\n",
      "episode 3185, reward 92.0, memory_length 2000, epsilon 0.20341643444169002\n",
      "travel time- 723.0\n",
      "--- 1.5564618110656738 seconds ---\n",
      "episode 3186, reward 68.0, memory_length 2000, epsilon 0.20331475164728618\n",
      "travel time- 722.0\n",
      "--- 1.610710859298706 seconds ---\n",
      "episode 3187, reward 32.0, memory_length 2000, epsilon 0.20321311968157127\n",
      "travel time- 721.0\n",
      "--- 1.589749813079834 seconds ---\n",
      "episode 3188, reward 54.0, memory_length 2000, epsilon 0.20311153851913738\n",
      "travel time- 730.0\n",
      "--- 1.5074615478515625 seconds ---\n",
      "episode 3189, reward 182.0, memory_length 2000, epsilon 0.2030100081345892\n",
      "travel time- 722.0\n",
      "--- 1.690530776977539 seconds ---\n",
      "episode 3190, reward -31.0, memory_length 2000, epsilon 0.20290852850254407\n",
      "travel time- 726.0\n",
      "--- 1.4537808895111084 seconds ---\n",
      "episode 3191, reward 106.0, memory_length 2000, epsilon 0.2028070995976321\n",
      "travel time- 720.0\n",
      "--- 1.7837400436401367 seconds ---\n",
      "episode 3192, reward 77.0, memory_length 2000, epsilon 0.2027057213944961\n",
      "travel time- 721.0\n",
      "--- 1.7371175289154053 seconds ---\n",
      "episode 3193, reward 50.0, memory_length 2000, epsilon 0.20260439386779155\n",
      "travel time- 726.0\n",
      "--- 1.8098602294921875 seconds ---\n",
      "episode 3194, reward 157.0, memory_length 2000, epsilon 0.20250311699218648\n",
      "travel time- 724.0\n",
      "--- 1.6434800624847412 seconds ---\n",
      "episode 3195, reward -379.0, memory_length 2000, epsilon 0.2024018907423617\n",
      "travel time- 732.0\n",
      "--- 1.7351322174072266 seconds ---\n",
      "episode 3196, reward 96.0, memory_length 2000, epsilon 0.2023007150930107\n",
      "travel time- 721.0\n",
      "--- 1.5448932647705078 seconds ---\n",
      "episode 3197, reward 85.0, memory_length 2000, epsilon 0.20219959001883953\n",
      "travel time- 725.0\n",
      "--- 1.608384609222412 seconds ---\n",
      "episode 3198, reward 42.0, memory_length 2000, epsilon 0.2020985154945669\n",
      "travel time- 734.0\n",
      "--- 1.6157081127166748 seconds ---\n",
      "episode 3199, reward -190.0, memory_length 2000, epsilon 0.20199749149492416\n",
      "travel time- 723.0\n",
      "--- 1.9777107238769531 seconds ---\n",
      "episode 3200, reward 83.0, memory_length 2000, epsilon 0.20189651799465538\n",
      "travel time- 722.0\n",
      "--- 2.021559000015259 seconds ---\n",
      "episode 3201, reward 197.0, memory_length 2000, epsilon 0.20179559496851718\n",
      "travel time- 724.0\n",
      "--- 1.6068823337554932 seconds ---\n",
      "episode 3202, reward -284.0, memory_length 2000, epsilon 0.20169472239127875\n",
      "travel time- 724.0\n",
      "--- 1.633040428161621 seconds ---\n",
      "episode 3203, reward 184.0, memory_length 2000, epsilon 0.20159390023772197\n",
      "travel time- 721.0\n",
      "--- 1.6689727306365967 seconds ---\n",
      "episode 3204, reward 174.0, memory_length 2000, epsilon 0.20149312848264125\n",
      "travel time- 730.0\n",
      "--- 1.4573845863342285 seconds ---\n",
      "episode 3205, reward -61.0, memory_length 2000, epsilon 0.20139240710084375\n",
      "travel time- 723.0\n",
      "--- 1.513352394104004 seconds ---\n",
      "episode 3206, reward 295.0, memory_length 2000, epsilon 0.2012917360671491\n",
      "travel time- 724.0\n",
      "--- 1.5620453357696533 seconds ---\n",
      "episode 3207, reward -108.0, memory_length 2000, epsilon 0.20119111535638948\n",
      "travel time- 729.0\n",
      "--- 1.7631988525390625 seconds ---\n",
      "episode 3208, reward -124.0, memory_length 2000, epsilon 0.20109054494340972\n",
      "travel time- 720.0\n",
      "--- 1.5747060775756836 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3209, reward -231.0, memory_length 2000, epsilon 0.20099002480306727\n",
      "travel time- 724.0\n",
      "--- 1.7315592765808105 seconds ---\n",
      "episode 3210, reward 76.0, memory_length 2000, epsilon 0.20088955491023208\n",
      "travel time- 720.0\n",
      "--- 1.9161252975463867 seconds ---\n",
      "episode 3211, reward 271.0, memory_length 2000, epsilon 0.20078913523978667\n",
      "travel time- 730.0\n",
      "--- 1.7975966930389404 seconds ---\n",
      "episode 3212, reward 145.0, memory_length 2000, epsilon 0.20068876576662606\n",
      "travel time- 725.0\n",
      "--- 1.5313355922698975 seconds ---\n",
      "episode 3213, reward -135.0, memory_length 2000, epsilon 0.200588446465658\n",
      "travel time- 722.0\n",
      "--- 1.9766592979431152 seconds ---\n",
      "episode 3214, reward 157.0, memory_length 2000, epsilon 0.20048817731180257\n",
      "travel time- 723.0\n",
      "--- 1.4759302139282227 seconds ---\n",
      "episode 3215, reward -169.0, memory_length 2000, epsilon 0.20038795827999253\n",
      "travel time- 724.0\n",
      "--- 1.6506528854370117 seconds ---\n",
      "episode 3216, reward -28.0, memory_length 2000, epsilon 0.20028778934517305\n",
      "travel time- 720.0\n",
      "--- 1.8423876762390137 seconds ---\n",
      "episode 3217, reward -176.0, memory_length 2000, epsilon 0.20018767048230202\n",
      "travel time- 720.0\n",
      "--- 1.6657392978668213 seconds ---\n",
      "episode 3218, reward 17.0, memory_length 2000, epsilon 0.20008760166634962\n",
      "travel time- 722.0\n",
      "--- 1.7051823139190674 seconds ---\n",
      "episode 3219, reward 96.0, memory_length 2000, epsilon 0.1999875828722987\n",
      "travel time- 736.0\n",
      "--- 1.5978484153747559 seconds ---\n",
      "episode 3220, reward -198.0, memory_length 2000, epsilon 0.1998876140751445\n",
      "travel time- 721.0\n",
      "--- 1.7855193614959717 seconds ---\n",
      "episode 3221, reward 143.0, memory_length 2000, epsilon 0.19978769524989487\n",
      "travel time- 721.0\n",
      "--- 1.6730620861053467 seconds ---\n",
      "episode 3222, reward -63.0, memory_length 2000, epsilon 0.19968782637157012\n",
      "travel time- 724.0\n",
      "--- 1.5721070766448975 seconds ---\n",
      "episode 3223, reward 30.0, memory_length 2000, epsilon 0.199588007415203\n",
      "travel time- 720.0\n",
      "--- 1.6601948738098145 seconds ---\n",
      "episode 3224, reward -162.0, memory_length 2000, epsilon 0.19948823835583873\n",
      "travel time- 721.0\n",
      "--- 1.801940679550171 seconds ---\n",
      "episode 3225, reward -203.0, memory_length 2000, epsilon 0.19938851916853514\n",
      "travel time- 720.0\n",
      "--- 1.6302950382232666 seconds ---\n",
      "episode 3226, reward -230.0, memory_length 2000, epsilon 0.19928884982836237\n",
      "travel time- 723.0\n",
      "--- 1.8139429092407227 seconds ---\n",
      "episode 3227, reward 15.0, memory_length 2000, epsilon 0.1991892303104031\n",
      "travel time- 721.0\n",
      "--- 1.7285444736480713 seconds ---\n",
      "episode 3228, reward -24.0, memory_length 2000, epsilon 0.1990896605897524\n",
      "travel time- 722.0\n",
      "--- 1.6714520454406738 seconds ---\n",
      "episode 3229, reward 28.0, memory_length 2000, epsilon 0.1989901406415179\n",
      "travel time- 725.0\n",
      "--- 1.4667530059814453 seconds ---\n",
      "episode 3230, reward 38.0, memory_length 2000, epsilon 0.19889067044081962\n",
      "travel time- 723.0\n",
      "--- 1.7386934757232666 seconds ---\n",
      "episode 3231, reward 99.0, memory_length 2000, epsilon 0.19879124996279\n",
      "travel time- 722.0\n",
      "--- 1.9689109325408936 seconds ---\n",
      "episode 3232, reward 80.0, memory_length 2000, epsilon 0.19869187918257386\n",
      "travel time- 720.0\n",
      "--- 1.5840060710906982 seconds ---\n",
      "episode 3233, reward -208.0, memory_length 2000, epsilon 0.19859255807532858\n",
      "travel time- 724.0\n",
      "--- 1.7605383396148682 seconds ---\n",
      "episode 3234, reward 9.0, memory_length 2000, epsilon 0.19849328661622387\n",
      "travel time- 722.0\n",
      "--- 1.8030824661254883 seconds ---\n",
      "episode 3235, reward -238.0, memory_length 2000, epsilon 0.19839406478044183\n",
      "travel time- 724.0\n",
      "--- 1.7481772899627686 seconds ---\n",
      "episode 3236, reward 106.0, memory_length 2000, epsilon 0.19829489254317698\n",
      "travel time- 725.0\n",
      "--- 1.7977509498596191 seconds ---\n",
      "episode 3237, reward -34.0, memory_length 2000, epsilon 0.19819576987963633\n",
      "travel time- 723.0\n",
      "--- 1.2985103130340576 seconds ---\n",
      "episode 3238, reward -124.0, memory_length 2000, epsilon 0.19809669676503922\n",
      "travel time- 731.0\n",
      "--- 1.731614112854004 seconds ---\n",
      "episode 3239, reward -121.0, memory_length 2000, epsilon 0.19799767317461728\n",
      "travel time- 725.0\n",
      "--- 1.6038033962249756 seconds ---\n",
      "episode 3240, reward -146.0, memory_length 2000, epsilon 0.19789869908361465\n",
      "travel time- 731.0\n",
      "--- 1.5332090854644775 seconds ---\n",
      "episode 3241, reward 133.0, memory_length 2000, epsilon 0.1977997744672879\n",
      "travel time- 725.0\n",
      "--- 1.6424314975738525 seconds ---\n",
      "episode 3242, reward -159.0, memory_length 2000, epsilon 0.19770089930090573\n",
      "travel time- 729.0\n",
      "--- 1.765953540802002 seconds ---\n",
      "episode 3243, reward -142.0, memory_length 2000, epsilon 0.19760207355974946\n",
      "travel time- 731.0\n",
      "--- 1.6269102096557617 seconds ---\n",
      "episode 3244, reward -25.0, memory_length 2000, epsilon 0.19750329721911256\n",
      "travel time- 721.0\n",
      "--- 1.5147459506988525 seconds ---\n",
      "episode 3245, reward -114.0, memory_length 2000, epsilon 0.19740457025430103\n",
      "travel time- 721.0\n",
      "--- 1.5938150882720947 seconds ---\n",
      "episode 3246, reward 6.0, memory_length 2000, epsilon 0.19730589264063308\n",
      "travel time- 724.0\n",
      "--- 1.6903984546661377 seconds ---\n",
      "episode 3247, reward -284.0, memory_length 2000, epsilon 0.19720726435343933\n",
      "travel time- 723.0\n",
      "--- 1.7967276573181152 seconds ---\n",
      "episode 3248, reward -163.0, memory_length 2000, epsilon 0.19710868536806264\n",
      "travel time- 722.0\n",
      "--- 1.7973713874816895 seconds ---\n",
      "episode 3249, reward 138.0, memory_length 2000, epsilon 0.19701015565985838\n",
      "travel time- 734.0\n",
      "--- 1.7091350555419922 seconds ---\n",
      "episode 3250, reward -27.0, memory_length 2000, epsilon 0.19691167520419406\n",
      "travel time- 724.0\n",
      "--- 1.5740513801574707 seconds ---\n",
      "episode 3251, reward -334.0, memory_length 2000, epsilon 0.19681324397644956\n",
      "travel time- 721.0\n",
      "--- 1.8643479347229004 seconds ---\n",
      "episode 3252, reward -268.0, memory_length 2000, epsilon 0.19671486195201704\n",
      "travel time- 723.0\n",
      "--- 1.89243745803833 seconds ---\n",
      "episode 3253, reward 28.0, memory_length 2000, epsilon 0.19661652910630106\n",
      "travel time- 722.0\n",
      "--- 1.500420093536377 seconds ---\n",
      "episode 3254, reward -68.0, memory_length 2000, epsilon 0.19651824541471838\n",
      "travel time- 725.0\n",
      "--- 1.633470058441162 seconds ---\n",
      "episode 3255, reward -207.0, memory_length 2000, epsilon 0.1964200108526981\n",
      "travel time- 723.0\n",
      "--- 1.5649974346160889 seconds ---\n",
      "episode 3256, reward 18.0, memory_length 2000, epsilon 0.1963218253956815\n",
      "travel time- 720.0\n",
      "--- 1.644683837890625 seconds ---\n",
      "episode 3257, reward 172.0, memory_length 2000, epsilon 0.19622368901912232\n",
      "travel time- 731.0\n",
      "--- 1.5168583393096924 seconds ---\n",
      "episode 3258, reward -66.0, memory_length 2000, epsilon 0.19612560169848642\n",
      "travel time- 725.0\n",
      "--- 1.8776013851165771 seconds ---\n",
      "episode 3259, reward 240.0, memory_length 2000, epsilon 0.19602756340925195\n",
      "travel time- 721.0\n",
      "--- 1.553229808807373 seconds ---\n",
      "episode 3260, reward -130.0, memory_length 2000, epsilon 0.19592957412690934\n",
      "travel time- 724.0\n",
      "--- 1.6094768047332764 seconds ---\n",
      "episode 3261, reward -66.0, memory_length 2000, epsilon 0.19583163382696128\n",
      "travel time- 722.0\n",
      "--- 1.6140389442443848 seconds ---\n",
      "episode 3262, reward 12.0, memory_length 2000, epsilon 0.19573374248492273\n",
      "travel time- 721.0\n",
      "--- 1.7494311332702637 seconds ---\n",
      "episode 3263, reward 320.0, memory_length 2000, epsilon 0.1956359000763208\n",
      "travel time- 723.0\n",
      "--- 1.6689698696136475 seconds ---\n",
      "episode 3264, reward 36.0, memory_length 2000, epsilon 0.1955381065766949\n",
      "travel time- 725.0\n",
      "--- 1.7321341037750244 seconds ---\n",
      "episode 3265, reward -305.0, memory_length 2000, epsilon 0.19544036196159667\n",
      "travel time- 731.0\n",
      "--- 1.7627837657928467 seconds ---\n",
      "episode 3266, reward -236.0, memory_length 2000, epsilon 0.19534266620658997\n",
      "travel time- 723.0\n",
      "--- 1.7176241874694824 seconds ---\n",
      "episode 3267, reward 43.0, memory_length 2000, epsilon 0.19524501928725083\n",
      "travel time- 720.0\n",
      "--- 1.5498337745666504 seconds ---\n",
      "episode 3268, reward 63.0, memory_length 2000, epsilon 0.1951474211791675\n",
      "travel time- 722.0\n",
      "--- 1.7123520374298096 seconds ---\n",
      "episode 3269, reward 162.0, memory_length 2000, epsilon 0.1950498718579405\n",
      "travel time- 722.0\n",
      "--- 1.7778575420379639 seconds ---\n",
      "episode 3270, reward 50.0, memory_length 2000, epsilon 0.1949523712991825\n",
      "travel time- 724.0\n",
      "--- 1.9656319618225098 seconds ---\n",
      "episode 3271, reward 253.0, memory_length 2000, epsilon 0.19485491947851832\n",
      "travel time- 727.0\n",
      "--- 1.6050357818603516 seconds ---\n",
      "episode 3272, reward -192.0, memory_length 2000, epsilon 0.194757516371585\n",
      "travel time- 726.0\n",
      "--- 1.586305856704712 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3273, reward 283.0, memory_length 2000, epsilon 0.19466016195403182\n",
      "travel time- 724.0\n",
      "--- 1.7105302810668945 seconds ---\n",
      "episode 3274, reward -91.0, memory_length 2000, epsilon 0.19456285620152014\n",
      "travel time- 720.0\n",
      "--- 1.7272167205810547 seconds ---\n",
      "episode 3275, reward 285.0, memory_length 2000, epsilon 0.19446559908972355\n",
      "travel time- 724.0\n",
      "--- 1.687821626663208 seconds ---\n",
      "episode 3276, reward 190.0, memory_length 2000, epsilon 0.19436839059432767\n",
      "travel time- 728.0\n",
      "--- 1.6886975765228271 seconds ---\n",
      "episode 3277, reward 294.0, memory_length 2000, epsilon 0.1942712306910305\n",
      "travel time- 727.0\n",
      "--- 1.6620275974273682 seconds ---\n",
      "episode 3278, reward 303.0, memory_length 2000, epsilon 0.19417411935554202\n",
      "travel time- 724.0\n",
      "--- 1.7332079410552979 seconds ---\n",
      "episode 3279, reward -20.0, memory_length 2000, epsilon 0.1940770565635844\n",
      "travel time- 721.0\n",
      "--- 1.6848084926605225 seconds ---\n",
      "episode 3280, reward -83.0, memory_length 2000, epsilon 0.19398004229089189\n",
      "travel time- 722.0\n",
      "--- 1.6726880073547363 seconds ---\n",
      "episode 3281, reward 112.0, memory_length 2000, epsilon 0.193883076513211\n",
      "travel time- 723.0\n",
      "--- 1.707533597946167 seconds ---\n",
      "episode 3282, reward -230.0, memory_length 2000, epsilon 0.1937861592063002\n",
      "travel time- 728.0\n",
      "--- 1.748856544494629 seconds ---\n",
      "episode 3283, reward -62.0, memory_length 2000, epsilon 0.19368929034593027\n",
      "travel time- 720.0\n",
      "--- 1.9584460258483887 seconds ---\n",
      "episode 3284, reward -233.0, memory_length 2000, epsilon 0.1935924699078839\n",
      "travel time- 720.0\n",
      "--- 1.6681053638458252 seconds ---\n",
      "episode 3285, reward -46.0, memory_length 2000, epsilon 0.19349569786795603\n",
      "travel time- 722.0\n",
      "--- 1.8817408084869385 seconds ---\n",
      "episode 3286, reward -136.0, memory_length 2000, epsilon 0.19339897420195362\n",
      "travel time- 722.0\n",
      "--- 1.7778284549713135 seconds ---\n",
      "episode 3287, reward -22.0, memory_length 2000, epsilon 0.1933022988856958\n",
      "travel time- 721.0\n",
      "--- 1.4328796863555908 seconds ---\n",
      "episode 3288, reward -119.0, memory_length 2000, epsilon 0.19320567189501364\n",
      "travel time- 726.0\n",
      "--- 1.723092794418335 seconds ---\n",
      "episode 3289, reward 250.0, memory_length 2000, epsilon 0.19310909320575054\n",
      "travel time- 722.0\n",
      "--- 1.7634639739990234 seconds ---\n",
      "episode 3290, reward 49.0, memory_length 2000, epsilon 0.19301256279376172\n",
      "travel time- 720.0\n",
      "--- 1.5582826137542725 seconds ---\n",
      "episode 3291, reward 127.0, memory_length 2000, epsilon 0.19291608063491458\n",
      "travel time- 724.0\n",
      "--- 1.831981897354126 seconds ---\n",
      "episode 3292, reward -31.0, memory_length 2000, epsilon 0.1928196467050886\n",
      "travel time- 721.0\n",
      "--- 1.7420825958251953 seconds ---\n",
      "episode 3293, reward 38.0, memory_length 2000, epsilon 0.19272326098017534\n",
      "travel time- 723.0\n",
      "--- 1.5261523723602295 seconds ---\n",
      "episode 3294, reward 46.0, memory_length 2000, epsilon 0.19262692343607832\n",
      "travel time- 729.0\n",
      "--- 1.6622169017791748 seconds ---\n",
      "episode 3295, reward -117.0, memory_length 2000, epsilon 0.19253063404871315\n",
      "travel time- 732.0\n",
      "--- 1.6966731548309326 seconds ---\n",
      "episode 3296, reward -350.0, memory_length 2000, epsilon 0.19243439279400748\n",
      "travel time- 722.0\n",
      "--- 2.0218632221221924 seconds ---\n",
      "episode 3297, reward 337.0, memory_length 2000, epsilon 0.19233819964790103\n",
      "travel time- 726.0\n",
      "--- 1.7236967086791992 seconds ---\n",
      "episode 3298, reward 146.0, memory_length 2000, epsilon 0.1922420545863455\n",
      "travel time- 723.0\n",
      "--- 1.656813621520996 seconds ---\n",
      "episode 3299, reward 208.0, memory_length 2000, epsilon 0.19214595758530462\n",
      "travel time- 722.0\n",
      "--- 1.6854088306427002 seconds ---\n",
      "episode 3300, reward 102.0, memory_length 2000, epsilon 0.19204990862075408\n",
      "travel time- 721.0\n",
      "--- 1.5920538902282715 seconds ---\n",
      "episode 3301, reward -247.0, memory_length 2000, epsilon 0.19195390766868176\n",
      "travel time- 729.0\n",
      "--- 1.6237049102783203 seconds ---\n",
      "episode 3302, reward -21.0, memory_length 2000, epsilon 0.19185795470508735\n",
      "travel time- 729.0\n",
      "--- 1.7128384113311768 seconds ---\n",
      "episode 3303, reward 92.0, memory_length 2000, epsilon 0.19176204970598262\n",
      "travel time- 723.0\n",
      "--- 1.5288100242614746 seconds ---\n",
      "episode 3304, reward 204.0, memory_length 2000, epsilon 0.19166619264739126\n",
      "travel time- 726.0\n",
      "--- 1.4859740734100342 seconds ---\n",
      "episode 3305, reward 173.0, memory_length 2000, epsilon 0.1915703835053491\n",
      "travel time- 725.0\n",
      "--- 1.5046558380126953 seconds ---\n",
      "episode 3306, reward -25.0, memory_length 2000, epsilon 0.19147462225590384\n",
      "travel time- 726.0\n",
      "--- 1.688600778579712 seconds ---\n",
      "episode 3307, reward 438.0, memory_length 2000, epsilon 0.1913789088751151\n",
      "travel time- 723.0\n",
      "--- 1.8594005107879639 seconds ---\n",
      "episode 3308, reward 162.0, memory_length 2000, epsilon 0.19128324333905458\n",
      "travel time- 721.0\n",
      "--- 1.607490062713623 seconds ---\n",
      "episode 3309, reward 102.0, memory_length 2000, epsilon 0.1911876256238059\n",
      "travel time- 721.0\n",
      "--- 1.4205377101898193 seconds ---\n",
      "episode 3310, reward -117.0, memory_length 2000, epsilon 0.19109205570546464\n",
      "travel time- 722.0\n",
      "--- 1.7022833824157715 seconds ---\n",
      "episode 3311, reward -400.0, memory_length 2000, epsilon 0.1909965335601383\n",
      "travel time- 724.0\n",
      "--- 1.8082695007324219 seconds ---\n",
      "episode 3312, reward -16.0, memory_length 2000, epsilon 0.19090105916394629\n",
      "travel time- 724.0\n",
      "--- 1.7315311431884766 seconds ---\n",
      "episode 3313, reward 16.0, memory_length 2000, epsilon 0.1908056324930201\n",
      "travel time- 725.0\n",
      "--- 1.4637236595153809 seconds ---\n",
      "episode 3314, reward 322.0, memory_length 2000, epsilon 0.19071025352350304\n",
      "travel time- 722.0\n",
      "--- 1.5799334049224854 seconds ---\n",
      "episode 3315, reward -256.0, memory_length 2000, epsilon 0.19061492223155038\n",
      "travel time- 722.0\n",
      "--- 1.6212012767791748 seconds ---\n",
      "episode 3316, reward 198.0, memory_length 2000, epsilon 0.19051963859332918\n",
      "travel time- 722.0\n",
      "--- 1.6474506855010986 seconds ---\n",
      "episode 3317, reward -8.0, memory_length 2000, epsilon 0.1904244025850187\n",
      "travel time- 733.0\n",
      "--- 1.6543843746185303 seconds ---\n",
      "episode 3318, reward -53.0, memory_length 2000, epsilon 0.19032921418280985\n",
      "travel time- 733.0\n",
      "--- 1.3758063316345215 seconds ---\n",
      "episode 3319, reward 290.0, memory_length 2000, epsilon 0.19023407336290554\n",
      "travel time- 727.0\n",
      "--- 1.7323665618896484 seconds ---\n",
      "episode 3320, reward -216.0, memory_length 2000, epsilon 0.1901389801015205\n",
      "travel time- 723.0\n",
      "--- 1.8669953346252441 seconds ---\n",
      "episode 3321, reward 113.0, memory_length 2000, epsilon 0.19004393437488154\n",
      "travel time- 723.0\n",
      "--- 1.684234857559204 seconds ---\n",
      "episode 3322, reward -5.0, memory_length 2000, epsilon 0.18994893615922714\n",
      "travel time- 723.0\n",
      "--- 1.6178841590881348 seconds ---\n",
      "episode 3323, reward 39.0, memory_length 2000, epsilon 0.18985398543080778\n",
      "travel time- 720.0\n",
      "--- 1.9851007461547852 seconds ---\n",
      "episode 3324, reward -277.0, memory_length 2000, epsilon 0.18975908216588572\n",
      "travel time- 720.0\n",
      "--- 1.7032203674316406 seconds ---\n",
      "episode 3325, reward 0.0, memory_length 2000, epsilon 0.18966422634073524\n",
      "travel time- 720.0\n",
      "--- 1.8467724323272705 seconds ---\n",
      "episode 3326, reward -324.0, memory_length 2000, epsilon 0.18956941793164234\n",
      "travel time- 723.0\n",
      "--- 1.9466447830200195 seconds ---\n",
      "episode 3327, reward -273.0, memory_length 2000, epsilon 0.1894746569149049\n",
      "travel time- 721.0\n",
      "--- 1.9543042182922363 seconds ---\n",
      "episode 3328, reward -95.0, memory_length 2000, epsilon 0.18937994326683263\n",
      "travel time- 724.0\n",
      "--- 1.559006929397583 seconds ---\n",
      "episode 3329, reward 4.0, memory_length 2000, epsilon 0.18928527696374722\n",
      "travel time- 723.0\n",
      "--- 1.7142207622528076 seconds ---\n",
      "episode 3330, reward -229.0, memory_length 2000, epsilon 0.18919065798198204\n",
      "travel time- 727.0\n",
      "--- 1.560849905014038 seconds ---\n",
      "episode 3331, reward -175.0, memory_length 2000, epsilon 0.1890960862978823\n",
      "travel time- 733.0\n",
      "--- 1.6085071563720703 seconds ---\n",
      "episode 3332, reward 298.0, memory_length 2000, epsilon 0.18900156188780515\n",
      "travel time- 724.0\n",
      "--- 1.6455979347229004 seconds ---\n",
      "episode 3333, reward -59.0, memory_length 2000, epsilon 0.18890708472811943\n",
      "travel time- 728.0\n",
      "--- 1.6993520259857178 seconds ---\n",
      "episode 3334, reward -237.0, memory_length 2000, epsilon 0.1888126547952059\n",
      "travel time- 732.0\n",
      "--- 1.8160438537597656 seconds ---\n",
      "episode 3335, reward -120.0, memory_length 2000, epsilon 0.18871827206545705\n",
      "travel time- 721.0\n",
      "--- 1.7200005054473877 seconds ---\n",
      "episode 3336, reward 310.0, memory_length 2000, epsilon 0.1886239365152772\n",
      "travel time- 723.0\n",
      "--- 1.6837592124938965 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3337, reward 3.0, memory_length 2000, epsilon 0.18852964812108242\n",
      "travel time- 725.0\n",
      "--- 1.6497406959533691 seconds ---\n",
      "episode 3338, reward -23.0, memory_length 2000, epsilon 0.18843540685930069\n",
      "travel time- 724.0\n",
      "--- 1.677893877029419 seconds ---\n",
      "episode 3339, reward -317.0, memory_length 2000, epsilon 0.18834121270637166\n",
      "travel time- 720.0\n",
      "--- 1.7069201469421387 seconds ---\n",
      "episode 3340, reward -169.0, memory_length 2000, epsilon 0.1882470656387468\n",
      "travel time- 725.0\n",
      "--- 1.8294486999511719 seconds ---\n",
      "episode 3341, reward 46.0, memory_length 2000, epsilon 0.18815296563288927\n",
      "travel time- 731.0\n",
      "--- 1.6591110229492188 seconds ---\n",
      "episode 3342, reward 21.0, memory_length 2000, epsilon 0.18805891266527416\n",
      "travel time- 725.0\n",
      "--- 1.8276443481445312 seconds ---\n",
      "episode 3343, reward 55.0, memory_length 2000, epsilon 0.18796490671238822\n",
      "travel time- 720.0\n",
      "--- 1.4733343124389648 seconds ---\n",
      "episode 3344, reward 120.0, memory_length 2000, epsilon 0.18787094775072993\n",
      "travel time- 723.0\n",
      "--- 1.6079576015472412 seconds ---\n",
      "episode 3345, reward -101.0, memory_length 2000, epsilon 0.1877770357568095\n",
      "travel time- 724.0\n",
      "--- 1.660794734954834 seconds ---\n",
      "episode 3346, reward -233.0, memory_length 2000, epsilon 0.18768317070714904\n",
      "travel time- 720.0\n",
      "--- 1.7437868118286133 seconds ---\n",
      "episode 3347, reward 198.0, memory_length 2000, epsilon 0.18758935257828224\n",
      "travel time- 723.0\n",
      "--- 1.5120859146118164 seconds ---\n",
      "episode 3348, reward -83.0, memory_length 2000, epsilon 0.18749558134675456\n",
      "travel time- 725.0\n",
      "--- 1.6510570049285889 seconds ---\n",
      "episode 3349, reward 100.0, memory_length 2000, epsilon 0.18740185698912315\n",
      "travel time- 723.0\n",
      "--- 1.676177978515625 seconds ---\n",
      "episode 3350, reward 61.0, memory_length 2000, epsilon 0.18730817948195702\n",
      "travel time- 724.0\n",
      "--- 1.7102088928222656 seconds ---\n",
      "episode 3351, reward -277.0, memory_length 2000, epsilon 0.18721454880183672\n",
      "travel time- 724.0\n",
      "--- 1.6826670169830322 seconds ---\n",
      "episode 3352, reward 141.0, memory_length 2000, epsilon 0.1871209649253546\n",
      "travel time- 725.0\n",
      "--- 1.6645677089691162 seconds ---\n",
      "episode 3353, reward 101.0, memory_length 2000, epsilon 0.18702742782911463\n",
      "travel time- 722.0\n",
      "--- 1.4832746982574463 seconds ---\n",
      "episode 3354, reward -155.0, memory_length 2000, epsilon 0.18693393748973264\n",
      "travel time- 724.0\n",
      "--- 1.8011839389801025 seconds ---\n",
      "episode 3355, reward -149.0, memory_length 2000, epsilon 0.186840493883836\n",
      "travel time- 722.0\n",
      "--- 1.7510104179382324 seconds ---\n",
      "episode 3356, reward 65.0, memory_length 2000, epsilon 0.1867470969880638\n",
      "travel time- 721.0\n",
      "--- 1.6953299045562744 seconds ---\n",
      "episode 3357, reward -147.0, memory_length 2000, epsilon 0.1866537467790668\n",
      "travel time- 720.0\n",
      "--- 1.8933954238891602 seconds ---\n",
      "episode 3358, reward -190.0, memory_length 2000, epsilon 0.18656044323350748\n",
      "travel time- 721.0\n",
      "--- 1.8299355506896973 seconds ---\n",
      "episode 3359, reward -170.0, memory_length 2000, epsilon 0.18646718632805995\n",
      "travel time- 720.0\n",
      "--- 1.528836965560913 seconds ---\n",
      "episode 3360, reward -110.0, memory_length 2000, epsilon 0.18637397603940997\n",
      "travel time- 729.0\n",
      "--- 1.9382309913635254 seconds ---\n",
      "episode 3361, reward -171.0, memory_length 2000, epsilon 0.18628081234425495\n",
      "travel time- 728.0\n",
      "--- 1.6929163932800293 seconds ---\n",
      "episode 3362, reward 73.0, memory_length 2000, epsilon 0.186187695219304\n",
      "travel time- 728.0\n",
      "--- 1.7133700847625732 seconds ---\n",
      "episode 3363, reward 63.0, memory_length 2000, epsilon 0.18609462464127785\n",
      "travel time- 723.0\n",
      "--- 1.6658427715301514 seconds ---\n",
      "episode 3364, reward 89.0, memory_length 2000, epsilon 0.1860016005869088\n",
      "travel time- 727.0\n",
      "--- 1.6719741821289062 seconds ---\n",
      "episode 3365, reward -15.0, memory_length 2000, epsilon 0.18590862303294084\n",
      "travel time- 725.0\n",
      "--- 1.5106408596038818 seconds ---\n",
      "episode 3366, reward -62.0, memory_length 2000, epsilon 0.18581569195612965\n",
      "travel time- 727.0\n",
      "--- 1.709108829498291 seconds ---\n",
      "episode 3367, reward 98.0, memory_length 2000, epsilon 0.18572280733324242\n",
      "travel time- 726.0\n",
      "--- 1.662477970123291 seconds ---\n",
      "episode 3368, reward 262.0, memory_length 2000, epsilon 0.18562996914105798\n",
      "travel time- 731.0\n",
      "--- 1.6444458961486816 seconds ---\n",
      "episode 3369, reward -263.0, memory_length 2000, epsilon 0.18553717735636674\n",
      "travel time- 721.0\n",
      "--- 1.3919434547424316 seconds ---\n",
      "episode 3370, reward -41.0, memory_length 2000, epsilon 0.18544443195597088\n",
      "travel time- 720.0\n",
      "--- 1.6962194442749023 seconds ---\n",
      "episode 3371, reward 187.0, memory_length 2000, epsilon 0.18535173291668394\n",
      "travel time- 721.0\n",
      "--- 1.6162195205688477 seconds ---\n",
      "episode 3372, reward 217.0, memory_length 2000, epsilon 0.18525908021533122\n",
      "travel time- 720.0\n",
      "--- 1.7429251670837402 seconds ---\n",
      "episode 3373, reward -312.0, memory_length 2000, epsilon 0.18516647382874946\n",
      "travel time- 722.0\n",
      "--- 1.7236230373382568 seconds ---\n",
      "episode 3374, reward -9.0, memory_length 2000, epsilon 0.18507391373378718\n",
      "travel time- 728.0\n",
      "--- 1.7971675395965576 seconds ---\n",
      "episode 3375, reward 104.0, memory_length 2000, epsilon 0.18498139990730428\n",
      "travel time- 723.0\n",
      "--- 1.5687024593353271 seconds ---\n",
      "episode 3376, reward -88.0, memory_length 2000, epsilon 0.18488893232617234\n",
      "travel time- 727.0\n",
      "--- 1.7248485088348389 seconds ---\n",
      "episode 3377, reward -127.0, memory_length 2000, epsilon 0.1847965109672744\n",
      "travel time- 726.0\n",
      "--- 1.6784422397613525 seconds ---\n",
      "episode 3378, reward 303.0, memory_length 2000, epsilon 0.1847041358075052\n",
      "travel time- 721.0\n",
      "--- 1.7536275386810303 seconds ---\n",
      "episode 3379, reward 226.0, memory_length 2000, epsilon 0.1846118068237709\n",
      "travel time- 726.0\n",
      "--- 1.3797297477722168 seconds ---\n",
      "episode 3380, reward 13.0, memory_length 2000, epsilon 0.18451952399298926\n",
      "travel time- 729.0\n",
      "--- 1.8422532081604004 seconds ---\n",
      "episode 3381, reward 93.0, memory_length 2000, epsilon 0.18442728729208957\n",
      "travel time- 725.0\n",
      "--- 1.644925832748413 seconds ---\n",
      "episode 3382, reward 74.0, memory_length 2000, epsilon 0.1843350966980127\n",
      "travel time- 725.0\n",
      "--- 1.4323062896728516 seconds ---\n",
      "episode 3383, reward 277.0, memory_length 2000, epsilon 0.18424295218771095\n",
      "travel time- 720.0\n",
      "--- 1.6384491920471191 seconds ---\n",
      "episode 3384, reward -267.0, memory_length 2000, epsilon 0.1841508537381482\n",
      "travel time- 725.0\n",
      "--- 1.6345891952514648 seconds ---\n",
      "episode 3385, reward 107.0, memory_length 2000, epsilon 0.18405880132629984\n",
      "travel time- 724.0\n",
      "--- 1.735445499420166 seconds ---\n",
      "episode 3386, reward 51.0, memory_length 2000, epsilon 0.18396679492915277\n",
      "travel time- 732.0\n",
      "--- 1.7854909896850586 seconds ---\n",
      "episode 3387, reward -25.0, memory_length 2000, epsilon 0.18387483452370543\n",
      "travel time- 723.0\n",
      "--- 1.6811895370483398 seconds ---\n",
      "episode 3388, reward -333.0, memory_length 2000, epsilon 0.18378292008696764\n",
      "travel time- 722.0\n",
      "--- 1.7366628646850586 seconds ---\n",
      "episode 3389, reward -256.0, memory_length 2000, epsilon 0.1836910515959608\n",
      "travel time- 726.0\n",
      "--- 1.819187879562378 seconds ---\n",
      "episode 3390, reward 133.0, memory_length 2000, epsilon 0.18359922902771786\n",
      "travel time- 724.0\n",
      "--- 1.6170506477355957 seconds ---\n",
      "episode 3391, reward -122.0, memory_length 2000, epsilon 0.18350745235928315\n",
      "travel time- 729.0\n",
      "--- 1.978456735610962 seconds ---\n",
      "episode 3392, reward 200.0, memory_length 2000, epsilon 0.18341572156771246\n",
      "travel time- 736.0\n",
      "--- 1.746551513671875 seconds ---\n",
      "episode 3393, reward -18.0, memory_length 2000, epsilon 0.18332403663007307\n",
      "travel time- 720.0\n",
      "--- 1.8434243202209473 seconds ---\n",
      "episode 3394, reward -145.0, memory_length 2000, epsilon 0.18323239752344386\n",
      "travel time- 727.0\n",
      "--- 1.828369379043579 seconds ---\n",
      "episode 3395, reward -224.0, memory_length 2000, epsilon 0.18314080422491497\n",
      "travel time- 720.0\n",
      "--- 1.600522756576538 seconds ---\n",
      "episode 3396, reward -87.0, memory_length 2000, epsilon 0.18304925671158812\n",
      "travel time- 727.0\n",
      "--- 1.8003785610198975 seconds ---\n",
      "episode 3397, reward -73.0, memory_length 2000, epsilon 0.1829577549605763\n",
      "travel time- 722.0\n",
      "--- 1.5995798110961914 seconds ---\n",
      "episode 3398, reward -5.0, memory_length 2000, epsilon 0.18286629894900427\n",
      "travel time- 724.0\n",
      "--- 1.7046942710876465 seconds ---\n",
      "episode 3399, reward -155.0, memory_length 2000, epsilon 0.1827748886540079\n",
      "travel time- 721.0\n",
      "--- 1.6814658641815186 seconds ---\n",
      "episode 3400, reward 27.0, memory_length 2000, epsilon 0.18268352405273466\n",
      "travel time- 729.0\n",
      "--- 1.8631737232208252 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3401, reward -482.0, memory_length 2000, epsilon 0.18259220512234334\n",
      "travel time- 723.0\n",
      "--- 1.8915305137634277 seconds ---\n",
      "episode 3402, reward 206.0, memory_length 2000, epsilon 0.1825009318400043\n",
      "travel time- 724.0\n",
      "--- 1.6128849983215332 seconds ---\n",
      "episode 3403, reward -4.0, memory_length 2000, epsilon 0.18240970418289915\n",
      "travel time- 728.0\n",
      "--- 1.7808213233947754 seconds ---\n",
      "episode 3404, reward -6.0, memory_length 2000, epsilon 0.182318522128221\n",
      "travel time- 722.0\n",
      "--- 1.65828275680542 seconds ---\n",
      "episode 3405, reward -99.0, memory_length 2000, epsilon 0.1822273856531743\n",
      "travel time- 721.0\n",
      "--- 1.5000483989715576 seconds ---\n",
      "episode 3406, reward -161.0, memory_length 2000, epsilon 0.182136294734975\n",
      "travel time- 720.0\n",
      "--- 1.8389663696289062 seconds ---\n",
      "episode 3407, reward -48.0, memory_length 2000, epsilon 0.18204524935085034\n",
      "travel time- 724.0\n",
      "--- 1.8152697086334229 seconds ---\n",
      "episode 3408, reward -7.0, memory_length 2000, epsilon 0.18195424947803895\n",
      "travel time- 721.0\n",
      "--- 1.577451229095459 seconds ---\n",
      "episode 3409, reward 78.0, memory_length 2000, epsilon 0.18186329509379084\n",
      "travel time- 733.0\n",
      "--- 1.6826388835906982 seconds ---\n",
      "episode 3410, reward 51.0, memory_length 2000, epsilon 0.1817723861753675\n",
      "travel time- 722.0\n",
      "--- 1.826080083847046 seconds ---\n",
      "episode 3411, reward -138.0, memory_length 2000, epsilon 0.18168152270004165\n",
      "travel time- 720.0\n",
      "--- 1.532585620880127 seconds ---\n",
      "episode 3412, reward 300.0, memory_length 2000, epsilon 0.1815907046450974\n",
      "travel time- 735.0\n",
      "--- 1.7203686237335205 seconds ---\n",
      "episode 3413, reward 68.0, memory_length 2000, epsilon 0.18149993198783027\n",
      "travel time- 724.0\n",
      "--- 1.8425748348236084 seconds ---\n",
      "episode 3414, reward 201.0, memory_length 2000, epsilon 0.18140920470554706\n",
      "travel time- 720.0\n",
      "--- 1.6674907207489014 seconds ---\n",
      "episode 3415, reward -32.0, memory_length 2000, epsilon 0.181318522775566\n",
      "travel time- 729.0\n",
      "--- 1.5251505374908447 seconds ---\n",
      "episode 3416, reward -103.0, memory_length 2000, epsilon 0.1812278861752166\n",
      "travel time- 724.0\n",
      "--- 1.788412094116211 seconds ---\n",
      "episode 3417, reward 16.0, memory_length 2000, epsilon 0.1811372948818396\n",
      "travel time- 724.0\n",
      "--- 1.7811543941497803 seconds ---\n",
      "episode 3418, reward 170.0, memory_length 2000, epsilon 0.18104674887278735\n",
      "travel time- 721.0\n",
      "--- 1.83414626121521 seconds ---\n",
      "episode 3419, reward -54.0, memory_length 2000, epsilon 0.1809562481254232\n",
      "travel time- 730.0\n",
      "--- 1.768613338470459 seconds ---\n",
      "episode 3420, reward -117.0, memory_length 2000, epsilon 0.1808657926171221\n",
      "travel time- 723.0\n",
      "--- 1.9648756980895996 seconds ---\n",
      "episode 3421, reward -113.0, memory_length 2000, epsilon 0.18077538232527002\n",
      "travel time- 725.0\n",
      "--- 1.437878131866455 seconds ---\n",
      "episode 3422, reward 191.0, memory_length 2000, epsilon 0.1806850172272645\n",
      "travel time- 725.0\n",
      "--- 1.6022891998291016 seconds ---\n",
      "episode 3423, reward 125.0, memory_length 2000, epsilon 0.18059469730051422\n",
      "travel time- 729.0\n",
      "--- 1.5784912109375 seconds ---\n",
      "episode 3424, reward 139.0, memory_length 2000, epsilon 0.18050442252243923\n",
      "travel time- 725.0\n",
      "--- 1.5393486022949219 seconds ---\n",
      "episode 3425, reward -6.0, memory_length 2000, epsilon 0.18041419287047075\n",
      "travel time- 724.0\n",
      "--- 1.802919626235962 seconds ---\n",
      "episode 3426, reward 229.0, memory_length 2000, epsilon 0.18032400832205148\n",
      "travel time- 724.0\n",
      "--- 1.585883378982544 seconds ---\n",
      "episode 3427, reward 120.0, memory_length 2000, epsilon 0.18023386885463522\n",
      "travel time- 722.0\n",
      "--- 1.604090929031372 seconds ---\n",
      "episode 3428, reward 181.0, memory_length 2000, epsilon 0.1801437744456871\n",
      "travel time- 724.0\n",
      "--- 1.6100237369537354 seconds ---\n",
      "episode 3429, reward 183.0, memory_length 2000, epsilon 0.18005372507268352\n",
      "travel time- 728.0\n",
      "--- 1.5896341800689697 seconds ---\n",
      "episode 3430, reward 185.0, memory_length 2000, epsilon 0.17996372071311217\n",
      "travel time- 723.0\n",
      "--- 1.6523213386535645 seconds ---\n",
      "episode 3431, reward -193.0, memory_length 2000, epsilon 0.17987376134447194\n",
      "travel time- 722.0\n",
      "--- 1.744316577911377 seconds ---\n",
      "episode 3432, reward -310.0, memory_length 2000, epsilon 0.17978384694427296\n",
      "travel time- 721.0\n",
      "--- 1.5571820735931396 seconds ---\n",
      "episode 3433, reward -119.0, memory_length 2000, epsilon 0.17969397749003665\n",
      "travel time- 721.0\n",
      "--- 1.6214203834533691 seconds ---\n",
      "episode 3434, reward -17.0, memory_length 2000, epsilon 0.17960415295929566\n",
      "travel time- 721.0\n",
      "--- 1.8166096210479736 seconds ---\n",
      "episode 3435, reward 31.0, memory_length 2000, epsilon 0.17951437332959386\n",
      "travel time- 722.0\n",
      "--- 1.6139724254608154 seconds ---\n",
      "episode 3436, reward 311.0, memory_length 2000, epsilon 0.17942463857848634\n",
      "travel time- 725.0\n",
      "--- 1.445622444152832 seconds ---\n",
      "episode 3437, reward -332.0, memory_length 2000, epsilon 0.17933494868353933\n",
      "travel time- 723.0\n",
      "--- 1.6192638874053955 seconds ---\n",
      "episode 3438, reward 21.0, memory_length 2000, epsilon 0.1792453036223305\n",
      "travel time- 721.0\n",
      "--- 1.62904953956604 seconds ---\n",
      "episode 3439, reward -39.0, memory_length 2000, epsilon 0.17915570337244846\n",
      "travel time- 728.0\n",
      "--- 1.725499153137207 seconds ---\n",
      "episode 3440, reward 38.0, memory_length 2000, epsilon 0.17906614791149322\n",
      "travel time- 721.0\n",
      "--- 1.6639928817749023 seconds ---\n",
      "episode 3441, reward 99.0, memory_length 2000, epsilon 0.17897663721707585\n",
      "travel time- 722.0\n",
      "--- 1.7831075191497803 seconds ---\n",
      "episode 3442, reward 92.0, memory_length 2000, epsilon 0.17888717126681877\n",
      "travel time- 725.0\n",
      "--- 1.576256513595581 seconds ---\n",
      "episode 3443, reward -57.0, memory_length 2000, epsilon 0.17879775003835544\n",
      "travel time- 727.0\n",
      "--- 1.6629993915557861 seconds ---\n",
      "episode 3444, reward 81.0, memory_length 2000, epsilon 0.17870837350933053\n",
      "travel time- 720.0\n",
      "--- 1.6236810684204102 seconds ---\n",
      "episode 3445, reward 91.0, memory_length 2000, epsilon 0.1786190416573999\n",
      "travel time- 720.0\n",
      "--- 1.591953992843628 seconds ---\n",
      "episode 3446, reward -25.0, memory_length 2000, epsilon 0.17852975446023064\n",
      "travel time- 722.0\n",
      "--- 1.6870803833007812 seconds ---\n",
      "episode 3447, reward -75.0, memory_length 2000, epsilon 0.17844051189550095\n",
      "travel time- 721.0\n",
      "--- 1.626530408859253 seconds ---\n",
      "episode 3448, reward 288.0, memory_length 2000, epsilon 0.17835131394090015\n",
      "travel time- 726.0\n",
      "--- 1.5604822635650635 seconds ---\n",
      "episode 3449, reward 54.0, memory_length 2000, epsilon 0.17826216057412872\n",
      "travel time- 723.0\n",
      "--- 1.7564735412597656 seconds ---\n",
      "episode 3450, reward -187.0, memory_length 2000, epsilon 0.1781730517728984\n",
      "travel time- 726.0\n",
      "--- 1.5847694873809814 seconds ---\n",
      "episode 3451, reward 20.0, memory_length 2000, epsilon 0.17808398751493196\n",
      "travel time- 728.0\n",
      "--- 1.6963882446289062 seconds ---\n",
      "episode 3452, reward -331.0, memory_length 2000, epsilon 0.17799496777796334\n",
      "travel time- 723.0\n",
      "--- 1.5082204341888428 seconds ---\n",
      "episode 3453, reward 43.0, memory_length 2000, epsilon 0.17790599253973752\n",
      "travel time- 731.0\n",
      "--- 1.6252386569976807 seconds ---\n",
      "episode 3454, reward 52.0, memory_length 2000, epsilon 0.17781706177801082\n",
      "travel time- 720.0\n",
      "--- 1.74135160446167 seconds ---\n",
      "episode 3455, reward 58.0, memory_length 2000, epsilon 0.1777281754705505\n",
      "travel time- 726.0\n",
      "--- 1.7427427768707275 seconds ---\n",
      "episode 3456, reward 236.0, memory_length 2000, epsilon 0.17763933359513495\n",
      "travel time- 720.0\n",
      "--- 1.7579472064971924 seconds ---\n",
      "episode 3457, reward 35.0, memory_length 2000, epsilon 0.17755053612955374\n",
      "travel time- 723.0\n",
      "--- 1.614788293838501 seconds ---\n",
      "episode 3458, reward -49.0, memory_length 2000, epsilon 0.17746178305160745\n",
      "travel time- 727.0\n",
      "--- 1.7226364612579346 seconds ---\n",
      "episode 3459, reward 106.0, memory_length 2000, epsilon 0.17737307433910787\n",
      "travel time- 723.0\n",
      "--- 1.5655419826507568 seconds ---\n",
      "episode 3460, reward 301.0, memory_length 2000, epsilon 0.17728440996987782\n",
      "travel time- 725.0\n",
      "--- 1.6661207675933838 seconds ---\n",
      "episode 3461, reward 203.0, memory_length 2000, epsilon 0.17719578992175117\n",
      "travel time- 723.0\n",
      "--- 1.4633705615997314 seconds ---\n",
      "episode 3462, reward -125.0, memory_length 2000, epsilon 0.17710721417257289\n",
      "travel time- 729.0\n",
      "--- 1.7081210613250732 seconds ---\n",
      "episode 3463, reward -65.0, memory_length 2000, epsilon 0.1770186827001991\n",
      "travel time- 727.0\n",
      "--- 1.918187141418457 seconds ---\n",
      "episode 3464, reward -46.0, memory_length 2000, epsilon 0.17693019548249692\n",
      "travel time- 720.0\n",
      "--- 1.6795721054077148 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3465, reward -210.0, memory_length 2000, epsilon 0.17684175249734455\n",
      "travel time- 726.0\n",
      "--- 1.6010866165161133 seconds ---\n",
      "episode 3466, reward 87.0, memory_length 2000, epsilon 0.17675335372263115\n",
      "travel time- 720.0\n",
      "--- 1.656545639038086 seconds ---\n",
      "episode 3467, reward 195.0, memory_length 2000, epsilon 0.17666499913625716\n",
      "travel time- 724.0\n",
      "--- 1.603074073791504 seconds ---\n",
      "episode 3468, reward -213.0, memory_length 2000, epsilon 0.17657668871613388\n",
      "travel time- 726.0\n",
      "--- 1.7369277477264404 seconds ---\n",
      "episode 3469, reward -79.0, memory_length 2000, epsilon 0.17648842244018367\n",
      "travel time- 728.0\n",
      "--- 1.7342872619628906 seconds ---\n",
      "episode 3470, reward -214.0, memory_length 2000, epsilon 0.17640020028634\n",
      "travel time- 728.0\n",
      "--- 1.688037633895874 seconds ---\n",
      "episode 3471, reward 48.0, memory_length 2000, epsilon 0.1763120222325473\n",
      "travel time- 726.0\n",
      "--- 1.5120158195495605 seconds ---\n",
      "episode 3472, reward -106.0, memory_length 2000, epsilon 0.1762238882567611\n",
      "travel time- 720.0\n",
      "--- 1.6611735820770264 seconds ---\n",
      "episode 3473, reward 180.0, memory_length 2000, epsilon 0.1761357983369479\n",
      "travel time- 722.0\n",
      "--- 1.6281442642211914 seconds ---\n",
      "episode 3474, reward -148.0, memory_length 2000, epsilon 0.17604775245108517\n",
      "travel time- 720.0\n",
      "--- 1.3695085048675537 seconds ---\n",
      "episode 3475, reward -151.0, memory_length 2000, epsilon 0.17595975057716148\n",
      "travel time- 720.0\n",
      "--- 1.574444055557251 seconds ---\n",
      "episode 3476, reward 202.0, memory_length 2000, epsilon 0.17587179269317638\n",
      "travel time- 721.0\n",
      "--- 1.646242380142212 seconds ---\n",
      "episode 3477, reward -150.0, memory_length 2000, epsilon 0.17578387877714033\n",
      "travel time- 725.0\n",
      "--- 1.7481935024261475 seconds ---\n",
      "episode 3478, reward 297.0, memory_length 2000, epsilon 0.17569600880707487\n",
      "travel time- 731.0\n",
      "--- 1.3899996280670166 seconds ---\n",
      "episode 3479, reward 171.0, memory_length 2000, epsilon 0.17560818276101256\n",
      "travel time- 728.0\n",
      "--- 1.5960288047790527 seconds ---\n",
      "episode 3480, reward 195.0, memory_length 2000, epsilon 0.17552040061699686\n",
      "travel time- 726.0\n",
      "--- 1.7170178890228271 seconds ---\n",
      "episode 3481, reward -201.0, memory_length 2000, epsilon 0.17543266235308225\n",
      "travel time- 728.0\n",
      "--- 1.9208359718322754 seconds ---\n",
      "episode 3482, reward 396.0, memory_length 2000, epsilon 0.1753449679473341\n",
      "travel time- 720.0\n",
      "--- 1.8143906593322754 seconds ---\n",
      "episode 3483, reward -34.0, memory_length 2000, epsilon 0.17525731737782885\n",
      "travel time- 727.0\n",
      "--- 1.6573288440704346 seconds ---\n",
      "episode 3484, reward 25.0, memory_length 2000, epsilon 0.17516971062265388\n",
      "travel time- 724.0\n",
      "--- 1.6205439567565918 seconds ---\n",
      "episode 3485, reward -232.0, memory_length 2000, epsilon 0.17508214765990748\n",
      "travel time- 722.0\n",
      "--- 1.773125410079956 seconds ---\n",
      "episode 3486, reward -104.0, memory_length 2000, epsilon 0.17499462846769887\n",
      "travel time- 727.0\n",
      "--- 1.7174007892608643 seconds ---\n",
      "episode 3487, reward -348.0, memory_length 2000, epsilon 0.1749071530241483\n",
      "travel time- 724.0\n",
      "--- 1.6290533542633057 seconds ---\n",
      "episode 3488, reward -282.0, memory_length 2000, epsilon 0.17481972130738693\n",
      "travel time- 723.0\n",
      "--- 1.7143754959106445 seconds ---\n",
      "episode 3489, reward -29.0, memory_length 2000, epsilon 0.1747323332955568\n",
      "travel time- 720.0\n",
      "--- 1.7393405437469482 seconds ---\n",
      "episode 3490, reward -169.0, memory_length 2000, epsilon 0.17464498896681085\n",
      "travel time- 727.0\n",
      "--- 1.8037700653076172 seconds ---\n",
      "episode 3491, reward 86.0, memory_length 2000, epsilon 0.1745576882993131\n",
      "travel time- 725.0\n",
      "--- 1.7183313369750977 seconds ---\n",
      "episode 3492, reward -381.0, memory_length 2000, epsilon 0.17447043127123832\n",
      "travel time- 731.0\n",
      "--- 1.8080253601074219 seconds ---\n",
      "episode 3493, reward 51.0, memory_length 2000, epsilon 0.17438321786077227\n",
      "travel time- 720.0\n",
      "--- 1.7591793537139893 seconds ---\n",
      "episode 3494, reward 116.0, memory_length 2000, epsilon 0.17429604804611157\n",
      "travel time- 723.0\n",
      "--- 1.6465542316436768 seconds ---\n",
      "episode 3495, reward 315.0, memory_length 2000, epsilon 0.1742089218054638\n",
      "travel time- 725.0\n",
      "--- 1.5465223789215088 seconds ---\n",
      "episode 3496, reward -11.0, memory_length 2000, epsilon 0.1741218391170474\n",
      "travel time- 723.0\n",
      "--- 1.8620879650115967 seconds ---\n",
      "episode 3497, reward 25.0, memory_length 2000, epsilon 0.17403479995909168\n",
      "travel time- 724.0\n",
      "--- 1.5715978145599365 seconds ---\n",
      "episode 3498, reward -282.0, memory_length 2000, epsilon 0.17394780430983683\n",
      "travel time- 722.0\n",
      "--- 1.7815704345703125 seconds ---\n",
      "episode 3499, reward 157.0, memory_length 2000, epsilon 0.17386085214753402\n",
      "travel time- 720.0\n",
      "--- 1.4728469848632812 seconds ---\n",
      "episode 3500, reward -54.0, memory_length 2000, epsilon 0.17377394345044514\n",
      "travel time- 723.0\n",
      "--- 1.7017786502838135 seconds ---\n",
      "episode 3501, reward 238.0, memory_length 2000, epsilon 0.173687078196843\n",
      "travel time- 726.0\n",
      "--- 1.5914063453674316 seconds ---\n",
      "episode 3502, reward -89.0, memory_length 2000, epsilon 0.1736002563650113\n",
      "travel time- 722.0\n",
      "--- 1.618213176727295 seconds ---\n",
      "episode 3503, reward -42.0, memory_length 2000, epsilon 0.17351347793324462\n",
      "travel time- 728.0\n",
      "--- 1.4789509773254395 seconds ---\n",
      "episode 3504, reward -232.0, memory_length 2000, epsilon 0.17342674287984836\n",
      "travel time- 728.0\n",
      "--- 1.8684935569763184 seconds ---\n",
      "episode 3505, reward 127.0, memory_length 2000, epsilon 0.1733400511831387\n",
      "travel time- 722.0\n",
      "--- 1.5857141017913818 seconds ---\n",
      "episode 3506, reward -207.0, memory_length 2000, epsilon 0.1732534028214427\n",
      "travel time- 722.0\n",
      "--- 1.7891206741333008 seconds ---\n",
      "episode 3507, reward -327.0, memory_length 2000, epsilon 0.17316679777309835\n",
      "travel time- 721.0\n",
      "--- 1.8193855285644531 seconds ---\n",
      "episode 3508, reward 135.0, memory_length 2000, epsilon 0.17308023601645434\n",
      "travel time- 721.0\n",
      "--- 1.743501901626587 seconds ---\n",
      "episode 3509, reward 191.0, memory_length 2000, epsilon 0.17299371752987022\n",
      "travel time- 724.0\n",
      "--- 1.7973361015319824 seconds ---\n",
      "episode 3510, reward 128.0, memory_length 2000, epsilon 0.17290724229171636\n",
      "travel time- 720.0\n",
      "--- 1.836439847946167 seconds ---\n",
      "episode 3511, reward 14.0, memory_length 2000, epsilon 0.17282081028037402\n",
      "travel time- 720.0\n",
      "--- 1.780061960220337 seconds ---\n",
      "episode 3512, reward -53.0, memory_length 2000, epsilon 0.17273442147423515\n",
      "travel time- 726.0\n",
      "--- 1.8971951007843018 seconds ---\n",
      "episode 3513, reward 237.0, memory_length 2000, epsilon 0.17264807585170253\n",
      "travel time- 721.0\n",
      "--- 1.6240062713623047 seconds ---\n",
      "episode 3514, reward 82.0, memory_length 2000, epsilon 0.17256177339118975\n",
      "travel time- 720.0\n",
      "--- 1.739227294921875 seconds ---\n",
      "episode 3515, reward -40.0, memory_length 2000, epsilon 0.17247551407112124\n",
      "travel time- 736.0\n",
      "--- 1.4996068477630615 seconds ---\n",
      "episode 3516, reward -30.0, memory_length 2000, epsilon 0.17238929786993218\n",
      "travel time- 720.0\n",
      "--- 1.6755995750427246 seconds ---\n",
      "episode 3517, reward -179.0, memory_length 2000, epsilon 0.17230312476606846\n",
      "travel time- 722.0\n",
      "--- 1.552837610244751 seconds ---\n",
      "episode 3518, reward -19.0, memory_length 2000, epsilon 0.1722169947379868\n",
      "travel time- 724.0\n",
      "--- 1.5383830070495605 seconds ---\n",
      "episode 3519, reward -57.0, memory_length 2000, epsilon 0.17213090776415474\n",
      "travel time- 725.0\n",
      "--- 1.611119270324707 seconds ---\n",
      "episode 3520, reward -171.0, memory_length 2000, epsilon 0.17204486382305054\n",
      "travel time- 720.0\n",
      "--- 1.8377892971038818 seconds ---\n",
      "episode 3521, reward 254.0, memory_length 2000, epsilon 0.17195886289316317\n",
      "travel time- 724.0\n",
      "--- 1.5809412002563477 seconds ---\n",
      "episode 3522, reward 248.0, memory_length 2000, epsilon 0.1718729049529924\n",
      "travel time- 730.0\n",
      "--- 1.6864619255065918 seconds ---\n",
      "episode 3523, reward 44.0, memory_length 2000, epsilon 0.1717869899810488\n",
      "travel time- 721.0\n",
      "--- 1.612086534500122 seconds ---\n",
      "episode 3524, reward -47.0, memory_length 2000, epsilon 0.17170111795585358\n",
      "travel time- 727.0\n",
      "--- 1.6793715953826904 seconds ---\n",
      "episode 3525, reward 2.0, memory_length 2000, epsilon 0.17161528885593874\n",
      "travel time- 725.0\n",
      "--- 1.5566608905792236 seconds ---\n",
      "episode 3526, reward -346.0, memory_length 2000, epsilon 0.17152950265984698\n",
      "travel time- 726.0\n",
      "--- 1.7651917934417725 seconds ---\n",
      "episode 3527, reward -57.0, memory_length 2000, epsilon 0.17144375934613182\n",
      "travel time- 720.0\n",
      "--- 1.6713650226593018 seconds ---\n",
      "episode 3528, reward 49.0, memory_length 2000, epsilon 0.17135805889335737\n",
      "travel time- 725.0\n",
      "--- 1.7688102722167969 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3529, reward 180.0, memory_length 2000, epsilon 0.17127240128009855\n",
      "travel time- 728.0\n",
      "--- 1.6516988277435303 seconds ---\n",
      "episode 3530, reward 29.0, memory_length 2000, epsilon 0.1711867864849409\n",
      "travel time- 725.0\n",
      "--- 1.5828802585601807 seconds ---\n",
      "episode 3531, reward -441.0, memory_length 2000, epsilon 0.1711012144864808\n",
      "travel time- 720.0\n",
      "--- 1.7997691631317139 seconds ---\n",
      "episode 3532, reward 34.0, memory_length 2000, epsilon 0.17101568526332522\n",
      "travel time- 724.0\n",
      "--- 1.7073519229888916 seconds ---\n",
      "episode 3533, reward 22.0, memory_length 2000, epsilon 0.17093019879409185\n",
      "travel time- 728.0\n",
      "--- 1.5615968704223633 seconds ---\n",
      "episode 3534, reward -63.0, memory_length 2000, epsilon 0.170844755057409\n",
      "travel time- 724.0\n",
      "--- 1.5623676776885986 seconds ---\n",
      "episode 3535, reward 231.0, memory_length 2000, epsilon 0.1707593540319159\n",
      "travel time- 730.0\n",
      "--- 1.453230857849121 seconds ---\n",
      "episode 3536, reward 252.0, memory_length 2000, epsilon 0.17067399569626215\n",
      "travel time- 722.0\n",
      "--- 1.562922477722168 seconds ---\n",
      "episode 3537, reward 45.0, memory_length 2000, epsilon 0.17058868002910824\n",
      "travel time- 720.0\n",
      "--- 1.411773443222046 seconds ---\n",
      "episode 3538, reward 126.0, memory_length 2000, epsilon 0.17050340700912517\n",
      "travel time- 722.0\n",
      "--- 1.383019208908081 seconds ---\n",
      "episode 3539, reward 112.0, memory_length 2000, epsilon 0.17041817661499478\n",
      "travel time- 730.0\n",
      "--- 1.70283842086792 seconds ---\n",
      "episode 3540, reward -117.0, memory_length 2000, epsilon 0.17033298882540943\n",
      "travel time- 722.0\n",
      "--- 1.5801851749420166 seconds ---\n",
      "episode 3541, reward 185.0, memory_length 2000, epsilon 0.17024784361907216\n",
      "travel time- 721.0\n",
      "--- 1.6040773391723633 seconds ---\n",
      "episode 3542, reward 384.0, memory_length 2000, epsilon 0.1701627409746967\n",
      "travel time- 729.0\n",
      "--- 1.6347451210021973 seconds ---\n",
      "episode 3543, reward -11.0, memory_length 2000, epsilon 0.17007768087100736\n",
      "travel time- 724.0\n",
      "--- 1.5789313316345215 seconds ---\n",
      "episode 3544, reward -109.0, memory_length 2000, epsilon 0.16999266328673912\n",
      "travel time- 720.0\n",
      "--- 1.5429577827453613 seconds ---\n",
      "episode 3545, reward -81.0, memory_length 2000, epsilon 0.1699076882006376\n",
      "travel time- 722.0\n",
      "--- 1.6701087951660156 seconds ---\n",
      "episode 3546, reward 304.0, memory_length 2000, epsilon 0.16982275559145898\n",
      "travel time- 720.0\n",
      "--- 1.4581210613250732 seconds ---\n",
      "episode 3547, reward 370.0, memory_length 2000, epsilon 0.16973786543797018\n",
      "travel time- 723.0\n",
      "--- 1.5577585697174072 seconds ---\n",
      "episode 3548, reward -153.0, memory_length 2000, epsilon 0.1696530177189486\n",
      "travel time- 725.0\n",
      "--- 1.5540425777435303 seconds ---\n",
      "episode 3549, reward -163.0, memory_length 2000, epsilon 0.16956821241318237\n",
      "travel time- 730.0\n",
      "--- 1.6691310405731201 seconds ---\n",
      "episode 3550, reward -167.0, memory_length 2000, epsilon 0.16948344949947006\n",
      "travel time- 729.0\n",
      "--- 1.6294169425964355 seconds ---\n",
      "episode 3551, reward -139.0, memory_length 2000, epsilon 0.16939872895662106\n",
      "travel time- 729.0\n",
      "--- 1.5857665538787842 seconds ---\n",
      "episode 3552, reward -114.0, memory_length 2000, epsilon 0.16931405076345518\n",
      "travel time- 721.0\n",
      "--- 1.8137478828430176 seconds ---\n",
      "episode 3553, reward -241.0, memory_length 2000, epsilon 0.1692294148988029\n",
      "travel time- 728.0\n",
      "--- 1.734447717666626 seconds ---\n",
      "episode 3554, reward -105.0, memory_length 2000, epsilon 0.16914482134150513\n",
      "travel time- 727.0\n",
      "--- 1.839824914932251 seconds ---\n",
      "episode 3555, reward -9.0, memory_length 2000, epsilon 0.16906027007041366\n",
      "travel time- 721.0\n",
      "--- 1.7701170444488525 seconds ---\n",
      "episode 3556, reward -300.0, memory_length 2000, epsilon 0.16897576106439058\n",
      "travel time- 722.0\n",
      "--- 1.9222767353057861 seconds ---\n",
      "episode 3557, reward 250.0, memory_length 2000, epsilon 0.16889129430230862\n",
      "travel time- 720.0\n",
      "--- 1.7012252807617188 seconds ---\n",
      "episode 3558, reward -224.0, memory_length 2000, epsilon 0.1688068697630511\n",
      "travel time- 722.0\n",
      "--- 1.9516847133636475 seconds ---\n",
      "episode 3559, reward 259.0, memory_length 2000, epsilon 0.16872248742551194\n",
      "travel time- 721.0\n",
      "--- 1.5464305877685547 seconds ---\n",
      "episode 3560, reward 399.0, memory_length 2000, epsilon 0.1686381472685955\n",
      "travel time- 723.0\n",
      "--- 1.671867847442627 seconds ---\n",
      "episode 3561, reward 25.0, memory_length 2000, epsilon 0.16855384927121678\n",
      "travel time- 722.0\n",
      "--- 1.7690658569335938 seconds ---\n",
      "episode 3562, reward 404.0, memory_length 2000, epsilon 0.1684695934123012\n",
      "travel time- 721.0\n",
      "--- 1.720046043395996 seconds ---\n",
      "episode 3563, reward -239.0, memory_length 2000, epsilon 0.16838537967078487\n",
      "travel time- 725.0\n",
      "--- 1.587472915649414 seconds ---\n",
      "episode 3564, reward 47.0, memory_length 2000, epsilon 0.16830120802561438\n",
      "travel time- 723.0\n",
      "--- 1.6708335876464844 seconds ---\n",
      "episode 3565, reward -378.0, memory_length 2000, epsilon 0.16821707845574674\n",
      "travel time- 725.0\n",
      "--- 1.7311618328094482 seconds ---\n",
      "episode 3566, reward 312.0, memory_length 2000, epsilon 0.16813299094014955\n",
      "travel time- 721.0\n",
      "--- 1.5987491607666016 seconds ---\n",
      "episode 3567, reward 109.0, memory_length 2000, epsilon 0.16804894545780102\n",
      "travel time- 724.0\n",
      "--- 1.545778751373291 seconds ---\n",
      "episode 3568, reward -123.0, memory_length 2000, epsilon 0.16796494198768974\n",
      "travel time- 733.0\n",
      "--- 1.6169016361236572 seconds ---\n",
      "episode 3569, reward 293.0, memory_length 2000, epsilon 0.1678809805088148\n",
      "travel time- 723.0\n",
      "--- 1.783240556716919 seconds ---\n",
      "episode 3570, reward 36.0, memory_length 2000, epsilon 0.16779706100018585\n",
      "travel time- 723.0\n",
      "--- 1.8759078979492188 seconds ---\n",
      "episode 3571, reward -112.0, memory_length 2000, epsilon 0.16771318344082306\n",
      "travel time- 726.0\n",
      "--- 1.6454453468322754 seconds ---\n",
      "episode 3572, reward 294.0, memory_length 2000, epsilon 0.167629347809757\n",
      "travel time- 720.0\n",
      "--- 1.802689552307129 seconds ---\n",
      "episode 3573, reward -56.0, memory_length 2000, epsilon 0.16754555408602878\n",
      "travel time- 730.0\n",
      "--- 1.7212162017822266 seconds ---\n",
      "episode 3574, reward 150.0, memory_length 2000, epsilon 0.1674618022486899\n",
      "travel time- 725.0\n",
      "--- 1.7771077156066895 seconds ---\n",
      "episode 3575, reward 9.0, memory_length 2000, epsilon 0.16737809227680248\n",
      "travel time- 724.0\n",
      "--- 1.751465082168579 seconds ---\n",
      "episode 3576, reward 201.0, memory_length 2000, epsilon 0.167294424149439\n",
      "travel time- 726.0\n",
      "--- 1.8156335353851318 seconds ---\n",
      "episode 3577, reward 38.0, memory_length 2000, epsilon 0.16721079784568246\n",
      "travel time- 727.0\n",
      "--- 1.4114975929260254 seconds ---\n",
      "episode 3578, reward -45.0, memory_length 2000, epsilon 0.1671272133446262\n",
      "travel time- 722.0\n",
      "--- 1.5419845581054688 seconds ---\n",
      "episode 3579, reward -224.0, memory_length 2000, epsilon 0.16704367062537417\n",
      "travel time- 730.0\n",
      "--- 1.803267478942871 seconds ---\n",
      "episode 3580, reward -39.0, memory_length 2000, epsilon 0.1669601696670407\n",
      "travel time- 729.0\n",
      "--- 1.5752966403961182 seconds ---\n",
      "episode 3581, reward -4.0, memory_length 2000, epsilon 0.1668767104487505\n",
      "travel time- 723.0\n",
      "--- 1.5438673496246338 seconds ---\n",
      "episode 3582, reward 165.0, memory_length 2000, epsilon 0.16679329294963874\n",
      "travel time- 724.0\n",
      "--- 1.6228704452514648 seconds ---\n",
      "episode 3583, reward 257.0, memory_length 2000, epsilon 0.1667099171488511\n",
      "travel time- 732.0\n",
      "--- 1.572169542312622 seconds ---\n",
      "episode 3584, reward -226.0, memory_length 2000, epsilon 0.16662658302554365\n",
      "travel time- 726.0\n",
      "--- 1.8370931148529053 seconds ---\n",
      "episode 3585, reward -2.0, memory_length 2000, epsilon 0.1665432905588828\n",
      "travel time- 720.0\n",
      "--- 1.9495980739593506 seconds ---\n",
      "episode 3586, reward 89.0, memory_length 2000, epsilon 0.1664600397280455\n",
      "travel time- 726.0\n",
      "--- 1.5943059921264648 seconds ---\n",
      "episode 3587, reward 98.0, memory_length 2000, epsilon 0.1663768305122189\n",
      "travel time- 722.0\n",
      "--- 1.7261755466461182 seconds ---\n",
      "episode 3588, reward -155.0, memory_length 2000, epsilon 0.16629366289060088\n",
      "travel time- 725.0\n",
      "--- 1.7251653671264648 seconds ---\n",
      "episode 3589, reward 108.0, memory_length 2000, epsilon 0.16621053684239942\n",
      "travel time- 727.0\n",
      "--- 1.4890902042388916 seconds ---\n",
      "episode 3590, reward 125.0, memory_length 2000, epsilon 0.16612745234683307\n",
      "travel time- 724.0\n",
      "--- 1.52085280418396 seconds ---\n",
      "episode 3591, reward 297.0, memory_length 2000, epsilon 0.1660444093831306\n",
      "travel time- 724.0\n",
      "--- 1.689805507659912 seconds ---\n",
      "episode 3592, reward -228.0, memory_length 2000, epsilon 0.16596140793053138\n",
      "travel time- 723.0\n",
      "--- 1.7146613597869873 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3593, reward -275.0, memory_length 2000, epsilon 0.16587844796828502\n",
      "travel time- 728.0\n",
      "--- 1.7454841136932373 seconds ---\n",
      "episode 3594, reward -212.0, memory_length 2000, epsilon 0.16579552947565152\n",
      "travel time- 721.0\n",
      "--- 1.7120552062988281 seconds ---\n",
      "episode 3595, reward 53.0, memory_length 2000, epsilon 0.16571265243190123\n",
      "travel time- 723.0\n",
      "--- 1.627608299255371 seconds ---\n",
      "episode 3596, reward -289.0, memory_length 2000, epsilon 0.16562981681631492\n",
      "travel time- 724.0\n",
      "--- 1.7021000385284424 seconds ---\n",
      "episode 3597, reward 286.0, memory_length 2000, epsilon 0.16554702260818369\n",
      "travel time- 722.0\n",
      "--- 1.4633004665374756 seconds ---\n",
      "episode 3598, reward 250.0, memory_length 2000, epsilon 0.16546426978680895\n",
      "travel time- 724.0\n",
      "--- 1.7180149555206299 seconds ---\n",
      "episode 3599, reward -317.0, memory_length 2000, epsilon 0.1653815583315025\n",
      "travel time- 720.0\n",
      "--- 1.8037104606628418 seconds ---\n",
      "episode 3600, reward -6.0, memory_length 2000, epsilon 0.16529888822158653\n",
      "travel time- 722.0\n",
      "--- 1.6076292991638184 seconds ---\n",
      "episode 3601, reward 236.0, memory_length 2000, epsilon 0.16521625943639348\n",
      "travel time- 720.0\n",
      "--- 1.6565420627593994 seconds ---\n",
      "episode 3602, reward 42.0, memory_length 2000, epsilon 0.16513367195526615\n",
      "travel time- 720.0\n",
      "--- 1.3568172454833984 seconds ---\n",
      "episode 3603, reward -208.0, memory_length 2000, epsilon 0.16505112575755762\n",
      "travel time- 721.0\n",
      "--- 1.6504731178283691 seconds ---\n",
      "episode 3604, reward -286.0, memory_length 2000, epsilon 0.16496862082263145\n",
      "travel time- 720.0\n",
      "--- 1.842684268951416 seconds ---\n",
      "episode 3605, reward 224.0, memory_length 2000, epsilon 0.16488615712986132\n",
      "travel time- 730.0\n",
      "--- 1.6841402053833008 seconds ---\n",
      "episode 3606, reward -285.0, memory_length 2000, epsilon 0.16480373465863135\n",
      "travel time- 721.0\n",
      "--- 1.776716709136963 seconds ---\n",
      "episode 3607, reward -70.0, memory_length 2000, epsilon 0.16472135338833585\n",
      "travel time- 720.0\n",
      "--- 1.7146804332733154 seconds ---\n",
      "episode 3608, reward -292.0, memory_length 2000, epsilon 0.1646390132983796\n",
      "travel time- 726.0\n",
      "--- 1.7670083045959473 seconds ---\n",
      "episode 3609, reward -103.0, memory_length 2000, epsilon 0.16455671436817754\n",
      "travel time- 730.0\n",
      "--- 1.7680623531341553 seconds ---\n",
      "episode 3610, reward 107.0, memory_length 2000, epsilon 0.1644744565771549\n",
      "travel time- 726.0\n",
      "--- 1.4978175163269043 seconds ---\n",
      "episode 3611, reward 202.0, memory_length 2000, epsilon 0.16439223990474724\n",
      "travel time- 725.0\n",
      "--- 1.8988792896270752 seconds ---\n",
      "episode 3612, reward -137.0, memory_length 2000, epsilon 0.16431006433040046\n",
      "travel time- 722.0\n",
      "--- 1.8734843730926514 seconds ---\n",
      "episode 3613, reward 44.0, memory_length 2000, epsilon 0.16422792983357062\n",
      "travel time- 723.0\n",
      "--- 1.5768094062805176 seconds ---\n",
      "episode 3614, reward 15.0, memory_length 2000, epsilon 0.16414583639372407\n",
      "travel time- 732.0\n",
      "--- 1.599231481552124 seconds ---\n",
      "episode 3615, reward 154.0, memory_length 2000, epsilon 0.16406378399033747\n",
      "travel time- 725.0\n",
      "--- 1.7983746528625488 seconds ---\n",
      "episode 3616, reward 4.0, memory_length 2000, epsilon 0.16398177260289773\n",
      "travel time- 726.0\n",
      "--- 1.7197015285491943 seconds ---\n",
      "episode 3617, reward -97.0, memory_length 2000, epsilon 0.163899802210902\n",
      "travel time- 722.0\n",
      "--- 1.573859691619873 seconds ---\n",
      "episode 3618, reward -127.0, memory_length 2000, epsilon 0.16381787279385768\n",
      "travel time- 721.0\n",
      "--- 1.6914005279541016 seconds ---\n",
      "episode 3619, reward -173.0, memory_length 2000, epsilon 0.1637359843312824\n",
      "travel time- 720.0\n",
      "--- 1.6634974479675293 seconds ---\n",
      "episode 3620, reward -67.0, memory_length 2000, epsilon 0.16365413680270405\n",
      "travel time- 727.0\n",
      "--- 1.5786075592041016 seconds ---\n",
      "episode 3621, reward 86.0, memory_length 2000, epsilon 0.1635723301876608\n",
      "travel time- 720.0\n",
      "--- 1.6561110019683838 seconds ---\n",
      "episode 3622, reward -576.0, memory_length 2000, epsilon 0.1634905644657009\n",
      "travel time- 724.0\n",
      "--- 1.6566228866577148 seconds ---\n",
      "episode 3623, reward -42.0, memory_length 2000, epsilon 0.16340883961638294\n",
      "travel time- 722.0\n",
      "--- 1.7946412563323975 seconds ---\n",
      "episode 3624, reward 101.0, memory_length 2000, epsilon 0.1633271556192758\n",
      "travel time- 723.0\n",
      "--- 1.661508560180664 seconds ---\n",
      "episode 3625, reward 249.0, memory_length 2000, epsilon 0.1632455124539584\n",
      "travel time- 725.0\n",
      "--- 1.6367356777191162 seconds ---\n",
      "episode 3626, reward -352.0, memory_length 2000, epsilon 0.16316391010001996\n",
      "travel time- 728.0\n",
      "--- 1.949122667312622 seconds ---\n",
      "episode 3627, reward -170.0, memory_length 2000, epsilon 0.16308234853705986\n",
      "travel time- 725.0\n",
      "--- 1.5822346210479736 seconds ---\n",
      "episode 3628, reward 33.0, memory_length 2000, epsilon 0.16300082774468777\n",
      "travel time- 726.0\n",
      "--- 1.7473313808441162 seconds ---\n",
      "episode 3629, reward -196.0, memory_length 2000, epsilon 0.1629193477025235\n",
      "travel time- 727.0\n",
      "--- 1.8798129558563232 seconds ---\n",
      "episode 3630, reward -71.0, memory_length 2000, epsilon 0.16283790839019696\n",
      "travel time- 720.0\n",
      "--- 1.8915953636169434 seconds ---\n",
      "episode 3631, reward -260.0, memory_length 2000, epsilon 0.16275650978734837\n",
      "travel time- 722.0\n",
      "--- 1.6652460098266602 seconds ---\n",
      "episode 3632, reward 360.0, memory_length 2000, epsilon 0.16267515187362808\n",
      "travel time- 725.0\n",
      "--- 1.5484395027160645 seconds ---\n",
      "episode 3633, reward -178.0, memory_length 2000, epsilon 0.16259383462869662\n",
      "travel time- 726.0\n",
      "--- 1.6197481155395508 seconds ---\n",
      "episode 3634, reward -63.0, memory_length 2000, epsilon 0.16251255803222467\n",
      "travel time- 721.0\n",
      "--- 1.9347906112670898 seconds ---\n",
      "episode 3635, reward -276.0, memory_length 2000, epsilon 0.16243132206389302\n",
      "travel time- 725.0\n",
      "--- 1.6595945358276367 seconds ---\n",
      "episode 3636, reward -136.0, memory_length 2000, epsilon 0.16235012670339277\n",
      "travel time- 721.0\n",
      "--- 1.7096538543701172 seconds ---\n",
      "episode 3637, reward 23.0, memory_length 2000, epsilon 0.16226897193042505\n",
      "travel time- 725.0\n",
      "--- 1.6622300148010254 seconds ---\n",
      "episode 3638, reward 37.0, memory_length 2000, epsilon 0.16218785772470118\n",
      "travel time- 721.0\n",
      "--- 1.6572542190551758 seconds ---\n",
      "episode 3639, reward 285.0, memory_length 2000, epsilon 0.1621067840659425\n",
      "travel time- 731.0\n",
      "--- 1.4057633876800537 seconds ---\n",
      "episode 3640, reward -266.0, memory_length 2000, epsilon 0.16202575093388075\n",
      "travel time- 727.0\n",
      "--- 1.6793015003204346 seconds ---\n",
      "episode 3641, reward -252.0, memory_length 2000, epsilon 0.16194475830825758\n",
      "travel time- 727.0\n",
      "--- 1.5730524063110352 seconds ---\n",
      "episode 3642, reward -68.0, memory_length 2000, epsilon 0.16186380616882481\n",
      "travel time- 721.0\n",
      "--- 1.5356941223144531 seconds ---\n",
      "episode 3643, reward -169.0, memory_length 2000, epsilon 0.16178289449534441\n",
      "travel time- 723.0\n",
      "--- 1.6781041622161865 seconds ---\n",
      "episode 3644, reward 47.0, memory_length 2000, epsilon 0.1617020232675885\n",
      "travel time- 721.0\n",
      "--- 1.7603754997253418 seconds ---\n",
      "episode 3645, reward 14.0, memory_length 2000, epsilon 0.16162119246533926\n",
      "travel time- 720.0\n",
      "--- 1.7887060642242432 seconds ---\n",
      "episode 3646, reward -13.0, memory_length 2000, epsilon 0.16154040206838896\n",
      "travel time- 721.0\n",
      "--- 1.6793479919433594 seconds ---\n",
      "episode 3647, reward 35.0, memory_length 2000, epsilon 0.16145965205654\n",
      "travel time- 722.0\n",
      "--- 1.7914280891418457 seconds ---\n",
      "episode 3648, reward -46.0, memory_length 2000, epsilon 0.16137894240960493\n",
      "travel time- 724.0\n",
      "--- 1.8737666606903076 seconds ---\n",
      "episode 3649, reward -95.0, memory_length 2000, epsilon 0.1612982731074063\n",
      "travel time- 721.0\n",
      "--- 1.7312438488006592 seconds ---\n",
      "episode 3650, reward -202.0, memory_length 2000, epsilon 0.16121764412977677\n",
      "travel time- 723.0\n",
      "--- 1.6182935237884521 seconds ---\n",
      "episode 3651, reward -63.0, memory_length 2000, epsilon 0.1611370554565591\n",
      "travel time- 734.0\n",
      "--- 1.8475661277770996 seconds ---\n",
      "episode 3652, reward -177.0, memory_length 2000, epsilon 0.16105650706760616\n",
      "travel time- 726.0\n",
      "--- 1.7762465476989746 seconds ---\n",
      "episode 3653, reward -135.0, memory_length 2000, epsilon 0.1609759989427808\n",
      "travel time- 726.0\n",
      "--- 1.5612030029296875 seconds ---\n",
      "episode 3654, reward -74.0, memory_length 2000, epsilon 0.16089553106195606\n",
      "travel time- 724.0\n",
      "--- 1.5286407470703125 seconds ---\n",
      "episode 3655, reward 69.0, memory_length 2000, epsilon 0.16081510340501487\n",
      "travel time- 731.0\n",
      "--- 1.7460136413574219 seconds ---\n",
      "episode 3656, reward 107.0, memory_length 2000, epsilon 0.16073471595185038\n",
      "travel time- 723.0\n",
      "--- 1.8673985004425049 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3657, reward 7.0, memory_length 2000, epsilon 0.16065436868236574\n",
      "travel time- 726.0\n",
      "--- 1.746107816696167 seconds ---\n",
      "episode 3658, reward 216.0, memory_length 2000, epsilon 0.1605740615764741\n",
      "travel time- 722.0\n",
      "--- 1.4830896854400635 seconds ---\n",
      "episode 3659, reward -109.0, memory_length 2000, epsilon 0.16049379461409866\n",
      "travel time- 725.0\n",
      "--- 1.7517180442810059 seconds ---\n",
      "episode 3660, reward -174.0, memory_length 2000, epsilon 0.16041356777517274\n",
      "travel time- 723.0\n",
      "--- 1.805936574935913 seconds ---\n",
      "episode 3661, reward 13.0, memory_length 2000, epsilon 0.16033338103963962\n",
      "travel time- 721.0\n",
      "--- 1.4882166385650635 seconds ---\n",
      "episode 3662, reward -50.0, memory_length 2000, epsilon 0.16025323438745256\n",
      "travel time- 724.0\n",
      "--- 2.0503807067871094 seconds ---\n",
      "episode 3663, reward -191.0, memory_length 2000, epsilon 0.16017312779857493\n",
      "travel time- 727.0\n",
      "--- 1.9805214405059814 seconds ---\n",
      "episode 3664, reward 43.0, memory_length 2000, epsilon 0.1600930612529801\n",
      "travel time- 720.0\n",
      "--- 1.8973612785339355 seconds ---\n",
      "episode 3665, reward -257.0, memory_length 2000, epsilon 0.16001303473065143\n",
      "travel time- 720.0\n",
      "--- 1.7731173038482666 seconds ---\n",
      "episode 3666, reward -29.0, memory_length 2000, epsilon 0.15993304821158225\n",
      "travel time- 729.0\n",
      "--- 1.7353184223175049 seconds ---\n",
      "episode 3667, reward 29.0, memory_length 2000, epsilon 0.15985310167577593\n",
      "travel time- 730.0\n",
      "--- 1.7010397911071777 seconds ---\n",
      "episode 3668, reward 105.0, memory_length 2000, epsilon 0.15977319510324592\n",
      "travel time- 722.0\n",
      "--- 1.556471586227417 seconds ---\n",
      "episode 3669, reward -49.0, memory_length 2000, epsilon 0.1596933284740155\n",
      "travel time- 723.0\n",
      "--- 1.6155004501342773 seconds ---\n",
      "episode 3670, reward -68.0, memory_length 2000, epsilon 0.15961350176811803\n",
      "travel time- 724.0\n",
      "--- 1.7688853740692139 seconds ---\n",
      "episode 3671, reward -4.0, memory_length 2000, epsilon 0.1595337149655968\n",
      "travel time- 732.0\n",
      "--- 1.6305491924285889 seconds ---\n",
      "episode 3672, reward 50.0, memory_length 2000, epsilon 0.15945396804650516\n",
      "travel time- 723.0\n",
      "--- 1.8573031425476074 seconds ---\n",
      "episode 3673, reward 138.0, memory_length 2000, epsilon 0.1593742609909064\n",
      "travel time- 722.0\n",
      "--- 1.6473240852355957 seconds ---\n",
      "episode 3674, reward -63.0, memory_length 2000, epsilon 0.1592945937788737\n",
      "travel time- 720.0\n",
      "--- 1.8734629154205322 seconds ---\n",
      "episode 3675, reward -32.0, memory_length 2000, epsilon 0.15921496639049024\n",
      "travel time- 721.0\n",
      "--- 1.709388256072998 seconds ---\n",
      "episode 3676, reward 163.0, memory_length 2000, epsilon 0.15913537880584921\n",
      "travel time- 720.0\n",
      "--- 1.39241361618042 seconds ---\n",
      "episode 3677, reward -352.0, memory_length 2000, epsilon 0.15905583100505374\n",
      "travel time- 727.0\n",
      "--- 1.859729528427124 seconds ---\n",
      "episode 3678, reward 359.0, memory_length 2000, epsilon 0.15897632296821687\n",
      "travel time- 721.0\n",
      "--- 1.6048870086669922 seconds ---\n",
      "episode 3679, reward -3.0, memory_length 2000, epsilon 0.1588968546754615\n",
      "travel time- 723.0\n",
      "--- 1.7955024242401123 seconds ---\n",
      "episode 3680, reward 73.0, memory_length 2000, epsilon 0.15881742610692068\n",
      "travel time- 720.0\n",
      "--- 1.7567253112792969 seconds ---\n",
      "episode 3681, reward 163.0, memory_length 2000, epsilon 0.15873803724273722\n",
      "travel time- 723.0\n",
      "--- 1.7705326080322266 seconds ---\n",
      "episode 3682, reward 193.0, memory_length 2000, epsilon 0.15865868806306388\n",
      "travel time- 726.0\n",
      "--- 1.6869025230407715 seconds ---\n",
      "episode 3683, reward -41.0, memory_length 2000, epsilon 0.15857937854806334\n",
      "travel time- 727.0\n",
      "--- 1.6707608699798584 seconds ---\n",
      "episode 3684, reward 271.0, memory_length 2000, epsilon 0.1585001086779083\n",
      "travel time- 720.0\n",
      "--- 1.6105294227600098 seconds ---\n",
      "episode 3685, reward -102.0, memory_length 2000, epsilon 0.1584208784327813\n",
      "travel time- 724.0\n",
      "--- 1.7589800357818604 seconds ---\n",
      "episode 3686, reward 299.0, memory_length 2000, epsilon 0.1583416877928747\n",
      "travel time- 723.0\n",
      "--- 1.705817699432373 seconds ---\n",
      "episode 3687, reward 238.0, memory_length 2000, epsilon 0.15826253673839083\n",
      "travel time- 720.0\n",
      "--- 1.8553247451782227 seconds ---\n",
      "episode 3688, reward 3.0, memory_length 2000, epsilon 0.15818342524954201\n",
      "travel time- 725.0\n",
      "--- 1.5586333274841309 seconds ---\n",
      "episode 3689, reward 42.0, memory_length 2000, epsilon 0.15810435330655032\n",
      "travel time- 722.0\n",
      "--- 1.6123778820037842 seconds ---\n",
      "episode 3690, reward -16.0, memory_length 2000, epsilon 0.1580253208896478\n",
      "travel time- 731.0\n",
      "--- 1.6207828521728516 seconds ---\n",
      "episode 3691, reward -127.0, memory_length 2000, epsilon 0.15794632797907626\n",
      "travel time- 723.0\n",
      "--- 1.8411822319030762 seconds ---\n",
      "episode 3692, reward 143.0, memory_length 2000, epsilon 0.1578673745550876\n",
      "travel time- 732.0\n",
      "--- 1.8431968688964844 seconds ---\n",
      "episode 3693, reward 134.0, memory_length 2000, epsilon 0.15778846059794338\n",
      "travel time- 720.0\n",
      "--- 1.6022648811340332 seconds ---\n",
      "episode 3694, reward 113.0, memory_length 2000, epsilon 0.15770958608791516\n",
      "travel time- 720.0\n",
      "--- 1.6144027709960938 seconds ---\n",
      "episode 3695, reward -19.0, memory_length 2000, epsilon 0.15763075100528423\n",
      "travel time- 721.0\n",
      "--- 1.7532570362091064 seconds ---\n",
      "episode 3696, reward -230.0, memory_length 2000, epsilon 0.15755195533034191\n",
      "travel time- 723.0\n",
      "--- 1.7067673206329346 seconds ---\n",
      "episode 3697, reward -38.0, memory_length 2000, epsilon 0.15747319904338924\n",
      "travel time- 727.0\n",
      "--- 1.9006810188293457 seconds ---\n",
      "episode 3698, reward 51.0, memory_length 2000, epsilon 0.15739448212473714\n",
      "travel time- 724.0\n",
      "--- 1.830878734588623 seconds ---\n",
      "episode 3699, reward 267.0, memory_length 2000, epsilon 0.15731580455470637\n",
      "travel time- 722.0\n",
      "--- 1.5552430152893066 seconds ---\n",
      "episode 3700, reward -206.0, memory_length 2000, epsilon 0.1572371663136276\n",
      "travel time- 721.0\n",
      "--- 1.7302606105804443 seconds ---\n",
      "episode 3701, reward 117.0, memory_length 2000, epsilon 0.15715856738184122\n",
      "travel time- 724.0\n",
      "--- 1.5196013450622559 seconds ---\n",
      "episode 3702, reward -33.0, memory_length 2000, epsilon 0.1570800077396975\n",
      "travel time- 721.0\n",
      "--- 1.619239330291748 seconds ---\n",
      "episode 3703, reward -214.0, memory_length 2000, epsilon 0.1570014873675565\n",
      "travel time- 720.0\n",
      "--- 1.674781084060669 seconds ---\n",
      "episode 3704, reward -22.0, memory_length 2000, epsilon 0.1569230062457882\n",
      "travel time- 724.0\n",
      "--- 1.6378116607666016 seconds ---\n",
      "episode 3705, reward 87.0, memory_length 2000, epsilon 0.1568445643547723\n",
      "travel time- 724.0\n",
      "--- 1.4296674728393555 seconds ---\n",
      "episode 3706, reward 240.0, memory_length 2000, epsilon 0.15676616167489826\n",
      "travel time- 721.0\n",
      "--- 1.664064884185791 seconds ---\n",
      "episode 3707, reward -431.0, memory_length 2000, epsilon 0.15668779818656545\n",
      "travel time- 725.0\n",
      "--- 1.5611639022827148 seconds ---\n",
      "episode 3708, reward 53.0, memory_length 2000, epsilon 0.156609473870183\n",
      "travel time- 730.0\n",
      "--- 1.4868497848510742 seconds ---\n",
      "episode 3709, reward 212.0, memory_length 2000, epsilon 0.1565311887061699\n",
      "travel time- 727.0\n",
      "--- 1.6397597789764404 seconds ---\n",
      "episode 3710, reward 31.0, memory_length 2000, epsilon 0.15645294267495474\n",
      "travel time- 722.0\n",
      "--- 1.6238336563110352 seconds ---\n",
      "episode 3711, reward -82.0, memory_length 2000, epsilon 0.15637473575697602\n",
      "travel time- 721.0\n",
      "--- 1.6370034217834473 seconds ---\n",
      "episode 3712, reward -124.0, memory_length 2000, epsilon 0.15629656793268212\n",
      "travel time- 724.0\n",
      "--- 1.716811180114746 seconds ---\n",
      "episode 3713, reward -272.0, memory_length 2000, epsilon 0.156218439182531\n",
      "travel time- 723.0\n",
      "--- 1.7928955554962158 seconds ---\n",
      "episode 3714, reward 100.0, memory_length 2000, epsilon 0.15614034948699052\n",
      "travel time- 722.0\n",
      "--- 1.6348302364349365 seconds ---\n",
      "episode 3715, reward -18.0, memory_length 2000, epsilon 0.1560622988265382\n",
      "travel time- 722.0\n",
      "--- 1.7252748012542725 seconds ---\n",
      "episode 3716, reward 103.0, memory_length 2000, epsilon 0.15598428718166135\n",
      "travel time- 725.0\n",
      "--- 1.7562892436981201 seconds ---\n",
      "episode 3717, reward 90.0, memory_length 2000, epsilon 0.15590631453285717\n",
      "travel time- 723.0\n",
      "--- 1.7027812004089355 seconds ---\n",
      "episode 3718, reward 163.0, memory_length 2000, epsilon 0.15582838086063242\n",
      "travel time- 723.0\n",
      "--- 1.6607823371887207 seconds ---\n",
      "episode 3719, reward -114.0, memory_length 2000, epsilon 0.15575048614550369\n",
      "travel time- 720.0\n",
      "--- 1.8598582744598389 seconds ---\n",
      "episode 3720, reward -131.0, memory_length 2000, epsilon 0.1556726303679973\n",
      "travel time- 726.0\n",
      "--- 1.813452959060669 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3721, reward 150.0, memory_length 2000, epsilon 0.15559481350864932\n",
      "travel time- 722.0\n",
      "--- 1.526221752166748 seconds ---\n",
      "episode 3722, reward -241.0, memory_length 2000, epsilon 0.15551703554800556\n",
      "travel time- 726.0\n",
      "--- 1.555877685546875 seconds ---\n",
      "episode 3723, reward 172.0, memory_length 2000, epsilon 0.15543929646662147\n",
      "travel time- 723.0\n",
      "--- 1.721231460571289 seconds ---\n",
      "episode 3724, reward -107.0, memory_length 2000, epsilon 0.15536159624506227\n",
      "travel time- 725.0\n",
      "--- 1.7116434574127197 seconds ---\n",
      "episode 3725, reward -319.0, memory_length 2000, epsilon 0.155283934863903\n",
      "travel time- 728.0\n",
      "--- 1.7046406269073486 seconds ---\n",
      "episode 3726, reward -187.0, memory_length 2000, epsilon 0.15520631230372822\n",
      "travel time- 723.0\n",
      "--- 1.5456819534301758 seconds ---\n",
      "episode 3727, reward 10.0, memory_length 2000, epsilon 0.15512872854513235\n",
      "travel time- 721.0\n",
      "--- 1.6629669666290283 seconds ---\n",
      "episode 3728, reward -145.0, memory_length 2000, epsilon 0.15505118356871936\n",
      "travel time- 723.0\n",
      "--- 1.5053455829620361 seconds ---\n",
      "episode 3729, reward 64.0, memory_length 2000, epsilon 0.15497367735510315\n",
      "travel time- 720.0\n",
      "--- 1.5513720512390137 seconds ---\n",
      "episode 3730, reward -163.0, memory_length 2000, epsilon 0.15489620988490704\n",
      "travel time- 720.0\n",
      "--- 1.749354600906372 seconds ---\n",
      "episode 3731, reward 108.0, memory_length 2000, epsilon 0.15481878113876424\n",
      "travel time- 723.0\n",
      "--- 1.7607126235961914 seconds ---\n",
      "episode 3732, reward -44.0, memory_length 2000, epsilon 0.1547413910973175\n",
      "travel time- 725.0\n",
      "--- 1.7347996234893799 seconds ---\n",
      "episode 3733, reward -159.0, memory_length 2000, epsilon 0.15466403974121934\n",
      "travel time- 724.0\n",
      "--- 1.8290038108825684 seconds ---\n",
      "episode 3734, reward 84.0, memory_length 2000, epsilon 0.15458672705113194\n",
      "travel time- 721.0\n",
      "--- 1.5336740016937256 seconds ---\n",
      "episode 3735, reward -376.0, memory_length 2000, epsilon 0.15450945300772712\n",
      "travel time- 726.0\n",
      "--- 1.7727546691894531 seconds ---\n",
      "episode 3736, reward -305.0, memory_length 2000, epsilon 0.15443221759168632\n",
      "travel time- 728.0\n",
      "--- 1.5796747207641602 seconds ---\n",
      "episode 3737, reward -3.0, memory_length 2000, epsilon 0.15435502078370072\n",
      "travel time- 734.0\n",
      "--- 1.5552644729614258 seconds ---\n",
      "episode 3738, reward -243.0, memory_length 2000, epsilon 0.15427786256447115\n",
      "travel time- 723.0\n",
      "--- 1.6716420650482178 seconds ---\n",
      "episode 3739, reward -117.0, memory_length 2000, epsilon 0.15420074291470803\n",
      "travel time- 720.0\n",
      "--- 1.682271957397461 seconds ---\n",
      "episode 3740, reward -86.0, memory_length 2000, epsilon 0.1541236618151314\n",
      "travel time- 721.0\n",
      "--- 1.472015380859375 seconds ---\n",
      "episode 3741, reward 512.0, memory_length 2000, epsilon 0.15404661924647106\n",
      "travel time- 725.0\n",
      "--- 1.7206494808197021 seconds ---\n",
      "episode 3742, reward 104.0, memory_length 2000, epsilon 0.15396961518946634\n",
      "travel time- 721.0\n",
      "--- 1.44700288772583 seconds ---\n",
      "episode 3743, reward -86.0, memory_length 2000, epsilon 0.1538926496248662\n",
      "travel time- 723.0\n",
      "--- 1.532005786895752 seconds ---\n",
      "episode 3744, reward 191.0, memory_length 2000, epsilon 0.15381572253342926\n",
      "travel time- 721.0\n",
      "--- 1.5795025825500488 seconds ---\n",
      "episode 3745, reward -74.0, memory_length 2000, epsilon 0.1537388338959238\n",
      "travel time- 722.0\n",
      "--- 1.8272771835327148 seconds ---\n",
      "episode 3746, reward -79.0, memory_length 2000, epsilon 0.15366198369312759\n",
      "travel time- 720.0\n",
      "--- 1.8141660690307617 seconds ---\n",
      "episode 3747, reward 39.0, memory_length 2000, epsilon 0.1535851719058281\n",
      "travel time- 725.0\n",
      "--- 1.6491236686706543 seconds ---\n",
      "episode 3748, reward -62.0, memory_length 2000, epsilon 0.15350839851482234\n",
      "travel time- 725.0\n",
      "--- 1.7055273056030273 seconds ---\n",
      "episode 3749, reward -1.0, memory_length 2000, epsilon 0.15343166350091708\n",
      "travel time- 721.0\n",
      "--- 1.6149134635925293 seconds ---\n",
      "episode 3750, reward -78.0, memory_length 2000, epsilon 0.15335496684492847\n",
      "travel time- 723.0\n",
      "--- 1.6775741577148438 seconds ---\n",
      "episode 3751, reward -271.0, memory_length 2000, epsilon 0.15327830852768237\n",
      "travel time- 727.0\n",
      "--- 1.646637201309204 seconds ---\n",
      "episode 3752, reward 24.0, memory_length 2000, epsilon 0.15320168853001417\n",
      "travel time- 727.0\n",
      "--- 1.7802603244781494 seconds ---\n",
      "episode 3753, reward 150.0, memory_length 2000, epsilon 0.15312510683276892\n",
      "travel time- 720.0\n",
      "--- 1.4978272914886475 seconds ---\n",
      "episode 3754, reward -237.0, memory_length 2000, epsilon 0.1530485634168012\n",
      "travel time- 722.0\n",
      "--- 1.6538569927215576 seconds ---\n",
      "episode 3755, reward 41.0, memory_length 2000, epsilon 0.15297205826297514\n",
      "travel time- 721.0\n",
      "--- 1.95292329788208 seconds ---\n",
      "episode 3756, reward 189.0, memory_length 2000, epsilon 0.15289559135216438\n",
      "travel time- 728.0\n",
      "--- 2.0187764167785645 seconds ---\n",
      "episode 3757, reward 373.0, memory_length 2000, epsilon 0.1528191626652523\n",
      "travel time- 721.0\n",
      "--- 1.9480080604553223 seconds ---\n",
      "episode 3758, reward -493.0, memory_length 2000, epsilon 0.15274277218313168\n",
      "travel time- 727.0\n",
      "--- 1.849376916885376 seconds ---\n",
      "episode 3759, reward -112.0, memory_length 2000, epsilon 0.1526664198867049\n",
      "travel time- 720.0\n",
      "--- 1.7099764347076416 seconds ---\n",
      "episode 3760, reward -273.0, memory_length 2000, epsilon 0.15259010575688386\n",
      "travel time- 723.0\n",
      "--- 1.710799217224121 seconds ---\n",
      "episode 3761, reward -138.0, memory_length 2000, epsilon 0.15251382977459008\n",
      "travel time- 720.0\n",
      "--- 1.712191104888916 seconds ---\n",
      "episode 3762, reward -7.0, memory_length 2000, epsilon 0.15243759192075454\n",
      "travel time- 725.0\n",
      "--- 1.6072256565093994 seconds ---\n",
      "episode 3763, reward -148.0, memory_length 2000, epsilon 0.15236139217631778\n",
      "travel time- 720.0\n",
      "--- 1.6896388530731201 seconds ---\n",
      "episode 3764, reward 212.0, memory_length 2000, epsilon 0.1522852305222298\n",
      "travel time- 722.0\n",
      "--- 1.6072406768798828 seconds ---\n",
      "episode 3765, reward 136.0, memory_length 2000, epsilon 0.1522091069394503\n",
      "travel time- 721.0\n",
      "--- 1.7877864837646484 seconds ---\n",
      "episode 3766, reward -127.0, memory_length 2000, epsilon 0.15213302140894833\n",
      "travel time- 720.0\n",
      "--- 1.6923999786376953 seconds ---\n",
      "episode 3767, reward 92.0, memory_length 2000, epsilon 0.1520569739117025\n",
      "travel time- 733.0\n",
      "--- 1.6193420886993408 seconds ---\n",
      "episode 3768, reward 136.0, memory_length 2000, epsilon 0.1519809644287009\n",
      "travel time- 723.0\n",
      "--- 1.6513445377349854 seconds ---\n",
      "episode 3769, reward -342.0, memory_length 2000, epsilon 0.15190499294094123\n",
      "travel time- 720.0\n",
      "--- 1.7903409004211426 seconds ---\n",
      "episode 3770, reward -21.0, memory_length 2000, epsilon 0.1518290594294306\n",
      "travel time- 727.0\n",
      "--- 1.6693506240844727 seconds ---\n",
      "episode 3771, reward 61.0, memory_length 2000, epsilon 0.15175316387518561\n",
      "travel time- 726.0\n",
      "--- 1.70090651512146 seconds ---\n",
      "episode 3772, reward -58.0, memory_length 2000, epsilon 0.15167730625923234\n",
      "travel time- 726.0\n",
      "--- 1.4709992408752441 seconds ---\n",
      "episode 3773, reward -108.0, memory_length 2000, epsilon 0.15160148656260647\n",
      "travel time- 725.0\n",
      "--- 1.494832992553711 seconds ---\n",
      "episode 3774, reward 277.0, memory_length 2000, epsilon 0.15152570476635302\n",
      "travel time- 730.0\n",
      "--- 1.5327939987182617 seconds ---\n",
      "episode 3775, reward -125.0, memory_length 2000, epsilon 0.15144996085152657\n",
      "travel time- 728.0\n",
      "--- 1.586982250213623 seconds ---\n",
      "episode 3776, reward -149.0, memory_length 2000, epsilon 0.1513742547991911\n",
      "travel time- 731.0\n",
      "--- 1.5737481117248535 seconds ---\n",
      "episode 3777, reward -337.0, memory_length 2000, epsilon 0.15129858659042011\n",
      "travel time- 723.0\n",
      "--- 1.946610450744629 seconds ---\n",
      "episode 3778, reward 124.0, memory_length 2000, epsilon 0.15122295620629655\n",
      "travel time- 722.0\n",
      "--- 1.4061543941497803 seconds ---\n",
      "episode 3779, reward 245.0, memory_length 2000, epsilon 0.15114736362791287\n",
      "travel time- 725.0\n",
      "--- 1.7983922958374023 seconds ---\n",
      "episode 3780, reward -209.0, memory_length 2000, epsilon 0.15107180883637084\n",
      "travel time- 720.0\n",
      "--- 1.5124750137329102 seconds ---\n",
      "episode 3781, reward -89.0, memory_length 2000, epsilon 0.15099629181278182\n",
      "travel time- 726.0\n",
      "--- 1.606905221939087 seconds ---\n",
      "episode 3782, reward -22.0, memory_length 2000, epsilon 0.15092081253826656\n",
      "travel time- 728.0\n",
      "--- 1.6027865409851074 seconds ---\n",
      "episode 3783, reward 109.0, memory_length 2000, epsilon 0.1508453709939552\n",
      "travel time- 723.0\n",
      "--- 1.5502750873565674 seconds ---\n",
      "episode 3784, reward 1.0, memory_length 2000, epsilon 0.15076996716098734\n",
      "travel time- 729.0\n",
      "--- 1.5464563369750977 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3785, reward 238.0, memory_length 2000, epsilon 0.1506946010205121\n",
      "travel time- 724.0\n",
      "--- 1.6761350631713867 seconds ---\n",
      "episode 3786, reward -175.0, memory_length 2000, epsilon 0.15061927255368793\n",
      "travel time- 724.0\n",
      "--- 1.6881556510925293 seconds ---\n",
      "episode 3787, reward 37.0, memory_length 2000, epsilon 0.15054398174168265\n",
      "travel time- 723.0\n",
      "--- 1.4890179634094238 seconds ---\n",
      "episode 3788, reward -146.0, memory_length 2000, epsilon 0.15046872856567356\n",
      "travel time- 724.0\n",
      "--- 1.7623810768127441 seconds ---\n",
      "episode 3789, reward 104.0, memory_length 2000, epsilon 0.15039351300684742\n",
      "travel time- 724.0\n",
      "--- 1.6145007610321045 seconds ---\n",
      "episode 3790, reward 53.0, memory_length 2000, epsilon 0.15031833504640033\n",
      "travel time- 725.0\n",
      "--- 1.6472327709197998 seconds ---\n",
      "episode 3791, reward 13.0, memory_length 2000, epsilon 0.15024319466553776\n",
      "travel time- 723.0\n",
      "--- 1.7462866306304932 seconds ---\n",
      "episode 3792, reward 234.0, memory_length 2000, epsilon 0.15016809184547464\n",
      "travel time- 725.0\n",
      "--- 1.4737117290496826 seconds ---\n",
      "episode 3793, reward -223.0, memory_length 2000, epsilon 0.15009302656743528\n",
      "travel time- 723.0\n",
      "--- 1.7017707824707031 seconds ---\n",
      "episode 3794, reward -40.0, memory_length 2000, epsilon 0.15001799881265335\n",
      "travel time- 730.0\n",
      "--- 1.6149742603302002 seconds ---\n",
      "episode 3795, reward 243.0, memory_length 2000, epsilon 0.1499430085623719\n",
      "travel time- 729.0\n",
      "--- 1.6174001693725586 seconds ---\n",
      "episode 3796, reward -74.0, memory_length 2000, epsilon 0.14986805579784332\n",
      "travel time- 725.0\n",
      "--- 1.5825951099395752 seconds ---\n",
      "episode 3797, reward 190.0, memory_length 2000, epsilon 0.14979314050032952\n",
      "travel time- 722.0\n",
      "--- 1.6247811317443848 seconds ---\n",
      "episode 3798, reward 97.0, memory_length 2000, epsilon 0.14971826265110164\n",
      "travel time- 721.0\n",
      "--- 1.7675535678863525 seconds ---\n",
      "episode 3799, reward 144.0, memory_length 2000, epsilon 0.14964342223144017\n",
      "travel time- 726.0\n",
      "--- 1.7169256210327148 seconds ---\n",
      "episode 3800, reward -107.0, memory_length 2000, epsilon 0.14956861922263504\n",
      "travel time- 724.0\n",
      "--- 1.6011881828308105 seconds ---\n",
      "episode 3801, reward -28.0, memory_length 2000, epsilon 0.1494938536059855\n",
      "travel time- 721.0\n",
      "--- 1.6175041198730469 seconds ---\n",
      "episode 3802, reward 39.0, memory_length 2000, epsilon 0.14941912536280016\n",
      "travel time- 722.0\n",
      "--- 1.7414095401763916 seconds ---\n",
      "episode 3803, reward -256.0, memory_length 2000, epsilon 0.1493444344743969\n",
      "travel time- 723.0\n",
      "--- 1.51981520652771 seconds ---\n",
      "episode 3804, reward -150.0, memory_length 2000, epsilon 0.14926978092210305\n",
      "travel time- 721.0\n",
      "--- 1.814607858657837 seconds ---\n",
      "episode 3805, reward 90.0, memory_length 2000, epsilon 0.14919516468725522\n",
      "travel time- 721.0\n",
      "--- 1.7425105571746826 seconds ---\n",
      "episode 3806, reward 142.0, memory_length 2000, epsilon 0.14912058575119935\n",
      "travel time- 722.0\n",
      "--- 1.842282772064209 seconds ---\n",
      "episode 3807, reward 238.0, memory_length 2000, epsilon 0.14904604409529068\n",
      "travel time- 724.0\n",
      "--- 1.638063669204712 seconds ---\n",
      "episode 3808, reward -60.0, memory_length 2000, epsilon 0.1489715397008938\n",
      "travel time- 721.0\n",
      "--- 1.8874726295471191 seconds ---\n",
      "episode 3809, reward -36.0, memory_length 2000, epsilon 0.14889707254938264\n",
      "travel time- 721.0\n",
      "--- 1.7544958591461182 seconds ---\n",
      "episode 3810, reward -109.0, memory_length 2000, epsilon 0.14882264262214037\n",
      "travel time- 728.0\n",
      "--- 1.4548141956329346 seconds ---\n",
      "episode 3811, reward -102.0, memory_length 2000, epsilon 0.14874824990055957\n",
      "travel time- 721.0\n",
      "--- 1.5922422409057617 seconds ---\n",
      "episode 3812, reward -135.0, memory_length 2000, epsilon 0.14867389436604195\n",
      "travel time- 722.0\n",
      "--- 1.4663078784942627 seconds ---\n",
      "episode 3813, reward 16.0, memory_length 2000, epsilon 0.14859957599999876\n",
      "travel time- 722.0\n",
      "--- 1.6903479099273682 seconds ---\n",
      "episode 3814, reward 117.0, memory_length 2000, epsilon 0.14852529478385032\n",
      "travel time- 724.0\n",
      "--- 1.5182485580444336 seconds ---\n",
      "episode 3815, reward 184.0, memory_length 2000, epsilon 0.14845105069902637\n",
      "travel time- 722.0\n",
      "--- 1.6134462356567383 seconds ---\n",
      "episode 3816, reward -94.0, memory_length 2000, epsilon 0.14837684372696583\n",
      "travel time- 723.0\n",
      "--- 1.606745958328247 seconds ---\n",
      "episode 3817, reward 448.0, memory_length 2000, epsilon 0.14830267384911702\n",
      "travel time- 726.0\n",
      "--- 1.5200271606445312 seconds ---\n",
      "episode 3818, reward -94.0, memory_length 2000, epsilon 0.14822854104693745\n",
      "travel time- 726.0\n",
      "--- 1.6006519794464111 seconds ---\n",
      "episode 3819, reward -281.0, memory_length 2000, epsilon 0.1481544453018939\n",
      "travel time- 729.0\n",
      "--- 1.7853257656097412 seconds ---\n",
      "episode 3820, reward 71.0, memory_length 2000, epsilon 0.14808038659546244\n",
      "travel time- 720.0\n",
      "--- 1.8279972076416016 seconds ---\n",
      "episode 3821, reward 38.0, memory_length 2000, epsilon 0.1480063649091284\n",
      "travel time- 736.0\n",
      "--- 1.5535614490509033 seconds ---\n",
      "episode 3822, reward -183.0, memory_length 2000, epsilon 0.1479323802243864\n",
      "travel time- 730.0\n",
      "--- 1.769761562347412 seconds ---\n",
      "episode 3823, reward 240.0, memory_length 2000, epsilon 0.1478584325227402\n",
      "travel time- 732.0\n",
      "--- 1.7186627388000488 seconds ---\n",
      "episode 3824, reward -185.0, memory_length 2000, epsilon 0.14778452178570287\n",
      "travel time- 721.0\n",
      "--- 1.661529541015625 seconds ---\n",
      "episode 3825, reward 152.0, memory_length 2000, epsilon 0.14771064799479677\n",
      "travel time- 723.0\n",
      "--- 1.6387317180633545 seconds ---\n",
      "episode 3826, reward -227.0, memory_length 2000, epsilon 0.14763681113155347\n",
      "travel time- 721.0\n",
      "--- 1.7554864883422852 seconds ---\n",
      "episode 3827, reward 49.0, memory_length 2000, epsilon 0.14756301117751372\n",
      "travel time- 721.0\n",
      "--- 1.5382707118988037 seconds ---\n",
      "episode 3828, reward -179.0, memory_length 2000, epsilon 0.14748924811422748\n",
      "travel time- 720.0\n",
      "--- 1.6859617233276367 seconds ---\n",
      "episode 3829, reward -74.0, memory_length 2000, epsilon 0.14741552192325408\n",
      "travel time- 722.0\n",
      "--- 1.7048883438110352 seconds ---\n",
      "episode 3830, reward 121.0, memory_length 2000, epsilon 0.14734183258616193\n",
      "travel time- 725.0\n",
      "--- 1.48954439163208 seconds ---\n",
      "episode 3831, reward 22.0, memory_length 2000, epsilon 0.1472681800845287\n",
      "travel time- 727.0\n",
      "--- 1.4638850688934326 seconds ---\n",
      "episode 3832, reward 167.0, memory_length 2000, epsilon 0.14719456439994122\n",
      "travel time- 722.0\n",
      "--- 1.7101764678955078 seconds ---\n",
      "episode 3833, reward 192.0, memory_length 2000, epsilon 0.14712098551399563\n",
      "travel time- 720.0\n",
      "--- 1.6612029075622559 seconds ---\n",
      "episode 3834, reward 184.0, memory_length 2000, epsilon 0.1470474434082972\n",
      "travel time- 721.0\n",
      "--- 1.6949455738067627 seconds ---\n",
      "episode 3835, reward 45.0, memory_length 2000, epsilon 0.14697393806446038\n",
      "travel time- 724.0\n",
      "--- 1.6597342491149902 seconds ---\n",
      "episode 3836, reward -40.0, memory_length 2000, epsilon 0.1469004694641088\n",
      "travel time- 720.0\n",
      "--- 1.6371512413024902 seconds ---\n",
      "episode 3837, reward -4.0, memory_length 2000, epsilon 0.1468270375888754\n",
      "travel time- 725.0\n",
      "--- 1.5176331996917725 seconds ---\n",
      "episode 3838, reward 25.0, memory_length 2000, epsilon 0.14675364242040215\n",
      "travel time- 731.0\n",
      "--- 1.7132799625396729 seconds ---\n",
      "episode 3839, reward -282.0, memory_length 2000, epsilon 0.14668028394034027\n",
      "travel time- 723.0\n",
      "--- 1.5522611141204834 seconds ---\n",
      "episode 3840, reward -152.0, memory_length 2000, epsilon 0.14660696213035015\n",
      "travel time- 729.0\n",
      "--- 1.6709797382354736 seconds ---\n",
      "episode 3841, reward -302.0, memory_length 2000, epsilon 0.1465336769721013\n",
      "travel time- 721.0\n",
      "--- 1.7942521572113037 seconds ---\n",
      "episode 3842, reward 46.0, memory_length 2000, epsilon 0.14646042844727247\n",
      "travel time- 725.0\n",
      "--- 1.4704968929290771 seconds ---\n",
      "episode 3843, reward 86.0, memory_length 2000, epsilon 0.14638721653755152\n",
      "travel time- 721.0\n",
      "--- 1.7188992500305176 seconds ---\n",
      "episode 3844, reward -7.0, memory_length 2000, epsilon 0.14631404122463545\n",
      "travel time- 727.0\n",
      "--- 1.7038121223449707 seconds ---\n",
      "episode 3845, reward -102.0, memory_length 2000, epsilon 0.14624090249023045\n",
      "travel time- 721.0\n",
      "--- 1.7427144050598145 seconds ---\n",
      "episode 3846, reward 268.0, memory_length 2000, epsilon 0.14616780031605184\n",
      "travel time- 720.0\n",
      "--- 1.6179044246673584 seconds ---\n",
      "episode 3847, reward 69.0, memory_length 2000, epsilon 0.14609473468382408\n",
      "travel time- 737.0\n",
      "--- 1.493474006652832 seconds ---\n",
      "episode 3848, reward 13.0, memory_length 2000, epsilon 0.14602170557528074\n",
      "travel time- 721.0\n",
      "--- 1.497622013092041 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3849, reward 86.0, memory_length 2000, epsilon 0.14594871297216455\n",
      "travel time- 723.0\n",
      "--- 1.5291152000427246 seconds ---\n",
      "episode 3850, reward 38.0, memory_length 2000, epsilon 0.14587575685622736\n",
      "travel time- 720.0\n",
      "--- 1.5984117984771729 seconds ---\n",
      "episode 3851, reward 145.0, memory_length 2000, epsilon 0.14580283720923018\n",
      "travel time- 720.0\n",
      "--- 1.459240198135376 seconds ---\n",
      "episode 3852, reward 134.0, memory_length 2000, epsilon 0.14572995401294303\n",
      "travel time- 722.0\n",
      "--- 1.4593029022216797 seconds ---\n",
      "episode 3853, reward 18.0, memory_length 2000, epsilon 0.14565710724914513\n",
      "travel time- 723.0\n",
      "--- 1.696779727935791 seconds ---\n",
      "episode 3854, reward 116.0, memory_length 2000, epsilon 0.14558429689962482\n",
      "travel time- 721.0\n",
      "--- 1.633424997329712 seconds ---\n",
      "episode 3855, reward 152.0, memory_length 2000, epsilon 0.14551152294617953\n",
      "travel time- 729.0\n",
      "--- 1.7023844718933105 seconds ---\n",
      "episode 3856, reward 286.0, memory_length 2000, epsilon 0.1454387853706157\n",
      "travel time- 722.0\n",
      "--- 1.6748263835906982 seconds ---\n",
      "episode 3857, reward -108.0, memory_length 2000, epsilon 0.14536608415474894\n",
      "travel time- 722.0\n",
      "--- 1.5701241493225098 seconds ---\n",
      "episode 3858, reward 177.0, memory_length 2000, epsilon 0.145293419280404\n",
      "travel time- 720.0\n",
      "--- 1.5217323303222656 seconds ---\n",
      "episode 3859, reward 379.0, memory_length 2000, epsilon 0.14522079072941466\n",
      "travel time- 725.0\n",
      "--- 1.4861795902252197 seconds ---\n",
      "episode 3860, reward -59.0, memory_length 2000, epsilon 0.14514819848362373\n",
      "travel time- 723.0\n",
      "--- 1.7088756561279297 seconds ---\n",
      "episode 3861, reward 203.0, memory_length 2000, epsilon 0.14507564252488317\n",
      "travel time- 720.0\n",
      "--- 1.522829532623291 seconds ---\n",
      "episode 3862, reward -173.0, memory_length 2000, epsilon 0.145003122835054\n",
      "travel time- 721.0\n",
      "--- 1.853306770324707 seconds ---\n",
      "episode 3863, reward -33.0, memory_length 2000, epsilon 0.14493063939600634\n",
      "travel time- 727.0\n",
      "--- 1.7273409366607666 seconds ---\n",
      "episode 3864, reward 98.0, memory_length 2000, epsilon 0.14485819218961926\n",
      "travel time- 720.0\n",
      "--- 1.4077403545379639 seconds ---\n",
      "episode 3865, reward -16.0, memory_length 2000, epsilon 0.14478578119778093\n",
      "travel time- 728.0\n",
      "--- 1.5517518520355225 seconds ---\n",
      "episode 3866, reward -260.0, memory_length 2000, epsilon 0.14471340640238872\n",
      "travel time- 726.0\n",
      "--- 1.7984881401062012 seconds ---\n",
      "episode 3867, reward -68.0, memory_length 2000, epsilon 0.14464106778534885\n",
      "travel time- 721.0\n",
      "--- 1.5891306400299072 seconds ---\n",
      "episode 3868, reward -119.0, memory_length 2000, epsilon 0.14456876532857668\n",
      "travel time- 724.0\n",
      "--- 1.709200143814087 seconds ---\n",
      "episode 3869, reward 29.0, memory_length 2000, epsilon 0.14449649901399655\n",
      "travel time- 722.0\n",
      "--- 1.496300220489502 seconds ---\n",
      "episode 3870, reward 56.0, memory_length 2000, epsilon 0.14442426882354198\n",
      "travel time- 732.0\n",
      "--- 1.7022628784179688 seconds ---\n",
      "episode 3871, reward -41.0, memory_length 2000, epsilon 0.14435207473915534\n",
      "travel time- 732.0\n",
      "--- 1.6438965797424316 seconds ---\n",
      "episode 3872, reward -33.0, memory_length 2000, epsilon 0.14427991674278817\n",
      "travel time- 723.0\n",
      "--- 1.7071223258972168 seconds ---\n",
      "episode 3873, reward -121.0, memory_length 2000, epsilon 0.1442077948164009\n",
      "travel time- 720.0\n",
      "--- 1.5760490894317627 seconds ---\n",
      "episode 3874, reward -100.0, memory_length 2000, epsilon 0.1441357089419631\n",
      "travel time- 726.0\n",
      "--- 1.5955371856689453 seconds ---\n",
      "episode 3875, reward -328.0, memory_length 2000, epsilon 0.14406365910145327\n",
      "travel time- 722.0\n",
      "--- 1.7359154224395752 seconds ---\n",
      "episode 3876, reward -314.0, memory_length 2000, epsilon 0.143991645276859\n",
      "travel time- 724.0\n",
      "--- 1.9630811214447021 seconds ---\n",
      "episode 3877, reward -131.0, memory_length 2000, epsilon 0.14391966745017676\n",
      "travel time- 721.0\n",
      "--- 1.7821612358093262 seconds ---\n",
      "episode 3878, reward -87.0, memory_length 2000, epsilon 0.14384772560341216\n",
      "travel time- 721.0\n",
      "--- 1.546372413635254 seconds ---\n",
      "episode 3879, reward -151.0, memory_length 2000, epsilon 0.1437758197185797\n",
      "travel time- 721.0\n",
      "--- 1.8231565952301025 seconds ---\n",
      "episode 3880, reward -179.0, memory_length 2000, epsilon 0.14370394977770293\n",
      "travel time- 725.0\n",
      "--- 1.6318519115447998 seconds ---\n",
      "episode 3881, reward 79.0, memory_length 2000, epsilon 0.14363211576281432\n",
      "travel time- 720.0\n",
      "--- 1.920508861541748 seconds ---\n",
      "episode 3882, reward -252.0, memory_length 2000, epsilon 0.14356031765595542\n",
      "travel time- 728.0\n",
      "--- 1.7265150547027588 seconds ---\n",
      "episode 3883, reward -229.0, memory_length 2000, epsilon 0.14348855543917668\n",
      "travel time- 720.0\n",
      "--- 1.8050832748413086 seconds ---\n",
      "episode 3884, reward -100.0, memory_length 2000, epsilon 0.14341682909453757\n",
      "travel time- 724.0\n",
      "--- 1.9875307083129883 seconds ---\n",
      "episode 3885, reward -85.0, memory_length 2000, epsilon 0.14334513860410644\n",
      "travel time- 729.0\n",
      "--- 1.8481075763702393 seconds ---\n",
      "episode 3886, reward -91.0, memory_length 2000, epsilon 0.14327348394996073\n",
      "travel time- 720.0\n",
      "--- 1.814072608947754 seconds ---\n",
      "episode 3887, reward -255.0, memory_length 2000, epsilon 0.14320186511418675\n",
      "travel time- 728.0\n",
      "--- 1.8858661651611328 seconds ---\n",
      "episode 3888, reward -91.0, memory_length 2000, epsilon 0.14313028207887982\n",
      "travel time- 720.0\n",
      "--- 1.619267225265503 seconds ---\n",
      "episode 3889, reward 3.0, memory_length 2000, epsilon 0.14305873482614412\n",
      "travel time- 724.0\n",
      "--- 1.3848989009857178 seconds ---\n",
      "episode 3890, reward -151.0, memory_length 2000, epsilon 0.14298722333809288\n",
      "travel time- 730.0\n",
      "--- 1.6844193935394287 seconds ---\n",
      "episode 3891, reward -263.0, memory_length 2000, epsilon 0.14291574759684822\n",
      "travel time- 726.0\n",
      "--- 1.7980031967163086 seconds ---\n",
      "episode 3892, reward -444.0, memory_length 2000, epsilon 0.14284430758454122\n",
      "travel time- 723.0\n",
      "--- 1.525590419769287 seconds ---\n",
      "episode 3893, reward 368.0, memory_length 2000, epsilon 0.14277290328331183\n",
      "travel time- 722.0\n",
      "--- 1.5071794986724854 seconds ---\n",
      "episode 3894, reward -31.0, memory_length 2000, epsilon 0.14270153467530902\n",
      "travel time- 721.0\n",
      "--- 1.6335902214050293 seconds ---\n",
      "episode 3895, reward 135.0, memory_length 2000, epsilon 0.14263020174269064\n",
      "travel time- 722.0\n",
      "--- 1.9125795364379883 seconds ---\n",
      "episode 3896, reward -132.0, memory_length 2000, epsilon 0.14255890446762343\n",
      "travel time- 725.0\n",
      "--- 1.5445826053619385 seconds ---\n",
      "episode 3897, reward 20.0, memory_length 2000, epsilon 0.14248764283228305\n",
      "travel time- 725.0\n",
      "--- 1.6297907829284668 seconds ---\n",
      "episode 3898, reward -102.0, memory_length 2000, epsilon 0.14241641681885414\n",
      "travel time- 730.0\n",
      "--- 1.7888240814208984 seconds ---\n",
      "episode 3899, reward 177.0, memory_length 2000, epsilon 0.14234522640953018\n",
      "travel time- 721.0\n",
      "--- 1.6280004978179932 seconds ---\n",
      "episode 3900, reward -7.0, memory_length 2000, epsilon 0.1422740715865136\n",
      "travel time- 720.0\n",
      "--- 1.6261780261993408 seconds ---\n",
      "episode 3901, reward 234.0, memory_length 2000, epsilon 0.14220295233201558\n",
      "travel time- 723.0\n",
      "--- 1.6428978443145752 seconds ---\n",
      "episode 3902, reward -68.0, memory_length 2000, epsilon 0.1421318686282564\n",
      "travel time- 732.0\n",
      "--- 1.7887096405029297 seconds ---\n",
      "episode 3903, reward -1.0, memory_length 2000, epsilon 0.14206082045746518\n",
      "travel time- 727.0\n",
      "--- 1.7174081802368164 seconds ---\n",
      "episode 3904, reward 58.0, memory_length 2000, epsilon 0.14198980780187978\n",
      "travel time- 720.0\n",
      "--- 1.8181891441345215 seconds ---\n",
      "episode 3905, reward 14.0, memory_length 2000, epsilon 0.14191883064374702\n",
      "travel time- 720.0\n",
      "--- 1.8992481231689453 seconds ---\n",
      "episode 3906, reward 191.0, memory_length 2000, epsilon 0.14184788896532272\n",
      "travel time- 732.0\n",
      "--- 1.7687959671020508 seconds ---\n",
      "episode 3907, reward 8.0, memory_length 2000, epsilon 0.1417769827488714\n",
      "travel time- 720.0\n",
      "--- 1.8055033683776855 seconds ---\n",
      "episode 3908, reward 84.0, memory_length 2000, epsilon 0.1417061119766665\n",
      "travel time- 720.0\n",
      "--- 1.6670234203338623 seconds ---\n",
      "episode 3909, reward 3.0, memory_length 2000, epsilon 0.1416352766309903\n",
      "travel time- 722.0\n",
      "--- 1.6907167434692383 seconds ---\n",
      "episode 3910, reward -50.0, memory_length 2000, epsilon 0.14156447669413402\n",
      "travel time- 738.0\n",
      "--- 1.705049991607666 seconds ---\n",
      "episode 3911, reward -170.0, memory_length 2000, epsilon 0.14149371214839765\n",
      "travel time- 720.0\n",
      "--- 1.9578118324279785 seconds ---\n",
      "episode 3912, reward 177.0, memory_length 2000, epsilon 0.14142298297609007\n",
      "travel time- 723.0\n",
      "--- 1.691312313079834 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3913, reward 93.0, memory_length 2000, epsilon 0.14135228915952894\n",
      "travel time- 724.0\n",
      "--- 1.6400694847106934 seconds ---\n",
      "episode 3914, reward 125.0, memory_length 2000, epsilon 0.14128163068104085\n",
      "travel time- 720.0\n",
      "--- 1.5625672340393066 seconds ---\n",
      "episode 3915, reward 265.0, memory_length 2000, epsilon 0.14121100752296117\n",
      "travel time- 721.0\n",
      "--- 1.723482608795166 seconds ---\n",
      "episode 3916, reward -74.0, memory_length 2000, epsilon 0.1411404196676341\n",
      "travel time- 729.0\n",
      "--- 1.752699613571167 seconds ---\n",
      "episode 3917, reward -291.0, memory_length 2000, epsilon 0.14106986709741268\n",
      "travel time- 722.0\n",
      "--- 1.7757792472839355 seconds ---\n",
      "episode 3918, reward -61.0, memory_length 2000, epsilon 0.14099934979465875\n",
      "travel time- 720.0\n",
      "--- 1.435093879699707 seconds ---\n",
      "episode 3919, reward -16.0, memory_length 2000, epsilon 0.14092886774174304\n",
      "travel time- 720.0\n",
      "--- 1.7187695503234863 seconds ---\n",
      "episode 3920, reward 111.0, memory_length 2000, epsilon 0.140858420921045\n",
      "travel time- 733.0\n",
      "--- 1.690176248550415 seconds ---\n",
      "episode 3921, reward -11.0, memory_length 2000, epsilon 0.1407880093149529\n",
      "travel time- 722.0\n",
      "--- 1.5381996631622314 seconds ---\n",
      "episode 3922, reward 237.0, memory_length 2000, epsilon 0.14071763290586387\n",
      "travel time- 727.0\n",
      "--- 1.5319874286651611 seconds ---\n",
      "episode 3923, reward 229.0, memory_length 2000, epsilon 0.1406472916761838\n",
      "travel time- 725.0\n",
      "--- 1.514050006866455 seconds ---\n",
      "episode 3924, reward -246.0, memory_length 2000, epsilon 0.1405769856083274\n",
      "travel time- 723.0\n",
      "--- 1.4701018333435059 seconds ---\n",
      "episode 3925, reward -156.0, memory_length 2000, epsilon 0.1405067146847181\n",
      "travel time- 725.0\n",
      "--- 1.6109654903411865 seconds ---\n",
      "episode 3926, reward 265.0, memory_length 2000, epsilon 0.1404364788877882\n",
      "travel time- 726.0\n",
      "--- 1.4309194087982178 seconds ---\n",
      "episode 3927, reward 76.0, memory_length 2000, epsilon 0.1403662781999788\n",
      "travel time- 721.0\n",
      "--- 1.5776960849761963 seconds ---\n",
      "episode 3928, reward -292.0, memory_length 2000, epsilon 0.14029611260373964\n",
      "travel time- 723.0\n",
      "--- 1.5057220458984375 seconds ---\n",
      "episode 3929, reward 187.0, memory_length 2000, epsilon 0.14022598208152937\n",
      "travel time- 724.0\n",
      "--- 1.6409502029418945 seconds ---\n",
      "episode 3930, reward 202.0, memory_length 2000, epsilon 0.14015588661581535\n",
      "travel time- 735.0\n",
      "--- 1.551607370376587 seconds ---\n",
      "episode 3931, reward 45.0, memory_length 2000, epsilon 0.14008582618907373\n",
      "travel time- 726.0\n",
      "--- 1.8205296993255615 seconds ---\n",
      "episode 3932, reward 366.0, memory_length 2000, epsilon 0.1400158007837894\n",
      "travel time- 725.0\n",
      "--- 1.5371031761169434 seconds ---\n",
      "episode 3933, reward 21.0, memory_length 2000, epsilon 0.13994581038245593\n",
      "travel time- 722.0\n",
      "--- 1.4305057525634766 seconds ---\n",
      "episode 3934, reward -213.0, memory_length 2000, epsilon 0.13987585496757585\n",
      "travel time- 725.0\n",
      "--- 1.6607294082641602 seconds ---\n",
      "episode 3935, reward 352.0, memory_length 2000, epsilon 0.1398059345216602\n",
      "travel time- 721.0\n",
      "--- 1.7336664199829102 seconds ---\n",
      "episode 3936, reward -147.0, memory_length 2000, epsilon 0.13973604902722894\n",
      "travel time- 722.0\n",
      "--- 1.7267730236053467 seconds ---\n",
      "episode 3937, reward 108.0, memory_length 2000, epsilon 0.13966619846681064\n",
      "travel time- 727.0\n",
      "--- 1.7931725978851318 seconds ---\n",
      "episode 3938, reward 88.0, memory_length 2000, epsilon 0.1395963828229427\n",
      "travel time- 725.0\n",
      "--- 1.6558191776275635 seconds ---\n",
      "episode 3939, reward 112.0, memory_length 2000, epsilon 0.1395266020781712\n",
      "travel time- 725.0\n",
      "--- 2.1441633701324463 seconds ---\n",
      "episode 3940, reward -192.0, memory_length 2000, epsilon 0.13945685621505094\n",
      "travel time- 720.0\n",
      "--- 1.92024827003479 seconds ---\n",
      "episode 3941, reward -311.0, memory_length 2000, epsilon 0.13938714521614542\n",
      "travel time- 730.0\n",
      "--- 1.868896722793579 seconds ---\n",
      "episode 3942, reward 0.0, memory_length 2000, epsilon 0.13931746906402698\n",
      "travel time- 722.0\n",
      "--- 1.9380614757537842 seconds ---\n",
      "episode 3943, reward 447.0, memory_length 2000, epsilon 0.13924782774127653\n",
      "travel time- 721.0\n",
      "--- 1.5398533344268799 seconds ---\n",
      "episode 3944, reward 56.0, memory_length 2000, epsilon 0.13917822123048373\n",
      "travel time- 722.0\n",
      "--- 1.8643834590911865 seconds ---\n",
      "episode 3945, reward 185.0, memory_length 2000, epsilon 0.13910864951424692\n",
      "travel time- 720.0\n",
      "--- 1.5948047637939453 seconds ---\n",
      "episode 3946, reward -277.0, memory_length 2000, epsilon 0.13903911257517326\n",
      "travel time- 726.0\n",
      "--- 1.743520975112915 seconds ---\n",
      "episode 3947, reward 71.0, memory_length 2000, epsilon 0.13896961039587846\n",
      "travel time- 728.0\n",
      "--- 1.7413887977600098 seconds ---\n",
      "episode 3948, reward 92.0, memory_length 2000, epsilon 0.138900142958987\n",
      "travel time- 722.0\n",
      "--- 1.4800150394439697 seconds ---\n",
      "episode 3949, reward 75.0, memory_length 2000, epsilon 0.13883071024713198\n",
      "travel time- 725.0\n",
      "--- 1.532273769378662 seconds ---\n",
      "episode 3950, reward 109.0, memory_length 2000, epsilon 0.13876131224295524\n",
      "travel time- 722.0\n",
      "--- 1.7231738567352295 seconds ---\n",
      "episode 3951, reward 99.0, memory_length 2000, epsilon 0.1386919489291073\n",
      "travel time- 721.0\n",
      "--- 1.790410041809082 seconds ---\n",
      "episode 3952, reward -129.0, memory_length 2000, epsilon 0.13862262028824732\n",
      "travel time- 724.0\n",
      "--- 1.897831916809082 seconds ---\n",
      "episode 3953, reward -85.0, memory_length 2000, epsilon 0.1385533263030431\n",
      "travel time- 720.0\n",
      "--- 1.6862871646881104 seconds ---\n",
      "episode 3954, reward 150.0, memory_length 2000, epsilon 0.13848406695617121\n",
      "travel time- 724.0\n",
      "--- 1.514266014099121 seconds ---\n",
      "episode 3955, reward 98.0, memory_length 2000, epsilon 0.13841484223031678\n",
      "travel time- 727.0\n",
      "--- 1.660200595855713 seconds ---\n",
      "episode 3956, reward -72.0, memory_length 2000, epsilon 0.13834565210817362\n",
      "travel time- 724.0\n",
      "--- 1.679234504699707 seconds ---\n",
      "episode 3957, reward 19.0, memory_length 2000, epsilon 0.13827649657244417\n",
      "travel time- 730.0\n",
      "--- 1.6346094608306885 seconds ---\n",
      "episode 3958, reward 125.0, memory_length 2000, epsilon 0.13820737560583965\n",
      "travel time- 721.0\n",
      "--- 1.6323473453521729 seconds ---\n",
      "episode 3959, reward -323.0, memory_length 2000, epsilon 0.1381382891910797\n",
      "travel time- 721.0\n",
      "--- 1.7436916828155518 seconds ---\n",
      "episode 3960, reward 121.0, memory_length 2000, epsilon 0.13806923731089282\n",
      "travel time- 725.0\n",
      "--- 1.592581033706665 seconds ---\n",
      "episode 3961, reward -1.0, memory_length 2000, epsilon 0.13800021994801592\n",
      "travel time- 724.0\n",
      "--- 1.6769471168518066 seconds ---\n",
      "episode 3962, reward 122.0, memory_length 2000, epsilon 0.13793123708519478\n",
      "travel time- 726.0\n",
      "--- 1.5894138813018799 seconds ---\n",
      "episode 3963, reward 101.0, memory_length 2000, epsilon 0.1378622887051836\n",
      "travel time- 720.0\n",
      "--- 1.7928822040557861 seconds ---\n",
      "episode 3964, reward 95.0, memory_length 2000, epsilon 0.13779337479074535\n",
      "travel time- 720.0\n",
      "--- 1.6713545322418213 seconds ---\n",
      "episode 3965, reward 291.0, memory_length 2000, epsilon 0.13772449532465145\n",
      "travel time- 722.0\n",
      "--- 1.5858094692230225 seconds ---\n",
      "episode 3966, reward -397.0, memory_length 2000, epsilon 0.13765565028968216\n",
      "travel time- 723.0\n",
      "--- 1.5626389980316162 seconds ---\n",
      "episode 3967, reward -297.0, memory_length 2000, epsilon 0.13758683966862614\n",
      "travel time- 721.0\n",
      "--- 1.8065063953399658 seconds ---\n",
      "episode 3968, reward 39.0, memory_length 2000, epsilon 0.13751806344428075\n",
      "travel time- 727.0\n",
      "--- 1.6364612579345703 seconds ---\n",
      "episode 3969, reward -3.0, memory_length 2000, epsilon 0.13744932159945195\n",
      "travel time- 725.0\n",
      "--- 1.5732049942016602 seconds ---\n",
      "episode 3970, reward 52.0, memory_length 2000, epsilon 0.13738061411695424\n",
      "travel time- 721.0\n",
      "--- 1.7915899753570557 seconds ---\n",
      "episode 3971, reward -273.0, memory_length 2000, epsilon 0.1373119409796108\n",
      "travel time- 723.0\n",
      "--- 1.6917695999145508 seconds ---\n",
      "episode 3972, reward 47.0, memory_length 2000, epsilon 0.13724330217025332\n",
      "travel time- 737.0\n",
      "--- 1.7290103435516357 seconds ---\n",
      "episode 3973, reward 274.0, memory_length 2000, epsilon 0.13717469767172208\n",
      "travel time- 723.0\n",
      "--- 1.571080207824707 seconds ---\n",
      "episode 3974, reward 233.0, memory_length 2000, epsilon 0.13710612746686596\n",
      "travel time- 723.0\n",
      "--- 1.5064029693603516 seconds ---\n",
      "episode 3975, reward 92.0, memory_length 2000, epsilon 0.13703759153854245\n",
      "travel time- 726.0\n",
      "--- 1.7759883403778076 seconds ---\n",
      "episode 3976, reward 309.0, memory_length 2000, epsilon 0.13696908986961753\n",
      "travel time- 730.0\n",
      "--- 1.6040763854980469 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3977, reward 325.0, memory_length 2000, epsilon 0.1369006224429658\n",
      "travel time- 722.0\n",
      "--- 1.5513393878936768 seconds ---\n",
      "episode 3978, reward -48.0, memory_length 2000, epsilon 0.13683218924147036\n",
      "travel time- 720.0\n",
      "--- 1.6442804336547852 seconds ---\n",
      "episode 3979, reward 192.0, memory_length 2000, epsilon 0.13676379024802296\n",
      "travel time- 723.0\n",
      "--- 1.6100027561187744 seconds ---\n",
      "episode 3980, reward 322.0, memory_length 2000, epsilon 0.13669542544552385\n",
      "travel time- 725.0\n",
      "--- 1.6169981956481934 seconds ---\n",
      "episode 3981, reward -9.0, memory_length 2000, epsilon 0.13662709481688182\n",
      "travel time- 725.0\n",
      "--- 1.840101718902588 seconds ---\n",
      "episode 3982, reward -134.0, memory_length 2000, epsilon 0.13655879834501417\n",
      "travel time- 727.0\n",
      "--- 1.5777075290679932 seconds ---\n",
      "episode 3983, reward 211.0, memory_length 2000, epsilon 0.13649053601284683\n",
      "travel time- 720.0\n",
      "--- 1.5570647716522217 seconds ---\n",
      "episode 3984, reward 53.0, memory_length 2000, epsilon 0.13642230780331424\n",
      "travel time- 721.0\n",
      "--- 1.806558609008789 seconds ---\n",
      "episode 3985, reward -66.0, memory_length 2000, epsilon 0.1363541136993593\n",
      "travel time- 722.0\n",
      "--- 1.7464947700500488 seconds ---\n",
      "episode 3986, reward -269.0, memory_length 2000, epsilon 0.13628595368393343\n",
      "travel time- 721.0\n",
      "--- 1.7872288227081299 seconds ---\n",
      "episode 3987, reward -112.0, memory_length 2000, epsilon 0.13621782773999674\n",
      "travel time- 720.0\n",
      "--- 1.6740820407867432 seconds ---\n",
      "episode 3988, reward 144.0, memory_length 2000, epsilon 0.1361497358505177\n",
      "travel time- 729.0\n",
      "--- 1.5580999851226807 seconds ---\n",
      "episode 3989, reward 46.0, memory_length 2000, epsilon 0.13608167799847334\n",
      "travel time- 721.0\n",
      "--- 1.5369610786437988 seconds ---\n",
      "episode 3990, reward -415.0, memory_length 2000, epsilon 0.13601365416684916\n",
      "travel time- 727.0\n",
      "--- 1.7400398254394531 seconds ---\n",
      "episode 3991, reward -164.0, memory_length 2000, epsilon 0.13594566433863925\n",
      "travel time- 724.0\n",
      "--- 1.5857818126678467 seconds ---\n",
      "episode 3992, reward -12.0, memory_length 2000, epsilon 0.13587770849684613\n",
      "travel time- 723.0\n",
      "--- 1.7550525665283203 seconds ---\n",
      "episode 3993, reward 44.0, memory_length 2000, epsilon 0.13580978662448084\n",
      "travel time- 730.0\n",
      "--- 1.6985015869140625 seconds ---\n",
      "episode 3994, reward 211.0, memory_length 2000, epsilon 0.13574189870456288\n",
      "travel time- 724.0\n",
      "--- 1.6195178031921387 seconds ---\n",
      "episode 3995, reward -32.0, memory_length 2000, epsilon 0.13567404472012035\n",
      "travel time- 722.0\n",
      "--- 1.8767259120941162 seconds ---\n",
      "episode 3996, reward -122.0, memory_length 2000, epsilon 0.1356062246541897\n",
      "travel time- 727.0\n",
      "--- 1.868147850036621 seconds ---\n",
      "episode 3997, reward -170.0, memory_length 2000, epsilon 0.13553843848981592\n",
      "travel time- 723.0\n",
      "--- 1.7993676662445068 seconds ---\n",
      "episode 3998, reward 174.0, memory_length 2000, epsilon 0.13547068621005243\n",
      "travel time- 723.0\n",
      "--- 1.7474141120910645 seconds ---\n",
      "episode 3999, reward -209.0, memory_length 2000, epsilon 0.13540296779796124\n",
      "travel time- 720.0\n",
      "--- 1.5937440395355225 seconds ---\n",
      "episode 4000, reward 167.0, memory_length 2000, epsilon 0.1353352832366127\n",
      "travel time- 722.0\n",
      "--- 1.5088090896606445 seconds ---\n",
      "episode 4001, reward -134.0, memory_length 2000, epsilon 0.13526763250908563\n",
      "travel time- 720.0\n",
      "--- 1.7081377506256104 seconds ---\n",
      "episode 4002, reward -205.0, memory_length 2000, epsilon 0.13520001559846748\n",
      "travel time- 721.0\n",
      "--- 1.5944538116455078 seconds ---\n",
      "episode 4003, reward 388.0, memory_length 2000, epsilon 0.13513243248785384\n",
      "travel time- 724.0\n",
      "--- 1.5893926620483398 seconds ---\n",
      "episode 4004, reward 145.0, memory_length 2000, epsilon 0.13506488316034906\n",
      "travel time- 720.0\n",
      "--- 1.9823133945465088 seconds ---\n",
      "episode 4005, reward -23.0, memory_length 2000, epsilon 0.1349973675990658\n",
      "travel time- 721.0\n",
      "--- 1.7184803485870361 seconds ---\n",
      "episode 4006, reward -79.0, memory_length 2000, epsilon 0.13492988578712511\n",
      "travel time- 721.0\n",
      "--- 1.5493249893188477 seconds ---\n",
      "episode 4007, reward 55.0, memory_length 2000, epsilon 0.13486243770765663\n",
      "travel time- 736.0\n",
      "--- 1.676867961883545 seconds ---\n",
      "episode 4008, reward 11.0, memory_length 2000, epsilon 0.1347950233437982\n",
      "travel time- 724.0\n",
      "--- 1.6740341186523438 seconds ---\n",
      "episode 4009, reward -146.0, memory_length 2000, epsilon 0.13472764267869633\n",
      "travel time- 721.0\n",
      "--- 1.5427696704864502 seconds ---\n",
      "episode 4010, reward 116.0, memory_length 2000, epsilon 0.13466029569550586\n",
      "travel time- 730.0\n",
      "--- 1.8201792240142822 seconds ---\n",
      "episode 4011, reward 108.0, memory_length 2000, epsilon 0.13459298237738998\n",
      "travel time- 720.0\n",
      "--- 1.6951947212219238 seconds ---\n",
      "episode 4012, reward -79.0, memory_length 2000, epsilon 0.1345257027075204\n",
      "travel time- 723.0\n",
      "--- 1.5939714908599854 seconds ---\n",
      "episode 4013, reward -144.0, memory_length 2000, epsilon 0.13445845666907724\n",
      "travel time- 720.0\n",
      "--- 1.6142582893371582 seconds ---\n",
      "episode 4014, reward 231.0, memory_length 2000, epsilon 0.1343912442452489\n",
      "travel time- 720.0\n",
      "--- 1.6391515731811523 seconds ---\n",
      "episode 4015, reward 43.0, memory_length 2000, epsilon 0.13432406541923236\n",
      "travel time- 727.0\n",
      "--- 1.6423261165618896 seconds ---\n",
      "episode 4016, reward -148.0, memory_length 2000, epsilon 0.13425692017423285\n",
      "travel time- 723.0\n",
      "--- 1.5863165855407715 seconds ---\n",
      "episode 4017, reward 87.0, memory_length 2000, epsilon 0.13418980849346404\n",
      "travel time- 720.0\n",
      "--- 1.6913063526153564 seconds ---\n",
      "episode 4018, reward -135.0, memory_length 2000, epsilon 0.13412273036014816\n",
      "travel time- 721.0\n",
      "--- 1.6541950702667236 seconds ---\n",
      "episode 4019, reward -336.0, memory_length 2000, epsilon 0.13405568575751547\n",
      "travel time- 726.0\n",
      "--- 1.6302506923675537 seconds ---\n",
      "episode 4020, reward -189.0, memory_length 2000, epsilon 0.13398867466880493\n",
      "travel time- 721.0\n",
      "--- 1.6269571781158447 seconds ---\n",
      "episode 4021, reward 116.0, memory_length 2000, epsilon 0.1339216970772638\n",
      "travel time- 727.0\n",
      "--- 1.7912414073944092 seconds ---\n",
      "episode 4022, reward 320.0, memory_length 2000, epsilon 0.13385475296614763\n",
      "travel time- 732.0\n",
      "--- 1.8051323890686035 seconds ---\n",
      "episode 4023, reward -178.0, memory_length 2000, epsilon 0.1337878423187204\n",
      "travel time- 721.0\n",
      "--- 1.5283091068267822 seconds ---\n",
      "episode 4024, reward 253.0, memory_length 2000, epsilon 0.1337209651182544\n",
      "travel time- 721.0\n",
      "--- 1.8517796993255615 seconds ---\n",
      "episode 4025, reward 25.0, memory_length 2000, epsilon 0.1336541213480304\n",
      "travel time- 725.0\n",
      "--- 1.587916612625122 seconds ---\n",
      "episode 4026, reward -108.0, memory_length 2000, epsilon 0.13358731099133747\n",
      "travel time- 724.0\n",
      "--- 1.6328678131103516 seconds ---\n",
      "episode 4027, reward -70.0, memory_length 2000, epsilon 0.13352053403147293\n",
      "travel time- 720.0\n",
      "--- 1.6188759803771973 seconds ---\n",
      "episode 4028, reward 234.0, memory_length 2000, epsilon 0.1334537904517426\n",
      "travel time- 720.0\n",
      "--- 1.6977429389953613 seconds ---\n",
      "episode 4029, reward 25.0, memory_length 2000, epsilon 0.13338708023546064\n",
      "travel time- 722.0\n",
      "--- 1.7007222175598145 seconds ---\n",
      "episode 4030, reward -150.0, memory_length 2000, epsilon 0.13332040336594936\n",
      "travel time- 727.0\n",
      "--- 1.7075262069702148 seconds ---\n",
      "episode 4031, reward 12.0, memory_length 2000, epsilon 0.1332537598265397\n",
      "travel time- 722.0\n",
      "--- 1.6666762828826904 seconds ---\n",
      "episode 4032, reward -166.0, memory_length 2000, epsilon 0.1331871496005706\n",
      "travel time- 721.0\n",
      "--- 1.7203705310821533 seconds ---\n",
      "episode 4033, reward 79.0, memory_length 2000, epsilon 0.1331205726713896\n",
      "travel time- 729.0\n",
      "--- 1.9203639030456543 seconds ---\n",
      "episode 4034, reward -114.0, memory_length 2000, epsilon 0.13305402902235253\n",
      "travel time- 731.0\n",
      "--- 1.6055934429168701 seconds ---\n",
      "episode 4035, reward -225.0, memory_length 2000, epsilon 0.13298751863682334\n",
      "travel time- 726.0\n",
      "--- 1.6519317626953125 seconds ---\n",
      "episode 4036, reward -259.0, memory_length 2000, epsilon 0.13292104149817452\n",
      "travel time- 727.0\n",
      "--- 1.7640116214752197 seconds ---\n",
      "episode 4037, reward 183.0, memory_length 2000, epsilon 0.13285459758978682\n",
      "travel time- 723.0\n",
      "--- 1.743438482284546 seconds ---\n",
      "episode 4038, reward -103.0, memory_length 2000, epsilon 0.13278818689504915\n",
      "travel time- 726.0\n",
      "--- 1.8228812217712402 seconds ---\n",
      "episode 4039, reward -110.0, memory_length 2000, epsilon 0.13272180939735895\n",
      "travel time- 733.0\n",
      "--- 1.7306199073791504 seconds ---\n",
      "episode 4040, reward 16.0, memory_length 2000, epsilon 0.13265546508012172\n",
      "travel time- 722.0\n",
      "--- 1.67258882522583 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4041, reward 220.0, memory_length 2000, epsilon 0.13258915392675147\n",
      "travel time- 730.0\n",
      "--- 1.6442821025848389 seconds ---\n",
      "episode 4042, reward 139.0, memory_length 2000, epsilon 0.13252287592067044\n",
      "travel time- 726.0\n",
      "--- 1.7783427238464355 seconds ---\n",
      "episode 4043, reward -21.0, memory_length 2000, epsilon 0.13245663104530903\n",
      "travel time- 720.0\n",
      "--- 1.8378629684448242 seconds ---\n",
      "episode 4044, reward -237.0, memory_length 2000, epsilon 0.13239041928410605\n",
      "travel time- 721.0\n",
      "--- 1.764531135559082 seconds ---\n",
      "episode 4045, reward -52.0, memory_length 2000, epsilon 0.13232424062050865\n",
      "travel time- 727.0\n",
      "--- 1.6929798126220703 seconds ---\n",
      "episode 4046, reward 158.0, memory_length 2000, epsilon 0.13225809503797206\n",
      "travel time- 721.0\n",
      "--- 1.7290570735931396 seconds ---\n",
      "episode 4047, reward -3.0, memory_length 2000, epsilon 0.13219198251995995\n",
      "travel time- 723.0\n",
      "--- 1.5801782608032227 seconds ---\n",
      "episode 4048, reward 13.0, memory_length 2000, epsilon 0.1321259030499441\n",
      "travel time- 723.0\n",
      "--- 1.6966290473937988 seconds ---\n",
      "episode 4049, reward 6.0, memory_length 2000, epsilon 0.1320598566114047\n",
      "travel time- 721.0\n",
      "--- 1.696178674697876 seconds ---\n",
      "episode 4050, reward -135.0, memory_length 2000, epsilon 0.13199384318783022\n",
      "travel time- 720.0\n",
      "--- 1.627854824066162 seconds ---\n",
      "episode 4051, reward 157.0, memory_length 2000, epsilon 0.13192786276271715\n",
      "travel time- 725.0\n",
      "--- 1.6634304523468018 seconds ---\n",
      "episode 4052, reward 90.0, memory_length 2000, epsilon 0.13186191531957048\n",
      "travel time- 723.0\n",
      "--- 1.8423681259155273 seconds ---\n",
      "episode 4053, reward 7.0, memory_length 2000, epsilon 0.13179600084190335\n",
      "travel time- 730.0\n",
      "--- 1.8579018115997314 seconds ---\n",
      "episode 4054, reward 142.0, memory_length 2000, epsilon 0.13173011931323708\n",
      "travel time- 722.0\n",
      "--- 1.8409314155578613 seconds ---\n",
      "episode 4055, reward -126.0, memory_length 2000, epsilon 0.13166427071710138\n",
      "travel time- 728.0\n",
      "--- 1.6089870929718018 seconds ---\n",
      "episode 4056, reward 201.0, memory_length 2000, epsilon 0.131598455037034\n",
      "travel time- 723.0\n",
      "--- 1.607926607131958 seconds ---\n",
      "episode 4057, reward 148.0, memory_length 2000, epsilon 0.13153267225658102\n",
      "travel time- 721.0\n",
      "--- 1.5988259315490723 seconds ---\n",
      "episode 4058, reward -256.0, memory_length 2000, epsilon 0.13146692235929688\n",
      "travel time- 723.0\n",
      "--- 1.85959792137146 seconds ---\n",
      "episode 4059, reward 107.0, memory_length 2000, epsilon 0.13140120532874397\n",
      "travel time- 722.0\n",
      "--- 1.761312484741211 seconds ---\n",
      "episode 4060, reward -151.0, memory_length 2000, epsilon 0.13133552114849303\n",
      "travel time- 720.0\n",
      "--- 1.8954753875732422 seconds ---\n",
      "episode 4061, reward -315.0, memory_length 2000, epsilon 0.13126986980212316\n",
      "travel time- 720.0\n",
      "--- 1.671668291091919 seconds ---\n",
      "episode 4062, reward -19.0, memory_length 2000, epsilon 0.13120425127322136\n",
      "travel time- 720.0\n",
      "--- 1.702390432357788 seconds ---\n",
      "episode 4063, reward 109.0, memory_length 2000, epsilon 0.13113866554538312\n",
      "travel time- 726.0\n",
      "--- 1.6054394245147705 seconds ---\n",
      "episode 4064, reward -31.0, memory_length 2000, epsilon 0.13107311260221188\n",
      "travel time- 731.0\n",
      "--- 1.8616201877593994 seconds ---\n",
      "episode 4065, reward -16.0, memory_length 2000, epsilon 0.1310075924273195\n",
      "travel time- 722.0\n",
      "--- 1.818061351776123 seconds ---\n",
      "episode 4066, reward 77.0, memory_length 2000, epsilon 0.13094210500432593\n",
      "travel time- 721.0\n",
      "--- 1.7657601833343506 seconds ---\n",
      "episode 4067, reward 15.0, memory_length 2000, epsilon 0.13087665031685924\n",
      "travel time- 723.0\n",
      "--- 1.9814095497131348 seconds ---\n",
      "episode 4068, reward -274.0, memory_length 2000, epsilon 0.13081122834855582\n",
      "travel time- 721.0\n",
      "--- 1.7562732696533203 seconds ---\n",
      "episode 4069, reward 88.0, memory_length 2000, epsilon 0.13074583908306023\n",
      "travel time- 727.0\n",
      "--- 1.9373888969421387 seconds ---\n",
      "episode 4070, reward -95.0, memory_length 2000, epsilon 0.13068048250402503\n",
      "travel time- 721.0\n",
      "--- 1.7545661926269531 seconds ---\n",
      "episode 4071, reward 35.0, memory_length 2000, epsilon 0.13061515859511122\n",
      "travel time- 720.0\n",
      "--- 1.5432333946228027 seconds ---\n",
      "episode 4072, reward 455.0, memory_length 2000, epsilon 0.13054986733998764\n",
      "travel time- 721.0\n",
      "--- 1.6674120426177979 seconds ---\n",
      "episode 4073, reward 173.0, memory_length 2000, epsilon 0.13048460872233159\n",
      "travel time- 728.0\n",
      "--- 1.562328577041626 seconds ---\n",
      "episode 4074, reward 74.0, memory_length 2000, epsilon 0.13041938272582848\n",
      "travel time- 727.0\n",
      "--- 1.6243140697479248 seconds ---\n",
      "episode 4075, reward 205.0, memory_length 2000, epsilon 0.13035418933417164\n",
      "travel time- 721.0\n",
      "--- 1.4794390201568604 seconds ---\n",
      "episode 4076, reward -119.0, memory_length 2000, epsilon 0.13028902853106283\n",
      "travel time- 724.0\n",
      "--- 1.7721176147460938 seconds ---\n",
      "episode 4077, reward -272.0, memory_length 2000, epsilon 0.1302239003002119\n",
      "travel time- 733.0\n",
      "--- 1.6345679759979248 seconds ---\n",
      "episode 4078, reward 90.0, memory_length 2000, epsilon 0.13015880462533663\n",
      "travel time- 723.0\n",
      "--- 1.6350154876708984 seconds ---\n",
      "episode 4079, reward -338.0, memory_length 2000, epsilon 0.13009374149016328\n",
      "travel time- 721.0\n",
      "--- 1.6995446681976318 seconds ---\n",
      "episode 4080, reward -65.0, memory_length 2000, epsilon 0.1300287108784259\n",
      "travel time- 720.0\n",
      "--- 1.5776562690734863 seconds ---\n",
      "episode 4081, reward 61.0, memory_length 2000, epsilon 0.12996371277386695\n",
      "travel time- 720.0\n",
      "--- 1.6389870643615723 seconds ---\n",
      "episode 4082, reward -10.0, memory_length 2000, epsilon 0.12989874716023692\n",
      "travel time- 721.0\n",
      "--- 1.5455818176269531 seconds ---\n",
      "episode 4083, reward -150.0, memory_length 2000, epsilon 0.12983381402129426\n",
      "travel time- 720.0\n",
      "--- 1.6431996822357178 seconds ---\n",
      "episode 4084, reward 108.0, memory_length 2000, epsilon 0.1297689133408058\n",
      "travel time- 726.0\n",
      "--- 1.799851417541504 seconds ---\n",
      "episode 4085, reward 24.0, memory_length 2000, epsilon 0.12970404510254643\n",
      "travel time- 722.0\n",
      "--- 1.5895130634307861 seconds ---\n",
      "episode 4086, reward -121.0, memory_length 2000, epsilon 0.12963920929029896\n",
      "travel time- 726.0\n",
      "--- 1.5554490089416504 seconds ---\n",
      "episode 4087, reward 75.0, memory_length 2000, epsilon 0.12957440588785452\n",
      "travel time- 724.0\n",
      "--- 1.6465158462524414 seconds ---\n",
      "episode 4088, reward 62.0, memory_length 2000, epsilon 0.12950963487901218\n",
      "travel time- 725.0\n",
      "--- 1.6095235347747803 seconds ---\n",
      "episode 4089, reward -118.0, memory_length 2000, epsilon 0.12944489624757924\n",
      "travel time- 722.0\n",
      "--- 1.7128758430480957 seconds ---\n",
      "episode 4090, reward -28.0, memory_length 2000, epsilon 0.12938018997737108\n",
      "travel time- 721.0\n",
      "--- 1.4686052799224854 seconds ---\n",
      "episode 4091, reward 252.0, memory_length 2000, epsilon 0.12931551605221103\n",
      "travel time- 723.0\n",
      "--- 1.6521389484405518 seconds ---\n",
      "episode 4092, reward 20.0, memory_length 2000, epsilon 0.12925087445593067\n",
      "travel time- 732.0\n",
      "--- 1.640923023223877 seconds ---\n",
      "episode 4093, reward 115.0, memory_length 2000, epsilon 0.12918626517236967\n",
      "travel time- 737.0\n",
      "--- 1.6991126537322998 seconds ---\n",
      "episode 4094, reward 74.0, memory_length 2000, epsilon 0.12912168818537556\n",
      "travel time- 722.0\n",
      "--- 1.5193266868591309 seconds ---\n",
      "episode 4095, reward 48.0, memory_length 2000, epsilon 0.12905714347880423\n",
      "travel time- 721.0\n",
      "--- 1.5412805080413818 seconds ---\n",
      "episode 4096, reward -151.0, memory_length 2000, epsilon 0.1289926310365194\n",
      "travel time- 722.0\n",
      "--- 1.4678480625152588 seconds ---\n",
      "episode 4097, reward 267.0, memory_length 2000, epsilon 0.12892815084239298\n",
      "travel time- 723.0\n",
      "--- 1.688323974609375 seconds ---\n",
      "episode 4098, reward 218.0, memory_length 2000, epsilon 0.12886370288030502\n",
      "travel time- 720.0\n",
      "--- 1.6073038578033447 seconds ---\n",
      "episode 4099, reward 9.0, memory_length 2000, epsilon 0.12879928713414338\n",
      "travel time- 721.0\n",
      "--- 1.5106942653656006 seconds ---\n",
      "episode 4100, reward -134.0, memory_length 2000, epsilon 0.12873490358780423\n",
      "travel time- 721.0\n",
      "--- 1.6302733421325684 seconds ---\n",
      "episode 4101, reward -50.0, memory_length 2000, epsilon 0.12867055222519164\n",
      "travel time- 726.0\n",
      "--- 1.5805776119232178 seconds ---\n",
      "episode 4102, reward -130.0, memory_length 2000, epsilon 0.12860623303021773\n",
      "travel time- 720.0\n",
      "--- 1.754776954650879 seconds ---\n",
      "episode 4103, reward -84.0, memory_length 2000, epsilon 0.12854194598680282\n",
      "travel time- 723.0\n",
      "--- 1.7193291187286377 seconds ---\n",
      "episode 4104, reward 52.0, memory_length 2000, epsilon 0.12847769107887502\n",
      "travel time- 727.0\n",
      "--- 1.6543428897857666 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4105, reward 446.0, memory_length 2000, epsilon 0.12841346829037067\n",
      "travel time- 721.0\n",
      "--- 1.6750149726867676 seconds ---\n",
      "episode 4106, reward 146.0, memory_length 2000, epsilon 0.12834927760523412\n",
      "travel time- 720.0\n",
      "--- 1.5177206993103027 seconds ---\n",
      "episode 4107, reward 152.0, memory_length 2000, epsilon 0.12828511900741757\n",
      "travel time- 722.0\n",
      "--- 1.7086095809936523 seconds ---\n",
      "episode 4108, reward -115.0, memory_length 2000, epsilon 0.1282209924808815\n",
      "travel time- 722.0\n",
      "--- 1.7681491374969482 seconds ---\n",
      "episode 4109, reward 174.0, memory_length 2000, epsilon 0.12815689800959415\n",
      "travel time- 721.0\n",
      "--- 1.5405380725860596 seconds ---\n",
      "episode 4110, reward 320.0, memory_length 2000, epsilon 0.12809283557753198\n",
      "travel time- 728.0\n",
      "--- 1.7138009071350098 seconds ---\n",
      "episode 4111, reward -76.0, memory_length 2000, epsilon 0.12802880516867943\n",
      "travel time- 720.0\n",
      "--- 1.7067670822143555 seconds ---\n",
      "episode 4112, reward 239.0, memory_length 2000, epsilon 0.1279648067670288\n",
      "travel time- 721.0\n",
      "--- 1.6354598999023438 seconds ---\n",
      "episode 4113, reward -6.0, memory_length 2000, epsilon 0.1279008403565805\n",
      "travel time- 721.0\n",
      "--- 1.7817654609680176 seconds ---\n",
      "episode 4114, reward 28.0, memory_length 2000, epsilon 0.12783690592134303\n",
      "travel time- 728.0\n",
      "--- 1.5531554222106934 seconds ---\n",
      "episode 4115, reward -154.0, memory_length 2000, epsilon 0.12777300344533263\n",
      "travel time- 720.0\n",
      "--- 1.8517885208129883 seconds ---\n",
      "episode 4116, reward 145.0, memory_length 2000, epsilon 0.12770913291257383\n",
      "travel time- 726.0\n",
      "--- 1.6748642921447754 seconds ---\n",
      "episode 4117, reward -191.0, memory_length 2000, epsilon 0.12764529430709887\n",
      "travel time- 723.0\n",
      "--- 1.8106350898742676 seconds ---\n",
      "episode 4118, reward 48.0, memory_length 2000, epsilon 0.12758148761294813\n",
      "travel time- 723.0\n",
      "--- 1.5827362537384033 seconds ---\n",
      "episode 4119, reward -74.0, memory_length 2000, epsilon 0.12751771281417004\n",
      "travel time- 724.0\n",
      "--- 1.7697229385375977 seconds ---\n",
      "episode 4120, reward 51.0, memory_length 2000, epsilon 0.12745396989482075\n",
      "travel time- 721.0\n",
      "--- 1.5456454753875732 seconds ---\n",
      "episode 4121, reward -95.0, memory_length 2000, epsilon 0.12739025883896457\n",
      "travel time- 721.0\n",
      "--- 1.5318143367767334 seconds ---\n",
      "episode 4122, reward 162.0, memory_length 2000, epsilon 0.12732657963067387\n",
      "travel time- 735.0\n",
      "--- 1.9515395164489746 seconds ---\n",
      "episode 4123, reward 107.0, memory_length 2000, epsilon 0.12726293225402865\n",
      "travel time- 728.0\n",
      "--- 1.5664474964141846 seconds ---\n",
      "episode 4124, reward 27.0, memory_length 2000, epsilon 0.1271993166931172\n",
      "travel time- 723.0\n",
      "--- 1.6075496673583984 seconds ---\n",
      "episode 4125, reward -432.0, memory_length 2000, epsilon 0.1271357329320356\n",
      "travel time- 721.0\n",
      "--- 1.7875556945800781 seconds ---\n",
      "episode 4126, reward -193.0, memory_length 2000, epsilon 0.12707218095488781\n",
      "travel time- 727.0\n",
      "--- 1.5425779819488525 seconds ---\n",
      "episode 4127, reward -23.0, memory_length 2000, epsilon 0.12700866074578604\n",
      "travel time- 721.0\n",
      "--- 1.8121154308319092 seconds ---\n",
      "episode 4128, reward 54.0, memory_length 2000, epsilon 0.12694517228885002\n",
      "travel time- 720.0\n",
      "--- 1.6995909214019775 seconds ---\n",
      "episode 4129, reward 55.0, memory_length 2000, epsilon 0.12688171556820776\n",
      "travel time- 720.0\n",
      "--- 1.625378131866455 seconds ---\n",
      "episode 4130, reward 115.0, memory_length 2000, epsilon 0.1268182905679951\n",
      "travel time- 721.0\n",
      "--- 1.7260477542877197 seconds ---\n",
      "episode 4131, reward -109.0, memory_length 2000, epsilon 0.12675489727235567\n",
      "travel time- 726.0\n",
      "--- 1.9619958400726318 seconds ---\n",
      "episode 4132, reward -39.0, memory_length 2000, epsilon 0.1266915356654413\n",
      "travel time- 724.0\n",
      "--- 1.5940155982971191 seconds ---\n",
      "episode 4133, reward 78.0, memory_length 2000, epsilon 0.12662820573141143\n",
      "travel time- 725.0\n",
      "--- 1.3821399211883545 seconds ---\n",
      "episode 4134, reward 46.0, memory_length 2000, epsilon 0.12656490745443366\n",
      "travel time- 721.0\n",
      "--- 1.7448601722717285 seconds ---\n",
      "episode 4135, reward -66.0, memory_length 2000, epsilon 0.12650164081868348\n",
      "travel time- 722.0\n",
      "--- 1.867757797241211 seconds ---\n",
      "episode 4136, reward -97.0, memory_length 2000, epsilon 0.1264384058083441\n",
      "travel time- 727.0\n",
      "--- 1.832763671875 seconds ---\n",
      "episode 4137, reward -48.0, memory_length 2000, epsilon 0.12637520240760683\n",
      "travel time- 720.0\n",
      "--- 1.6098017692565918 seconds ---\n",
      "episode 4138, reward 183.0, memory_length 2000, epsilon 0.12631203060067087\n",
      "travel time- 725.0\n",
      "--- 1.514369010925293 seconds ---\n",
      "episode 4139, reward 91.0, memory_length 2000, epsilon 0.12624889037174317\n",
      "travel time- 720.0\n",
      "--- 1.6075632572174072 seconds ---\n",
      "episode 4140, reward 35.0, memory_length 2000, epsilon 0.12618578170503877\n",
      "travel time- 722.0\n",
      "--- 1.8068058490753174 seconds ---\n",
      "episode 4141, reward 82.0, memory_length 2000, epsilon 0.1261227045847804\n",
      "travel time- 725.0\n",
      "--- 1.685631513595581 seconds ---\n",
      "episode 4142, reward -69.0, memory_length 2000, epsilon 0.12605965899519883\n",
      "travel time- 724.0\n",
      "--- 1.7059776782989502 seconds ---\n",
      "episode 4143, reward 196.0, memory_length 2000, epsilon 0.12599664492053272\n",
      "travel time- 723.0\n",
      "--- 1.5540056228637695 seconds ---\n",
      "episode 4144, reward -303.0, memory_length 2000, epsilon 0.12593366234502845\n",
      "travel time- 720.0\n",
      "--- 1.737241506576538 seconds ---\n",
      "episode 4145, reward -105.0, memory_length 2000, epsilon 0.12587071125294041\n",
      "travel time- 720.0\n",
      "--- 1.6787638664245605 seconds ---\n",
      "episode 4146, reward -179.0, memory_length 2000, epsilon 0.12580779162853092\n",
      "travel time- 721.0\n",
      "--- 1.739884614944458 seconds ---\n",
      "episode 4147, reward -23.0, memory_length 2000, epsilon 0.12574490345606992\n",
      "travel time- 721.0\n",
      "--- 1.6053838729858398 seconds ---\n",
      "episode 4148, reward -137.0, memory_length 2000, epsilon 0.1256820467198355\n",
      "travel time- 721.0\n",
      "--- 1.7982470989227295 seconds ---\n",
      "episode 4149, reward -382.0, memory_length 2000, epsilon 0.12561922140411333\n",
      "travel time- 723.0\n",
      "--- 1.8723232746124268 seconds ---\n",
      "episode 4150, reward 49.0, memory_length 2000, epsilon 0.1255564274931972\n",
      "travel time- 726.0\n",
      "--- 1.9596271514892578 seconds ---\n",
      "episode 4151, reward -6.0, memory_length 2000, epsilon 0.12549366497138864\n",
      "travel time- 723.0\n",
      "--- 1.635446548461914 seconds ---\n",
      "episode 4152, reward -241.0, memory_length 2000, epsilon 0.12543093382299692\n",
      "travel time- 724.0\n",
      "--- 1.6658849716186523 seconds ---\n",
      "episode 4153, reward 194.0, memory_length 2000, epsilon 0.12536823403233932\n",
      "travel time- 726.0\n",
      "--- 1.658090353012085 seconds ---\n",
      "episode 4154, reward 172.0, memory_length 2000, epsilon 0.12530556558374092\n",
      "travel time- 723.0\n",
      "--- 1.760096549987793 seconds ---\n",
      "episode 4155, reward -299.0, memory_length 2000, epsilon 0.1252429284615345\n",
      "travel time- 721.0\n",
      "--- 1.8980395793914795 seconds ---\n",
      "episode 4156, reward -85.0, memory_length 2000, epsilon 0.12518032265006093\n",
      "travel time- 721.0\n",
      "--- 1.7359035015106201 seconds ---\n",
      "episode 4157, reward 82.0, memory_length 2000, epsilon 0.12511774813366863\n",
      "travel time- 721.0\n",
      "--- 1.577552318572998 seconds ---\n",
      "episode 4158, reward 301.0, memory_length 2000, epsilon 0.12505520489671398\n",
      "travel time- 720.0\n",
      "--- 1.6553661823272705 seconds ---\n",
      "episode 4159, reward 234.0, memory_length 2000, epsilon 0.12499269292356129\n",
      "travel time- 722.0\n",
      "--- 1.8084955215454102 seconds ---\n",
      "episode 4160, reward 86.0, memory_length 2000, epsilon 0.12493021219858241\n",
      "travel time- 723.0\n",
      "--- 1.6021099090576172 seconds ---\n",
      "episode 4161, reward 155.0, memory_length 2000, epsilon 0.12486776270615724\n",
      "travel time- 722.0\n",
      "--- 1.6683759689331055 seconds ---\n",
      "episode 4162, reward -21.0, memory_length 2000, epsilon 0.12480534443067345\n",
      "travel time- 725.0\n",
      "--- 1.5544180870056152 seconds ---\n",
      "episode 4163, reward -66.0, memory_length 2000, epsilon 0.12474295735652637\n",
      "travel time- 723.0\n",
      "--- 1.8127686977386475 seconds ---\n",
      "episode 4164, reward -50.0, memory_length 2000, epsilon 0.12468060146811931\n",
      "travel time- 722.0\n",
      "--- 1.8830337524414062 seconds ---\n",
      "episode 4165, reward -47.0, memory_length 2000, epsilon 0.12461827674986323\n",
      "travel time- 721.0\n",
      "--- 1.5672187805175781 seconds ---\n",
      "episode 4166, reward -135.0, memory_length 2000, epsilon 0.12455598318617699\n",
      "travel time- 726.0\n",
      "--- 1.7186567783355713 seconds ---\n",
      "episode 4167, reward 42.0, memory_length 2000, epsilon 0.12449372076148724\n",
      "travel time- 731.0\n",
      "--- 1.6287803649902344 seconds ---\n",
      "episode 4168, reward 249.0, memory_length 2000, epsilon 0.12443148946022826\n",
      "travel time- 723.0\n",
      "--- 1.552687168121338 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4169, reward -79.0, memory_length 2000, epsilon 0.12436928926684232\n",
      "travel time- 724.0\n",
      "--- 1.8009593486785889 seconds ---\n",
      "episode 4170, reward -85.0, memory_length 2000, epsilon 0.12430712016577938\n",
      "travel time- 726.0\n",
      "--- 1.7201011180877686 seconds ---\n",
      "episode 4171, reward 149.0, memory_length 2000, epsilon 0.12424498214149708\n",
      "travel time- 721.0\n",
      "--- 1.4953408241271973 seconds ---\n",
      "episode 4172, reward 36.0, memory_length 2000, epsilon 0.12418287517846102\n",
      "travel time- 726.0\n",
      "--- 1.5463435649871826 seconds ---\n",
      "episode 4173, reward -130.0, memory_length 2000, epsilon 0.12412079926114436\n",
      "travel time- 727.0\n",
      "--- 1.6822726726531982 seconds ---\n",
      "episode 4174, reward -116.0, memory_length 2000, epsilon 0.12405875437402814\n",
      "travel time- 722.0\n",
      "--- 1.6264503002166748 seconds ---\n",
      "episode 4175, reward -209.0, memory_length 2000, epsilon 0.12399674050160123\n",
      "travel time- 721.0\n",
      "--- 1.7391688823699951 seconds ---\n",
      "episode 4176, reward 57.0, memory_length 2000, epsilon 0.12393475762836002\n",
      "travel time- 727.0\n",
      "--- 1.6956489086151123 seconds ---\n",
      "episode 4177, reward -348.0, memory_length 2000, epsilon 0.12387280573880888\n",
      "travel time- 721.0\n",
      "--- 1.5722897052764893 seconds ---\n",
      "episode 4178, reward -84.0, memory_length 2000, epsilon 0.12381088481745986\n",
      "travel time- 721.0\n",
      "--- 1.732475996017456 seconds ---\n",
      "episode 4179, reward -112.0, memory_length 2000, epsilon 0.12374899484883264\n",
      "travel time- 720.0\n",
      "--- 1.6626901626586914 seconds ---\n",
      "episode 4180, reward -362.0, memory_length 2000, epsilon 0.12368713581745483\n",
      "travel time- 724.0\n",
      "--- 1.9590246677398682 seconds ---\n",
      "episode 4181, reward 36.0, memory_length 2000, epsilon 0.12362530770786156\n",
      "travel time- 728.0\n",
      "--- 1.665881633758545 seconds ---\n",
      "episode 4182, reward -148.0, memory_length 2000, epsilon 0.12356351050459588\n",
      "travel time- 720.0\n",
      "--- 1.7004823684692383 seconds ---\n",
      "episode 4183, reward 82.0, memory_length 2000, epsilon 0.12350174419220851\n",
      "travel time- 721.0\n",
      "--- 1.8032100200653076 seconds ---\n",
      "episode 4184, reward 181.0, memory_length 2000, epsilon 0.12344000875525778\n",
      "travel time- 723.0\n",
      "--- 1.6678378582000732 seconds ---\n",
      "episode 4185, reward -253.0, memory_length 2000, epsilon 0.12337830417830987\n",
      "travel time- 727.0\n",
      "--- 1.612504243850708 seconds ---\n",
      "episode 4186, reward -103.0, memory_length 2000, epsilon 0.12331663044593871\n",
      "travel time- 721.0\n",
      "--- 1.6171162128448486 seconds ---\n",
      "episode 4187, reward 137.0, memory_length 2000, epsilon 0.12325498754272576\n",
      "travel time- 731.0\n",
      "--- 1.5752074718475342 seconds ---\n",
      "episode 4188, reward -24.0, memory_length 2000, epsilon 0.12319337545326038\n",
      "travel time- 727.0\n",
      "--- 1.6135210990905762 seconds ---\n",
      "episode 4189, reward 266.0, memory_length 2000, epsilon 0.12313179416213946\n",
      "travel time- 725.0\n",
      "--- 1.8182930946350098 seconds ---\n",
      "episode 4190, reward 95.0, memory_length 2000, epsilon 0.12307024365396771\n",
      "travel time- 723.0\n",
      "--- 1.765840768814087 seconds ---\n",
      "episode 4191, reward -282.0, memory_length 2000, epsilon 0.12300872391335757\n",
      "travel time- 721.0\n",
      "--- 1.6866261959075928 seconds ---\n",
      "episode 4192, reward -89.0, memory_length 2000, epsilon 0.122947234924929\n",
      "travel time- 736.0\n",
      "--- 1.6135051250457764 seconds ---\n",
      "episode 4193, reward -111.0, memory_length 2000, epsilon 0.1228857766733098\n",
      "travel time- 727.0\n",
      "--- 1.6379802227020264 seconds ---\n",
      "episode 4194, reward -93.0, memory_length 2000, epsilon 0.12282434914313546\n",
      "travel time- 722.0\n",
      "--- 1.6886870861053467 seconds ---\n",
      "episode 4195, reward -192.0, memory_length 2000, epsilon 0.12276295231904899\n",
      "travel time- 722.0\n",
      "--- 1.8917198181152344 seconds ---\n",
      "episode 4196, reward -66.0, memory_length 2000, epsilon 0.1227015861857013\n",
      "travel time- 733.0\n",
      "--- 1.4726390838623047 seconds ---\n",
      "episode 4197, reward -71.0, memory_length 2000, epsilon 0.12264025072775074\n",
      "travel time- 723.0\n",
      "--- 1.5352604389190674 seconds ---\n",
      "episode 4198, reward 217.0, memory_length 2000, epsilon 0.1225789459298635\n",
      "travel time- 721.0\n",
      "--- 1.6254942417144775 seconds ---\n",
      "episode 4199, reward -96.0, memory_length 2000, epsilon 0.12251767177671344\n",
      "travel time- 724.0\n",
      "--- 1.7907812595367432 seconds ---\n",
      "episode 4200, reward -141.0, memory_length 2000, epsilon 0.1224564282529819\n",
      "travel time- 727.0\n",
      "--- 1.821028470993042 seconds ---\n",
      "episode 4201, reward 47.0, memory_length 2000, epsilon 0.12239521534335807\n",
      "travel time- 727.0\n",
      "--- 1.716902732849121 seconds ---\n",
      "episode 4202, reward 167.0, memory_length 2000, epsilon 0.12233403303253876\n",
      "travel time- 720.0\n",
      "--- 1.6924324035644531 seconds ---\n",
      "episode 4203, reward -7.0, memory_length 2000, epsilon 0.12227288130522829\n",
      "travel time- 721.0\n",
      "--- 1.6462352275848389 seconds ---\n",
      "episode 4204, reward 38.0, memory_length 2000, epsilon 0.12221176014613884\n",
      "travel time- 720.0\n",
      "--- 1.5852487087249756 seconds ---\n",
      "episode 4205, reward 256.0, memory_length 2000, epsilon 0.12215066953999\n",
      "travel time- 724.0\n",
      "--- 1.6915926933288574 seconds ---\n",
      "episode 4206, reward -76.0, memory_length 2000, epsilon 0.1220896094715092\n",
      "travel time- 724.0\n",
      "--- 1.75431489944458 seconds ---\n",
      "episode 4207, reward -47.0, memory_length 2000, epsilon 0.12202857992543144\n",
      "travel time- 723.0\n",
      "--- 1.8539350032806396 seconds ---\n",
      "episode 4208, reward 326.0, memory_length 2000, epsilon 0.12196758088649925\n",
      "travel time- 722.0\n",
      "--- 1.5414423942565918 seconds ---\n",
      "episode 4209, reward 148.0, memory_length 2000, epsilon 0.12190661233946291\n",
      "travel time- 720.0\n",
      "--- 1.7633295059204102 seconds ---\n",
      "episode 4210, reward -239.0, memory_length 2000, epsilon 0.12184567426908036\n",
      "travel time- 724.0\n",
      "--- 1.9273908138275146 seconds ---\n",
      "episode 4211, reward -185.0, memory_length 2000, epsilon 0.12178476666011695\n",
      "travel time- 725.0\n",
      "--- 1.6594791412353516 seconds ---\n",
      "episode 4212, reward -3.0, memory_length 2000, epsilon 0.12172388949734589\n",
      "travel time- 722.0\n",
      "--- 1.670442819595337 seconds ---\n",
      "episode 4213, reward -4.0, memory_length 2000, epsilon 0.12166304276554779\n",
      "travel time- 722.0\n",
      "--- 1.7441670894622803 seconds ---\n",
      "episode 4214, reward 165.0, memory_length 2000, epsilon 0.121602226449511\n",
      "travel time- 723.0\n",
      "--- 1.6510095596313477 seconds ---\n",
      "episode 4215, reward 61.0, memory_length 2000, epsilon 0.12154144053403153\n",
      "travel time- 727.0\n",
      "--- 1.6386816501617432 seconds ---\n",
      "episode 4216, reward 107.0, memory_length 2000, epsilon 0.12148068500391276\n",
      "travel time- 723.0\n",
      "--- 1.677706241607666 seconds ---\n",
      "episode 4217, reward 14.0, memory_length 2000, epsilon 0.12141995984396588\n",
      "travel time- 721.0\n",
      "--- 1.6926701068878174 seconds ---\n",
      "episode 4218, reward 337.0, memory_length 2000, epsilon 0.12135926503900965\n",
      "travel time- 721.0\n",
      "--- 1.542792797088623 seconds ---\n",
      "episode 4219, reward 152.0, memory_length 2000, epsilon 0.12129860057387025\n",
      "travel time- 722.0\n",
      "--- 1.6966261863708496 seconds ---\n",
      "episode 4220, reward 17.0, memory_length 2000, epsilon 0.12123796643338168\n",
      "travel time- 723.0\n",
      "--- 1.7065398693084717 seconds ---\n",
      "episode 4221, reward -197.0, memory_length 2000, epsilon 0.1211773626023853\n",
      "travel time- 722.0\n",
      "--- 1.6387159824371338 seconds ---\n",
      "episode 4222, reward -245.0, memory_length 2000, epsilon 0.1211167890657302\n",
      "travel time- 723.0\n",
      "--- 1.6710536479949951 seconds ---\n",
      "episode 4223, reward 4.0, memory_length 2000, epsilon 0.12105624580827305\n",
      "travel time- 725.0\n",
      "--- 1.4450485706329346 seconds ---\n",
      "episode 4224, reward -154.0, memory_length 2000, epsilon 0.12099573281487792\n",
      "travel time- 728.0\n",
      "--- 1.4956934452056885 seconds ---\n",
      "episode 4225, reward -198.0, memory_length 2000, epsilon 0.1209352500704167\n",
      "travel time- 722.0\n",
      "--- 1.6125524044036865 seconds ---\n",
      "episode 4226, reward -392.0, memory_length 2000, epsilon 0.12087479755976856\n",
      "travel time- 731.0\n",
      "--- 1.82613205909729 seconds ---\n",
      "episode 4227, reward 150.0, memory_length 2000, epsilon 0.12081437526782043\n",
      "travel time- 723.0\n",
      "--- 1.6050348281860352 seconds ---\n",
      "episode 4228, reward 2.0, memory_length 2000, epsilon 0.12075398317946681\n",
      "travel time- 729.0\n",
      "--- 1.6600861549377441 seconds ---\n",
      "episode 4229, reward 202.0, memory_length 2000, epsilon 0.12069362127960957\n",
      "travel time- 723.0\n",
      "--- 1.5660364627838135 seconds ---\n",
      "episode 4230, reward -230.0, memory_length 2000, epsilon 0.12063328955315826\n",
      "travel time- 720.0\n",
      "--- 1.6976184844970703 seconds ---\n",
      "episode 4231, reward -83.0, memory_length 2000, epsilon 0.12057298798503004\n",
      "travel time- 724.0\n",
      "--- 1.6501364707946777 seconds ---\n",
      "episode 4232, reward 68.0, memory_length 2000, epsilon 0.12051271656014938\n",
      "travel time- 720.0\n",
      "--- 1.8004684448242188 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4233, reward 170.0, memory_length 2000, epsilon 0.12045247526344853\n",
      "travel time- 727.0\n",
      "--- 1.751983880996704 seconds ---\n",
      "episode 4234, reward 182.0, memory_length 2000, epsilon 0.12039226407986708\n",
      "travel time- 721.0\n",
      "--- 1.4375197887420654 seconds ---\n",
      "episode 4235, reward 254.0, memory_length 2000, epsilon 0.12033208299435229\n",
      "travel time- 725.0\n",
      "--- 1.474501132965088 seconds ---\n",
      "episode 4236, reward 171.0, memory_length 2000, epsilon 0.12027193199185891\n",
      "travel time- 727.0\n",
      "--- 1.6690282821655273 seconds ---\n",
      "episode 4237, reward -10.0, memory_length 2000, epsilon 0.12021181105734911\n",
      "travel time- 730.0\n",
      "--- 1.6605267524719238 seconds ---\n",
      "episode 4238, reward -37.0, memory_length 2000, epsilon 0.12015172017579269\n",
      "travel time- 723.0\n",
      "--- 1.753424882888794 seconds ---\n",
      "episode 4239, reward 113.0, memory_length 2000, epsilon 0.120091659332167\n",
      "travel time- 726.0\n",
      "--- 1.8180043697357178 seconds ---\n",
      "episode 4240, reward 110.0, memory_length 2000, epsilon 0.12003162851145673\n",
      "travel time- 720.0\n",
      "--- 1.6389997005462646 seconds ---\n",
      "episode 4241, reward -79.0, memory_length 2000, epsilon 0.11997162769865424\n",
      "travel time- 724.0\n",
      "--- 1.66066312789917 seconds ---\n",
      "episode 4242, reward -141.0, memory_length 2000, epsilon 0.11991165687875927\n",
      "travel time- 725.0\n",
      "--- 1.8120217323303223 seconds ---\n",
      "episode 4243, reward -228.0, memory_length 2000, epsilon 0.11985171603677913\n",
      "travel time- 720.0\n",
      "--- 1.6233458518981934 seconds ---\n",
      "episode 4244, reward -426.0, memory_length 2000, epsilon 0.11979180515772868\n",
      "travel time- 721.0\n",
      "--- 1.655332088470459 seconds ---\n",
      "episode 4245, reward -95.0, memory_length 2000, epsilon 0.11973192422663008\n",
      "travel time- 722.0\n",
      "--- 1.6334326267242432 seconds ---\n",
      "episode 4246, reward -118.0, memory_length 2000, epsilon 0.11967207322851317\n",
      "travel time- 723.0\n",
      "--- 1.8234796524047852 seconds ---\n",
      "episode 4247, reward 166.0, memory_length 2000, epsilon 0.11961225214841525\n",
      "travel time- 722.0\n",
      "--- 1.790999412536621 seconds ---\n",
      "episode 4248, reward 56.0, memory_length 2000, epsilon 0.11955246097138093\n",
      "travel time- 722.0\n",
      "--- 1.703023910522461 seconds ---\n",
      "episode 4249, reward -121.0, memory_length 2000, epsilon 0.11949269968246252\n",
      "travel time- 722.0\n",
      "--- 1.5811669826507568 seconds ---\n",
      "episode 4250, reward 90.0, memory_length 2000, epsilon 0.11943296826671962\n",
      "travel time- 725.0\n",
      "--- 1.740394115447998 seconds ---\n",
      "episode 4251, reward 153.0, memory_length 2000, epsilon 0.1193732667092194\n",
      "travel time- 723.0\n",
      "--- 1.7859961986541748 seconds ---\n",
      "episode 4252, reward -237.0, memory_length 2000, epsilon 0.11931359499503652\n",
      "travel time- 728.0\n",
      "--- 1.80702805519104 seconds ---\n",
      "episode 4253, reward 123.0, memory_length 2000, epsilon 0.11925395310925298\n",
      "travel time- 727.0\n",
      "--- 1.664254903793335 seconds ---\n",
      "episode 4254, reward 63.0, memory_length 2000, epsilon 0.11919434103695832\n",
      "travel time- 726.0\n",
      "--- 1.658215045928955 seconds ---\n",
      "episode 4255, reward -94.0, memory_length 2000, epsilon 0.1191347587632496\n",
      "travel time- 720.0\n",
      "--- 1.8239357471466064 seconds ---\n",
      "episode 4256, reward 76.0, memory_length 2000, epsilon 0.11907520627323114\n",
      "travel time- 724.0\n",
      "--- 1.5510399341583252 seconds ---\n",
      "episode 4257, reward 274.0, memory_length 2000, epsilon 0.11901568355201492\n",
      "travel time- 738.0\n",
      "--- 1.5727448463439941 seconds ---\n",
      "episode 4258, reward 353.0, memory_length 2000, epsilon 0.11895619058472015\n",
      "travel time- 720.0\n",
      "--- 1.5558452606201172 seconds ---\n",
      "episode 4259, reward 70.0, memory_length 2000, epsilon 0.11889672735647365\n",
      "travel time- 728.0\n",
      "--- 1.692535400390625 seconds ---\n",
      "episode 4260, reward -164.0, memory_length 2000, epsilon 0.11883729385240965\n",
      "travel time- 726.0\n",
      "--- 1.5542640686035156 seconds ---\n",
      "episode 4261, reward -102.0, memory_length 2000, epsilon 0.1187778900576697\n",
      "travel time- 730.0\n",
      "--- 1.619135856628418 seconds ---\n",
      "episode 4262, reward -11.0, memory_length 2000, epsilon 0.11871851595740286\n",
      "travel time- 724.0\n",
      "--- 1.5422334671020508 seconds ---\n",
      "episode 4263, reward 196.0, memory_length 2000, epsilon 0.1186591715367657\n",
      "travel time- 725.0\n",
      "--- 1.4049060344696045 seconds ---\n",
      "episode 4264, reward 197.0, memory_length 2000, epsilon 0.11859985678092198\n",
      "travel time- 724.0\n",
      "--- 1.6539385318756104 seconds ---\n",
      "episode 4265, reward 50.0, memory_length 2000, epsilon 0.11854057167504313\n",
      "travel time- 722.0\n",
      "--- 1.615051507949829 seconds ---\n",
      "episode 4266, reward 332.0, memory_length 2000, epsilon 0.11848131620430775\n",
      "travel time- 720.0\n",
      "--- 1.5806286334991455 seconds ---\n",
      "episode 4267, reward 161.0, memory_length 2000, epsilon 0.11842209035390205\n",
      "travel time- 722.0\n",
      "--- 1.636310338973999 seconds ---\n",
      "episode 4268, reward -251.0, memory_length 2000, epsilon 0.11836289410901962\n",
      "travel time- 722.0\n",
      "--- 1.7123260498046875 seconds ---\n",
      "episode 4269, reward -180.0, memory_length 2000, epsilon 0.11830372745486127\n",
      "travel time- 722.0\n",
      "--- 1.7019751071929932 seconds ---\n",
      "episode 4270, reward 92.0, memory_length 2000, epsilon 0.1182445903766354\n",
      "travel time- 723.0\n",
      "--- 1.6641252040863037 seconds ---\n",
      "episode 4271, reward -246.0, memory_length 2000, epsilon 0.11818548285955778\n",
      "travel time- 722.0\n",
      "--- 1.570267677307129 seconds ---\n",
      "episode 4272, reward 70.0, memory_length 2000, epsilon 0.11812640488885146\n",
      "travel time- 724.0\n",
      "--- 1.6862547397613525 seconds ---\n",
      "episode 4273, reward -51.0, memory_length 2000, epsilon 0.11806735644974702\n",
      "travel time- 721.0\n",
      "--- 1.5754516124725342 seconds ---\n",
      "episode 4274, reward -27.0, memory_length 2000, epsilon 0.11800833752748224\n",
      "travel time- 728.0\n",
      "--- 1.6319403648376465 seconds ---\n",
      "episode 4275, reward 18.0, memory_length 2000, epsilon 0.11794934810730248\n",
      "travel time- 722.0\n",
      "--- 1.6936545372009277 seconds ---\n",
      "episode 4276, reward 222.0, memory_length 2000, epsilon 0.1178903881744604\n",
      "travel time- 720.0\n",
      "--- 1.4999990463256836 seconds ---\n",
      "episode 4277, reward -205.0, memory_length 2000, epsilon 0.11783145771421594\n",
      "travel time- 732.0\n",
      "--- 1.6915204524993896 seconds ---\n",
      "episode 4278, reward -465.0, memory_length 2000, epsilon 0.1177725567118365\n",
      "travel time- 722.0\n",
      "--- 1.7537269592285156 seconds ---\n",
      "episode 4279, reward 93.0, memory_length 2000, epsilon 0.11771368515259692\n",
      "travel time- 737.0\n",
      "--- 1.7552874088287354 seconds ---\n",
      "episode 4280, reward 111.0, memory_length 2000, epsilon 0.11765484302177918\n",
      "travel time- 731.0\n",
      "--- 1.7393770217895508 seconds ---\n",
      "episode 4281, reward 80.0, memory_length 2000, epsilon 0.11759603030467286\n",
      "travel time- 724.0\n",
      "--- 1.5422637462615967 seconds ---\n",
      "episode 4282, reward 20.0, memory_length 2000, epsilon 0.11753724698657468\n",
      "travel time- 723.0\n",
      "--- 1.7743358612060547 seconds ---\n",
      "episode 4283, reward -179.0, memory_length 2000, epsilon 0.11747849305278886\n",
      "travel time- 729.0\n",
      "--- 1.7623398303985596 seconds ---\n",
      "episode 4284, reward -28.0, memory_length 2000, epsilon 0.11741976848862698\n",
      "travel time- 721.0\n",
      "--- 1.8458919525146484 seconds ---\n",
      "episode 4285, reward -199.0, memory_length 2000, epsilon 0.11736107327940776\n",
      "travel time- 721.0\n",
      "--- 1.621553897857666 seconds ---\n",
      "episode 4286, reward 111.0, memory_length 2000, epsilon 0.11730240741045748\n",
      "travel time- 723.0\n",
      "--- 1.58201003074646 seconds ---\n",
      "episode 4287, reward -134.0, memory_length 2000, epsilon 0.11724377086710971\n",
      "travel time- 721.0\n",
      "--- 1.723907470703125 seconds ---\n",
      "episode 4288, reward -184.0, memory_length 2000, epsilon 0.11718516363470523\n",
      "travel time- 721.0\n",
      "--- 1.5898821353912354 seconds ---\n",
      "episode 4289, reward 114.0, memory_length 2000, epsilon 0.11712658569859231\n",
      "travel time- 722.0\n",
      "--- 1.6572926044464111 seconds ---\n",
      "episode 4290, reward 343.0, memory_length 2000, epsilon 0.11706803704412637\n",
      "travel time- 722.0\n",
      "--- 1.7889108657836914 seconds ---\n",
      "episode 4291, reward 109.0, memory_length 2000, epsilon 0.11700951765667031\n",
      "travel time- 730.0\n",
      "--- 1.6760447025299072 seconds ---\n",
      "episode 4292, reward -196.0, memory_length 2000, epsilon 0.11695102752159432\n",
      "travel time- 736.0\n",
      "--- 1.782644510269165 seconds ---\n",
      "episode 4293, reward 170.0, memory_length 2000, epsilon 0.11689256662427577\n",
      "travel time- 734.0\n",
      "--- 1.5862188339233398 seconds ---\n",
      "episode 4294, reward -68.0, memory_length 2000, epsilon 0.11683413495009948\n",
      "travel time- 720.0\n",
      "--- 1.6369268894195557 seconds ---\n",
      "episode 4295, reward 18.0, memory_length 2000, epsilon 0.11677573248445759\n",
      "travel time- 720.0\n",
      "--- 1.6242692470550537 seconds ---\n",
      "episode 4296, reward 314.0, memory_length 2000, epsilon 0.11671735921274938\n",
      "travel time- 723.0\n",
      "--- 1.522510051727295 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4297, reward -87.0, memory_length 2000, epsilon 0.11665901512038163\n",
      "travel time- 725.0\n",
      "--- 1.7644500732421875 seconds ---\n",
      "episode 4298, reward 229.0, memory_length 2000, epsilon 0.11660070019276822\n",
      "travel time- 726.0\n",
      "--- 1.8506808280944824 seconds ---\n",
      "episode 4299, reward -119.0, memory_length 2000, epsilon 0.11654241441533046\n",
      "travel time- 720.0\n",
      "--- 1.6666138172149658 seconds ---\n",
      "episode 4300, reward -324.0, memory_length 2000, epsilon 0.11648415777349697\n",
      "travel time- 726.0\n",
      "--- 2.0144402980804443 seconds ---\n",
      "episode 4301, reward 309.0, memory_length 2000, epsilon 0.11642593025270347\n",
      "travel time- 727.0\n",
      "--- 1.755364179611206 seconds ---\n",
      "episode 4302, reward -203.0, memory_length 2000, epsilon 0.11636773183839315\n",
      "travel time- 726.0\n",
      "--- 1.7032990455627441 seconds ---\n",
      "episode 4303, reward 203.0, memory_length 2000, epsilon 0.11630956251601643\n",
      "travel time- 734.0\n",
      "--- 1.811248540878296 seconds ---\n",
      "episode 4304, reward -138.0, memory_length 2000, epsilon 0.11625142227103091\n",
      "travel time- 726.0\n",
      "--- 1.827878713607788 seconds ---\n",
      "episode 4305, reward -221.0, memory_length 2000, epsilon 0.1161933110889016\n",
      "travel time- 731.0\n",
      "--- 1.9467663764953613 seconds ---\n",
      "episode 4306, reward -93.0, memory_length 2000, epsilon 0.11613522895510063\n",
      "travel time- 720.0\n",
      "--- 1.8097734451293945 seconds ---\n",
      "episode 4307, reward 31.0, memory_length 2000, epsilon 0.1160771758551075\n",
      "travel time- 734.0\n",
      "--- 1.601264476776123 seconds ---\n",
      "episode 4308, reward -112.0, memory_length 2000, epsilon 0.116019151774409\n",
      "travel time- 723.0\n",
      "--- 1.8593053817749023 seconds ---\n",
      "episode 4309, reward -168.0, memory_length 2000, epsilon 0.11596115669849898\n",
      "travel time- 725.0\n",
      "--- 1.803969383239746 seconds ---\n",
      "episode 4310, reward -44.0, memory_length 2000, epsilon 0.11590319061287874\n",
      "travel time- 720.0\n",
      "--- 1.6241412162780762 seconds ---\n",
      "episode 4311, reward -50.0, memory_length 2000, epsilon 0.11584525350305681\n",
      "travel time- 727.0\n",
      "--- 1.6228585243225098 seconds ---\n",
      "episode 4312, reward 61.0, memory_length 2000, epsilon 0.1157873453545488\n",
      "travel time- 720.0\n",
      "--- 1.6495387554168701 seconds ---\n",
      "episode 4313, reward -15.0, memory_length 2000, epsilon 0.1157294661528778\n",
      "travel time- 727.0\n",
      "--- 1.696305513381958 seconds ---\n",
      "episode 4314, reward 363.0, memory_length 2000, epsilon 0.11567161588357389\n",
      "travel time- 721.0\n",
      "--- 1.5756251811981201 seconds ---\n",
      "episode 4315, reward 77.0, memory_length 2000, epsilon 0.11561379453217453\n",
      "travel time- 728.0\n",
      "--- 1.6580276489257812 seconds ---\n",
      "episode 4316, reward -284.0, memory_length 2000, epsilon 0.11555600208422448\n",
      "travel time- 720.0\n",
      "--- 1.8846886157989502 seconds ---\n",
      "episode 4317, reward 232.0, memory_length 2000, epsilon 0.11549823852527549\n",
      "travel time- 721.0\n",
      "--- 1.7291948795318604 seconds ---\n",
      "episode 4318, reward -214.0, memory_length 2000, epsilon 0.11544050384088674\n",
      "travel time- 722.0\n",
      "--- 1.7541987895965576 seconds ---\n",
      "episode 4319, reward 271.0, memory_length 2000, epsilon 0.1153827980166246\n",
      "travel time- 726.0\n",
      "--- 1.545936107635498 seconds ---\n",
      "episode 4320, reward 183.0, memory_length 2000, epsilon 0.11532512103806251\n",
      "travel time- 720.0\n",
      "--- 1.716381549835205 seconds ---\n",
      "episode 4321, reward 134.0, memory_length 2000, epsilon 0.11526747289078133\n",
      "travel time- 720.0\n",
      "--- 1.5629189014434814 seconds ---\n",
      "episode 4322, reward 200.0, memory_length 2000, epsilon 0.11520985356036893\n",
      "travel time- 723.0\n",
      "--- 1.5842015743255615 seconds ---\n",
      "episode 4323, reward 308.0, memory_length 2000, epsilon 0.11515226303242052\n",
      "travel time- 721.0\n",
      "--- 1.6804652214050293 seconds ---\n",
      "episode 4324, reward -105.0, memory_length 2000, epsilon 0.11509470129253851\n",
      "travel time- 726.0\n",
      "--- 1.722532033920288 seconds ---\n",
      "episode 4325, reward -153.0, memory_length 2000, epsilon 0.11503716832633237\n",
      "travel time- 723.0\n",
      "--- 1.7565710544586182 seconds ---\n",
      "episode 4326, reward -44.0, memory_length 2000, epsilon 0.11497966411941893\n",
      "travel time- 727.0\n",
      "--- 1.5579984188079834 seconds ---\n",
      "episode 4327, reward -45.0, memory_length 2000, epsilon 0.11492218865742215\n",
      "travel time- 721.0\n",
      "--- 1.5554816722869873 seconds ---\n",
      "episode 4328, reward 363.0, memory_length 2000, epsilon 0.11486474192597308\n",
      "travel time- 736.0\n",
      "--- 1.6590077877044678 seconds ---\n",
      "episode 4329, reward 193.0, memory_length 2000, epsilon 0.11480732391071016\n",
      "travel time- 721.0\n",
      "--- 1.761061191558838 seconds ---\n",
      "episode 4330, reward -54.0, memory_length 2000, epsilon 0.11474993459727875\n",
      "travel time- 722.0\n",
      "--- 1.6201550960540771 seconds ---\n",
      "episode 4331, reward -248.0, memory_length 2000, epsilon 0.11469257397133159\n",
      "travel time- 724.0\n",
      "--- 1.6997478008270264 seconds ---\n",
      "episode 4332, reward -96.0, memory_length 2000, epsilon 0.11463524201852858\n",
      "travel time- 727.0\n",
      "--- 1.6976234912872314 seconds ---\n",
      "episode 4333, reward 39.0, memory_length 2000, epsilon 0.11457793872453662\n",
      "travel time- 727.0\n",
      "--- 1.7699453830718994 seconds ---\n",
      "episode 4334, reward 58.0, memory_length 2000, epsilon 0.11452066407502992\n",
      "travel time- 726.0\n",
      "--- 1.686758279800415 seconds ---\n",
      "episode 4335, reward 145.0, memory_length 2000, epsilon 0.1144634180556899\n",
      "travel time- 729.0\n",
      "--- 1.4640488624572754 seconds ---\n",
      "episode 4336, reward 261.0, memory_length 2000, epsilon 0.11440620065220493\n",
      "travel time- 729.0\n",
      "--- 1.8459861278533936 seconds ---\n",
      "episode 4337, reward 77.0, memory_length 2000, epsilon 0.11434901185027078\n",
      "travel time- 720.0\n",
      "--- 1.5833258628845215 seconds ---\n",
      "episode 4338, reward 30.0, memory_length 2000, epsilon 0.11429185163559014\n",
      "travel time- 726.0\n",
      "--- 1.4848902225494385 seconds ---\n",
      "episode 4339, reward 201.0, memory_length 2000, epsilon 0.114234719993873\n",
      "travel time- 728.0\n",
      "--- 1.6133489608764648 seconds ---\n",
      "episode 4340, reward -59.0, memory_length 2000, epsilon 0.1141776169108365\n",
      "travel time- 721.0\n",
      "--- 1.7248480319976807 seconds ---\n",
      "episode 4341, reward 97.0, memory_length 2000, epsilon 0.11412054237220477\n",
      "travel time- 728.0\n",
      "--- 1.6299901008605957 seconds ---\n",
      "episode 4342, reward 10.0, memory_length 2000, epsilon 0.11406349636370923\n",
      "travel time- 725.0\n",
      "--- 1.7603046894073486 seconds ---\n",
      "episode 4343, reward -62.0, memory_length 2000, epsilon 0.11400647887108842\n",
      "travel time- 721.0\n",
      "--- 1.7669456005096436 seconds ---\n",
      "episode 4344, reward 67.0, memory_length 2000, epsilon 0.11394948988008788\n",
      "travel time- 728.0\n",
      "--- 1.5595271587371826 seconds ---\n",
      "episode 4345, reward -111.0, memory_length 2000, epsilon 0.11389252937646045\n",
      "travel time- 724.0\n",
      "--- 1.690751314163208 seconds ---\n",
      "episode 4346, reward 84.0, memory_length 2000, epsilon 0.11383559734596592\n",
      "travel time- 724.0\n",
      "--- 1.5598671436309814 seconds ---\n",
      "episode 4347, reward 102.0, memory_length 2000, epsilon 0.1137786937743713\n",
      "travel time- 722.0\n",
      "--- 1.5317659378051758 seconds ---\n",
      "episode 4348, reward -279.0, memory_length 2000, epsilon 0.11372181864745078\n",
      "travel time- 721.0\n",
      "--- 1.848355770111084 seconds ---\n",
      "episode 4349, reward -57.0, memory_length 2000, epsilon 0.11366497195098545\n",
      "travel time- 720.0\n",
      "--- 1.7296040058135986 seconds ---\n",
      "episode 4350, reward -26.0, memory_length 2000, epsilon 0.11360815367076371\n",
      "travel time- 722.0\n",
      "--- 1.8000569343566895 seconds ---\n",
      "episode 4351, reward -90.0, memory_length 2000, epsilon 0.11355136379258103\n",
      "travel time- 723.0\n",
      "--- 1.726893424987793 seconds ---\n",
      "episode 4352, reward -120.0, memory_length 2000, epsilon 0.11349460230223983\n",
      "travel time- 721.0\n",
      "--- 1.8039240837097168 seconds ---\n",
      "episode 4353, reward -117.0, memory_length 2000, epsilon 0.11343786918554986\n",
      "travel time- 722.0\n",
      "--- 1.690176010131836 seconds ---\n",
      "episode 4354, reward 349.0, memory_length 2000, epsilon 0.11338116442832771\n",
      "travel time- 727.0\n",
      "--- 1.693758487701416 seconds ---\n",
      "episode 4355, reward -160.0, memory_length 2000, epsilon 0.11332448801639727\n",
      "travel time- 720.0\n",
      "--- 1.81223726272583 seconds ---\n",
      "episode 4356, reward 114.0, memory_length 2000, epsilon 0.11326783993558948\n",
      "travel time- 720.0\n",
      "--- 1.6440894603729248 seconds ---\n",
      "episode 4357, reward -176.0, memory_length 2000, epsilon 0.1132112201717422\n",
      "travel time- 720.0\n",
      "--- 1.5837562084197998 seconds ---\n",
      "episode 4358, reward 157.0, memory_length 2000, epsilon 0.11315462871070062\n",
      "travel time- 722.0\n",
      "--- 1.7426199913024902 seconds ---\n",
      "episode 4359, reward 76.0, memory_length 2000, epsilon 0.11309806553831675\n",
      "travel time- 722.0\n",
      "--- 1.6206495761871338 seconds ---\n",
      "episode 4360, reward 107.0, memory_length 2000, epsilon 0.11304153064044985\n",
      "travel time- 724.0\n",
      "--- 1.5471653938293457 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4361, reward 0.0, memory_length 2000, epsilon 0.11298502400296624\n",
      "travel time- 731.0\n",
      "--- 1.7784311771392822 seconds ---\n",
      "episode 4362, reward 91.0, memory_length 2000, epsilon 0.11292854561173918\n",
      "travel time- 720.0\n",
      "--- 1.71687650680542 seconds ---\n",
      "episode 4363, reward -16.0, memory_length 2000, epsilon 0.1128720954526491\n",
      "travel time- 722.0\n",
      "--- 1.8924329280853271 seconds ---\n",
      "episode 4364, reward -14.0, memory_length 2000, epsilon 0.11281567351158354\n",
      "travel time- 732.0\n",
      "--- 1.7175190448760986 seconds ---\n",
      "episode 4365, reward 36.0, memory_length 2000, epsilon 0.11275927977443688\n",
      "travel time- 721.0\n",
      "--- 1.7137792110443115 seconds ---\n",
      "episode 4366, reward 203.0, memory_length 2000, epsilon 0.11270291422711082\n",
      "travel time- 721.0\n",
      "--- 1.778808832168579 seconds ---\n",
      "episode 4367, reward 291.0, memory_length 2000, epsilon 0.11264657685551384\n",
      "travel time- 721.0\n",
      "--- 1.72468900680542 seconds ---\n",
      "episode 4368, reward 72.0, memory_length 2000, epsilon 0.11259026764556165\n",
      "travel time- 720.0\n",
      "--- 1.6201138496398926 seconds ---\n",
      "episode 4369, reward 81.0, memory_length 2000, epsilon 0.11253398658317702\n",
      "travel time- 724.0\n",
      "--- 1.5000100135803223 seconds ---\n",
      "episode 4370, reward -221.0, memory_length 2000, epsilon 0.11247773365428958\n",
      "travel time- 730.0\n",
      "--- 1.8348073959350586 seconds ---\n",
      "episode 4371, reward 44.0, memory_length 2000, epsilon 0.11242150884483612\n",
      "travel time- 728.0\n",
      "--- 1.6167161464691162 seconds ---\n",
      "episode 4372, reward 58.0, memory_length 2000, epsilon 0.11236531214076052\n",
      "travel time- 724.0\n",
      "--- 1.650841474533081 seconds ---\n",
      "episode 4373, reward 92.0, memory_length 2000, epsilon 0.11230914352801348\n",
      "travel time- 721.0\n",
      "--- 1.7411797046661377 seconds ---\n",
      "episode 4374, reward -98.0, memory_length 2000, epsilon 0.11225300299255297\n",
      "travel time- 722.0\n",
      "--- 1.694183349609375 seconds ---\n",
      "episode 4375, reward 21.0, memory_length 2000, epsilon 0.11219689052034373\n",
      "travel time- 720.0\n",
      "--- 1.6007702350616455 seconds ---\n",
      "episode 4376, reward 36.0, memory_length 2000, epsilon 0.11214080609735771\n",
      "travel time- 720.0\n",
      "--- 1.6794297695159912 seconds ---\n",
      "episode 4377, reward 91.0, memory_length 2000, epsilon 0.11208474970957386\n",
      "travel time- 720.0\n",
      "--- 1.5800414085388184 seconds ---\n",
      "episode 4378, reward -49.0, memory_length 2000, epsilon 0.11202872134297796\n",
      "travel time- 725.0\n",
      "--- 1.6809179782867432 seconds ---\n",
      "episode 4379, reward 270.0, memory_length 2000, epsilon 0.11197272098356298\n",
      "travel time- 727.0\n",
      "--- 1.6497087478637695 seconds ---\n",
      "episode 4380, reward 96.0, memory_length 2000, epsilon 0.11191674861732888\n",
      "travel time- 736.0\n",
      "--- 1.5065855979919434 seconds ---\n",
      "episode 4381, reward 268.0, memory_length 2000, epsilon 0.11186080423028247\n",
      "travel time- 721.0\n",
      "--- 1.6619038581848145 seconds ---\n",
      "episode 4382, reward -194.0, memory_length 2000, epsilon 0.11180488780843774\n",
      "travel time- 722.0\n",
      "--- 1.6529121398925781 seconds ---\n",
      "episode 4383, reward -66.0, memory_length 2000, epsilon 0.1117489993378155\n",
      "travel time- 721.0\n",
      "--- 1.426699161529541 seconds ---\n",
      "episode 4384, reward -76.0, memory_length 2000, epsilon 0.11169313880444368\n",
      "travel time- 728.0\n",
      "--- 2.0351309776306152 seconds ---\n",
      "episode 4385, reward -200.0, memory_length 2000, epsilon 0.11163730619435719\n",
      "travel time- 720.0\n",
      "--- 1.6004126071929932 seconds ---\n",
      "episode 4386, reward -65.0, memory_length 2000, epsilon 0.11158150149359779\n",
      "travel time- 725.0\n",
      "--- 1.7034919261932373 seconds ---\n",
      "episode 4387, reward -102.0, memory_length 2000, epsilon 0.11152572468821433\n",
      "travel time- 730.0\n",
      "--- 1.8137600421905518 seconds ---\n",
      "episode 4388, reward -69.0, memory_length 2000, epsilon 0.11146997576426268\n",
      "travel time- 720.0\n",
      "--- 1.6536478996276855 seconds ---\n",
      "episode 4389, reward 131.0, memory_length 2000, epsilon 0.1114142547078055\n",
      "travel time- 722.0\n",
      "--- 1.728588342666626 seconds ---\n",
      "episode 4390, reward 104.0, memory_length 2000, epsilon 0.11135856150491262\n",
      "travel time- 736.0\n",
      "--- 1.8167102336883545 seconds ---\n",
      "episode 4391, reward -122.0, memory_length 2000, epsilon 0.11130289614166065\n",
      "travel time- 721.0\n",
      "--- 1.6426618099212646 seconds ---\n",
      "episode 4392, reward -134.0, memory_length 2000, epsilon 0.1112472586041333\n",
      "travel time- 723.0\n",
      "--- 1.7516496181488037 seconds ---\n",
      "episode 4393, reward 250.0, memory_length 2000, epsilon 0.11119164887842123\n",
      "travel time- 721.0\n",
      "--- 1.431032657623291 seconds ---\n",
      "episode 4394, reward 108.0, memory_length 2000, epsilon 0.1111360669506219\n",
      "travel time- 724.0\n",
      "--- 1.6007511615753174 seconds ---\n",
      "episode 4395, reward 194.0, memory_length 2000, epsilon 0.1110805128068399\n",
      "travel time- 728.0\n",
      "--- 1.6206262111663818 seconds ---\n",
      "episode 4396, reward 168.0, memory_length 2000, epsilon 0.11102498643318673\n",
      "travel time- 729.0\n",
      "--- 1.5716211795806885 seconds ---\n",
      "episode 4397, reward -94.0, memory_length 2000, epsilon 0.11096948781578068\n",
      "travel time- 721.0\n",
      "--- 1.7647957801818848 seconds ---\n",
      "episode 4398, reward -15.0, memory_length 2000, epsilon 0.11091401694074722\n",
      "travel time- 720.0\n",
      "--- 1.5054986476898193 seconds ---\n",
      "episode 4399, reward 18.0, memory_length 2000, epsilon 0.11085857379421853\n",
      "travel time- 723.0\n",
      "--- 1.8598158359527588 seconds ---\n",
      "episode 4400, reward 181.0, memory_length 2000, epsilon 0.11080315836233387\n",
      "travel time- 728.0\n",
      "--- 1.7986292839050293 seconds ---\n",
      "episode 4401, reward -153.0, memory_length 2000, epsilon 0.11074777063123942\n",
      "travel time- 730.0\n",
      "--- 1.6578612327575684 seconds ---\n",
      "episode 4402, reward 45.0, memory_length 2000, epsilon 0.11069241058708815\n",
      "travel time- 724.0\n",
      "--- 1.7257766723632812 seconds ---\n",
      "episode 4403, reward -198.0, memory_length 2000, epsilon 0.1106370782160401\n",
      "travel time- 729.0\n",
      "--- 1.7722728252410889 seconds ---\n",
      "episode 4404, reward -91.0, memory_length 2000, epsilon 0.11058177350426224\n",
      "travel time- 721.0\n",
      "--- 1.567157506942749 seconds ---\n",
      "episode 4405, reward -52.0, memory_length 2000, epsilon 0.11052649643792828\n",
      "travel time- 720.0\n",
      "--- 1.5714590549468994 seconds ---\n",
      "episode 4406, reward -227.0, memory_length 2000, epsilon 0.11047124700321906\n",
      "travel time- 724.0\n",
      "--- 1.7099926471710205 seconds ---\n",
      "episode 4407, reward -187.0, memory_length 2000, epsilon 0.1104160251863221\n",
      "travel time- 723.0\n",
      "--- 1.6257734298706055 seconds ---\n",
      "episode 4408, reward 51.0, memory_length 2000, epsilon 0.11036083097343202\n",
      "travel time- 723.0\n",
      "--- 1.759953498840332 seconds ---\n",
      "episode 4409, reward -88.0, memory_length 2000, epsilon 0.11030566435075032\n",
      "travel time- 724.0\n",
      "--- 1.5885119438171387 seconds ---\n",
      "episode 4410, reward 91.0, memory_length 2000, epsilon 0.11025052530448522\n",
      "travel time- 724.0\n",
      "--- 1.4711978435516357 seconds ---\n",
      "episode 4411, reward 173.0, memory_length 2000, epsilon 0.11019541382085202\n",
      "travel time- 724.0\n",
      "--- 1.4835128784179688 seconds ---\n",
      "episode 4412, reward -21.0, memory_length 2000, epsilon 0.1101403298860729\n",
      "travel time- 724.0\n",
      "--- 1.7455737590789795 seconds ---\n",
      "episode 4413, reward 47.0, memory_length 2000, epsilon 0.11008527348637678\n",
      "travel time- 720.0\n",
      "--- 1.7348730564117432 seconds ---\n",
      "episode 4414, reward 162.0, memory_length 2000, epsilon 0.11003024460799965\n",
      "travel time- 724.0\n",
      "--- 1.713881254196167 seconds ---\n",
      "episode 4415, reward -32.0, memory_length 2000, epsilon 0.1099752432371842\n",
      "travel time- 728.0\n",
      "--- 1.7645752429962158 seconds ---\n",
      "episode 4416, reward 52.0, memory_length 2000, epsilon 0.10992026936018012\n",
      "travel time- 720.0\n",
      "--- 1.723247766494751 seconds ---\n",
      "episode 4417, reward -31.0, memory_length 2000, epsilon 0.10986532296324401\n",
      "travel time- 727.0\n",
      "--- 1.5350642204284668 seconds ---\n",
      "episode 4418, reward 0.0, memory_length 2000, epsilon 0.10981040403263917\n",
      "travel time- 720.0\n",
      "--- 1.6110925674438477 seconds ---\n",
      "episode 4419, reward -133.0, memory_length 2000, epsilon 0.1097555125546359\n",
      "travel time- 722.0\n",
      "--- 1.7342545986175537 seconds ---\n",
      "episode 4420, reward 523.0, memory_length 2000, epsilon 0.10970064851551141\n",
      "travel time- 724.0\n",
      "--- 1.5030200481414795 seconds ---\n",
      "episode 4421, reward 80.0, memory_length 2000, epsilon 0.10964581190154955\n",
      "travel time- 723.0\n",
      "--- 1.602919340133667 seconds ---\n",
      "episode 4422, reward 199.0, memory_length 2000, epsilon 0.10959100269904129\n",
      "travel time- 722.0\n",
      "--- 1.7196886539459229 seconds ---\n",
      "episode 4423, reward 196.0, memory_length 2000, epsilon 0.10953622089428423\n",
      "travel time- 725.0\n",
      "--- 1.7459118366241455 seconds ---\n",
      "episode 4424, reward 186.0, memory_length 2000, epsilon 0.10948146647358296\n",
      "travel time- 721.0\n",
      "--- 1.9228341579437256 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4425, reward -259.0, memory_length 2000, epsilon 0.10942673942324893\n",
      "travel time- 730.0\n",
      "--- 1.6710424423217773 seconds ---\n",
      "episode 4426, reward 234.0, memory_length 2000, epsilon 0.10937203972960027\n",
      "travel time- 720.0\n",
      "--- 1.739546298980713 seconds ---\n",
      "episode 4427, reward 98.0, memory_length 2000, epsilon 0.10931736737896212\n",
      "travel time- 720.0\n",
      "--- 1.6848206520080566 seconds ---\n",
      "episode 4428, reward 117.0, memory_length 2000, epsilon 0.10926272235766643\n",
      "travel time- 726.0\n",
      "--- 1.7564384937286377 seconds ---\n",
      "episode 4429, reward 94.0, memory_length 2000, epsilon 0.10920810465205186\n",
      "travel time- 721.0\n",
      "--- 1.6098694801330566 seconds ---\n",
      "episode 4430, reward -81.0, memory_length 2000, epsilon 0.10915351424846406\n",
      "travel time- 721.0\n",
      "--- 1.4612834453582764 seconds ---\n",
      "episode 4431, reward 145.0, memory_length 2000, epsilon 0.10909895113325534\n",
      "travel time- 727.0\n",
      "--- 1.6666879653930664 seconds ---\n",
      "episode 4432, reward -133.0, memory_length 2000, epsilon 0.10904441529278498\n",
      "travel time- 722.0\n",
      "--- 1.7444658279418945 seconds ---\n",
      "episode 4433, reward 295.0, memory_length 2000, epsilon 0.10898990671341906\n",
      "travel time- 728.0\n",
      "--- 1.5611052513122559 seconds ---\n",
      "episode 4434, reward -56.0, memory_length 2000, epsilon 0.10893542538153032\n",
      "travel time- 726.0\n",
      "--- 1.6660664081573486 seconds ---\n",
      "episode 4435, reward -321.0, memory_length 2000, epsilon 0.10888097128349851\n",
      "travel time- 727.0\n",
      "--- 1.922966718673706 seconds ---\n",
      "episode 4436, reward 265.0, memory_length 2000, epsilon 0.10882654440571013\n",
      "travel time- 723.0\n",
      "--- 1.6407091617584229 seconds ---\n",
      "episode 4437, reward 142.0, memory_length 2000, epsilon 0.10877214473455837\n",
      "travel time- 724.0\n",
      "--- 1.8323028087615967 seconds ---\n",
      "episode 4438, reward 100.0, memory_length 2000, epsilon 0.10871777225644341\n",
      "travel time- 731.0\n",
      "--- 1.7235655784606934 seconds ---\n",
      "episode 4439, reward -206.0, memory_length 2000, epsilon 0.10866342695777204\n",
      "travel time- 720.0\n",
      "--- 1.8567590713500977 seconds ---\n",
      "episode 4440, reward 66.0, memory_length 2000, epsilon 0.10860910882495796\n",
      "travel time- 721.0\n",
      "--- 1.9682328701019287 seconds ---\n",
      "episode 4441, reward -224.0, memory_length 2000, epsilon 0.10855481784442171\n",
      "travel time- 720.0\n",
      "--- 1.5909054279327393 seconds ---\n",
      "episode 4442, reward -87.0, memory_length 2000, epsilon 0.10850055400259043\n",
      "travel time- 721.0\n",
      "--- 1.5526771545410156 seconds ---\n",
      "episode 4443, reward 448.0, memory_length 2000, epsilon 0.10844631728589822\n",
      "travel time- 720.0\n",
      "--- 1.5602822303771973 seconds ---\n",
      "episode 4444, reward 194.0, memory_length 2000, epsilon 0.10839210768078596\n",
      "travel time- 721.0\n",
      "--- 1.5501022338867188 seconds ---\n",
      "episode 4445, reward 136.0, memory_length 2000, epsilon 0.10833792517370111\n",
      "travel time- 724.0\n",
      "--- 1.6312956809997559 seconds ---\n",
      "episode 4446, reward -374.0, memory_length 2000, epsilon 0.10828376975109819\n",
      "travel time- 721.0\n",
      "--- 1.7083916664123535 seconds ---\n",
      "episode 4447, reward 88.0, memory_length 2000, epsilon 0.1082296413994382\n",
      "travel time- 722.0\n",
      "--- 1.6113250255584717 seconds ---\n",
      "episode 4448, reward -100.0, memory_length 2000, epsilon 0.10817554010518914\n",
      "travel time- 728.0\n",
      "--- 1.5738964080810547 seconds ---\n",
      "episode 4449, reward -35.0, memory_length 2000, epsilon 0.10812146585482571\n",
      "travel time- 728.0\n",
      "--- 1.5563323497772217 seconds ---\n",
      "episode 4450, reward 288.0, memory_length 2000, epsilon 0.10806741863482926\n",
      "travel time- 727.0\n",
      "--- 1.4680864810943604 seconds ---\n",
      "episode 4451, reward 33.0, memory_length 2000, epsilon 0.10801339843168804\n",
      "travel time- 721.0\n",
      "--- 1.5362262725830078 seconds ---\n",
      "episode 4452, reward 33.0, memory_length 2000, epsilon 0.10795940523189702\n",
      "travel time- 723.0\n",
      "--- 1.591904640197754 seconds ---\n",
      "episode 4453, reward -92.0, memory_length 2000, epsilon 0.10790543902195784\n",
      "travel time- 725.0\n",
      "--- 1.7340655326843262 seconds ---\n",
      "episode 4454, reward 158.0, memory_length 2000, epsilon 0.10785149978837902\n",
      "travel time- 724.0\n",
      "--- 1.498772144317627 seconds ---\n",
      "episode 4455, reward -19.0, memory_length 2000, epsilon 0.10779758751767567\n",
      "travel time- 721.0\n",
      "--- 1.502373218536377 seconds ---\n",
      "episode 4456, reward -115.0, memory_length 2000, epsilon 0.10774370219636975\n",
      "travel time- 725.0\n",
      "--- 1.5319840908050537 seconds ---\n",
      "episode 4457, reward 82.0, memory_length 2000, epsilon 0.10768984381098999\n",
      "travel time- 722.0\n",
      "--- 1.6868162155151367 seconds ---\n",
      "episode 4458, reward 229.0, memory_length 2000, epsilon 0.10763601234807169\n",
      "travel time- 725.0\n",
      "--- 1.614518404006958 seconds ---\n",
      "episode 4459, reward 237.0, memory_length 2000, epsilon 0.10758220779415704\n",
      "travel time- 738.0\n",
      "--- 1.5706086158752441 seconds ---\n",
      "episode 4460, reward -79.0, memory_length 2000, epsilon 0.10752843013579495\n",
      "travel time- 730.0\n",
      "--- 1.552335262298584 seconds ---\n",
      "episode 4461, reward 155.0, memory_length 2000, epsilon 0.10747467935954091\n",
      "travel time- 723.0\n",
      "--- 1.722102403640747 seconds ---\n",
      "episode 4462, reward -21.0, memory_length 2000, epsilon 0.10742095545195732\n",
      "travel time- 732.0\n",
      "--- 1.7063050270080566 seconds ---\n",
      "episode 4463, reward 170.0, memory_length 2000, epsilon 0.10736725839961309\n",
      "travel time- 725.0\n",
      "--- 1.727741003036499 seconds ---\n",
      "episode 4464, reward 147.0, memory_length 2000, epsilon 0.10731358818908403\n",
      "travel time- 720.0\n",
      "--- 1.6149826049804688 seconds ---\n",
      "episode 4465, reward 23.0, memory_length 2000, epsilon 0.10725994480695261\n",
      "travel time- 727.0\n",
      "--- 1.6203503608703613 seconds ---\n",
      "episode 4466, reward -93.0, memory_length 2000, epsilon 0.10720632823980793\n",
      "travel time- 720.0\n",
      "--- 1.5199222564697266 seconds ---\n",
      "episode 4467, reward -8.0, memory_length 2000, epsilon 0.10715273847424585\n",
      "travel time- 721.0\n",
      "--- 1.6073975563049316 seconds ---\n",
      "episode 4468, reward -43.0, memory_length 2000, epsilon 0.107099175496869\n",
      "travel time- 727.0\n",
      "--- 1.4764201641082764 seconds ---\n",
      "episode 4469, reward 44.0, memory_length 2000, epsilon 0.10704563929428652\n",
      "travel time- 728.0\n",
      "--- 1.8239631652832031 seconds ---\n",
      "episode 4470, reward -21.0, memory_length 2000, epsilon 0.10699212985311449\n",
      "travel time- 722.0\n",
      "--- 1.6199345588684082 seconds ---\n",
      "episode 4471, reward 205.0, memory_length 2000, epsilon 0.10693864715997542\n",
      "travel time- 721.0\n",
      "--- 1.424955129623413 seconds ---\n",
      "episode 4472, reward 48.0, memory_length 2000, epsilon 0.1068851912014987\n",
      "travel time- 723.0\n",
      "--- 1.8950104713439941 seconds ---\n",
      "episode 4473, reward -74.0, memory_length 2000, epsilon 0.10683176196432037\n",
      "travel time- 726.0\n",
      "--- 1.6440749168395996 seconds ---\n",
      "episode 4474, reward -88.0, memory_length 2000, epsilon 0.10677835943508306\n",
      "travel time- 732.0\n",
      "--- 1.8260204792022705 seconds ---\n",
      "episode 4475, reward -216.0, memory_length 2000, epsilon 0.10672498360043615\n",
      "travel time- 721.0\n",
      "--- 1.6752264499664307 seconds ---\n",
      "episode 4476, reward 230.0, memory_length 2000, epsilon 0.10667163444703576\n",
      "travel time- 723.0\n",
      "--- 1.5114357471466064 seconds ---\n",
      "episode 4477, reward -107.0, memory_length 2000, epsilon 0.10661831196154449\n",
      "travel time- 723.0\n",
      "--- 1.6154096126556396 seconds ---\n",
      "episode 4478, reward 272.0, memory_length 2000, epsilon 0.1065650161306318\n",
      "travel time- 721.0\n",
      "--- 1.5303370952606201 seconds ---\n",
      "episode 4479, reward -180.0, memory_length 2000, epsilon 0.10651174694097365\n",
      "travel time- 723.0\n",
      "--- 1.7275609970092773 seconds ---\n",
      "episode 4480, reward 90.0, memory_length 2000, epsilon 0.1064585043792528\n",
      "travel time- 735.0\n",
      "--- 1.6784052848815918 seconds ---\n",
      "episode 4481, reward 182.0, memory_length 2000, epsilon 0.10640528843215864\n",
      "travel time- 722.0\n",
      "--- 1.6313362121582031 seconds ---\n",
      "episode 4482, reward 182.0, memory_length 2000, epsilon 0.1063520990863871\n",
      "travel time- 722.0\n",
      "--- 1.4488296508789062 seconds ---\n",
      "episode 4483, reward 60.0, memory_length 2000, epsilon 0.10629893632864093\n",
      "travel time- 725.0\n",
      "--- 1.7627711296081543 seconds ---\n",
      "episode 4484, reward 334.0, memory_length 2000, epsilon 0.10624580014562934\n",
      "travel time- 731.0\n",
      "--- 1.7230918407440186 seconds ---\n",
      "episode 4485, reward 170.0, memory_length 2000, epsilon 0.10619269052406835\n",
      "travel time- 721.0\n",
      "--- 1.638164758682251 seconds ---\n",
      "episode 4486, reward 66.0, memory_length 2000, epsilon 0.1061396074506806\n",
      "travel time- 722.0\n",
      "--- 1.8373181819915771 seconds ---\n",
      "episode 4487, reward -125.0, memory_length 2000, epsilon 0.10608655091219521\n",
      "travel time- 728.0\n",
      "--- 1.8188800811767578 seconds ---\n",
      "episode 4488, reward -120.0, memory_length 2000, epsilon 0.1060335208953481\n",
      "travel time- 720.0\n",
      "--- 1.8864169120788574 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4489, reward -104.0, memory_length 2000, epsilon 0.1059805173868818\n",
      "travel time- 722.0\n",
      "--- 1.5895209312438965 seconds ---\n",
      "episode 4490, reward -60.0, memory_length 2000, epsilon 0.10592754037354536\n",
      "travel time- 723.0\n",
      "--- 1.6168129444122314 seconds ---\n",
      "episode 4491, reward 171.0, memory_length 2000, epsilon 0.10587458984209462\n",
      "travel time- 720.0\n",
      "--- 1.4679985046386719 seconds ---\n",
      "episode 4492, reward -225.0, memory_length 2000, epsilon 0.10582166577929185\n",
      "travel time- 727.0\n",
      "--- 1.645430564880371 seconds ---\n",
      "episode 4493, reward 13.0, memory_length 2000, epsilon 0.10576876817190606\n",
      "travel time- 720.0\n",
      "--- 1.690765380859375 seconds ---\n",
      "episode 4494, reward 214.0, memory_length 2000, epsilon 0.10571589700671291\n",
      "travel time- 724.0\n",
      "--- 1.695758581161499 seconds ---\n",
      "episode 4495, reward -98.0, memory_length 2000, epsilon 0.10566305227049452\n",
      "travel time- 730.0\n",
      "--- 1.7704174518585205 seconds ---\n",
      "episode 4496, reward -194.0, memory_length 2000, epsilon 0.10561023395003975\n",
      "travel time- 721.0\n",
      "--- 1.7660551071166992 seconds ---\n",
      "episode 4497, reward -74.0, memory_length 2000, epsilon 0.10555744203214408\n",
      "travel time- 721.0\n",
      "--- 1.6689746379852295 seconds ---\n",
      "episode 4498, reward 186.0, memory_length 2000, epsilon 0.1055046765036094\n",
      "travel time- 732.0\n",
      "--- 1.6142098903656006 seconds ---\n",
      "episode 4499, reward 89.0, memory_length 2000, epsilon 0.10545193735124445\n",
      "travel time- 722.0\n",
      "--- 1.6719965934753418 seconds ---\n",
      "episode 4500, reward 203.0, memory_length 2000, epsilon 0.10539922456186433\n",
      "travel time- 722.0\n",
      "--- 1.8106541633605957 seconds ---\n",
      "episode 4501, reward 70.0, memory_length 2000, epsilon 0.10534653812229092\n",
      "travel time- 724.0\n",
      "--- 1.6411752700805664 seconds ---\n",
      "episode 4502, reward 47.0, memory_length 2000, epsilon 0.10529387801935262\n",
      "travel time- 725.0\n",
      "--- 1.5376091003417969 seconds ---\n",
      "episode 4503, reward -181.0, memory_length 2000, epsilon 0.10524124423988433\n",
      "travel time- 726.0\n",
      "--- 1.6589910984039307 seconds ---\n",
      "episode 4504, reward -343.0, memory_length 2000, epsilon 0.10518863677072765\n",
      "travel time- 726.0\n",
      "--- 1.7322266101837158 seconds ---\n",
      "episode 4505, reward 152.0, memory_length 2000, epsilon 0.10513605559873075\n",
      "travel time- 720.0\n",
      "--- 1.6585297584533691 seconds ---\n",
      "episode 4506, reward 47.0, memory_length 2000, epsilon 0.10508350071074826\n",
      "travel time- 720.0\n",
      "--- 1.5173041820526123 seconds ---\n",
      "episode 4507, reward 29.0, memory_length 2000, epsilon 0.10503097209364154\n",
      "travel time- 726.0\n",
      "--- 1.5948307514190674 seconds ---\n",
      "episode 4508, reward -340.0, memory_length 2000, epsilon 0.10497846973427834\n",
      "travel time- 732.0\n",
      "--- 1.7237155437469482 seconds ---\n",
      "episode 4509, reward -365.0, memory_length 2000, epsilon 0.10492599361953311\n",
      "travel time- 727.0\n",
      "--- 1.778351068496704 seconds ---\n",
      "episode 4510, reward -28.0, memory_length 2000, epsilon 0.1048735437362869\n",
      "travel time- 731.0\n",
      "--- 1.7002146244049072 seconds ---\n",
      "episode 4511, reward -230.0, memory_length 2000, epsilon 0.10482112007142712\n",
      "travel time- 726.0\n",
      "--- 1.959366798400879 seconds ---\n",
      "episode 4512, reward -177.0, memory_length 2000, epsilon 0.10476872261184789\n",
      "travel time- 728.0\n",
      "--- 1.8030223846435547 seconds ---\n",
      "episode 4513, reward 156.0, memory_length 2000, epsilon 0.10471635134444991\n",
      "travel time- 722.0\n",
      "--- 1.754490613937378 seconds ---\n",
      "episode 4514, reward -122.0, memory_length 2000, epsilon 0.10466400625614027\n",
      "travel time- 726.0\n",
      "--- 1.7340424060821533 seconds ---\n",
      "episode 4515, reward -256.0, memory_length 2000, epsilon 0.10461168733383279\n",
      "travel time- 733.0\n",
      "--- 1.8755953311920166 seconds ---\n",
      "episode 4516, reward 403.0, memory_length 2000, epsilon 0.10455939456444763\n",
      "travel time- 731.0\n",
      "--- 1.513578176498413 seconds ---\n",
      "episode 4517, reward -105.0, memory_length 2000, epsilon 0.10450712793491167\n",
      "travel time- 733.0\n",
      "--- 1.6395699977874756 seconds ---\n",
      "episode 4518, reward 38.0, memory_length 2000, epsilon 0.10445488743215826\n",
      "travel time- 720.0\n",
      "--- 1.6483139991760254 seconds ---\n",
      "episode 4519, reward 0.0, memory_length 2000, epsilon 0.10440267304312723\n",
      "travel time- 731.0\n",
      "--- 1.7520883083343506 seconds ---\n",
      "episode 4520, reward 514.0, memory_length 2000, epsilon 0.104350484754765\n",
      "travel time- 724.0\n",
      "--- 1.4849340915679932 seconds ---\n",
      "episode 4521, reward -27.0, memory_length 2000, epsilon 0.10429832255402453\n",
      "travel time- 723.0\n",
      "--- 1.7644801139831543 seconds ---\n",
      "episode 4522, reward 82.0, memory_length 2000, epsilon 0.10424618642786522\n",
      "travel time- 724.0\n",
      "--- 1.725644588470459 seconds ---\n",
      "episode 4523, reward 109.0, memory_length 2000, epsilon 0.10419407636325309\n",
      "travel time- 725.0\n",
      "--- 1.7375948429107666 seconds ---\n",
      "episode 4524, reward -78.0, memory_length 2000, epsilon 0.10414199234716055\n",
      "travel time- 725.0\n",
      "--- 1.642669916152954 seconds ---\n",
      "episode 4525, reward -85.0, memory_length 2000, epsilon 0.10408993436656665\n",
      "travel time- 720.0\n",
      "--- 1.6258561611175537 seconds ---\n",
      "episode 4526, reward 157.0, memory_length 2000, epsilon 0.10403790240845692\n",
      "travel time- 721.0\n",
      "--- 1.7406821250915527 seconds ---\n",
      "episode 4527, reward -91.0, memory_length 2000, epsilon 0.10398589645982328\n",
      "travel time- 721.0\n",
      "--- 1.5859565734863281 seconds ---\n",
      "episode 4528, reward -149.0, memory_length 2000, epsilon 0.10393391650766431\n",
      "travel time- 731.0\n",
      "--- 1.8356597423553467 seconds ---\n",
      "episode 4529, reward 315.0, memory_length 2000, epsilon 0.10388196253898506\n",
      "travel time- 724.0\n",
      "--- 1.567307472229004 seconds ---\n",
      "episode 4530, reward -32.0, memory_length 2000, epsilon 0.10383003454079692\n",
      "travel time- 722.0\n",
      "--- 1.7414793968200684 seconds ---\n",
      "episode 4531, reward 393.0, memory_length 2000, epsilon 0.10377813250011803\n",
      "travel time- 725.0\n",
      "--- 1.5453932285308838 seconds ---\n",
      "episode 4532, reward 25.0, memory_length 2000, epsilon 0.10372625640397273\n",
      "travel time- 722.0\n",
      "--- 1.6553680896759033 seconds ---\n",
      "episode 4533, reward -178.0, memory_length 2000, epsilon 0.10367440623939209\n",
      "travel time- 726.0\n",
      "--- 1.4250471591949463 seconds ---\n",
      "episode 4534, reward -107.0, memory_length 2000, epsilon 0.10362258199341358\n",
      "travel time- 723.0\n",
      "--- 1.6933839321136475 seconds ---\n",
      "episode 4535, reward -254.0, memory_length 2000, epsilon 0.10357078365308107\n",
      "travel time- 722.0\n",
      "--- 1.8445959091186523 seconds ---\n",
      "episode 4536, reward 361.0, memory_length 2000, epsilon 0.10351901120544502\n",
      "travel time- 723.0\n",
      "--- 1.6684579849243164 seconds ---\n",
      "episode 4537, reward -343.0, memory_length 2000, epsilon 0.10346726463756235\n",
      "travel time- 722.0\n",
      "--- 1.6541905403137207 seconds ---\n",
      "episode 4538, reward -118.0, memory_length 2000, epsilon 0.10341554393649634\n",
      "travel time- 724.0\n",
      "--- 1.6913299560546875 seconds ---\n",
      "episode 4539, reward 25.0, memory_length 2000, epsilon 0.10336384908931688\n",
      "travel time- 722.0\n",
      "--- 1.738675832748413 seconds ---\n",
      "episode 4540, reward 77.0, memory_length 2000, epsilon 0.1033121800831002\n",
      "travel time- 722.0\n",
      "--- 1.6775484085083008 seconds ---\n",
      "episode 4541, reward 70.0, memory_length 2000, epsilon 0.10326053690492908\n",
      "travel time- 726.0\n",
      "--- 1.683788537979126 seconds ---\n",
      "episode 4542, reward -260.0, memory_length 2000, epsilon 0.10320891954189276\n",
      "travel time- 720.0\n",
      "--- 1.801375389099121 seconds ---\n",
      "episode 4543, reward -52.0, memory_length 2000, epsilon 0.10315732798108682\n",
      "travel time- 724.0\n",
      "--- 1.6395783424377441 seconds ---\n",
      "episode 4544, reward -68.0, memory_length 2000, epsilon 0.10310576220961341\n",
      "travel time- 721.0\n",
      "--- 1.9285180568695068 seconds ---\n",
      "episode 4545, reward 80.0, memory_length 2000, epsilon 0.10305422221458115\n",
      "travel time- 729.0\n",
      "--- 1.6209969520568848 seconds ---\n",
      "episode 4546, reward 161.0, memory_length 2000, epsilon 0.10300270798310492\n",
      "travel time- 720.0\n",
      "--- 1.6853938102722168 seconds ---\n",
      "episode 4547, reward 167.0, memory_length 2000, epsilon 0.10295121950230628\n",
      "travel time- 720.0\n",
      "--- 1.4611129760742188 seconds ---\n",
      "episode 4548, reward 153.0, memory_length 2000, epsilon 0.102899756759313\n",
      "travel time- 721.0\n",
      "--- 1.5301055908203125 seconds ---\n",
      "episode 4549, reward -163.0, memory_length 2000, epsilon 0.10284831974125944\n",
      "travel time- 721.0\n",
      "--- 1.8626768589019775 seconds ---\n",
      "episode 4550, reward 2.0, memory_length 2000, epsilon 0.1027969084352864\n",
      "travel time- 721.0\n",
      "--- 1.575199842453003 seconds ---\n",
      "episode 4551, reward -9.0, memory_length 2000, epsilon 0.10274552282854095\n",
      "travel time- 723.0\n",
      "--- 1.7224011421203613 seconds ---\n",
      "episode 4552, reward -159.0, memory_length 2000, epsilon 0.10269416290817676\n",
      "travel time- 736.0\n",
      "--- 1.5557880401611328 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4553, reward -417.0, memory_length 2000, epsilon 0.10264282866135387\n",
      "travel time- 729.0\n",
      "--- 1.8372869491577148 seconds ---\n",
      "episode 4554, reward 199.0, memory_length 2000, epsilon 0.10259152007523863\n",
      "travel time- 729.0\n",
      "--- 1.675288438796997 seconds ---\n",
      "episode 4555, reward 53.0, memory_length 2000, epsilon 0.102540237137004\n",
      "travel time- 720.0\n",
      "--- 1.3134925365447998 seconds ---\n",
      "episode 4556, reward -181.0, memory_length 2000, epsilon 0.10248897983382912\n",
      "travel time- 722.0\n",
      "--- 1.6646952629089355 seconds ---\n",
      "episode 4557, reward -208.0, memory_length 2000, epsilon 0.10243774815289976\n",
      "travel time- 728.0\n",
      "--- 1.7879211902618408 seconds ---\n",
      "episode 4558, reward -276.0, memory_length 2000, epsilon 0.102386542081408\n",
      "travel time- 724.0\n",
      "--- 1.704082727432251 seconds ---\n",
      "episode 4559, reward 121.0, memory_length 2000, epsilon 0.10233536160655225\n",
      "travel time- 727.0\n",
      "--- 1.6710593700408936 seconds ---\n",
      "episode 4560, reward -51.0, memory_length 2000, epsilon 0.10228420671553744\n",
      "travel time- 724.0\n",
      "--- 1.745537281036377 seconds ---\n",
      "episode 4561, reward 125.0, memory_length 2000, epsilon 0.10223307739557488\n",
      "travel time- 722.0\n",
      "--- 1.6768829822540283 seconds ---\n",
      "episode 4562, reward 275.0, memory_length 2000, epsilon 0.10218197363388216\n",
      "travel time- 721.0\n",
      "--- 1.7498393058776855 seconds ---\n",
      "episode 4563, reward -85.0, memory_length 2000, epsilon 0.10213089541768343\n",
      "travel time- 722.0\n",
      "--- 1.6819958686828613 seconds ---\n",
      "episode 4564, reward -295.0, memory_length 2000, epsilon 0.10207984273420903\n",
      "travel time- 724.0\n",
      "--- 1.822458028793335 seconds ---\n",
      "episode 4565, reward 126.0, memory_length 2000, epsilon 0.10202881557069586\n",
      "travel time- 725.0\n",
      "--- 1.5982084274291992 seconds ---\n",
      "episode 4566, reward 174.0, memory_length 2000, epsilon 0.10197781391438715\n",
      "travel time- 721.0\n",
      "--- 1.5325884819030762 seconds ---\n",
      "episode 4567, reward 419.0, memory_length 2000, epsilon 0.1019268377525324\n",
      "travel time- 720.0\n",
      "--- 1.6852126121520996 seconds ---\n",
      "episode 4568, reward -59.0, memory_length 2000, epsilon 0.10187588707238764\n",
      "travel time- 720.0\n",
      "--- 1.6124844551086426 seconds ---\n",
      "episode 4569, reward -106.0, memory_length 2000, epsilon 0.1018249618612152\n",
      "travel time- 732.0\n",
      "--- 1.636746883392334 seconds ---\n",
      "episode 4570, reward -144.0, memory_length 2000, epsilon 0.10177406210628372\n",
      "travel time- 723.0\n",
      "--- 1.682102918624878 seconds ---\n",
      "episode 4571, reward 3.0, memory_length 2000, epsilon 0.10172318779486834\n",
      "travel time- 722.0\n",
      "--- 1.8600072860717773 seconds ---\n",
      "episode 4572, reward 197.0, memory_length 2000, epsilon 0.1016723389142504\n",
      "travel time- 738.0\n",
      "--- 1.6367645263671875 seconds ---\n",
      "episode 4573, reward -227.0, memory_length 2000, epsilon 0.10162151545171771\n",
      "travel time- 724.0\n",
      "--- 1.6036076545715332 seconds ---\n",
      "episode 4574, reward -71.0, memory_length 2000, epsilon 0.10157071739456447\n",
      "travel time- 720.0\n",
      "--- 1.7624423503875732 seconds ---\n",
      "episode 4575, reward -11.0, memory_length 2000, epsilon 0.10151994473009104\n",
      "travel time- 722.0\n",
      "--- 1.8547825813293457 seconds ---\n",
      "episode 4576, reward -206.0, memory_length 2000, epsilon 0.10146919744560434\n",
      "travel time- 726.0\n",
      "--- 1.6614315509796143 seconds ---\n",
      "episode 4577, reward 169.0, memory_length 2000, epsilon 0.10141847552841757\n",
      "travel time- 720.0\n",
      "--- 1.7691371440887451 seconds ---\n",
      "episode 4578, reward 187.0, memory_length 2000, epsilon 0.10136777896585017\n",
      "travel time- 720.0\n",
      "--- 1.5596013069152832 seconds ---\n",
      "episode 4579, reward -43.0, memory_length 2000, epsilon 0.10131710774522808\n",
      "travel time- 722.0\n",
      "--- 1.693854570388794 seconds ---\n",
      "episode 4580, reward -26.0, memory_length 2000, epsilon 0.1012664618538834\n",
      "travel time- 726.0\n",
      "--- 1.5746443271636963 seconds ---\n",
      "episode 4581, reward 115.0, memory_length 2000, epsilon 0.10121584127915471\n",
      "travel time- 720.0\n",
      "--- 1.6143298149108887 seconds ---\n",
      "episode 4582, reward -432.0, memory_length 2000, epsilon 0.10116524600838693\n",
      "travel time- 732.0\n",
      "--- 1.6429393291473389 seconds ---\n",
      "episode 4583, reward 111.0, memory_length 2000, epsilon 0.10111467602893112\n",
      "travel time- 726.0\n",
      "--- 1.613036870956421 seconds ---\n",
      "episode 4584, reward -63.0, memory_length 2000, epsilon 0.10106413132814486\n",
      "travel time- 722.0\n",
      "--- 1.5534813404083252 seconds ---\n",
      "episode 4585, reward 145.0, memory_length 2000, epsilon 0.10101361189339199\n",
      "travel time- 732.0\n",
      "--- 1.5476632118225098 seconds ---\n",
      "episode 4586, reward -129.0, memory_length 2000, epsilon 0.10096311771204257\n",
      "travel time- 724.0\n",
      "--- 1.5635666847229004 seconds ---\n",
      "episode 4587, reward -83.0, memory_length 2000, epsilon 0.10091264877147316\n",
      "travel time- 733.0\n",
      "--- 1.6442701816558838 seconds ---\n",
      "episode 4588, reward 44.0, memory_length 2000, epsilon 0.10086220505906641\n",
      "travel time- 725.0\n",
      "--- 1.699782371520996 seconds ---\n",
      "episode 4589, reward 39.0, memory_length 2000, epsilon 0.10081178656221147\n",
      "travel time- 726.0\n",
      "--- 1.614903211593628 seconds ---\n",
      "episode 4590, reward 47.0, memory_length 2000, epsilon 0.10076139326830373\n",
      "travel time- 732.0\n",
      "--- 1.4921205043792725 seconds ---\n",
      "episode 4591, reward 231.0, memory_length 2000, epsilon 0.10071102516474478\n",
      "travel time- 723.0\n",
      "--- 1.4382703304290771 seconds ---\n",
      "episode 4592, reward -166.0, memory_length 2000, epsilon 0.10066068223894266\n",
      "travel time- 720.0\n",
      "--- 1.6787233352661133 seconds ---\n",
      "episode 4593, reward 6.0, memory_length 2000, epsilon 0.10061036447831166\n",
      "travel time- 732.0\n",
      "--- 1.5774493217468262 seconds ---\n",
      "episode 4594, reward -56.0, memory_length 2000, epsilon 0.10056007187027226\n",
      "travel time- 724.0\n",
      "--- 1.7003138065338135 seconds ---\n",
      "episode 4595, reward 20.0, memory_length 2000, epsilon 0.1005098044022514\n",
      "travel time- 725.0\n",
      "--- 1.5632548332214355 seconds ---\n",
      "episode 4596, reward 184.0, memory_length 2000, epsilon 0.1004595620616821\n",
      "travel time- 720.0\n",
      "--- 1.5570292472839355 seconds ---\n",
      "episode 4597, reward 70.0, memory_length 2000, epsilon 0.10040934483600386\n",
      "travel time- 726.0\n",
      "--- 1.670551061630249 seconds ---\n",
      "episode 4598, reward -48.0, memory_length 2000, epsilon 0.1003591527126624\n",
      "travel time- 728.0\n",
      "--- 1.729163646697998 seconds ---\n",
      "episode 4599, reward -239.0, memory_length 2000, epsilon 0.10030898567910958\n",
      "travel time- 736.0\n",
      "--- 1.695451021194458 seconds ---\n",
      "episode 4600, reward 169.0, memory_length 2000, epsilon 0.1002588437228037\n",
      "travel time- 723.0\n",
      "--- 1.5273704528808594 seconds ---\n",
      "episode 4601, reward 222.0, memory_length 2000, epsilon 0.10020872683120934\n",
      "travel time- 720.0\n",
      "--- 1.6096549034118652 seconds ---\n",
      "episode 4602, reward -166.0, memory_length 2000, epsilon 0.10015863499179714\n",
      "travel time- 723.0\n",
      "--- 1.7880370616912842 seconds ---\n",
      "episode 4603, reward -37.0, memory_length 2000, epsilon 0.10010856819204426\n",
      "travel time- 725.0\n",
      "--- 1.6152098178863525 seconds ---\n",
      "episode 4604, reward 82.0, memory_length 2000, epsilon 0.10005852641943393\n",
      "travel time- 725.0\n",
      "--- 1.8286142349243164 seconds ---\n",
      "episode 4605, reward 15.0, memory_length 2000, epsilon 0.10000850966145569\n",
      "travel time- 726.0\n",
      "--- 1.4912488460540771 seconds ---\n",
      "episode 4606, reward -323.0, memory_length 2000, epsilon 0.09995851790560546\n",
      "travel time- 725.0\n",
      "--- 1.6166694164276123 seconds ---\n",
      "episode 4607, reward -238.0, memory_length 2000, epsilon 0.09990855113938517\n",
      "travel time- 722.0\n",
      "--- 1.6440434455871582 seconds ---\n",
      "episode 4608, reward 181.0, memory_length 2000, epsilon 0.09985860935030318\n",
      "travel time- 728.0\n",
      "--- 1.52555251121521 seconds ---\n",
      "episode 4609, reward -6.0, memory_length 2000, epsilon 0.0998086925258741\n",
      "travel time- 724.0\n",
      "--- 1.7081325054168701 seconds ---\n",
      "episode 4610, reward 97.0, memory_length 2000, epsilon 0.09975880065361863\n",
      "travel time- 726.0\n",
      "--- 1.725114345550537 seconds ---\n",
      "episode 4611, reward -27.0, memory_length 2000, epsilon 0.09970893372106387\n",
      "travel time- 726.0\n",
      "--- 1.557640790939331 seconds ---\n",
      "episode 4612, reward -307.0, memory_length 2000, epsilon 0.09965909171574303\n",
      "travel time- 724.0\n",
      "--- 1.8458666801452637 seconds ---\n",
      "episode 4613, reward -307.0, memory_length 2000, epsilon 0.09960927462519563\n",
      "travel time- 720.0\n",
      "--- 1.866518259048462 seconds ---\n",
      "episode 4614, reward -103.0, memory_length 2000, epsilon 0.09955948243696745\n",
      "travel time- 727.0\n",
      "--- 1.8069217205047607 seconds ---\n",
      "episode 4615, reward -41.0, memory_length 2000, epsilon 0.09950971513861037\n",
      "travel time- 720.0\n",
      "--- 1.5375936031341553 seconds ---\n",
      "episode 4616, reward -46.0, memory_length 2000, epsilon 0.09945997271768262\n",
      "travel time- 727.0\n",
      "--- 1.5836589336395264 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4617, reward 42.0, memory_length 2000, epsilon 0.09941025516174853\n",
      "travel time- 725.0\n",
      "--- 1.5547833442687988 seconds ---\n",
      "episode 4618, reward -148.0, memory_length 2000, epsilon 0.09936056245837875\n",
      "travel time- 728.0\n",
      "--- 1.8276987075805664 seconds ---\n",
      "episode 4619, reward 152.0, memory_length 2000, epsilon 0.09931089459515013\n",
      "travel time- 723.0\n",
      "--- 1.6271016597747803 seconds ---\n",
      "episode 4620, reward -186.0, memory_length 2000, epsilon 0.09926125155964566\n",
      "travel time- 735.0\n",
      "--- 1.7785255908966064 seconds ---\n",
      "episode 4621, reward 79.0, memory_length 2000, epsilon 0.09921163333945457\n",
      "travel time- 729.0\n",
      "--- 1.6020386219024658 seconds ---\n",
      "episode 4622, reward 58.0, memory_length 2000, epsilon 0.09916203992217239\n",
      "travel time- 720.0\n",
      "--- 1.7063195705413818 seconds ---\n",
      "episode 4623, reward -45.0, memory_length 2000, epsilon 0.09911247129540066\n",
      "travel time- 725.0\n",
      "--- 1.6607403755187988 seconds ---\n",
      "episode 4624, reward 46.0, memory_length 2000, epsilon 0.09906292744674731\n",
      "travel time- 727.0\n",
      "--- 1.7892439365386963 seconds ---\n",
      "episode 4625, reward -497.0, memory_length 2000, epsilon 0.0990134083638263\n",
      "travel time- 722.0\n",
      "--- 2.0364725589752197 seconds ---\n",
      "episode 4626, reward 7.0, memory_length 2000, epsilon 0.0989639140342579\n",
      "travel time- 721.0\n",
      "--- 1.960155725479126 seconds ---\n",
      "episode 4627, reward -85.0, memory_length 2000, epsilon 0.09891444444566856\n",
      "travel time- 722.0\n",
      "--- 1.8732855319976807 seconds ---\n",
      "episode 4628, reward 19.0, memory_length 2000, epsilon 0.09886499958569081\n",
      "travel time- 733.0\n",
      "--- 1.7476909160614014 seconds ---\n",
      "episode 4629, reward -220.0, memory_length 2000, epsilon 0.09881557944196347\n",
      "travel time- 722.0\n",
      "--- 1.7118618488311768 seconds ---\n",
      "episode 4630, reward -75.0, memory_length 2000, epsilon 0.09876618400213154\n",
      "travel time- 733.0\n",
      "--- 1.8275861740112305 seconds ---\n",
      "episode 4631, reward -116.0, memory_length 2000, epsilon 0.09871681325384608\n",
      "travel time- 734.0\n",
      "--- 1.6879701614379883 seconds ---\n",
      "episode 4632, reward -184.0, memory_length 2000, epsilon 0.0986674671847645\n",
      "travel time- 725.0\n",
      "--- 1.551002025604248 seconds ---\n",
      "episode 4633, reward 267.0, memory_length 2000, epsilon 0.09861814578255018\n",
      "travel time- 730.0\n",
      "--- 1.7194218635559082 seconds ---\n",
      "episode 4634, reward -209.0, memory_length 2000, epsilon 0.09856884903487283\n",
      "travel time- 731.0\n",
      "--- 1.5380287170410156 seconds ---\n",
      "episode 4635, reward -39.0, memory_length 2000, epsilon 0.09851957692940828\n",
      "travel time- 720.0\n",
      "--- 1.6806330680847168 seconds ---\n",
      "episode 4636, reward 43.0, memory_length 2000, epsilon 0.09847032945383845\n",
      "travel time- 723.0\n",
      "--- 1.6645312309265137 seconds ---\n",
      "episode 4637, reward 163.0, memory_length 2000, epsilon 0.09842110659585149\n",
      "travel time- 723.0\n",
      "--- 1.5425968170166016 seconds ---\n",
      "episode 4638, reward -70.0, memory_length 2000, epsilon 0.09837190834314173\n",
      "travel time- 727.0\n",
      "--- 1.766348123550415 seconds ---\n",
      "episode 4639, reward -45.0, memory_length 2000, epsilon 0.09832273468340952\n",
      "travel time- 724.0\n",
      "--- 1.589038372039795 seconds ---\n",
      "episode 4640, reward 376.0, memory_length 2000, epsilon 0.09827358560436154\n",
      "travel time- 720.0\n",
      "--- 1.7546775341033936 seconds ---\n",
      "episode 4641, reward 189.0, memory_length 2000, epsilon 0.09822446109371044\n",
      "travel time- 729.0\n",
      "--- 1.840118646621704 seconds ---\n",
      "episode 4642, reward -128.0, memory_length 2000, epsilon 0.09817536113917512\n",
      "travel time- 727.0\n",
      "--- 1.6213572025299072 seconds ---\n",
      "episode 4643, reward 102.0, memory_length 2000, epsilon 0.09812628572848063\n",
      "travel time- 720.0\n",
      "--- 1.7761971950531006 seconds ---\n",
      "episode 4644, reward 25.0, memory_length 2000, epsilon 0.09807723484935806\n",
      "travel time- 720.0\n",
      "--- 1.6247296333312988 seconds ---\n",
      "episode 4645, reward 509.0, memory_length 2000, epsilon 0.09802820848954469\n",
      "travel time- 722.0\n",
      "--- 1.5868396759033203 seconds ---\n",
      "episode 4646, reward 8.0, memory_length 2000, epsilon 0.09797920663678401\n",
      "travel time- 720.0\n",
      "--- 1.667038917541504 seconds ---\n",
      "episode 4647, reward 97.0, memory_length 2000, epsilon 0.09793022927882546\n",
      "travel time- 725.0\n",
      "--- 1.802427053451538 seconds ---\n",
      "episode 4648, reward -53.0, memory_length 2000, epsilon 0.09788127640342477\n",
      "travel time- 723.0\n",
      "--- 1.5728225708007812 seconds ---\n",
      "episode 4649, reward -161.0, memory_length 2000, epsilon 0.09783234799834366\n",
      "travel time- 727.0\n",
      "--- 1.4844255447387695 seconds ---\n",
      "episode 4650, reward -140.0, memory_length 2000, epsilon 0.09778344405135005\n",
      "travel time- 722.0\n",
      "--- 1.6999099254608154 seconds ---\n",
      "episode 4651, reward 468.0, memory_length 2000, epsilon 0.097734564550218\n",
      "travel time- 724.0\n",
      "--- 1.4085123538970947 seconds ---\n",
      "episode 4652, reward 465.0, memory_length 2000, epsilon 0.09768570948272756\n",
      "travel time- 721.0\n",
      "--- 1.7211239337921143 seconds ---\n",
      "episode 4653, reward -91.0, memory_length 2000, epsilon 0.09763687883666501\n",
      "travel time- 729.0\n",
      "--- 1.7829570770263672 seconds ---\n",
      "episode 4654, reward 220.0, memory_length 2000, epsilon 0.0975880725998227\n",
      "travel time- 723.0\n",
      "--- 1.5316009521484375 seconds ---\n",
      "episode 4655, reward -133.0, memory_length 2000, epsilon 0.09753929075999902\n",
      "travel time- 721.0\n",
      "--- 1.5193440914154053 seconds ---\n",
      "episode 4656, reward -169.0, memory_length 2000, epsilon 0.09749053330499859\n",
      "travel time- 722.0\n",
      "--- 1.6109960079193115 seconds ---\n",
      "episode 4657, reward -129.0, memory_length 2000, epsilon 0.09744180022263194\n",
      "travel time- 733.0\n",
      "--- 1.674814224243164 seconds ---\n",
      "episode 4658, reward 151.0, memory_length 2000, epsilon 0.09739309150071584\n",
      "travel time- 724.0\n",
      "--- 1.640746831893921 seconds ---\n",
      "episode 4659, reward 95.0, memory_length 2000, epsilon 0.09734440712707318\n",
      "travel time- 721.0\n",
      "--- 1.8029770851135254 seconds ---\n",
      "episode 4660, reward -22.0, memory_length 2000, epsilon 0.09729574708953276\n",
      "travel time- 732.0\n",
      "--- 1.6623427867889404 seconds ---\n",
      "episode 4661, reward -76.0, memory_length 2000, epsilon 0.09724711137592962\n",
      "travel time- 721.0\n",
      "--- 1.5004446506500244 seconds ---\n",
      "episode 4662, reward 83.0, memory_length 2000, epsilon 0.09719849997410487\n",
      "travel time- 726.0\n",
      "--- 1.62184476852417 seconds ---\n",
      "episode 4663, reward 95.0, memory_length 2000, epsilon 0.0971499128719056\n",
      "travel time- 722.0\n",
      "--- 1.4886789321899414 seconds ---\n",
      "episode 4664, reward -19.0, memory_length 2000, epsilon 0.09710135005718508\n",
      "travel time- 720.0\n",
      "--- 1.5540673732757568 seconds ---\n",
      "episode 4665, reward 115.0, memory_length 2000, epsilon 0.09705281151780253\n",
      "travel time- 722.0\n",
      "--- 1.6320247650146484 seconds ---\n",
      "episode 4666, reward -4.0, memory_length 2000, epsilon 0.09700429724162336\n",
      "travel time- 721.0\n",
      "--- 1.6822049617767334 seconds ---\n",
      "episode 4667, reward -297.0, memory_length 2000, epsilon 0.09695580721651907\n",
      "travel time- 724.0\n",
      "--- 1.8656773567199707 seconds ---\n",
      "episode 4668, reward 53.0, memory_length 2000, epsilon 0.09690734143036704\n",
      "travel time- 721.0\n",
      "--- 1.7777013778686523 seconds ---\n",
      "episode 4669, reward -297.0, memory_length 2000, epsilon 0.09685889987105087\n",
      "travel time- 729.0\n",
      "--- 1.7942166328430176 seconds ---\n",
      "episode 4670, reward -41.0, memory_length 2000, epsilon 0.09681048252646021\n",
      "travel time- 720.0\n",
      "--- 1.8596701622009277 seconds ---\n",
      "episode 4671, reward -288.0, memory_length 2000, epsilon 0.09676208938449064\n",
      "travel time- 722.0\n",
      "--- 1.8739335536956787 seconds ---\n",
      "episode 4672, reward -90.0, memory_length 2000, epsilon 0.09671372043304398\n",
      "travel time- 723.0\n",
      "--- 1.702118158340454 seconds ---\n",
      "episode 4673, reward 141.0, memory_length 2000, epsilon 0.09666537566002788\n",
      "travel time- 726.0\n",
      "--- 1.6473455429077148 seconds ---\n",
      "episode 4674, reward 123.0, memory_length 2000, epsilon 0.09661705505335619\n",
      "travel time- 721.0\n",
      "--- 1.6465044021606445 seconds ---\n",
      "episode 4675, reward -177.0, memory_length 2000, epsilon 0.09656875860094882\n",
      "travel time- 724.0\n",
      "--- 1.6338179111480713 seconds ---\n",
      "episode 4676, reward -49.0, memory_length 2000, epsilon 0.09652048629073155\n",
      "travel time- 725.0\n",
      "--- 1.5676994323730469 seconds ---\n",
      "episode 4677, reward -152.0, memory_length 2000, epsilon 0.09647223811063636\n",
      "travel time- 727.0\n",
      "--- 1.5970687866210938 seconds ---\n",
      "episode 4678, reward -110.0, memory_length 2000, epsilon 0.09642401404860125\n",
      "travel time- 726.0\n",
      "--- 1.4506182670593262 seconds ---\n",
      "episode 4679, reward 339.0, memory_length 2000, epsilon 0.09637581409257011\n",
      "travel time- 720.0\n",
      "--- 1.4498443603515625 seconds ---\n",
      "episode 4680, reward -143.0, memory_length 2000, epsilon 0.09632763823049303\n",
      "travel time- 722.0\n",
      "--- 1.6225249767303467 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4681, reward 196.0, memory_length 2000, epsilon 0.09627948645032597\n",
      "travel time- 726.0\n",
      "--- 1.6839637756347656 seconds ---\n",
      "episode 4682, reward 46.0, memory_length 2000, epsilon 0.09623135874003103\n",
      "travel time- 726.0\n",
      "--- 1.6188900470733643 seconds ---\n",
      "episode 4683, reward -37.0, memory_length 2000, epsilon 0.09618325508757632\n",
      "travel time- 721.0\n",
      "--- 1.6192996501922607 seconds ---\n",
      "episode 4684, reward 113.0, memory_length 2000, epsilon 0.09613517548093582\n",
      "travel time- 728.0\n",
      "--- 1.551156759262085 seconds ---\n",
      "episode 4685, reward 9.0, memory_length 2000, epsilon 0.09608711990808971\n",
      "travel time- 721.0\n",
      "--- 1.5682976245880127 seconds ---\n",
      "episode 4686, reward 62.0, memory_length 2000, epsilon 0.09603908835702411\n",
      "travel time- 720.0\n",
      "--- 1.7102017402648926 seconds ---\n",
      "episode 4687, reward -28.0, memory_length 2000, epsilon 0.09599108081573107\n",
      "travel time- 724.0\n",
      "--- 1.8995530605316162 seconds ---\n",
      "episode 4688, reward 29.0, memory_length 2000, epsilon 0.09594309727220877\n",
      "travel time- 723.0\n",
      "--- 1.7220487594604492 seconds ---\n",
      "episode 4689, reward -52.0, memory_length 2000, epsilon 0.09589513771446125\n",
      "travel time- 723.0\n",
      "--- 1.7300708293914795 seconds ---\n",
      "episode 4690, reward -160.0, memory_length 2000, epsilon 0.09584720213049865\n",
      "travel time- 730.0\n",
      "--- 1.7584049701690674 seconds ---\n",
      "episode 4691, reward 110.0, memory_length 2000, epsilon 0.09579929050833712\n",
      "travel time- 721.0\n",
      "--- 1.5829763412475586 seconds ---\n",
      "episode 4692, reward 25.0, memory_length 2000, epsilon 0.09575140283599869\n",
      "travel time- 728.0\n",
      "--- 1.483194351196289 seconds ---\n",
      "episode 4693, reward 204.0, memory_length 2000, epsilon 0.09570353910151146\n",
      "travel time- 720.0\n",
      "--- 1.5571520328521729 seconds ---\n",
      "episode 4694, reward 206.0, memory_length 2000, epsilon 0.09565569929290954\n",
      "travel time- 720.0\n",
      "--- 1.5438976287841797 seconds ---\n",
      "episode 4695, reward 101.0, memory_length 2000, epsilon 0.0956078833982329\n",
      "travel time- 723.0\n",
      "--- 1.6747198104858398 seconds ---\n",
      "episode 4696, reward 73.0, memory_length 2000, epsilon 0.09556009140552765\n",
      "travel time- 721.0\n",
      "--- 1.860332727432251 seconds ---\n",
      "episode 4697, reward -72.0, memory_length 2000, epsilon 0.0955123233028457\n",
      "travel time- 726.0\n",
      "--- 1.5256693363189697 seconds ---\n",
      "episode 4698, reward 20.0, memory_length 2000, epsilon 0.0954645790782451\n",
      "travel time- 725.0\n",
      "--- 1.685929775238037 seconds ---\n",
      "episode 4699, reward -83.0, memory_length 2000, epsilon 0.09541685871978979\n",
      "travel time- 730.0\n",
      "--- 1.8155086040496826 seconds ---\n",
      "episode 4700, reward -500.0, memory_length 2000, epsilon 0.09536916221554961\n",
      "travel time- 729.0\n",
      "--- 1.5249695777893066 seconds ---\n",
      "episode 4701, reward 76.0, memory_length 2000, epsilon 0.0953214895536005\n",
      "travel time- 724.0\n",
      "--- 1.6449635028839111 seconds ---\n",
      "episode 4702, reward -42.0, memory_length 2000, epsilon 0.09527384072202429\n",
      "travel time- 729.0\n",
      "--- 1.8907053470611572 seconds ---\n",
      "episode 4703, reward 12.0, memory_length 2000, epsilon 0.09522621570890873\n",
      "travel time- 725.0\n",
      "--- 1.4195208549499512 seconds ---\n",
      "episode 4704, reward -74.0, memory_length 2000, epsilon 0.09517861450234763\n",
      "travel time- 725.0\n",
      "--- 1.5893580913543701 seconds ---\n",
      "episode 4705, reward -5.0, memory_length 2000, epsilon 0.09513103709044061\n",
      "travel time- 721.0\n",
      "--- 1.761401891708374 seconds ---\n",
      "episode 4706, reward -257.0, memory_length 2000, epsilon 0.09508348346129337\n",
      "travel time- 729.0\n",
      "--- 1.5610411167144775 seconds ---\n",
      "episode 4707, reward 225.0, memory_length 2000, epsilon 0.09503595360301752\n",
      "travel time- 727.0\n",
      "--- 1.5329289436340332 seconds ---\n",
      "episode 4708, reward 42.0, memory_length 2000, epsilon 0.09498844750373053\n",
      "travel time- 720.0\n",
      "--- 1.578477382659912 seconds ---\n",
      "episode 4709, reward 76.0, memory_length 2000, epsilon 0.09494096515155591\n",
      "travel time- 720.0\n",
      "--- 1.5143187046051025 seconds ---\n",
      "episode 4710, reward -323.0, memory_length 2000, epsilon 0.09489350653462311\n",
      "travel time- 720.0\n",
      "--- 1.901207447052002 seconds ---\n",
      "episode 4711, reward 106.0, memory_length 2000, epsilon 0.0948460716410674\n",
      "travel time- 723.0\n",
      "--- 1.5602455139160156 seconds ---\n",
      "episode 4712, reward 113.0, memory_length 2000, epsilon 0.09479866045903014\n",
      "travel time- 720.0\n",
      "--- 1.615077257156372 seconds ---\n",
      "episode 4713, reward -56.0, memory_length 2000, epsilon 0.09475127297665843\n",
      "travel time- 722.0\n",
      "--- 1.5835654735565186 seconds ---\n",
      "episode 4714, reward -160.0, memory_length 2000, epsilon 0.09470390918210547\n",
      "travel time- 722.0\n",
      "--- 1.746840476989746 seconds ---\n",
      "episode 4715, reward -262.0, memory_length 2000, epsilon 0.09465656906353034\n",
      "travel time- 724.0\n",
      "--- 1.8716192245483398 seconds ---\n",
      "episode 4716, reward -146.0, memory_length 2000, epsilon 0.09460925260909793\n",
      "travel time- 725.0\n",
      "--- 1.7208819389343262 seconds ---\n",
      "episode 4717, reward -28.0, memory_length 2000, epsilon 0.09456195980697917\n",
      "travel time- 720.0\n",
      "--- 1.7903177738189697 seconds ---\n",
      "episode 4718, reward 309.0, memory_length 2000, epsilon 0.09451469064535088\n",
      "travel time- 727.0\n",
      "--- 1.5963575839996338 seconds ---\n",
      "episode 4719, reward -15.0, memory_length 2000, epsilon 0.09446744511239571\n",
      "travel time- 720.0\n",
      "--- 1.5197274684906006 seconds ---\n",
      "episode 4720, reward -174.0, memory_length 2000, epsilon 0.09442022319630235\n",
      "travel time- 721.0\n",
      "--- 1.8023779392242432 seconds ---\n",
      "episode 4721, reward -177.0, memory_length 2000, epsilon 0.09437302488526524\n",
      "travel time- 732.0\n",
      "--- 1.895049810409546 seconds ---\n",
      "episode 4722, reward 119.0, memory_length 2000, epsilon 0.09432585016748485\n",
      "travel time- 720.0\n",
      "--- 1.68845534324646 seconds ---\n",
      "episode 4723, reward 38.0, memory_length 2000, epsilon 0.09427869903116752\n",
      "travel time- 733.0\n",
      "--- 1.838350534439087 seconds ---\n",
      "episode 4724, reward -14.0, memory_length 2000, epsilon 0.0942315714645254\n",
      "travel time- 720.0\n",
      "--- 1.7558467388153076 seconds ---\n",
      "episode 4725, reward -11.0, memory_length 2000, epsilon 0.09418446745577665\n",
      "travel time- 721.0\n",
      "--- 1.5865325927734375 seconds ---\n",
      "episode 4726, reward 3.0, memory_length 2000, epsilon 0.09413738699314529\n",
      "travel time- 723.0\n",
      "--- 1.688047170639038 seconds ---\n",
      "episode 4727, reward -12.0, memory_length 2000, epsilon 0.09409033006486113\n",
      "travel time- 720.0\n",
      "--- 1.7054407596588135 seconds ---\n",
      "episode 4728, reward 107.0, memory_length 2000, epsilon 0.09404329665916\n",
      "travel time- 720.0\n",
      "--- 1.8618874549865723 seconds ---\n",
      "episode 4729, reward 104.0, memory_length 2000, epsilon 0.09399628676428351\n",
      "travel time- 729.0\n",
      "--- 1.704955816268921 seconds ---\n",
      "episode 4730, reward 71.0, memory_length 2000, epsilon 0.09394930036847918\n",
      "travel time- 724.0\n",
      "--- 1.5402917861938477 seconds ---\n",
      "episode 4731, reward -193.0, memory_length 2000, epsilon 0.09390233746000048\n",
      "travel time- 720.0\n",
      "--- 1.7074716091156006 seconds ---\n",
      "episode 4732, reward -35.0, memory_length 2000, epsilon 0.09385539802710659\n",
      "travel time- 725.0\n",
      "--- 1.7725193500518799 seconds ---\n",
      "episode 4733, reward -151.0, memory_length 2000, epsilon 0.0938084820580627\n",
      "travel time- 727.0\n",
      "--- 1.7319073677062988 seconds ---\n",
      "episode 4734, reward -73.0, memory_length 2000, epsilon 0.09376158954113986\n",
      "travel time- 723.0\n",
      "--- 1.7815394401550293 seconds ---\n",
      "episode 4735, reward -174.0, memory_length 2000, epsilon 0.09371472046461483\n",
      "travel time- 723.0\n",
      "--- 1.7098431587219238 seconds ---\n",
      "episode 4736, reward -131.0, memory_length 2000, epsilon 0.09366787481677047\n",
      "travel time- 727.0\n",
      "--- 1.6054410934448242 seconds ---\n",
      "episode 4737, reward 6.0, memory_length 2000, epsilon 0.09362105258589525\n",
      "travel time- 727.0\n",
      "--- 1.554140567779541 seconds ---\n",
      "episode 4738, reward 60.0, memory_length 2000, epsilon 0.09357425376028367\n",
      "travel time- 720.0\n",
      "--- 1.7853400707244873 seconds ---\n",
      "episode 4739, reward -239.0, memory_length 2000, epsilon 0.09352747832823605\n",
      "travel time- 721.0\n",
      "--- 1.797875165939331 seconds ---\n",
      "episode 4740, reward 12.0, memory_length 2000, epsilon 0.09348072627805847\n",
      "travel time- 721.0\n",
      "--- 1.5765831470489502 seconds ---\n",
      "episode 4741, reward 99.0, memory_length 2000, epsilon 0.09343399759806298\n",
      "travel time- 723.0\n",
      "--- 1.619455099105835 seconds ---\n",
      "episode 4742, reward 295.0, memory_length 2000, epsilon 0.09338729227656732\n",
      "travel time- 723.0\n",
      "--- 1.6421620845794678 seconds ---\n",
      "episode 4743, reward -170.0, memory_length 2000, epsilon 0.09334061030189524\n",
      "travel time- 724.0\n",
      "--- 1.77988862991333 seconds ---\n",
      "episode 4744, reward -46.0, memory_length 2000, epsilon 0.09329395166237625\n",
      "travel time- 722.0\n",
      "--- 1.4122347831726074 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4745, reward 80.0, memory_length 2000, epsilon 0.09324731634634563\n",
      "travel time- 723.0\n",
      "--- 1.7683384418487549 seconds ---\n",
      "episode 4746, reward 201.0, memory_length 2000, epsilon 0.09320070434214457\n",
      "travel time- 724.0\n",
      "--- 1.6271798610687256 seconds ---\n",
      "episode 4747, reward -141.0, memory_length 2000, epsilon 0.09315411563812012\n",
      "travel time- 720.0\n",
      "--- 1.7210428714752197 seconds ---\n",
      "episode 4748, reward 345.0, memory_length 2000, epsilon 0.09310755022262504\n",
      "travel time- 734.0\n",
      "--- 1.6857943534851074 seconds ---\n",
      "episode 4749, reward -131.0, memory_length 2000, epsilon 0.09306100808401803\n",
      "travel time- 725.0\n",
      "--- 1.6965646743774414 seconds ---\n",
      "episode 4750, reward 195.0, memory_length 2000, epsilon 0.09301448921066349\n",
      "travel time- 734.0\n",
      "--- 1.5994691848754883 seconds ---\n",
      "episode 4751, reward 192.0, memory_length 2000, epsilon 0.09296799359093173\n",
      "travel time- 724.0\n",
      "--- 1.5950431823730469 seconds ---\n",
      "episode 4752, reward 22.0, memory_length 2000, epsilon 0.0929215212131989\n",
      "travel time- 726.0\n",
      "--- 1.722402572631836 seconds ---\n",
      "episode 4753, reward 383.0, memory_length 2000, epsilon 0.09287507206584682\n",
      "travel time- 730.0\n",
      "--- 1.7061736583709717 seconds ---\n",
      "episode 4754, reward 18.0, memory_length 2000, epsilon 0.09282864613726323\n",
      "travel time- 730.0\n",
      "--- 1.6788966655731201 seconds ---\n",
      "episode 4755, reward -335.0, memory_length 2000, epsilon 0.0927822434158417\n",
      "travel time- 721.0\n",
      "--- 1.9425323009490967 seconds ---\n",
      "episode 4756, reward 17.0, memory_length 2000, epsilon 0.09273586388998147\n",
      "travel time- 728.0\n",
      "--- 1.5623672008514404 seconds ---\n",
      "episode 4757, reward 50.0, memory_length 2000, epsilon 0.09268950754808773\n",
      "travel time- 721.0\n",
      "--- 1.6498816013336182 seconds ---\n",
      "episode 4758, reward 252.0, memory_length 2000, epsilon 0.09264317437857132\n",
      "travel time- 726.0\n",
      "--- 1.6554782390594482 seconds ---\n",
      "episode 4759, reward -187.0, memory_length 2000, epsilon 0.092596864369849\n",
      "travel time- 724.0\n",
      "--- 1.8113105297088623 seconds ---\n",
      "episode 4760, reward 313.0, memory_length 2000, epsilon 0.09255057751034329\n",
      "travel time- 726.0\n",
      "--- 1.619797945022583 seconds ---\n",
      "episode 4761, reward -127.0, memory_length 2000, epsilon 0.0925043137884824\n",
      "travel time- 725.0\n",
      "--- 1.7316277027130127 seconds ---\n",
      "episode 4762, reward -301.0, memory_length 2000, epsilon 0.09245807319270043\n",
      "travel time- 725.0\n",
      "--- 1.6508312225341797 seconds ---\n",
      "episode 4763, reward -178.0, memory_length 2000, epsilon 0.09241185571143729\n",
      "travel time- 724.0\n",
      "--- 1.7251291275024414 seconds ---\n",
      "episode 4764, reward -204.0, memory_length 2000, epsilon 0.0923656613331385\n",
      "travel time- 722.0\n",
      "--- 1.772874116897583 seconds ---\n",
      "episode 4765, reward -51.0, memory_length 2000, epsilon 0.09231949004625559\n",
      "travel time- 730.0\n",
      "--- 1.544339656829834 seconds ---\n",
      "episode 4766, reward 70.0, memory_length 2000, epsilon 0.09227334183924561\n",
      "travel time- 721.0\n",
      "--- 1.549058437347412 seconds ---\n",
      "episode 4767, reward 27.0, memory_length 2000, epsilon 0.09222721670057159\n",
      "travel time- 722.0\n",
      "--- 1.6283257007598877 seconds ---\n",
      "episode 4768, reward -100.0, memory_length 2000, epsilon 0.09218111461870225\n",
      "travel time- 728.0\n",
      "--- 1.7511403560638428 seconds ---\n",
      "episode 4769, reward -118.0, memory_length 2000, epsilon 0.09213503558211202\n",
      "travel time- 723.0\n",
      "--- 1.8209052085876465 seconds ---\n",
      "episode 4770, reward -30.0, memory_length 2000, epsilon 0.09208897957928115\n",
      "travel time- 720.0\n",
      "--- 1.7490293979644775 seconds ---\n",
      "episode 4771, reward -202.0, memory_length 2000, epsilon 0.0920429465986957\n",
      "travel time- 723.0\n",
      "--- 1.8909204006195068 seconds ---\n",
      "episode 4772, reward 139.0, memory_length 2000, epsilon 0.09199693662884734\n",
      "travel time- 726.0\n",
      "--- 1.6431667804718018 seconds ---\n",
      "episode 4773, reward -290.0, memory_length 2000, epsilon 0.09195094965823365\n",
      "travel time- 724.0\n",
      "--- 1.6679434776306152 seconds ---\n",
      "episode 4774, reward -242.0, memory_length 2000, epsilon 0.09190498567535783\n",
      "travel time- 726.0\n",
      "--- 1.91168212890625 seconds ---\n",
      "episode 4775, reward -94.0, memory_length 2000, epsilon 0.09185904466872889\n",
      "travel time- 722.0\n",
      "--- 1.7448186874389648 seconds ---\n",
      "episode 4776, reward 166.0, memory_length 2000, epsilon 0.09181312662686165\n",
      "travel time- 721.0\n",
      "--- 1.5226280689239502 seconds ---\n",
      "episode 4777, reward 82.0, memory_length 2000, epsilon 0.0917672315382765\n",
      "travel time- 728.0\n",
      "--- 1.6068227291107178 seconds ---\n",
      "episode 4778, reward 227.0, memory_length 2000, epsilon 0.09172135939149971\n",
      "travel time- 720.0\n",
      "--- 1.5674400329589844 seconds ---\n",
      "episode 4779, reward 425.0, memory_length 2000, epsilon 0.09167551017506329\n",
      "travel time- 730.0\n",
      "--- 1.8079404830932617 seconds ---\n",
      "episode 4780, reward 204.0, memory_length 2000, epsilon 0.09162968387750484\n",
      "travel time- 721.0\n",
      "--- 1.579132318496704 seconds ---\n",
      "episode 4781, reward 91.0, memory_length 2000, epsilon 0.09158388048736789\n",
      "travel time- 727.0\n",
      "--- 1.610778570175171 seconds ---\n",
      "episode 4782, reward -3.0, memory_length 2000, epsilon 0.09153809999320149\n",
      "travel time- 720.0\n",
      "--- 1.671062707901001 seconds ---\n",
      "episode 4783, reward -184.0, memory_length 2000, epsilon 0.09149234238356056\n",
      "travel time- 729.0\n",
      "--- 1.6622576713562012 seconds ---\n",
      "episode 4784, reward 368.0, memory_length 2000, epsilon 0.09144660764700575\n",
      "travel time- 720.0\n",
      "--- 1.4879605770111084 seconds ---\n",
      "episode 4785, reward 75.0, memory_length 2000, epsilon 0.0914008957721033\n",
      "travel time- 720.0\n",
      "--- 1.7370076179504395 seconds ---\n",
      "episode 4786, reward 87.0, memory_length 2000, epsilon 0.09135520674742525\n",
      "travel time- 728.0\n",
      "--- 1.5349147319793701 seconds ---\n",
      "episode 4787, reward 79.0, memory_length 2000, epsilon 0.09130954056154941\n",
      "travel time- 721.0\n",
      "--- 1.7138142585754395 seconds ---\n",
      "episode 4788, reward 37.0, memory_length 2000, epsilon 0.09126389720305915\n",
      "travel time- 721.0\n",
      "--- 1.4698536396026611 seconds ---\n",
      "episode 4789, reward 238.0, memory_length 2000, epsilon 0.0912182766605437\n",
      "travel time- 728.0\n",
      "--- 1.7420387268066406 seconds ---\n",
      "episode 4790, reward -293.0, memory_length 2000, epsilon 0.09117267892259785\n",
      "travel time- 727.0\n",
      "--- 1.4540979862213135 seconds ---\n",
      "episode 4791, reward -72.0, memory_length 2000, epsilon 0.09112710397782221\n",
      "travel time- 725.0\n",
      "--- 1.6393556594848633 seconds ---\n",
      "episode 4792, reward -101.0, memory_length 2000, epsilon 0.09108155181482308\n",
      "travel time- 722.0\n",
      "--- 1.7544305324554443 seconds ---\n",
      "episode 4793, reward 179.0, memory_length 2000, epsilon 0.09103602242221233\n",
      "travel time- 724.0\n",
      "--- 1.451049566268921 seconds ---\n",
      "episode 4794, reward -13.0, memory_length 2000, epsilon 0.09099051578860767\n",
      "travel time- 720.0\n",
      "--- 1.653285026550293 seconds ---\n",
      "episode 4795, reward 333.0, memory_length 2000, epsilon 0.09094503190263246\n",
      "travel time- 721.0\n",
      "--- 1.7044651508331299 seconds ---\n",
      "episode 4796, reward -78.0, memory_length 2000, epsilon 0.09089957075291567\n",
      "travel time- 724.0\n",
      "--- 1.6189966201782227 seconds ---\n",
      "episode 4797, reward 48.0, memory_length 2000, epsilon 0.09085413232809207\n",
      "travel time- 720.0\n",
      "--- 1.5694994926452637 seconds ---\n",
      "episode 4798, reward 75.0, memory_length 2000, epsilon 0.090808716616802\n",
      "travel time- 720.0\n",
      "--- 2.001725912094116 seconds ---\n",
      "episode 4799, reward 253.0, memory_length 2000, epsilon 0.09076332360769154\n",
      "travel time- 728.0\n",
      "--- 1.6284990310668945 seconds ---\n",
      "episode 4800, reward -202.0, memory_length 2000, epsilon 0.09071795328941251\n",
      "travel time- 724.0\n",
      "--- 1.4864418506622314 seconds ---\n",
      "episode 4801, reward 266.0, memory_length 2000, epsilon 0.09067260565062223\n",
      "travel time- 723.0\n",
      "--- 1.6362659931182861 seconds ---\n",
      "episode 4802, reward 329.0, memory_length 2000, epsilon 0.09062728067998384\n",
      "travel time- 720.0\n",
      "--- 1.7314565181732178 seconds ---\n",
      "episode 4803, reward 66.0, memory_length 2000, epsilon 0.09058197836616612\n",
      "travel time- 723.0\n",
      "--- 1.6237058639526367 seconds ---\n",
      "episode 4804, reward 53.0, memory_length 2000, epsilon 0.09053669869784343\n",
      "travel time- 725.0\n",
      "--- 1.669123888015747 seconds ---\n",
      "episode 4805, reward 11.0, memory_length 2000, epsilon 0.09049144166369592\n",
      "travel time- 722.0\n",
      "--- 1.5816268920898438 seconds ---\n",
      "episode 4806, reward -76.0, memory_length 2000, epsilon 0.09044620725240926\n",
      "travel time- 726.0\n",
      "--- 1.6572024822235107 seconds ---\n",
      "episode 4807, reward -271.0, memory_length 2000, epsilon 0.0904009954526749\n",
      "travel time- 725.0\n",
      "--- 1.5125007629394531 seconds ---\n",
      "episode 4808, reward 20.0, memory_length 2000, epsilon 0.0903558062531899\n",
      "travel time- 726.0\n",
      "--- 1.7003486156463623 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4809, reward 298.0, memory_length 2000, epsilon 0.09031063964265688\n",
      "travel time- 721.0\n",
      "--- 1.7686874866485596 seconds ---\n",
      "episode 4810, reward -222.0, memory_length 2000, epsilon 0.09026549560978427\n",
      "travel time- 720.0\n",
      "--- 1.8396673202514648 seconds ---\n",
      "episode 4811, reward 251.0, memory_length 2000, epsilon 0.09022037414328606\n",
      "travel time- 720.0\n",
      "--- 1.7351195812225342 seconds ---\n",
      "episode 4812, reward 268.0, memory_length 2000, epsilon 0.0901752752318818\n",
      "travel time- 730.0\n",
      "--- 1.6133668422698975 seconds ---\n",
      "episode 4813, reward 244.0, memory_length 2000, epsilon 0.09013019886429688\n",
      "travel time- 721.0\n",
      "--- 1.6502094268798828 seconds ---\n",
      "episode 4814, reward 58.0, memory_length 2000, epsilon 0.0900851450292621\n",
      "travel time- 729.0\n",
      "--- 1.709787130355835 seconds ---\n",
      "episode 4815, reward -137.0, memory_length 2000, epsilon 0.09004011371551404\n",
      "travel time- 721.0\n",
      "--- 1.5191493034362793 seconds ---\n",
      "episode 4816, reward -4.0, memory_length 2000, epsilon 0.08999510491179491\n",
      "travel time- 720.0\n",
      "--- 1.5514557361602783 seconds ---\n",
      "episode 4817, reward -124.0, memory_length 2000, epsilon 0.08995011860685245\n",
      "travel time- 720.0\n",
      "--- 1.779879093170166 seconds ---\n",
      "episode 4818, reward 160.0, memory_length 2000, epsilon 0.08990515478944011\n",
      "travel time- 722.0\n",
      "--- 1.5915398597717285 seconds ---\n",
      "episode 4819, reward 126.0, memory_length 2000, epsilon 0.08986021344831698\n",
      "travel time- 727.0\n",
      "--- 1.6896088123321533 seconds ---\n",
      "episode 4820, reward -275.0, memory_length 2000, epsilon 0.08981529457224763\n",
      "travel time- 722.0\n",
      "--- 1.7115147113800049 seconds ---\n",
      "episode 4821, reward -156.0, memory_length 2000, epsilon 0.08977039815000243\n",
      "travel time- 720.0\n",
      "--- 1.5943050384521484 seconds ---\n",
      "episode 4822, reward -40.0, memory_length 2000, epsilon 0.0897255241703572\n",
      "travel time- 720.0\n",
      "--- 1.8686573505401611 seconds ---\n",
      "episode 4823, reward -319.0, memory_length 2000, epsilon 0.08968067262209348\n",
      "travel time- 731.0\n",
      "--- 1.7221641540527344 seconds ---\n",
      "episode 4824, reward 151.0, memory_length 2000, epsilon 0.08963584349399842\n",
      "travel time- 723.0\n",
      "--- 1.6566965579986572 seconds ---\n",
      "episode 4825, reward 30.0, memory_length 2000, epsilon 0.08959103677486467\n",
      "travel time- 723.0\n",
      "--- 1.6043674945831299 seconds ---\n",
      "episode 4826, reward -211.0, memory_length 2000, epsilon 0.08954625245349057\n",
      "travel time- 732.0\n",
      "--- 1.5511541366577148 seconds ---\n",
      "episode 4827, reward 90.0, memory_length 2000, epsilon 0.08950149051868009\n",
      "travel time- 731.0\n",
      "--- 1.5785303115844727 seconds ---\n",
      "episode 4828, reward 195.0, memory_length 2000, epsilon 0.08945675095924267\n",
      "travel time- 729.0\n",
      "--- 1.6716408729553223 seconds ---\n",
      "episode 4829, reward -162.0, memory_length 2000, epsilon 0.0894120337639935\n",
      "travel time- 721.0\n",
      "--- 1.553121566772461 seconds ---\n",
      "episode 4830, reward 175.0, memory_length 2000, epsilon 0.08936733892175319\n",
      "travel time- 729.0\n",
      "--- 1.608583688735962 seconds ---\n",
      "episode 4831, reward 178.0, memory_length 2000, epsilon 0.08932266642134808\n",
      "travel time- 722.0\n",
      "--- 1.5554430484771729 seconds ---\n",
      "episode 4832, reward -241.0, memory_length 2000, epsilon 0.08927801625161007\n",
      "travel time- 723.0\n",
      "--- 1.6999053955078125 seconds ---\n",
      "episode 4833, reward 113.0, memory_length 2000, epsilon 0.08923338840137655\n",
      "travel time- 721.0\n",
      "--- 1.598975658416748 seconds ---\n",
      "episode 4834, reward 14.0, memory_length 2000, epsilon 0.08918878285949061\n",
      "travel time- 724.0\n",
      "--- 1.6060278415679932 seconds ---\n",
      "episode 4835, reward 60.0, memory_length 2000, epsilon 0.08914419961480087\n",
      "travel time- 721.0\n",
      "--- 1.644484281539917 seconds ---\n",
      "episode 4836, reward 381.0, memory_length 2000, epsilon 0.08909963865616147\n",
      "travel time- 731.0\n",
      "--- 1.492746353149414 seconds ---\n",
      "episode 4837, reward -210.0, memory_length 2000, epsilon 0.08905509997243224\n",
      "travel time- 721.0\n",
      "--- 1.6416103839874268 seconds ---\n",
      "episode 4838, reward 333.0, memory_length 2000, epsilon 0.08901058355247843\n",
      "travel time- 721.0\n",
      "--- 1.6719567775726318 seconds ---\n",
      "episode 4839, reward 176.0, memory_length 2000, epsilon 0.08896608938517096\n",
      "travel time- 722.0\n",
      "--- 1.671757459640503 seconds ---\n",
      "episode 4840, reward -34.0, memory_length 2000, epsilon 0.08892161745938634\n",
      "travel time- 723.0\n",
      "--- 1.609421730041504 seconds ---\n",
      "episode 4841, reward 246.0, memory_length 2000, epsilon 0.08887716776400652\n",
      "travel time- 723.0\n",
      "--- 1.7027361392974854 seconds ---\n",
      "episode 4842, reward 195.0, memory_length 2000, epsilon 0.08883274028791908\n",
      "travel time- 720.0\n",
      "--- 1.7261130809783936 seconds ---\n",
      "episode 4843, reward 92.0, memory_length 2000, epsilon 0.08878833502001723\n",
      "travel time- 720.0\n",
      "--- 1.6021904945373535 seconds ---\n",
      "episode 4844, reward -292.0, memory_length 2000, epsilon 0.08874395194919957\n",
      "travel time- 724.0\n",
      "--- 1.6735410690307617 seconds ---\n",
      "episode 4845, reward -152.0, memory_length 2000, epsilon 0.08869959106437038\n",
      "travel time- 723.0\n",
      "--- 1.659569263458252 seconds ---\n",
      "episode 4846, reward 84.0, memory_length 2000, epsilon 0.08865525235443938\n",
      "travel time- 738.0\n",
      "--- 1.475231647491455 seconds ---\n",
      "episode 4847, reward -365.0, memory_length 2000, epsilon 0.08861093580832195\n",
      "travel time- 726.0\n",
      "--- 1.799851655960083 seconds ---\n",
      "episode 4848, reward 38.0, memory_length 2000, epsilon 0.08856664141493896\n",
      "travel time- 728.0\n",
      "--- 1.5791151523590088 seconds ---\n",
      "episode 4849, reward -228.0, memory_length 2000, epsilon 0.08852236916321674\n",
      "travel time- 723.0\n",
      "--- 1.8546991348266602 seconds ---\n",
      "episode 4850, reward -10.0, memory_length 2000, epsilon 0.08847811904208727\n",
      "travel time- 721.0\n",
      "--- 1.722951889038086 seconds ---\n",
      "episode 4851, reward 102.0, memory_length 2000, epsilon 0.08843389104048807\n",
      "travel time- 728.0\n",
      "--- 1.6434218883514404 seconds ---\n",
      "episode 4852, reward -193.0, memory_length 2000, epsilon 0.08838968514736205\n",
      "travel time- 726.0\n",
      "--- 1.6658716201782227 seconds ---\n",
      "episode 4853, reward 171.0, memory_length 2000, epsilon 0.08834550135165782\n",
      "travel time- 722.0\n",
      "--- 1.542344093322754 seconds ---\n",
      "episode 4854, reward 130.0, memory_length 2000, epsilon 0.08830133964232935\n",
      "travel time- 725.0\n",
      "--- 1.9755795001983643 seconds ---\n",
      "episode 4855, reward 132.0, memory_length 2000, epsilon 0.08825720000833624\n",
      "travel time- 725.0\n",
      "--- 1.5749561786651611 seconds ---\n",
      "episode 4856, reward 76.0, memory_length 2000, epsilon 0.08821308243864363\n",
      "travel time- 728.0\n",
      "--- 1.5368173122406006 seconds ---\n",
      "episode 4857, reward 155.0, memory_length 2000, epsilon 0.08816898692222205\n",
      "travel time- 722.0\n",
      "--- 1.6852333545684814 seconds ---\n",
      "episode 4858, reward -100.0, memory_length 2000, epsilon 0.08812491344804767\n",
      "travel time- 732.0\n",
      "--- 1.6913838386535645 seconds ---\n",
      "episode 4859, reward -140.0, memory_length 2000, epsilon 0.08808086200510215\n",
      "travel time- 729.0\n",
      "--- 1.8988265991210938 seconds ---\n",
      "episode 4860, reward -287.0, memory_length 2000, epsilon 0.08803683258237255\n",
      "travel time- 721.0\n",
      "--- 1.6178157329559326 seconds ---\n",
      "episode 4861, reward 34.0, memory_length 2000, epsilon 0.08799282516885158\n",
      "travel time- 724.0\n",
      "--- 1.5416650772094727 seconds ---\n",
      "episode 4862, reward 259.0, memory_length 2000, epsilon 0.08794883975353733\n",
      "travel time- 723.0\n",
      "--- 1.4701836109161377 seconds ---\n",
      "episode 4863, reward 44.0, memory_length 2000, epsilon 0.08790487632543348\n",
      "travel time- 721.0\n",
      "--- 1.8450207710266113 seconds ---\n",
      "episode 4864, reward -22.0, memory_length 2000, epsilon 0.0878609348735492\n",
      "travel time- 721.0\n",
      "--- 1.6226859092712402 seconds ---\n",
      "episode 4865, reward 289.0, memory_length 2000, epsilon 0.08781701538689907\n",
      "travel time- 722.0\n",
      "--- 1.609999656677246 seconds ---\n",
      "episode 4866, reward -157.0, memory_length 2000, epsilon 0.08777311785450327\n",
      "travel time- 720.0\n",
      "--- 1.665513038635254 seconds ---\n",
      "episode 4867, reward 65.0, memory_length 2000, epsilon 0.08772924226538736\n",
      "travel time- 726.0\n",
      "--- 1.6314723491668701 seconds ---\n",
      "episode 4868, reward -68.0, memory_length 2000, epsilon 0.08768538860858248\n",
      "travel time- 731.0\n",
      "--- 1.453765869140625 seconds ---\n",
      "episode 4869, reward -43.0, memory_length 2000, epsilon 0.08764155687312523\n",
      "travel time- 722.0\n",
      "--- 1.7640917301177979 seconds ---\n",
      "episode 4870, reward 14.0, memory_length 2000, epsilon 0.08759774704805763\n",
      "travel time- 724.0\n",
      "--- 1.6556241512298584 seconds ---\n",
      "episode 4871, reward 151.0, memory_length 2000, epsilon 0.08755395912242724\n",
      "travel time- 727.0\n",
      "--- 1.6387543678283691 seconds ---\n",
      "episode 4872, reward -14.0, memory_length 2000, epsilon 0.08751019308528712\n",
      "travel time- 720.0\n",
      "--- 1.5897269248962402 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4873, reward 57.0, memory_length 2000, epsilon 0.0874664489256957\n",
      "travel time- 723.0\n",
      "--- 1.6351027488708496 seconds ---\n",
      "episode 4874, reward -1.0, memory_length 2000, epsilon 0.08742272663271701\n",
      "travel time- 729.0\n",
      "--- 1.607051134109497 seconds ---\n",
      "episode 4875, reward -161.0, memory_length 2000, epsilon 0.08737902619542039\n",
      "travel time- 722.0\n",
      "--- 1.5136351585388184 seconds ---\n",
      "episode 4876, reward 16.0, memory_length 2000, epsilon 0.08733534760288077\n",
      "travel time- 724.0\n",
      "--- 1.5727086067199707 seconds ---\n",
      "episode 4877, reward 504.0, memory_length 2000, epsilon 0.08729169084417854\n",
      "travel time- 729.0\n",
      "--- 1.521955966949463 seconds ---\n",
      "episode 4878, reward 69.0, memory_length 2000, epsilon 0.08724805590839944\n",
      "travel time- 720.0\n",
      "--- 1.7249815464019775 seconds ---\n",
      "episode 4879, reward 119.0, memory_length 2000, epsilon 0.08720444278463478\n",
      "travel time- 721.0\n",
      "--- 1.6917545795440674 seconds ---\n",
      "episode 4880, reward 189.0, memory_length 2000, epsilon 0.0871608514619813\n",
      "travel time- 730.0\n",
      "--- 1.5785527229309082 seconds ---\n",
      "episode 4881, reward -114.0, memory_length 2000, epsilon 0.0871172819295411\n",
      "travel time- 721.0\n",
      "--- 1.6816294193267822 seconds ---\n",
      "episode 4882, reward -324.0, memory_length 2000, epsilon 0.08707373417642188\n",
      "travel time- 721.0\n",
      "--- 1.5797042846679688 seconds ---\n",
      "episode 4883, reward 122.0, memory_length 2000, epsilon 0.08703020819173661\n",
      "travel time- 723.0\n",
      "--- 1.566695213317871 seconds ---\n",
      "episode 4884, reward 188.0, memory_length 2000, epsilon 0.08698670396460385\n",
      "travel time- 721.0\n",
      "--- 1.6079771518707275 seconds ---\n",
      "episode 4885, reward 141.0, memory_length 2000, epsilon 0.08694322148414757\n",
      "travel time- 722.0\n",
      "--- 1.6865596771240234 seconds ---\n",
      "episode 4886, reward -19.0, memory_length 2000, epsilon 0.08689976073949708\n",
      "travel time- 723.0\n",
      "--- 1.5902855396270752 seconds ---\n",
      "episode 4887, reward -184.0, memory_length 2000, epsilon 0.08685632171978723\n",
      "travel time- 720.0\n",
      "--- 1.6885993480682373 seconds ---\n",
      "episode 4888, reward 31.0, memory_length 2000, epsilon 0.08681290441415829\n",
      "travel time- 721.0\n",
      "--- 1.5674734115600586 seconds ---\n",
      "episode 4889, reward -113.0, memory_length 2000, epsilon 0.08676950881175588\n",
      "travel time- 722.0\n",
      "--- 1.5100047588348389 seconds ---\n",
      "episode 4890, reward 77.0, memory_length 2000, epsilon 0.08672613490173114\n",
      "travel time- 721.0\n",
      "--- 1.6750304698944092 seconds ---\n",
      "episode 4891, reward -33.0, memory_length 2000, epsilon 0.08668278267324056\n",
      "travel time- 724.0\n",
      "--- 1.6987388134002686 seconds ---\n",
      "episode 4892, reward 139.0, memory_length 2000, epsilon 0.0866394521154461\n",
      "travel time- 725.0\n",
      "--- 1.5787184238433838 seconds ---\n",
      "episode 4893, reward -32.0, memory_length 2000, epsilon 0.08659614321751515\n",
      "travel time- 720.0\n",
      "--- 1.669546365737915 seconds ---\n",
      "episode 4894, reward -55.0, memory_length 2000, epsilon 0.08655285596862042\n",
      "travel time- 727.0\n",
      "--- 1.7742512226104736 seconds ---\n",
      "episode 4895, reward -62.0, memory_length 2000, epsilon 0.08650959035794013\n",
      "travel time- 722.0\n",
      "--- 1.8992993831634521 seconds ---\n",
      "episode 4896, reward 144.0, memory_length 2000, epsilon 0.08646634637465792\n",
      "travel time- 722.0\n",
      "--- 1.5994055271148682 seconds ---\n",
      "episode 4897, reward -250.0, memory_length 2000, epsilon 0.08642312400796272\n",
      "travel time- 723.0\n",
      "--- 1.6945526599884033 seconds ---\n",
      "episode 4898, reward -31.0, memory_length 2000, epsilon 0.086379923247049\n",
      "travel time- 722.0\n",
      "--- 1.7396602630615234 seconds ---\n",
      "episode 4899, reward -149.0, memory_length 2000, epsilon 0.08633674408111651\n",
      "travel time- 728.0\n",
      "--- 1.6355869770050049 seconds ---\n",
      "episode 4900, reward -181.0, memory_length 2000, epsilon 0.0862935864993705\n",
      "travel time- 725.0\n",
      "--- 1.6896204948425293 seconds ---\n",
      "episode 4901, reward 123.0, memory_length 2000, epsilon 0.08625045049102159\n",
      "travel time- 722.0\n",
      "--- 1.6279551982879639 seconds ---\n",
      "episode 4902, reward -31.0, memory_length 2000, epsilon 0.08620733604528572\n",
      "travel time- 728.0\n",
      "--- 1.7870421409606934 seconds ---\n",
      "episode 4903, reward 95.0, memory_length 2000, epsilon 0.0861642431513843\n",
      "travel time- 722.0\n",
      "--- 1.7587385177612305 seconds ---\n",
      "episode 4904, reward 130.0, memory_length 2000, epsilon 0.08612117179854416\n",
      "travel time- 725.0\n",
      "--- 1.8605663776397705 seconds ---\n",
      "episode 4905, reward 52.0, memory_length 2000, epsilon 0.08607812197599739\n",
      "travel time- 722.0\n",
      "--- 1.4899029731750488 seconds ---\n",
      "episode 4906, reward 159.0, memory_length 2000, epsilon 0.08603509367298158\n",
      "travel time- 729.0\n",
      "--- 1.592726230621338 seconds ---\n",
      "episode 4907, reward 64.0, memory_length 2000, epsilon 0.08599208687873962\n",
      "travel time- 723.0\n",
      "--- 1.7056236267089844 seconds ---\n",
      "episode 4908, reward 104.0, memory_length 2000, epsilon 0.08594910158251981\n",
      "travel time- 722.0\n",
      "--- 1.503586769104004 seconds ---\n",
      "episode 4909, reward 305.0, memory_length 2000, epsilon 0.08590613777357589\n",
      "travel time- 725.0\n",
      "--- 1.5812060832977295 seconds ---\n",
      "episode 4910, reward -119.0, memory_length 2000, epsilon 0.08586319544116683\n",
      "travel time- 721.0\n",
      "--- 1.601714849472046 seconds ---\n",
      "episode 4911, reward -31.0, memory_length 2000, epsilon 0.08582027457455707\n",
      "travel time- 720.0\n",
      "--- 1.7598376274108887 seconds ---\n",
      "episode 4912, reward -224.0, memory_length 2000, epsilon 0.08577737516301644\n",
      "travel time- 730.0\n",
      "--- 1.8299572467803955 seconds ---\n",
      "episode 4913, reward 11.0, memory_length 2000, epsilon 0.08573449719582\n",
      "travel time- 722.0\n",
      "--- 1.6168456077575684 seconds ---\n",
      "episode 4914, reward -137.0, memory_length 2000, epsilon 0.08569164066224835\n",
      "travel time- 723.0\n",
      "--- 1.5502915382385254 seconds ---\n",
      "episode 4915, reward -225.0, memory_length 2000, epsilon 0.08564880555158727\n",
      "travel time- 737.0\n",
      "--- 1.7887253761291504 seconds ---\n",
      "episode 4916, reward 157.0, memory_length 2000, epsilon 0.08560599185312803\n",
      "travel time- 724.0\n",
      "--- 1.6554114818572998 seconds ---\n",
      "episode 4917, reward -93.0, memory_length 2000, epsilon 0.08556319955616724\n",
      "travel time- 721.0\n",
      "--- 1.6253552436828613 seconds ---\n",
      "episode 4918, reward -118.0, memory_length 2000, epsilon 0.08552042865000674\n",
      "travel time- 722.0\n",
      "--- 1.5954680442810059 seconds ---\n",
      "episode 4919, reward 305.0, memory_length 2000, epsilon 0.08547767912395386\n",
      "travel time- 723.0\n",
      "--- 1.5558419227600098 seconds ---\n",
      "episode 4920, reward -44.0, memory_length 2000, epsilon 0.08543495096732123\n",
      "travel time- 721.0\n",
      "--- 1.6176464557647705 seconds ---\n",
      "episode 4921, reward 125.0, memory_length 2000, epsilon 0.08539224416942676\n",
      "travel time- 728.0\n",
      "--- 1.4952473640441895 seconds ---\n",
      "episode 4922, reward 256.0, memory_length 2000, epsilon 0.08534955871959381\n",
      "travel time- 726.0\n",
      "--- 1.596177339553833 seconds ---\n",
      "episode 4923, reward -328.0, memory_length 2000, epsilon 0.08530689460715093\n",
      "travel time- 721.0\n",
      "--- 2.0236759185791016 seconds ---\n",
      "episode 4924, reward 71.0, memory_length 2000, epsilon 0.08526425182143217\n",
      "travel time- 723.0\n",
      "--- 1.6160993576049805 seconds ---\n",
      "episode 4925, reward 391.0, memory_length 2000, epsilon 0.08522163035177684\n",
      "travel time- 728.0\n",
      "--- 1.5465891361236572 seconds ---\n",
      "episode 4926, reward 130.0, memory_length 2000, epsilon 0.0851790301875295\n",
      "travel time- 738.0\n",
      "--- 1.5647523403167725 seconds ---\n",
      "episode 4927, reward -287.0, memory_length 2000, epsilon 0.08513645131804015\n",
      "travel time- 726.0\n",
      "--- 1.633537769317627 seconds ---\n",
      "episode 4928, reward 0.0, memory_length 2000, epsilon 0.08509389373266411\n",
      "travel time- 725.0\n",
      "--- 1.5077102184295654 seconds ---\n",
      "episode 4929, reward 319.0, memory_length 2000, epsilon 0.08505135742076192\n",
      "travel time- 722.0\n",
      "--- 1.6013274192810059 seconds ---\n",
      "episode 4930, reward 183.0, memory_length 2000, epsilon 0.08500884237169956\n",
      "travel time- 725.0\n",
      "--- 1.5131421089172363 seconds ---\n",
      "episode 4931, reward 71.0, memory_length 2000, epsilon 0.0849663485748482\n",
      "travel time- 722.0\n",
      "--- 1.4849882125854492 seconds ---\n",
      "episode 4932, reward -62.0, memory_length 2000, epsilon 0.08492387601958441\n",
      "travel time- 721.0\n",
      "--- 1.748431921005249 seconds ---\n",
      "episode 4933, reward 234.0, memory_length 2000, epsilon 0.08488142469529013\n",
      "travel time- 725.0\n",
      "--- 1.5461156368255615 seconds ---\n",
      "episode 4934, reward 211.0, memory_length 2000, epsilon 0.08483899459135241\n",
      "travel time- 732.0\n",
      "--- 1.5138823986053467 seconds ---\n",
      "episode 4935, reward -113.0, memory_length 2000, epsilon 0.08479658569716379\n",
      "travel time- 722.0\n",
      "--- 1.6253852844238281 seconds ---\n",
      "episode 4936, reward 109.0, memory_length 2000, epsilon 0.08475419800212207\n",
      "travel time- 720.0\n",
      "--- 1.4572453498840332 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4937, reward 18.0, memory_length 2000, epsilon 0.08471183149563025\n",
      "travel time- 721.0\n",
      "--- 1.3945350646972656 seconds ---\n",
      "episode 4938, reward -157.0, memory_length 2000, epsilon 0.08466948616709678\n",
      "travel time- 720.0\n",
      "--- 1.780731201171875 seconds ---\n",
      "episode 4939, reward 127.0, memory_length 2000, epsilon 0.08462716200593527\n",
      "travel time- 720.0\n",
      "--- 1.6076111793518066 seconds ---\n",
      "episode 4940, reward 496.0, memory_length 2000, epsilon 0.08458485900156469\n",
      "travel time- 731.0\n",
      "--- 1.7366390228271484 seconds ---\n",
      "episode 4941, reward 123.0, memory_length 2000, epsilon 0.08454257714340935\n",
      "travel time- 726.0\n",
      "--- 1.643953561782837 seconds ---\n",
      "episode 4942, reward -126.0, memory_length 2000, epsilon 0.08450031642089868\n",
      "travel time- 725.0\n",
      "--- 1.8467354774475098 seconds ---\n",
      "episode 4943, reward 147.0, memory_length 2000, epsilon 0.08445807682346756\n",
      "travel time- 726.0\n",
      "--- 1.5618236064910889 seconds ---\n",
      "episode 4944, reward -79.0, memory_length 2000, epsilon 0.08441585834055614\n",
      "travel time- 729.0\n",
      "--- 1.6345329284667969 seconds ---\n",
      "episode 4945, reward -368.0, memory_length 2000, epsilon 0.0843736609616097\n",
      "travel time- 723.0\n",
      "--- 1.8116819858551025 seconds ---\n",
      "episode 4946, reward 48.0, memory_length 2000, epsilon 0.08433148467607897\n",
      "travel time- 721.0\n",
      "--- 1.664898157119751 seconds ---\n",
      "episode 4947, reward -28.0, memory_length 2000, epsilon 0.08428932947341981\n",
      "travel time- 729.0\n",
      "--- 1.5962731838226318 seconds ---\n",
      "episode 4948, reward -263.0, memory_length 2000, epsilon 0.08424719534309347\n",
      "travel time- 721.0\n",
      "--- 1.7053818702697754 seconds ---\n",
      "episode 4949, reward 188.0, memory_length 2000, epsilon 0.08420508227456643\n",
      "travel time- 721.0\n",
      "--- 1.6533782482147217 seconds ---\n",
      "episode 4950, reward -4.0, memory_length 2000, epsilon 0.08416299025731036\n",
      "travel time- 725.0\n",
      "--- 1.5131111145019531 seconds ---\n",
      "episode 4951, reward -41.0, memory_length 2000, epsilon 0.0841209192808023\n",
      "travel time- 722.0\n",
      "--- 1.61179518699646 seconds ---\n",
      "episode 4952, reward -91.0, memory_length 2000, epsilon 0.08407886933452453\n",
      "travel time- 721.0\n",
      "--- 1.6337394714355469 seconds ---\n",
      "episode 4953, reward 80.0, memory_length 2000, epsilon 0.0840368404079645\n",
      "travel time- 720.0\n",
      "--- 1.5923194885253906 seconds ---\n",
      "episode 4954, reward 196.0, memory_length 2000, epsilon 0.08399483249061504\n",
      "travel time- 721.0\n",
      "--- 1.7364535331726074 seconds ---\n",
      "episode 4955, reward 167.0, memory_length 2000, epsilon 0.0839528455719741\n",
      "travel time- 723.0\n",
      "--- 1.6158316135406494 seconds ---\n",
      "episode 4956, reward -40.0, memory_length 2000, epsilon 0.083910879641545\n",
      "travel time- 730.0\n",
      "--- 1.7377095222473145 seconds ---\n",
      "episode 4957, reward 33.0, memory_length 2000, epsilon 0.08386893468883629\n",
      "travel time- 723.0\n",
      "--- 1.6935086250305176 seconds ---\n",
      "episode 4958, reward -223.0, memory_length 2000, epsilon 0.08382701070336164\n",
      "travel time- 727.0\n",
      "--- 1.6108903884887695 seconds ---\n",
      "episode 4959, reward -68.0, memory_length 2000, epsilon 0.0837851076746401\n",
      "travel time- 721.0\n",
      "--- 1.688657283782959 seconds ---\n",
      "episode 4960, reward 222.0, memory_length 2000, epsilon 0.08374322559219596\n",
      "travel time- 720.0\n",
      "--- 1.696488857269287 seconds ---\n",
      "episode 4961, reward 110.0, memory_length 2000, epsilon 0.08370136444555862\n",
      "travel time- 727.0\n",
      "--- 1.5772457122802734 seconds ---\n",
      "episode 4962, reward 256.0, memory_length 2000, epsilon 0.08365952422426286\n",
      "travel time- 721.0\n",
      "--- 1.3916301727294922 seconds ---\n",
      "episode 4963, reward -22.0, memory_length 2000, epsilon 0.08361770491784855\n",
      "travel time- 727.0\n",
      "--- 1.4177768230438232 seconds ---\n",
      "episode 4964, reward 330.0, memory_length 2000, epsilon 0.0835759065158609\n",
      "travel time- 723.0\n",
      "--- 1.4781982898712158 seconds ---\n",
      "episode 4965, reward -30.0, memory_length 2000, epsilon 0.08353412900785037\n",
      "travel time- 733.0\n",
      "--- 1.6036067008972168 seconds ---\n",
      "episode 4966, reward -241.0, memory_length 2000, epsilon 0.08349237238337248\n",
      "travel time- 720.0\n",
      "--- 1.5656812191009521 seconds ---\n",
      "episode 4967, reward 211.0, memory_length 2000, epsilon 0.08345063663198811\n",
      "travel time- 722.0\n",
      "--- 1.5553536415100098 seconds ---\n",
      "episode 4968, reward 15.0, memory_length 2000, epsilon 0.08340892174326339\n",
      "travel time- 723.0\n",
      "--- 1.7109603881835938 seconds ---\n",
      "episode 4969, reward 77.0, memory_length 2000, epsilon 0.08336722770676949\n",
      "travel time- 725.0\n",
      "--- 1.596907615661621 seconds ---\n",
      "episode 4970, reward -63.0, memory_length 2000, epsilon 0.083325554512083\n",
      "travel time- 724.0\n",
      "--- 1.695389986038208 seconds ---\n",
      "episode 4971, reward 229.0, memory_length 2000, epsilon 0.08328390214878552\n",
      "travel time- 722.0\n",
      "--- 1.6082000732421875 seconds ---\n",
      "episode 4972, reward 303.0, memory_length 2000, epsilon 0.08324227060646401\n",
      "travel time- 723.0\n",
      "--- 1.625483512878418 seconds ---\n",
      "episode 4973, reward -59.0, memory_length 2000, epsilon 0.08320065987471063\n",
      "travel time- 720.0\n",
      "--- 1.5435237884521484 seconds ---\n",
      "episode 4974, reward 28.0, memory_length 2000, epsilon 0.08315906994312262\n",
      "travel time- 721.0\n",
      "--- 1.534388542175293 seconds ---\n",
      "episode 4975, reward 240.0, memory_length 2000, epsilon 0.08311750080130252\n",
      "travel time- 720.0\n",
      "--- 1.5660061836242676 seconds ---\n",
      "episode 4976, reward -171.0, memory_length 2000, epsilon 0.0830759524388581\n",
      "travel time- 723.0\n",
      "--- 1.7668788433074951 seconds ---\n",
      "episode 4977, reward -168.0, memory_length 2000, epsilon 0.08303442484540217\n",
      "travel time- 720.0\n",
      "--- 1.6201739311218262 seconds ---\n",
      "episode 4978, reward 130.0, memory_length 2000, epsilon 0.08299291801055293\n",
      "travel time- 726.0\n",
      "--- 1.6875872611999512 seconds ---\n",
      "episode 4979, reward -238.0, memory_length 2000, epsilon 0.08295143192393359\n",
      "travel time- 722.0\n",
      "--- 1.7877602577209473 seconds ---\n",
      "episode 4980, reward -300.0, memory_length 2000, epsilon 0.08290996657517266\n",
      "travel time- 726.0\n",
      "--- 1.692936658859253 seconds ---\n",
      "episode 4981, reward -202.0, memory_length 2000, epsilon 0.08286852195390385\n",
      "travel time- 720.0\n",
      "--- 1.7064197063446045 seconds ---\n",
      "episode 4982, reward 15.0, memory_length 2000, epsilon 0.08282709804976592\n",
      "travel time- 726.0\n",
      "--- 1.736854076385498 seconds ---\n",
      "episode 4983, reward 63.0, memory_length 2000, epsilon 0.08278569485240293\n",
      "travel time- 723.0\n",
      "--- 1.684833288192749 seconds ---\n",
      "episode 4984, reward 97.0, memory_length 2000, epsilon 0.08274431235146412\n",
      "travel time- 721.0\n",
      "--- 1.6538257598876953 seconds ---\n",
      "episode 4985, reward 114.0, memory_length 2000, epsilon 0.08270295053660379\n",
      "travel time- 727.0\n",
      "--- 1.618119239807129 seconds ---\n",
      "episode 4986, reward 215.0, memory_length 2000, epsilon 0.08266160939748157\n",
      "travel time- 721.0\n",
      "--- 1.421675205230713 seconds ---\n",
      "episode 4987, reward -166.0, memory_length 2000, epsilon 0.08262028892376208\n",
      "travel time- 721.0\n",
      "--- 1.654475212097168 seconds ---\n",
      "episode 4988, reward -296.0, memory_length 2000, epsilon 0.08257898910511527\n",
      "travel time- 720.0\n",
      "--- 1.9814090728759766 seconds ---\n",
      "episode 4989, reward 46.0, memory_length 2000, epsilon 0.08253770993121619\n",
      "travel time- 725.0\n",
      "--- 1.6551272869110107 seconds ---\n",
      "episode 4990, reward 63.0, memory_length 2000, epsilon 0.08249645139174498\n",
      "travel time- 720.0\n",
      "--- 1.5416243076324463 seconds ---\n",
      "episode 4991, reward -349.0, memory_length 2000, epsilon 0.08245521347638707\n",
      "travel time- 720.0\n",
      "--- 1.6398611068725586 seconds ---\n",
      "episode 4992, reward -222.0, memory_length 2000, epsilon 0.08241399617483297\n",
      "travel time- 720.0\n",
      "--- 1.53482985496521 seconds ---\n",
      "episode 4993, reward 103.0, memory_length 2000, epsilon 0.08237279947677832\n",
      "travel time- 725.0\n",
      "--- 1.6058344841003418 seconds ---\n",
      "episode 4994, reward -408.0, memory_length 2000, epsilon 0.08233162337192401\n",
      "travel time- 723.0\n",
      "--- 1.6535439491271973 seconds ---\n",
      "episode 4995, reward -132.0, memory_length 2000, epsilon 0.08229046784997593\n",
      "travel time- 728.0\n",
      "--- 1.8517472743988037 seconds ---\n",
      "episode 4996, reward 20.0, memory_length 2000, epsilon 0.08224933290064523\n",
      "travel time- 723.0\n",
      "--- 1.4362998008728027 seconds ---\n",
      "episode 4997, reward -131.0, memory_length 2000, epsilon 0.08220821851364823\n",
      "travel time- 723.0\n",
      "--- 1.6960132122039795 seconds ---\n",
      "episode 4998, reward 314.0, memory_length 2000, epsilon 0.08216712467870625\n",
      "travel time- 720.0\n",
      "--- 1.730402946472168 seconds ---\n",
      "episode 4999, reward 54.0, memory_length 2000, epsilon 0.0821260513855459\n",
      "travel time- 729.0\n",
      "--- 1.829655647277832 seconds ---\n",
      "episode 5000, reward 145.0, memory_length 2000, epsilon 0.0820849986238988\n",
      "travel time- 721.0\n",
      "--- 1.7217297554016113 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5001, reward 159.0, memory_length 2000, epsilon 0.08204396638350177\n",
      "travel time- 724.0\n",
      "--- 1.7220349311828613 seconds ---\n",
      "episode 5002, reward 43.0, memory_length 2000, epsilon 0.08200295465409681\n",
      "travel time- 722.0\n",
      "--- 1.6452417373657227 seconds ---\n",
      "episode 5003, reward 37.0, memory_length 2000, epsilon 0.0819619634254309\n",
      "travel time- 728.0\n",
      "--- 1.8206603527069092 seconds ---\n",
      "episode 5004, reward -37.0, memory_length 2000, epsilon 0.08192099268725626\n",
      "travel time- 721.0\n",
      "--- 1.6169886589050293 seconds ---\n",
      "episode 5005, reward -63.0, memory_length 2000, epsilon 0.08188004242933027\n",
      "travel time- 722.0\n",
      "--- 1.6547966003417969 seconds ---\n",
      "episode 5006, reward -149.0, memory_length 2000, epsilon 0.08183911264141527\n",
      "travel time- 722.0\n",
      "--- 1.776644229888916 seconds ---\n",
      "episode 5007, reward -6.0, memory_length 2000, epsilon 0.0817982033132789\n",
      "travel time- 723.0\n",
      "--- 1.368546962738037 seconds ---\n",
      "episode 5008, reward -17.0, memory_length 2000, epsilon 0.08175731443469375\n",
      "travel time- 726.0\n",
      "--- 1.7535784244537354 seconds ---\n",
      "episode 5009, reward 292.0, memory_length 2000, epsilon 0.08171644599543762\n",
      "travel time- 726.0\n",
      "--- 1.6672420501708984 seconds ---\n",
      "episode 5010, reward -92.0, memory_length 2000, epsilon 0.08167559798529346\n",
      "travel time- 723.0\n",
      "--- 1.5343470573425293 seconds ---\n",
      "episode 5011, reward -50.0, memory_length 2000, epsilon 0.08163477039404919\n",
      "travel time- 728.0\n",
      "--- 1.629944086074829 seconds ---\n",
      "episode 5012, reward 123.0, memory_length 2000, epsilon 0.08159396321149794\n",
      "travel time- 727.0\n",
      "--- 1.8181850910186768 seconds ---\n",
      "episode 5013, reward 155.0, memory_length 2000, epsilon 0.08155317642743795\n",
      "travel time- 722.0\n",
      "--- 1.6204719543457031 seconds ---\n",
      "episode 5014, reward -101.0, memory_length 2000, epsilon 0.08151241003167246\n",
      "travel time- 725.0\n",
      "--- 1.7163453102111816 seconds ---\n",
      "episode 5015, reward -39.0, memory_length 2000, epsilon 0.08147166401400995\n",
      "travel time- 730.0\n",
      "--- 1.6509199142456055 seconds ---\n",
      "episode 5016, reward -165.0, memory_length 2000, epsilon 0.08143093836426381\n",
      "travel time- 723.0\n",
      "--- 1.969578742980957 seconds ---\n",
      "episode 5017, reward 58.0, memory_length 2000, epsilon 0.0813902330722527\n",
      "travel time- 725.0\n",
      "--- 1.5240764617919922 seconds ---\n",
      "episode 5018, reward -139.0, memory_length 2000, epsilon 0.0813495481278003\n",
      "travel time- 720.0\n",
      "--- 1.5302832126617432 seconds ---\n",
      "episode 5019, reward -34.0, memory_length 2000, epsilon 0.08130888352073534\n",
      "travel time- 730.0\n",
      "--- 1.7159905433654785 seconds ---\n",
      "episode 5020, reward 41.0, memory_length 2000, epsilon 0.08126823924089167\n",
      "travel time- 720.0\n",
      "--- 1.8016808032989502 seconds ---\n",
      "episode 5021, reward -17.0, memory_length 2000, epsilon 0.08122761527810828\n",
      "travel time- 723.0\n",
      "--- 1.7838962078094482 seconds ---\n",
      "episode 5022, reward -123.0, memory_length 2000, epsilon 0.08118701162222909\n",
      "travel time- 721.0\n",
      "--- 1.61204195022583 seconds ---\n",
      "episode 5023, reward -52.0, memory_length 2000, epsilon 0.08114642826310327\n",
      "travel time- 723.0\n",
      "--- 1.5771582126617432 seconds ---\n",
      "episode 5024, reward 73.0, memory_length 2000, epsilon 0.0811058651905849\n",
      "travel time- 722.0\n",
      "--- 1.7073206901550293 seconds ---\n",
      "episode 5025, reward 120.0, memory_length 2000, epsilon 0.08106532239453323\n",
      "travel time- 734.0\n",
      "--- 1.6689419746398926 seconds ---\n",
      "episode 5026, reward 378.0, memory_length 2000, epsilon 0.08102479986481265\n",
      "travel time- 727.0\n",
      "--- 1.697310209274292 seconds ---\n",
      "episode 5027, reward 27.0, memory_length 2000, epsilon 0.0809842975912924\n",
      "travel time- 726.0\n",
      "--- 1.6760597229003906 seconds ---\n",
      "episode 5028, reward -165.0, memory_length 2000, epsilon 0.08094381556384699\n",
      "travel time- 722.0\n",
      "--- 1.9780747890472412 seconds ---\n",
      "episode 5029, reward 96.0, memory_length 2000, epsilon 0.08090335377235591\n",
      "travel time- 732.0\n",
      "--- 1.5947439670562744 seconds ---\n",
      "episode 5030, reward -250.0, memory_length 2000, epsilon 0.08086291220670366\n",
      "travel time- 725.0\n",
      "--- 1.7773795127868652 seconds ---\n",
      "episode 5031, reward -19.0, memory_length 2000, epsilon 0.08082249085677992\n",
      "travel time- 723.0\n",
      "--- 1.6881499290466309 seconds ---\n",
      "episode 5032, reward -148.0, memory_length 2000, epsilon 0.08078208971247929\n",
      "travel time- 720.0\n",
      "--- 1.4925379753112793 seconds ---\n",
      "episode 5033, reward -192.0, memory_length 2000, epsilon 0.0807417087637015\n",
      "travel time- 722.0\n",
      "--- 1.5403120517730713 seconds ---\n",
      "episode 5034, reward -146.0, memory_length 2000, epsilon 0.08070134800035135\n",
      "travel time- 724.0\n",
      "--- 1.7071943283081055 seconds ---\n",
      "episode 5035, reward 101.0, memory_length 2000, epsilon 0.0806610074123386\n",
      "travel time- 723.0\n",
      "--- 1.504060983657837 seconds ---\n",
      "episode 5036, reward 267.0, memory_length 2000, epsilon 0.08062068698957811\n",
      "travel time- 725.0\n",
      "--- 1.6650266647338867 seconds ---\n",
      "episode 5037, reward 75.0, memory_length 2000, epsilon 0.08058038672198983\n",
      "travel time- 721.0\n",
      "--- 1.8316524028778076 seconds ---\n",
      "episode 5038, reward 18.0, memory_length 2000, epsilon 0.08054010659949862\n",
      "travel time- 721.0\n",
      "--- 1.7308087348937988 seconds ---\n",
      "episode 5039, reward 136.0, memory_length 2000, epsilon 0.0804998466120345\n",
      "travel time- 722.0\n",
      "--- 1.7514512538909912 seconds ---\n",
      "episode 5040, reward 129.0, memory_length 2000, epsilon 0.08045960674953244\n",
      "travel time- 731.0\n",
      "--- 1.816781759262085 seconds ---\n",
      "episode 5041, reward 83.0, memory_length 2000, epsilon 0.08041938700193246\n",
      "travel time- 722.0\n",
      "--- 1.7294354438781738 seconds ---\n",
      "episode 5042, reward 176.0, memory_length 2000, epsilon 0.0803791873591797\n",
      "travel time- 722.0\n",
      "--- 1.6207592487335205 seconds ---\n",
      "episode 5043, reward 96.0, memory_length 2000, epsilon 0.08033900781122416\n",
      "travel time- 730.0\n",
      "--- 1.5905170440673828 seconds ---\n",
      "episode 5044, reward -83.0, memory_length 2000, epsilon 0.08029884834802099\n",
      "travel time- 721.0\n",
      "--- 1.5511672496795654 seconds ---\n",
      "episode 5045, reward 150.0, memory_length 2000, epsilon 0.08025870895953036\n",
      "travel time- 727.0\n",
      "--- 1.6486339569091797 seconds ---\n",
      "episode 5046, reward 13.0, memory_length 2000, epsilon 0.08021858963571736\n",
      "travel time- 721.0\n",
      "--- 1.748175859451294 seconds ---\n",
      "episode 5047, reward -76.0, memory_length 2000, epsilon 0.08017849036655221\n",
      "travel time- 720.0\n",
      "--- 1.6363887786865234 seconds ---\n",
      "episode 5048, reward -311.0, memory_length 2000, epsilon 0.08013841114201005\n",
      "travel time- 731.0\n",
      "--- 1.5778870582580566 seconds ---\n",
      "episode 5049, reward 25.0, memory_length 2000, epsilon 0.08009835195207107\n",
      "travel time- 722.0\n",
      "--- 1.7338087558746338 seconds ---\n",
      "episode 5050, reward 6.0, memory_length 2000, epsilon 0.08005831278672054\n",
      "travel time- 723.0\n",
      "--- 1.6592097282409668 seconds ---\n",
      "episode 5051, reward -24.0, memory_length 2000, epsilon 0.0800182936359486\n",
      "travel time- 723.0\n",
      "--- 1.640141248703003 seconds ---\n",
      "episode 5052, reward 263.0, memory_length 2000, epsilon 0.07997829448975048\n",
      "travel time- 726.0\n",
      "--- 1.5195555686950684 seconds ---\n",
      "episode 5053, reward 206.0, memory_length 2000, epsilon 0.07993831533812643\n",
      "travel time- 721.0\n",
      "--- 1.5543475151062012 seconds ---\n",
      "episode 5054, reward -81.0, memory_length 2000, epsilon 0.0798983561710816\n",
      "travel time- 728.0\n",
      "--- 1.5895195007324219 seconds ---\n",
      "episode 5055, reward 421.0, memory_length 2000, epsilon 0.07985841697862626\n",
      "travel time- 720.0\n",
      "--- 1.5648164749145508 seconds ---\n",
      "episode 5056, reward 186.0, memory_length 2000, epsilon 0.07981849775077554\n",
      "travel time- 725.0\n",
      "--- 1.7086498737335205 seconds ---\n",
      "episode 5057, reward 232.0, memory_length 2000, epsilon 0.07977859847754969\n",
      "travel time- 720.0\n",
      "--- 1.763601303100586 seconds ---\n",
      "episode 5058, reward 193.0, memory_length 2000, epsilon 0.0797387191489739\n",
      "travel time- 723.0\n",
      "--- 1.5398812294006348 seconds ---\n",
      "episode 5059, reward -42.0, memory_length 2000, epsilon 0.07969885975507827\n",
      "travel time- 723.0\n",
      "--- 1.536905288696289 seconds ---\n",
      "episode 5060, reward -102.0, memory_length 2000, epsilon 0.07965902028589801\n",
      "travel time- 723.0\n",
      "--- 1.6422317028045654 seconds ---\n",
      "episode 5061, reward 116.0, memory_length 2000, epsilon 0.07961920073147326\n",
      "travel time- 728.0\n",
      "--- 1.6268856525421143 seconds ---\n",
      "episode 5062, reward 148.0, memory_length 2000, epsilon 0.07957940108184908\n",
      "travel time- 720.0\n",
      "--- 1.5442225933074951 seconds ---\n",
      "episode 5063, reward 288.0, memory_length 2000, epsilon 0.07953962132707561\n",
      "travel time- 730.0\n",
      "--- 1.4802756309509277 seconds ---\n",
      "episode 5064, reward 138.0, memory_length 2000, epsilon 0.07949986145720786\n",
      "travel time- 721.0\n",
      "--- 1.6206490993499756 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5065, reward 193.0, memory_length 2000, epsilon 0.07946012146230588\n",
      "travel time- 727.0\n",
      "--- 1.4834184646606445 seconds ---\n",
      "episode 5066, reward -2.0, memory_length 2000, epsilon 0.07942040133243472\n",
      "travel time- 721.0\n",
      "--- 1.7775137424468994 seconds ---\n",
      "episode 5067, reward -71.0, memory_length 2000, epsilon 0.07938070105766427\n",
      "travel time- 720.0\n",
      "--- 1.676253080368042 seconds ---\n",
      "episode 5068, reward -112.0, memory_length 2000, epsilon 0.0793410206280695\n",
      "travel time- 720.0\n",
      "--- 1.5925276279449463 seconds ---\n",
      "episode 5069, reward -389.0, memory_length 2000, epsilon 0.07930136003373034\n",
      "travel time- 731.0\n",
      "--- 1.7196485996246338 seconds ---\n",
      "episode 5070, reward -198.0, memory_length 2000, epsilon 0.07926171926473155\n",
      "travel time- 723.0\n",
      "--- 1.5823428630828857 seconds ---\n",
      "episode 5071, reward 66.0, memory_length 2000, epsilon 0.07922209831116304\n",
      "travel time- 721.0\n",
      "--- 1.5101089477539062 seconds ---\n",
      "episode 5072, reward 1.0, memory_length 2000, epsilon 0.07918249716311948\n",
      "travel time- 727.0\n",
      "--- 1.6153950691223145 seconds ---\n",
      "episode 5073, reward 200.0, memory_length 2000, epsilon 0.07914291581070063\n",
      "travel time- 728.0\n",
      "--- 1.553584337234497 seconds ---\n",
      "episode 5074, reward 41.0, memory_length 2000, epsilon 0.07910335424401117\n",
      "travel time- 724.0\n",
      "--- 1.6798999309539795 seconds ---\n",
      "episode 5075, reward -2.0, memory_length 2000, epsilon 0.07906381245316065\n",
      "travel time- 722.0\n",
      "--- 1.412266492843628 seconds ---\n",
      "episode 5076, reward 210.0, memory_length 2000, epsilon 0.07902429042826366\n",
      "travel time- 723.0\n",
      "--- 1.5694804191589355 seconds ---\n",
      "episode 5077, reward -201.0, memory_length 2000, epsilon 0.07898478815943971\n",
      "travel time- 729.0\n",
      "--- 1.863435983657837 seconds ---\n",
      "episode 5078, reward 41.0, memory_length 2000, epsilon 0.07894530563681319\n",
      "travel time- 725.0\n",
      "--- 1.5452940464019775 seconds ---\n",
      "episode 5079, reward -158.0, memory_length 2000, epsilon 0.07890584285051352\n",
      "travel time- 720.0\n",
      "--- 1.5140748023986816 seconds ---\n",
      "episode 5080, reward 107.0, memory_length 2000, epsilon 0.07886639979067495\n",
      "travel time- 721.0\n",
      "--- 1.6204586029052734 seconds ---\n",
      "episode 5081, reward 43.0, memory_length 2000, epsilon 0.07882697644743672\n",
      "travel time- 721.0\n",
      "--- 1.67329740524292 seconds ---\n",
      "episode 5082, reward -5.0, memory_length 2000, epsilon 0.07878757281094306\n",
      "travel time- 722.0\n",
      "--- 1.7026619911193848 seconds ---\n",
      "episode 5083, reward 163.0, memory_length 2000, epsilon 0.07874818887134297\n",
      "travel time- 722.0\n",
      "--- 1.6268401145935059 seconds ---\n",
      "episode 5084, reward -41.0, memory_length 2000, epsilon 0.07870882461879052\n",
      "travel time- 724.0\n",
      "--- 1.620682954788208 seconds ---\n",
      "episode 5085, reward 125.0, memory_length 2000, epsilon 0.07866948004344465\n",
      "travel time- 721.0\n",
      "--- 1.7665746212005615 seconds ---\n",
      "episode 5086, reward 142.0, memory_length 2000, epsilon 0.07863015513546918\n",
      "travel time- 725.0\n",
      "--- 1.8611934185028076 seconds ---\n",
      "episode 5087, reward -72.0, memory_length 2000, epsilon 0.07859084988503294\n",
      "travel time- 722.0\n",
      "--- 1.777843952178955 seconds ---\n",
      "episode 5088, reward 128.0, memory_length 2000, epsilon 0.07855156428230954\n",
      "travel time- 720.0\n",
      "--- 1.5688209533691406 seconds ---\n",
      "episode 5089, reward 140.0, memory_length 2000, epsilon 0.07851229831747762\n",
      "travel time- 726.0\n",
      "--- 1.817310094833374 seconds ---\n",
      "episode 5090, reward 332.0, memory_length 2000, epsilon 0.07847305198072073\n",
      "travel time- 720.0\n",
      "--- 1.720855712890625 seconds ---\n",
      "episode 5091, reward 195.0, memory_length 2000, epsilon 0.0784338252622272\n",
      "travel time- 723.0\n",
      "--- 1.7047340869903564 seconds ---\n",
      "episode 5092, reward 110.0, memory_length 2000, epsilon 0.0783946181521904\n",
      "travel time- 727.0\n",
      "--- 1.7167720794677734 seconds ---\n",
      "episode 5093, reward -5.0, memory_length 2000, epsilon 0.07835543064080858\n",
      "travel time- 723.0\n",
      "--- 1.590104579925537 seconds ---\n",
      "episode 5094, reward -386.0, memory_length 2000, epsilon 0.07831626271828479\n",
      "travel time- 726.0\n",
      "--- 1.7789607048034668 seconds ---\n",
      "episode 5095, reward -125.0, memory_length 2000, epsilon 0.07827711437482712\n",
      "travel time- 732.0\n",
      "--- 1.8044142723083496 seconds ---\n",
      "episode 5096, reward -229.0, memory_length 2000, epsilon 0.07823798560064842\n",
      "travel time- 721.0\n",
      "--- 1.7960255146026611 seconds ---\n",
      "episode 5097, reward -84.0, memory_length 2000, epsilon 0.07819887638596652\n",
      "travel time- 721.0\n",
      "--- 1.7731645107269287 seconds ---\n",
      "episode 5098, reward -20.0, memory_length 2000, epsilon 0.07815978672100418\n",
      "travel time- 726.0\n",
      "--- 1.5235569477081299 seconds ---\n",
      "episode 5099, reward -53.0, memory_length 2000, epsilon 0.07812071659598888\n",
      "travel time- 722.0\n",
      "--- 1.6047744750976562 seconds ---\n",
      "episode 5100, reward 187.0, memory_length 2000, epsilon 0.07808166600115313\n",
      "travel time- 722.0\n",
      "--- 1.7308719158172607 seconds ---\n",
      "episode 5101, reward 153.0, memory_length 2000, epsilon 0.07804263492673433\n",
      "travel time- 728.0\n",
      "--- 1.6657938957214355 seconds ---\n",
      "episode 5102, reward 401.0, memory_length 2000, epsilon 0.07800362336297463\n",
      "travel time- 721.0\n",
      "--- 1.5459678173065186 seconds ---\n",
      "episode 5103, reward -21.0, memory_length 2000, epsilon 0.07796463130012121\n",
      "travel time- 722.0\n",
      "--- 1.6443932056427002 seconds ---\n",
      "episode 5104, reward 189.0, memory_length 2000, epsilon 0.077925658728426\n",
      "travel time- 723.0\n",
      "--- 1.6376311779022217 seconds ---\n",
      "episode 5105, reward 143.0, memory_length 2000, epsilon 0.07788670563814586\n",
      "travel time- 720.0\n",
      "--- 1.6988849639892578 seconds ---\n",
      "episode 5106, reward 148.0, memory_length 2000, epsilon 0.07784777201954257\n",
      "travel time- 721.0\n",
      "--- 1.5011060237884521 seconds ---\n",
      "episode 5107, reward -2.0, memory_length 2000, epsilon 0.07780885786288266\n",
      "travel time- 727.0\n",
      "--- 1.6509919166564941 seconds ---\n",
      "episode 5108, reward -173.0, memory_length 2000, epsilon 0.07776996315843764\n",
      "travel time- 720.0\n",
      "--- 1.9320731163024902 seconds ---\n",
      "episode 5109, reward -275.0, memory_length 2000, epsilon 0.07773108789648382\n",
      "travel time- 727.0\n",
      "--- 1.6514580249786377 seconds ---\n",
      "episode 5110, reward 204.0, memory_length 2000, epsilon 0.07769223206730236\n",
      "travel time- 729.0\n",
      "--- 1.5040793418884277 seconds ---\n",
      "episode 5111, reward -200.0, memory_length 2000, epsilon 0.07765339566117935\n",
      "travel time- 724.0\n",
      "--- 1.8145740032196045 seconds ---\n",
      "episode 5112, reward -41.0, memory_length 2000, epsilon 0.07761457866840563\n",
      "travel time- 721.0\n",
      "--- 1.6183857917785645 seconds ---\n",
      "episode 5113, reward 144.0, memory_length 2000, epsilon 0.07757578107927698\n",
      "travel time- 726.0\n",
      "--- 1.8373665809631348 seconds ---\n",
      "episode 5114, reward -153.0, memory_length 2000, epsilon 0.07753700288409404\n",
      "travel time- 723.0\n",
      "--- 1.814948558807373 seconds ---\n",
      "episode 5115, reward 69.0, memory_length 2000, epsilon 0.07749824407316218\n",
      "travel time- 726.0\n",
      "--- 1.796367883682251 seconds ---\n",
      "episode 5116, reward -191.0, memory_length 2000, epsilon 0.07745950463679176\n",
      "travel time- 720.0\n",
      "--- 1.6305181980133057 seconds ---\n",
      "episode 5117, reward -234.0, memory_length 2000, epsilon 0.07742078456529793\n",
      "travel time- 723.0\n",
      "--- 1.6235027313232422 seconds ---\n",
      "episode 5118, reward 235.0, memory_length 2000, epsilon 0.0773820838490006\n",
      "travel time- 720.0\n",
      "--- 1.6305956840515137 seconds ---\n",
      "episode 5119, reward 53.0, memory_length 2000, epsilon 0.07734340247822467\n",
      "travel time- 729.0\n",
      "--- 1.6638469696044922 seconds ---\n",
      "episode 5120, reward 35.0, memory_length 2000, epsilon 0.07730474044329974\n",
      "travel time- 728.0\n",
      "--- 1.7152879238128662 seconds ---\n",
      "episode 5121, reward 146.0, memory_length 2000, epsilon 0.07726609773456032\n",
      "travel time- 726.0\n",
      "--- 1.7320880889892578 seconds ---\n",
      "episode 5122, reward 331.0, memory_length 2000, epsilon 0.07722747434234577\n",
      "travel time- 720.0\n",
      "--- 1.6229734420776367 seconds ---\n",
      "episode 5123, reward 168.0, memory_length 2000, epsilon 0.07718887025700018\n",
      "travel time- 723.0\n",
      "--- 1.434464454650879 seconds ---\n",
      "episode 5124, reward 225.0, memory_length 2000, epsilon 0.07715028546887258\n",
      "travel time- 724.0\n",
      "--- 1.8371715545654297 seconds ---\n",
      "episode 5125, reward 55.0, memory_length 2000, epsilon 0.07711171996831671\n",
      "travel time- 731.0\n",
      "--- 1.7192251682281494 seconds ---\n",
      "episode 5126, reward -50.0, memory_length 2000, epsilon 0.07707317374569124\n",
      "travel time- 727.0\n",
      "--- 1.8254070281982422 seconds ---\n",
      "episode 5127, reward 118.0, memory_length 2000, epsilon 0.07703464679135964\n",
      "travel time- 721.0\n",
      "--- 1.5599095821380615 seconds ---\n",
      "episode 5128, reward -210.0, memory_length 2000, epsilon 0.07699613909569011\n",
      "travel time- 720.0\n",
      "--- 2.0202691555023193 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5129, reward 53.0, memory_length 2000, epsilon 0.07695765064905576\n",
      "travel time- 725.0\n",
      "--- 1.5257823467254639 seconds ---\n",
      "episode 5130, reward -513.0, memory_length 2000, epsilon 0.0769191814418345\n",
      "travel time- 720.0\n",
      "--- 1.783759593963623 seconds ---\n",
      "episode 5131, reward 146.0, memory_length 2000, epsilon 0.07688073146440896\n",
      "travel time- 722.0\n",
      "--- 1.5264968872070312 seconds ---\n",
      "episode 5132, reward 165.0, memory_length 2000, epsilon 0.07684230070716673\n",
      "travel time- 723.0\n",
      "--- 1.8106329441070557 seconds ---\n",
      "episode 5133, reward 62.0, memory_length 2000, epsilon 0.07680388916050004\n",
      "travel time- 720.0\n",
      "--- 1.5790579319000244 seconds ---\n",
      "episode 5134, reward -63.0, memory_length 2000, epsilon 0.07676549681480604\n",
      "travel time- 722.0\n",
      "--- 1.6603538990020752 seconds ---\n",
      "episode 5135, reward 185.0, memory_length 2000, epsilon 0.07672712366048669\n",
      "travel time- 722.0\n",
      "--- 1.636023998260498 seconds ---\n",
      "episode 5136, reward 161.0, memory_length 2000, epsilon 0.0766887696879486\n",
      "travel time- 721.0\n",
      "--- 1.4305152893066406 seconds ---\n",
      "episode 5137, reward -188.0, memory_length 2000, epsilon 0.07665043488760334\n",
      "travel time- 734.0\n",
      "--- 1.7519381046295166 seconds ---\n",
      "episode 5138, reward -364.0, memory_length 2000, epsilon 0.07661211924986724\n",
      "travel time- 727.0\n",
      "--- 1.7890863418579102 seconds ---\n",
      "episode 5139, reward -246.0, memory_length 2000, epsilon 0.07657382276516132\n",
      "travel time- 723.0\n",
      "--- 1.798858880996704 seconds ---\n",
      "episode 5140, reward -221.0, memory_length 2000, epsilon 0.07653554542391151\n",
      "travel time- 720.0\n",
      "--- 1.6720659732818604 seconds ---\n",
      "episode 5141, reward 288.0, memory_length 2000, epsilon 0.07649728721654843\n",
      "travel time- 722.0\n",
      "--- 1.5911321640014648 seconds ---\n",
      "episode 5142, reward 1.0, memory_length 2000, epsilon 0.07645904813350755\n",
      "travel time- 721.0\n",
      "--- 1.8200390338897705 seconds ---\n",
      "episode 5143, reward 222.0, memory_length 2000, epsilon 0.07642082816522913\n",
      "travel time- 720.0\n",
      "--- 1.4536869525909424 seconds ---\n",
      "episode 5144, reward 107.0, memory_length 2000, epsilon 0.07638262730215813\n",
      "travel time- 726.0\n",
      "--- 1.6025817394256592 seconds ---\n",
      "episode 5145, reward 94.0, memory_length 2000, epsilon 0.07634444553474434\n",
      "travel time- 720.0\n",
      "--- 1.6008827686309814 seconds ---\n",
      "episode 5146, reward 75.0, memory_length 2000, epsilon 0.07630628285344238\n",
      "travel time- 720.0\n",
      "--- 1.6020796298980713 seconds ---\n",
      "episode 5147, reward -24.0, memory_length 2000, epsilon 0.07626813924871148\n",
      "travel time- 729.0\n",
      "--- 1.6655771732330322 seconds ---\n",
      "episode 5148, reward -84.0, memory_length 2000, epsilon 0.07623001471101583\n",
      "travel time- 726.0\n",
      "--- 1.8591673374176025 seconds ---\n",
      "episode 5149, reward 190.0, memory_length 2000, epsilon 0.07619190923082422\n",
      "travel time- 720.0\n",
      "--- 1.717996597290039 seconds ---\n",
      "episode 5150, reward -131.0, memory_length 2000, epsilon 0.07615382279861033\n",
      "travel time- 724.0\n",
      "--- 1.9851524829864502 seconds ---\n",
      "episode 5151, reward -77.0, memory_length 2000, epsilon 0.07611575540485255\n",
      "travel time- 730.0\n",
      "--- 1.476762056350708 seconds ---\n",
      "episode 5152, reward 125.0, memory_length 2000, epsilon 0.07607770704003398\n",
      "travel time- 720.0\n",
      "--- 1.896454095840454 seconds ---\n",
      "episode 5153, reward 175.0, memory_length 2000, epsilon 0.07603967769464258\n",
      "travel time- 723.0\n",
      "--- 1.4866981506347656 seconds ---\n",
      "episode 5154, reward 86.0, memory_length 2000, epsilon 0.07600166735917104\n",
      "travel time- 724.0\n",
      "--- 1.5127055644989014 seconds ---\n",
      "episode 5155, reward -128.0, memory_length 2000, epsilon 0.07596367602411669\n",
      "travel time- 731.0\n",
      "--- 1.7132728099822998 seconds ---\n",
      "episode 5156, reward 65.0, memory_length 2000, epsilon 0.07592570367998178\n",
      "travel time- 725.0\n",
      "--- 1.5874745845794678 seconds ---\n",
      "episode 5157, reward 242.0, memory_length 2000, epsilon 0.07588775031727314\n",
      "travel time- 723.0\n",
      "--- 1.7217402458190918 seconds ---\n",
      "episode 5158, reward -261.0, memory_length 2000, epsilon 0.07584981592650249\n",
      "travel time- 720.0\n",
      "--- 1.774765968322754 seconds ---\n",
      "episode 5159, reward 34.0, memory_length 2000, epsilon 0.07581190049818624\n",
      "travel time- 721.0\n",
      "--- 1.9092521667480469 seconds ---\n",
      "episode 5160, reward -446.0, memory_length 2000, epsilon 0.07577400402284548\n",
      "travel time- 727.0\n",
      "--- 1.7870543003082275 seconds ---\n",
      "episode 5161, reward 294.0, memory_length 2000, epsilon 0.07573612649100611\n",
      "travel time- 724.0\n",
      "--- 1.6877999305725098 seconds ---\n",
      "episode 5162, reward 57.0, memory_length 2000, epsilon 0.0756982678931988\n",
      "travel time- 720.0\n",
      "--- 1.7830469608306885 seconds ---\n",
      "episode 5163, reward -68.0, memory_length 2000, epsilon 0.07566042821995883\n",
      "travel time- 724.0\n",
      "--- 1.7251534461975098 seconds ---\n",
      "episode 5164, reward 212.0, memory_length 2000, epsilon 0.07562260746182634\n",
      "travel time- 725.0\n",
      "--- 1.824310064315796 seconds ---\n",
      "episode 5165, reward -194.0, memory_length 2000, epsilon 0.07558480560934606\n",
      "travel time- 720.0\n",
      "--- 1.7501709461212158 seconds ---\n",
      "episode 5166, reward -253.0, memory_length 2000, epsilon 0.0755470226530676\n",
      "travel time- 720.0\n",
      "--- 1.705092430114746 seconds ---\n",
      "episode 5167, reward 132.0, memory_length 2000, epsilon 0.07550925858354522\n",
      "travel time- 726.0\n",
      "--- 1.7808446884155273 seconds ---\n",
      "episode 5168, reward 127.0, memory_length 2000, epsilon 0.07547151339133784\n",
      "travel time- 729.0\n",
      "--- 1.4384117126464844 seconds ---\n",
      "episode 5169, reward -84.0, memory_length 2000, epsilon 0.0754337870670092\n",
      "travel time- 729.0\n",
      "--- 1.6363401412963867 seconds ---\n",
      "episode 5170, reward 133.0, memory_length 2000, epsilon 0.07539607960112776\n",
      "travel time- 722.0\n",
      "--- 1.827805519104004 seconds ---\n",
      "episode 5171, reward 235.0, memory_length 2000, epsilon 0.07535839098426658\n",
      "travel time- 725.0\n",
      "--- 1.8949644565582275 seconds ---\n",
      "episode 5172, reward 176.0, memory_length 2000, epsilon 0.07532072120700357\n",
      "travel time- 720.0\n",
      "--- 1.5527856349945068 seconds ---\n",
      "episode 5173, reward -227.0, memory_length 2000, epsilon 0.07528307025992123\n",
      "travel time- 721.0\n",
      "--- 1.781296730041504 seconds ---\n",
      "episode 5174, reward -55.0, memory_length 2000, epsilon 0.07524543813360683\n",
      "travel time- 722.0\n",
      "--- 1.6044647693634033 seconds ---\n",
      "episode 5175, reward -464.0, memory_length 2000, epsilon 0.0752078248186524\n",
      "travel time- 727.0\n",
      "--- 1.777980089187622 seconds ---\n",
      "episode 5176, reward -48.0, memory_length 2000, epsilon 0.07517023030565453\n",
      "travel time- 722.0\n",
      "--- 1.8293631076812744 seconds ---\n",
      "episode 5177, reward 211.0, memory_length 2000, epsilon 0.07513265458521463\n",
      "travel time- 723.0\n",
      "--- 1.645883560180664 seconds ---\n",
      "episode 5178, reward -158.0, memory_length 2000, epsilon 0.0750950976479388\n",
      "travel time- 720.0\n",
      "--- 1.7620306015014648 seconds ---\n",
      "episode 5179, reward -13.0, memory_length 2000, epsilon 0.07505755948443774\n",
      "travel time- 724.0\n",
      "--- 1.6329412460327148 seconds ---\n",
      "episode 5180, reward 48.0, memory_length 2000, epsilon 0.07502004008532698\n",
      "travel time- 730.0\n",
      "--- 1.7725245952606201 seconds ---\n",
      "episode 5181, reward 151.0, memory_length 2000, epsilon 0.07498253944122658\n",
      "travel time- 720.0\n",
      "--- 1.5901353359222412 seconds ---\n",
      "episode 5182, reward 166.0, memory_length 2000, epsilon 0.07494505754276144\n",
      "travel time- 722.0\n",
      "--- 1.7196741104125977 seconds ---\n",
      "episode 5183, reward -188.0, memory_length 2000, epsilon 0.07490759438056112\n",
      "travel time- 720.0\n",
      "--- 1.6980562210083008 seconds ---\n",
      "episode 5184, reward 133.0, memory_length 2000, epsilon 0.07487014994525974\n",
      "travel time- 721.0\n",
      "--- 1.606562852859497 seconds ---\n",
      "episode 5185, reward -119.0, memory_length 2000, epsilon 0.07483272422749625\n",
      "travel time- 723.0\n",
      "--- 1.7679986953735352 seconds ---\n",
      "episode 5186, reward -282.0, memory_length 2000, epsilon 0.07479531721791423\n",
      "travel time- 727.0\n",
      "--- 1.756563425064087 seconds ---\n",
      "episode 5187, reward -176.0, memory_length 2000, epsilon 0.07475792890716187\n",
      "travel time- 720.0\n",
      "--- 1.9274938106536865 seconds ---\n",
      "episode 5188, reward 131.0, memory_length 2000, epsilon 0.07472055928589216\n",
      "travel time- 721.0\n",
      "--- 1.9021973609924316 seconds ---\n",
      "episode 5189, reward -68.0, memory_length 2000, epsilon 0.07468320834476262\n",
      "travel time- 728.0\n",
      "--- 1.7352490425109863 seconds ---\n",
      "episode 5190, reward -77.0, memory_length 2000, epsilon 0.07464587607443557\n",
      "travel time- 722.0\n",
      "--- 1.724365234375 seconds ---\n",
      "episode 5191, reward 105.0, memory_length 2000, epsilon 0.07460856246557795\n",
      "travel time- 730.0\n",
      "--- 1.6249260902404785 seconds ---\n",
      "episode 5192, reward -36.0, memory_length 2000, epsilon 0.07457126750886131\n",
      "travel time- 721.0\n",
      "--- 1.8249025344848633 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5193, reward -80.0, memory_length 2000, epsilon 0.07453399119496193\n",
      "travel time- 723.0\n",
      "--- 1.7354745864868164 seconds ---\n",
      "episode 5194, reward -68.0, memory_length 2000, epsilon 0.07449673351456078\n",
      "travel time- 728.0\n",
      "--- 1.4839022159576416 seconds ---\n",
      "episode 5195, reward -52.0, memory_length 2000, epsilon 0.07445949445834335\n",
      "travel time- 725.0\n",
      "--- 1.6545448303222656 seconds ---\n",
      "episode 5196, reward 167.0, memory_length 2000, epsilon 0.07442227401699995\n",
      "travel time- 722.0\n",
      "--- 1.7195017337799072 seconds ---\n",
      "episode 5197, reward 201.0, memory_length 2000, epsilon 0.07438507218122543\n",
      "travel time- 723.0\n",
      "--- 1.7822763919830322 seconds ---\n",
      "episode 5198, reward -137.0, memory_length 2000, epsilon 0.07434788894171933\n",
      "travel time- 725.0\n",
      "--- 1.6780080795288086 seconds ---\n",
      "episode 5199, reward -187.0, memory_length 2000, epsilon 0.07431072428918589\n",
      "travel time- 722.0\n",
      "--- 1.6975007057189941 seconds ---\n",
      "episode 5200, reward 295.0, memory_length 2000, epsilon 0.07427357821433388\n",
      "travel time- 720.0\n",
      "--- 1.384547472000122 seconds ---\n",
      "episode 5201, reward 43.0, memory_length 2000, epsilon 0.0742364507078768\n",
      "travel time- 720.0\n",
      "--- 1.8123602867126465 seconds ---\n",
      "episode 5202, reward 92.0, memory_length 2000, epsilon 0.07419934176053282\n",
      "travel time- 733.0\n",
      "--- 1.6720223426818848 seconds ---\n",
      "episode 5203, reward -23.0, memory_length 2000, epsilon 0.07416225136302464\n",
      "travel time- 720.0\n",
      "--- 1.4564392566680908 seconds ---\n",
      "episode 5204, reward -91.0, memory_length 2000, epsilon 0.0741251795060797\n",
      "travel time- 725.0\n",
      "--- 1.7382850646972656 seconds ---\n",
      "episode 5205, reward 86.0, memory_length 2000, epsilon 0.07408812618043001\n",
      "travel time- 734.0\n",
      "--- 1.7722246646881104 seconds ---\n",
      "episode 5206, reward -120.0, memory_length 2000, epsilon 0.07405109137681225\n",
      "travel time- 720.0\n",
      "--- 1.7572660446166992 seconds ---\n",
      "episode 5207, reward -2.0, memory_length 2000, epsilon 0.07401407508596775\n",
      "travel time- 730.0\n",
      "--- 1.891127347946167 seconds ---\n",
      "episode 5208, reward 93.0, memory_length 2000, epsilon 0.07397707729864236\n",
      "travel time- 722.0\n",
      "--- 1.522505760192871 seconds ---\n",
      "episode 5209, reward 123.0, memory_length 2000, epsilon 0.07394009800558671\n",
      "travel time- 720.0\n",
      "--- 1.967972993850708 seconds ---\n",
      "episode 5210, reward 244.0, memory_length 2000, epsilon 0.07390313719755595\n",
      "travel time- 736.0\n",
      "--- 1.5374157428741455 seconds ---\n",
      "episode 5211, reward -206.0, memory_length 2000, epsilon 0.07386619486530986\n",
      "travel time- 730.0\n",
      "--- 1.7342302799224854 seconds ---\n",
      "episode 5212, reward 136.0, memory_length 2000, epsilon 0.0738292709996129\n",
      "travel time- 726.0\n",
      "--- 1.6511106491088867 seconds ---\n",
      "episode 5213, reward -52.0, memory_length 2000, epsilon 0.07379236559123403\n",
      "travel time- 725.0\n",
      "--- 1.7272095680236816 seconds ---\n",
      "episode 5214, reward -358.0, memory_length 2000, epsilon 0.07375547863094695\n",
      "travel time- 728.0\n",
      "--- 1.7683629989624023 seconds ---\n",
      "episode 5215, reward 180.0, memory_length 2000, epsilon 0.07371861010952994\n",
      "travel time- 729.0\n",
      "--- 1.5302248001098633 seconds ---\n",
      "episode 5216, reward 291.0, memory_length 2000, epsilon 0.07368176001776583\n",
      "travel time- 720.0\n",
      "--- 1.6835236549377441 seconds ---\n",
      "episode 5217, reward 139.0, memory_length 2000, epsilon 0.07364492834644208\n",
      "travel time- 722.0\n",
      "--- 1.6697561740875244 seconds ---\n",
      "episode 5218, reward -257.0, memory_length 2000, epsilon 0.07360811508635084\n",
      "travel time- 720.0\n",
      "--- 1.7445759773254395 seconds ---\n",
      "episode 5219, reward 220.0, memory_length 2000, epsilon 0.07357132022828873\n",
      "travel time- 721.0\n",
      "--- 1.9109034538269043 seconds ---\n",
      "episode 5220, reward 42.0, memory_length 2000, epsilon 0.0735345437630571\n",
      "travel time- 723.0\n",
      "--- 1.7899971008300781 seconds ---\n",
      "episode 5221, reward 154.0, memory_length 2000, epsilon 0.07349778568146174\n",
      "travel time- 721.0\n",
      "--- 1.9274301528930664 seconds ---\n",
      "episode 5222, reward 41.0, memory_length 2000, epsilon 0.0734610459743132\n",
      "travel time- 730.0\n",
      "--- 1.591440200805664 seconds ---\n",
      "episode 5223, reward 287.0, memory_length 2000, epsilon 0.07342432463242657\n",
      "travel time- 720.0\n",
      "--- 1.4924437999725342 seconds ---\n",
      "episode 5224, reward 8.0, memory_length 2000, epsilon 0.07338762164662144\n",
      "travel time- 722.0\n",
      "--- 1.5590717792510986 seconds ---\n",
      "episode 5225, reward -354.0, memory_length 2000, epsilon 0.0733509370077221\n",
      "travel time- 724.0\n",
      "--- 1.672861099243164 seconds ---\n",
      "episode 5226, reward -24.0, memory_length 2000, epsilon 0.07331427070655744\n",
      "travel time- 728.0\n",
      "--- 1.6516737937927246 seconds ---\n",
      "episode 5227, reward 266.0, memory_length 2000, epsilon 0.0732776227339608\n",
      "travel time- 734.0\n",
      "--- 1.5942833423614502 seconds ---\n",
      "episode 5228, reward 184.0, memory_length 2000, epsilon 0.07324099308077024\n",
      "travel time- 728.0\n",
      "--- 1.5165317058563232 seconds ---\n",
      "episode 5229, reward 241.0, memory_length 2000, epsilon 0.07320438173782833\n",
      "travel time- 724.0\n",
      "--- 1.6189470291137695 seconds ---\n",
      "episode 5230, reward 77.0, memory_length 2000, epsilon 0.07316778869598221\n",
      "travel time- 720.0\n",
      "--- 1.9098446369171143 seconds ---\n",
      "episode 5231, reward -38.0, memory_length 2000, epsilon 0.07313121394608368\n",
      "travel time- 721.0\n",
      "--- 1.4866509437561035 seconds ---\n",
      "episode 5232, reward -28.0, memory_length 2000, epsilon 0.07309465747898901\n",
      "travel time- 725.0\n",
      "--- 1.6519982814788818 seconds ---\n",
      "episode 5233, reward -262.0, memory_length 2000, epsilon 0.07305811928555907\n",
      "travel time- 720.0\n",
      "--- 1.6048805713653564 seconds ---\n",
      "episode 5234, reward -143.0, memory_length 2000, epsilon 0.07302159935665936\n",
      "travel time- 727.0\n",
      "--- 1.7020220756530762 seconds ---\n",
      "episode 5235, reward -195.0, memory_length 2000, epsilon 0.07298509768315985\n",
      "travel time- 723.0\n",
      "--- 1.8218307495117188 seconds ---\n",
      "episode 5236, reward 136.0, memory_length 2000, epsilon 0.07294861425593517\n",
      "travel time- 721.0\n",
      "--- 1.7419321537017822 seconds ---\n",
      "episode 5237, reward -100.0, memory_length 2000, epsilon 0.07291214906586439\n",
      "travel time- 722.0\n",
      "--- 1.524691104888916 seconds ---\n",
      "episode 5238, reward -198.0, memory_length 2000, epsilon 0.07287570210383128\n",
      "travel time- 722.0\n",
      "--- 1.5866963863372803 seconds ---\n",
      "episode 5239, reward -349.0, memory_length 2000, epsilon 0.07283927336072409\n",
      "travel time- 720.0\n",
      "--- 2.003220558166504 seconds ---\n",
      "episode 5240, reward 113.0, memory_length 2000, epsilon 0.07280286282743559\n",
      "travel time- 723.0\n",
      "--- 1.6830248832702637 seconds ---\n",
      "episode 5241, reward 88.0, memory_length 2000, epsilon 0.07276647049486318\n",
      "travel time- 724.0\n",
      "--- 1.6371495723724365 seconds ---\n",
      "episode 5242, reward 177.0, memory_length 2000, epsilon 0.0727300963539088\n",
      "travel time- 723.0\n",
      "--- 1.5047597885131836 seconds ---\n",
      "episode 5243, reward 126.0, memory_length 2000, epsilon 0.07269374039547885\n",
      "travel time- 722.0\n",
      "--- 1.7134308815002441 seconds ---\n",
      "episode 5244, reward -34.0, memory_length 2000, epsilon 0.07265740261048442\n",
      "travel time- 725.0\n",
      "--- 1.6649329662322998 seconds ---\n",
      "episode 5245, reward 42.0, memory_length 2000, epsilon 0.07262108298984098\n",
      "travel time- 727.0\n",
      "--- 1.3841886520385742 seconds ---\n",
      "episode 5246, reward 27.0, memory_length 2000, epsilon 0.07258478152446868\n",
      "travel time- 720.0\n",
      "--- 1.827878475189209 seconds ---\n",
      "episode 5247, reward 152.0, memory_length 2000, epsilon 0.07254849820529216\n",
      "travel time- 731.0\n",
      "--- 1.6636431217193604 seconds ---\n",
      "episode 5248, reward -64.0, memory_length 2000, epsilon 0.07251223302324053\n",
      "travel time- 724.0\n",
      "--- 1.6440112590789795 seconds ---\n",
      "episode 5249, reward -175.0, memory_length 2000, epsilon 0.07247598596924758\n",
      "travel time- 720.0\n",
      "--- 1.4709804058074951 seconds ---\n",
      "episode 5250, reward -188.0, memory_length 2000, epsilon 0.07243975703425146\n",
      "travel time- 720.0\n",
      "--- 1.8275279998779297 seconds ---\n",
      "episode 5251, reward -192.0, memory_length 2000, epsilon 0.07240354620919498\n",
      "travel time- 720.0\n",
      "--- 1.588911533355713 seconds ---\n",
      "episode 5252, reward -163.0, memory_length 2000, epsilon 0.07236735348502546\n",
      "travel time- 725.0\n",
      "--- 1.6628084182739258 seconds ---\n",
      "episode 5253, reward -17.0, memory_length 2000, epsilon 0.07233117885269466\n",
      "travel time- 727.0\n",
      "--- 1.5931687355041504 seconds ---\n",
      "episode 5254, reward 203.0, memory_length 2000, epsilon 0.07229502230315894\n",
      "travel time- 724.0\n",
      "--- 1.6628484725952148 seconds ---\n",
      "episode 5255, reward -68.0, memory_length 2000, epsilon 0.07225888382737922\n",
      "travel time- 724.0\n",
      "--- 1.72798752784729 seconds ---\n",
      "episode 5256, reward -53.0, memory_length 2000, epsilon 0.07222276341632078\n",
      "travel time- 720.0\n",
      "--- 1.7656733989715576 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5257, reward -191.0, memory_length 2000, epsilon 0.07218666106095362\n",
      "travel time- 725.0\n",
      "--- 1.7743382453918457 seconds ---\n",
      "episode 5258, reward 360.0, memory_length 2000, epsilon 0.07215057675225206\n",
      "travel time- 724.0\n",
      "--- 1.492936372756958 seconds ---\n",
      "episode 5259, reward -25.0, memory_length 2000, epsilon 0.07211451048119506\n",
      "travel time- 725.0\n",
      "--- 1.445906162261963 seconds ---\n",
      "episode 5260, reward -256.0, memory_length 2000, epsilon 0.0720784622387661\n",
      "travel time- 720.0\n",
      "--- 1.6905851364135742 seconds ---\n",
      "episode 5261, reward 168.0, memory_length 2000, epsilon 0.07204243201595305\n",
      "travel time- 720.0\n",
      "--- 1.6648318767547607 seconds ---\n",
      "episode 5262, reward 166.0, memory_length 2000, epsilon 0.07200641980374836\n",
      "travel time- 731.0\n",
      "--- 1.6755859851837158 seconds ---\n",
      "episode 5263, reward 147.0, memory_length 2000, epsilon 0.07197042559314903\n",
      "travel time- 727.0\n",
      "--- 1.360640048980713 seconds ---\n",
      "episode 5264, reward 103.0, memory_length 2000, epsilon 0.07193444937515645\n",
      "travel time- 720.0\n",
      "--- 1.6528992652893066 seconds ---\n",
      "episode 5265, reward -74.0, memory_length 2000, epsilon 0.07189849114077662\n",
      "travel time- 720.0\n",
      "--- 1.760511875152588 seconds ---\n",
      "episode 5266, reward -225.0, memory_length 2000, epsilon 0.07186255088101991\n",
      "travel time- 723.0\n",
      "--- 1.7092902660369873 seconds ---\n",
      "episode 5267, reward -125.0, memory_length 2000, epsilon 0.0718266285869013\n",
      "travel time- 722.0\n",
      "--- 1.810096263885498 seconds ---\n",
      "episode 5268, reward -181.0, memory_length 2000, epsilon 0.07179072424944025\n",
      "travel time- 724.0\n",
      "--- 1.7809247970581055 seconds ---\n",
      "episode 5269, reward 190.0, memory_length 2000, epsilon 0.07175483785966058\n",
      "travel time- 724.0\n",
      "--- 1.678844928741455 seconds ---\n",
      "episode 5270, reward 30.0, memory_length 2000, epsilon 0.07171896940859077\n",
      "travel time- 726.0\n",
      "--- 1.5605201721191406 seconds ---\n",
      "episode 5271, reward -176.0, memory_length 2000, epsilon 0.07168311888726371\n",
      "travel time- 724.0\n",
      "--- 1.677403450012207 seconds ---\n",
      "episode 5272, reward 173.0, memory_length 2000, epsilon 0.07164728628671672\n",
      "travel time- 728.0\n",
      "--- 1.5688128471374512 seconds ---\n",
      "episode 5273, reward 358.0, memory_length 2000, epsilon 0.07161147159799171\n",
      "travel time- 729.0\n",
      "--- 1.633101463317871 seconds ---\n",
      "episode 5274, reward -29.0, memory_length 2000, epsilon 0.07157567481213492\n",
      "travel time- 725.0\n",
      "--- 1.5548460483551025 seconds ---\n",
      "episode 5275, reward 30.0, memory_length 2000, epsilon 0.07153989592019722\n",
      "travel time- 723.0\n",
      "--- 1.76271653175354 seconds ---\n",
      "episode 5276, reward -221.0, memory_length 2000, epsilon 0.0715041349132339\n",
      "travel time- 726.0\n",
      "--- 1.6877825260162354 seconds ---\n",
      "episode 5277, reward 17.0, memory_length 2000, epsilon 0.07146839178230466\n",
      "travel time- 723.0\n",
      "--- 1.5616624355316162 seconds ---\n",
      "episode 5278, reward -34.0, memory_length 2000, epsilon 0.07143266651847373\n",
      "travel time- 723.0\n",
      "--- 1.707726240158081 seconds ---\n",
      "episode 5279, reward -327.0, memory_length 2000, epsilon 0.07139695911280983\n",
      "travel time- 724.0\n",
      "--- 1.684981346130371 seconds ---\n",
      "episode 5280, reward -39.0, memory_length 2000, epsilon 0.07136126955638605\n",
      "travel time- 723.0\n",
      "--- 1.6491146087646484 seconds ---\n",
      "episode 5281, reward -137.0, memory_length 2000, epsilon 0.07132559784028007\n",
      "travel time- 725.0\n",
      "--- 1.61433744430542 seconds ---\n",
      "episode 5282, reward -222.0, memory_length 2000, epsilon 0.07128994395557388\n",
      "travel time- 727.0\n",
      "--- 2.0256943702697754 seconds ---\n",
      "episode 5283, reward -251.0, memory_length 2000, epsilon 0.07125430789335406\n",
      "travel time- 727.0\n",
      "--- 1.671464443206787 seconds ---\n",
      "episode 5284, reward 44.0, memory_length 2000, epsilon 0.0712186896447116\n",
      "travel time- 721.0\n",
      "--- 1.69248628616333 seconds ---\n",
      "episode 5285, reward -216.0, memory_length 2000, epsilon 0.0711830892007419\n",
      "travel time- 721.0\n",
      "--- 1.5404138565063477 seconds ---\n",
      "episode 5286, reward -323.0, memory_length 2000, epsilon 0.07114750655254487\n",
      "travel time- 729.0\n",
      "--- 1.7034518718719482 seconds ---\n",
      "episode 5287, reward 142.0, memory_length 2000, epsilon 0.0711119416912249\n",
      "travel time- 721.0\n",
      "--- 1.578622817993164 seconds ---\n",
      "episode 5288, reward -132.0, memory_length 2000, epsilon 0.07107639460789066\n",
      "travel time- 720.0\n",
      "--- 1.44521164894104 seconds ---\n",
      "episode 5289, reward -30.0, memory_length 2000, epsilon 0.07104086529365548\n",
      "travel time- 722.0\n",
      "--- 1.4059810638427734 seconds ---\n",
      "episode 5290, reward -98.0, memory_length 2000, epsilon 0.07100535373963698\n",
      "travel time- 726.0\n",
      "--- 1.831847906112671 seconds ---\n",
      "episode 5291, reward 44.0, memory_length 2000, epsilon 0.07096985993695727\n",
      "travel time- 722.0\n",
      "--- 1.6947734355926514 seconds ---\n",
      "episode 5292, reward 81.0, memory_length 2000, epsilon 0.07093438387674295\n",
      "travel time- 720.0\n",
      "--- 1.6458077430725098 seconds ---\n",
      "episode 5293, reward -2.0, memory_length 2000, epsilon 0.07089892555012493\n",
      "travel time- 721.0\n",
      "--- 1.6024651527404785 seconds ---\n",
      "episode 5294, reward -149.0, memory_length 2000, epsilon 0.07086348494823869\n",
      "travel time- 724.0\n",
      "--- 1.8256182670593262 seconds ---\n",
      "episode 5295, reward 231.0, memory_length 2000, epsilon 0.07082806206222406\n",
      "travel time- 720.0\n",
      "--- 1.627790927886963 seconds ---\n",
      "episode 5296, reward -251.0, memory_length 2000, epsilon 0.0707926568832253\n",
      "travel time- 721.0\n",
      "--- 1.7511131763458252 seconds ---\n",
      "episode 5297, reward 94.0, memory_length 2000, epsilon 0.07075726940239115\n",
      "travel time- 721.0\n",
      "--- 1.6953258514404297 seconds ---\n",
      "episode 5298, reward -344.0, memory_length 2000, epsilon 0.07072189961087469\n",
      "travel time- 721.0\n",
      "--- 1.7027990818023682 seconds ---\n",
      "episode 5299, reward 125.0, memory_length 2000, epsilon 0.07068654749983351\n",
      "travel time- 723.0\n",
      "--- 1.6290524005889893 seconds ---\n",
      "episode 5300, reward -148.0, memory_length 2000, epsilon 0.0706512130604296\n",
      "travel time- 721.0\n",
      "--- 1.5224690437316895 seconds ---\n",
      "episode 5301, reward 271.0, memory_length 2000, epsilon 0.07061589628382928\n",
      "travel time- 722.0\n",
      "--- 1.6044983863830566 seconds ---\n",
      "episode 5302, reward 162.0, memory_length 2000, epsilon 0.0705805971612034\n",
      "travel time- 722.0\n",
      "--- 1.471921443939209 seconds ---\n",
      "episode 5303, reward 232.0, memory_length 2000, epsilon 0.07054531568372722\n",
      "travel time- 721.0\n",
      "--- 1.7533812522888184 seconds ---\n",
      "episode 5304, reward -6.0, memory_length 2000, epsilon 0.0705100518425803\n",
      "travel time- 726.0\n",
      "--- 1.6428391933441162 seconds ---\n",
      "episode 5305, reward -36.0, memory_length 2000, epsilon 0.07047480562894674\n",
      "travel time- 727.0\n",
      "--- 1.6803569793701172 seconds ---\n",
      "episode 5306, reward -21.0, memory_length 2000, epsilon 0.07043957703401492\n",
      "travel time- 726.0\n",
      "--- 1.5659902095794678 seconds ---\n",
      "episode 5307, reward 190.0, memory_length 2000, epsilon 0.07040436604897772\n",
      "travel time- 728.0\n",
      "--- 1.67551589012146 seconds ---\n",
      "episode 5308, reward 13.0, memory_length 2000, epsilon 0.07036917266503243\n",
      "travel time- 734.0\n",
      "--- 1.615851879119873 seconds ---\n",
      "episode 5309, reward 238.0, memory_length 2000, epsilon 0.07033399687338064\n",
      "travel time- 721.0\n",
      "--- 1.667391061782837 seconds ---\n",
      "episode 5310, reward 30.0, memory_length 2000, epsilon 0.07029883866522844\n",
      "travel time- 725.0\n",
      "--- 1.7218375205993652 seconds ---\n",
      "episode 5311, reward -3.0, memory_length 2000, epsilon 0.07026369803178631\n",
      "travel time- 720.0\n",
      "--- 1.68117356300354 seconds ---\n",
      "episode 5312, reward -285.0, memory_length 2000, epsilon 0.07022857496426901\n",
      "travel time- 721.0\n",
      "--- 1.672039270401001 seconds ---\n",
      "episode 5313, reward 229.0, memory_length 2000, epsilon 0.07019346945389585\n",
      "travel time- 725.0\n",
      "--- 1.7375519275665283 seconds ---\n",
      "episode 5314, reward -184.0, memory_length 2000, epsilon 0.0701583814918904\n",
      "travel time- 720.0\n",
      "--- 1.5795154571533203 seconds ---\n",
      "episode 5315, reward 378.0, memory_length 2000, epsilon 0.07012331106948068\n",
      "travel time- 722.0\n",
      "--- 1.60986328125 seconds ---\n",
      "episode 5316, reward 28.0, memory_length 2000, epsilon 0.07008825817789911\n",
      "travel time- 733.0\n",
      "--- 1.6692695617675781 seconds ---\n",
      "episode 5317, reward 148.0, memory_length 2000, epsilon 0.07005322280838244\n",
      "travel time- 726.0\n",
      "--- 1.6714606285095215 seconds ---\n",
      "episode 5318, reward -189.0, memory_length 2000, epsilon 0.07001820495217183\n",
      "travel time- 723.0\n",
      "--- 1.7583105564117432 seconds ---\n",
      "episode 5319, reward 330.0, memory_length 2000, epsilon 0.06998320460051284\n",
      "travel time- 727.0\n",
      "--- 1.5673165321350098 seconds ---\n",
      "episode 5320, reward 225.0, memory_length 2000, epsilon 0.06994822174465536\n",
      "travel time- 727.0\n",
      "--- 1.7219617366790771 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5321, reward 40.0, memory_length 2000, epsilon 0.06991325637585369\n",
      "travel time- 723.0\n",
      "--- 1.6271448135375977 seconds ---\n",
      "episode 5322, reward -239.0, memory_length 2000, epsilon 0.06987830848536646\n",
      "travel time- 724.0\n",
      "--- 1.6381886005401611 seconds ---\n",
      "episode 5323, reward -135.0, memory_length 2000, epsilon 0.0698433780644567\n",
      "travel time- 722.0\n",
      "--- 1.6967759132385254 seconds ---\n",
      "episode 5324, reward -30.0, memory_length 2000, epsilon 0.06980846510439187\n",
      "travel time- 725.0\n",
      "--- 1.898827314376831 seconds ---\n",
      "episode 5325, reward -259.0, memory_length 2000, epsilon 0.06977356959644364\n",
      "travel time- 726.0\n",
      "--- 1.7239515781402588 seconds ---\n",
      "episode 5326, reward 5.0, memory_length 2000, epsilon 0.06973869153188816\n",
      "travel time- 732.0\n",
      "--- 1.580118179321289 seconds ---\n",
      "episode 5327, reward 61.0, memory_length 2000, epsilon 0.06970383090200598\n",
      "travel time- 722.0\n",
      "--- 1.6085655689239502 seconds ---\n",
      "episode 5328, reward -114.0, memory_length 2000, epsilon 0.06966898769808184\n",
      "travel time- 726.0\n",
      "--- 1.573587417602539 seconds ---\n",
      "episode 5329, reward -133.0, memory_length 2000, epsilon 0.06963416191140502\n",
      "travel time- 721.0\n",
      "--- 1.8326644897460938 seconds ---\n",
      "episode 5330, reward -129.0, memory_length 2000, epsilon 0.06959935353326901\n",
      "travel time- 720.0\n",
      "--- 1.6314315795898438 seconds ---\n",
      "episode 5331, reward 430.0, memory_length 2000, epsilon 0.06956456255497176\n",
      "travel time- 722.0\n",
      "--- 1.692084550857544 seconds ---\n",
      "episode 5332, reward -318.0, memory_length 2000, epsilon 0.06952978896781553\n",
      "travel time- 720.0\n",
      "--- 1.5758557319641113 seconds ---\n",
      "episode 5333, reward -145.0, memory_length 2000, epsilon 0.06949503276310688\n",
      "travel time- 720.0\n",
      "--- 1.8494007587432861 seconds ---\n",
      "episode 5334, reward -13.0, memory_length 2000, epsilon 0.06946029393215677\n",
      "travel time- 720.0\n",
      "--- 1.8294107913970947 seconds ---\n",
      "episode 5335, reward 163.0, memory_length 2000, epsilon 0.06942557246628055\n",
      "travel time- 720.0\n",
      "--- 1.585237979888916 seconds ---\n",
      "episode 5336, reward 67.0, memory_length 2000, epsilon 0.06939086835679777\n",
      "travel time- 720.0\n",
      "--- 1.643895149230957 seconds ---\n",
      "episode 5337, reward -15.0, memory_length 2000, epsilon 0.06935618159503247\n",
      "travel time- 724.0\n",
      "--- 1.6016380786895752 seconds ---\n",
      "episode 5338, reward 208.0, memory_length 2000, epsilon 0.0693215121723129\n",
      "travel time- 720.0\n",
      "--- 1.6143014430999756 seconds ---\n",
      "episode 5339, reward -116.0, memory_length 2000, epsilon 0.06928686007997174\n",
      "travel time- 723.0\n",
      "--- 1.7046632766723633 seconds ---\n",
      "episode 5340, reward 154.0, memory_length 2000, epsilon 0.069252225309346\n",
      "travel time- 725.0\n",
      "--- 1.6857378482818604 seconds ---\n",
      "episode 5341, reward -218.0, memory_length 2000, epsilon 0.0692176078517769\n",
      "travel time- 721.0\n",
      "--- 1.7705962657928467 seconds ---\n",
      "episode 5342, reward 63.0, memory_length 2000, epsilon 0.06918300769861012\n",
      "travel time- 722.0\n",
      "--- 1.6242420673370361 seconds ---\n",
      "episode 5343, reward 302.0, memory_length 2000, epsilon 0.06914842484119567\n",
      "travel time- 722.0\n",
      "--- 1.583430290222168 seconds ---\n",
      "episode 5344, reward -73.0, memory_length 2000, epsilon 0.06911385927088774\n",
      "travel time- 728.0\n",
      "--- 1.5161221027374268 seconds ---\n",
      "episode 5345, reward -203.0, memory_length 2000, epsilon 0.06907931097904504\n",
      "travel time- 727.0\n",
      "--- 1.6098783016204834 seconds ---\n",
      "episode 5346, reward -61.0, memory_length 2000, epsilon 0.06904477995703041\n",
      "travel time- 725.0\n",
      "--- 1.592613935470581 seconds ---\n",
      "episode 5347, reward 25.0, memory_length 2000, epsilon 0.06901026619621112\n",
      "travel time- 727.0\n",
      "--- 1.6715521812438965 seconds ---\n",
      "episode 5348, reward -247.0, memory_length 2000, epsilon 0.06897576968795878\n",
      "travel time- 725.0\n",
      "--- 1.6419100761413574 seconds ---\n",
      "episode 5349, reward 170.0, memory_length 2000, epsilon 0.06894129042364917\n",
      "travel time- 724.0\n",
      "--- 1.5682530403137207 seconds ---\n",
      "episode 5350, reward 24.0, memory_length 2000, epsilon 0.06890682839466256\n",
      "travel time- 724.0\n",
      "--- 1.6283650398254395 seconds ---\n",
      "episode 5351, reward -183.0, memory_length 2000, epsilon 0.0688723835923834\n",
      "travel time- 723.0\n",
      "--- 1.8424131870269775 seconds ---\n",
      "episode 5352, reward -68.0, memory_length 2000, epsilon 0.06883795600820049\n",
      "travel time- 728.0\n",
      "--- 1.7675294876098633 seconds ---\n",
      "episode 5353, reward 192.0, memory_length 2000, epsilon 0.06880354563350696\n",
      "travel time- 724.0\n",
      "--- 1.9128763675689697 seconds ---\n",
      "episode 5354, reward -127.0, memory_length 2000, epsilon 0.06876915245970018\n",
      "travel time- 727.0\n",
      "--- 1.6240918636322021 seconds ---\n",
      "episode 5355, reward -36.0, memory_length 2000, epsilon 0.06873477647818187\n",
      "travel time- 725.0\n",
      "--- 1.6910400390625 seconds ---\n",
      "episode 5356, reward -72.0, memory_length 2000, epsilon 0.06870041768035805\n",
      "travel time- 723.0\n",
      "--- 1.9741246700286865 seconds ---\n",
      "episode 5357, reward -99.0, memory_length 2000, epsilon 0.068666076057639\n",
      "travel time- 722.0\n",
      "--- 1.5384013652801514 seconds ---\n",
      "episode 5358, reward 146.0, memory_length 2000, epsilon 0.0686317516014393\n",
      "travel time- 721.0\n",
      "--- 1.6813795566558838 seconds ---\n",
      "episode 5359, reward 223.0, memory_length 2000, epsilon 0.0685974443031779\n",
      "travel time- 722.0\n",
      "--- 1.5118281841278076 seconds ---\n",
      "episode 5360, reward 222.0, memory_length 2000, epsilon 0.06856315415427791\n",
      "travel time- 720.0\n",
      "--- 1.7105863094329834 seconds ---\n",
      "episode 5361, reward -146.0, memory_length 2000, epsilon 0.06852888114616684\n",
      "travel time- 724.0\n",
      "--- 1.769989013671875 seconds ---\n",
      "episode 5362, reward -179.0, memory_length 2000, epsilon 0.06849462527027637\n",
      "travel time- 720.0\n",
      "--- 1.6536340713500977 seconds ---\n",
      "episode 5363, reward 164.0, memory_length 2000, epsilon 0.06846038651804259\n",
      "travel time- 723.0\n",
      "--- 1.5790774822235107 seconds ---\n",
      "episode 5364, reward 42.0, memory_length 2000, epsilon 0.06842616488090583\n",
      "travel time- 723.0\n",
      "--- 1.5247302055358887 seconds ---\n",
      "episode 5365, reward 36.0, memory_length 2000, epsilon 0.0683919603503106\n",
      "travel time- 724.0\n",
      "--- 1.5799305438995361 seconds ---\n",
      "episode 5366, reward 129.0, memory_length 2000, epsilon 0.06835777291770583\n",
      "travel time- 721.0\n",
      "--- 1.6944448947906494 seconds ---\n",
      "episode 5367, reward 173.0, memory_length 2000, epsilon 0.06832360257454467\n",
      "travel time- 720.0\n",
      "--- 1.56392240524292 seconds ---\n",
      "episode 5368, reward 135.0, memory_length 2000, epsilon 0.06828944931228448\n",
      "travel time- 733.0\n",
      "--- 1.7762706279754639 seconds ---\n",
      "episode 5369, reward 11.0, memory_length 2000, epsilon 0.068255313122387\n",
      "travel time- 720.0\n",
      "--- 1.6001148223876953 seconds ---\n",
      "episode 5370, reward -117.0, memory_length 2000, epsilon 0.06822119399631812\n",
      "travel time- 731.0\n",
      "--- 1.6752474308013916 seconds ---\n",
      "episode 5371, reward -219.0, memory_length 2000, epsilon 0.0681870919255481\n",
      "travel time- 727.0\n",
      "--- 1.932091474533081 seconds ---\n",
      "episode 5372, reward -68.0, memory_length 2000, epsilon 0.06815300690155146\n",
      "travel time- 723.0\n",
      "--- 1.755645751953125 seconds ---\n",
      "episode 5373, reward -80.0, memory_length 2000, epsilon 0.06811893891580685\n",
      "travel time- 721.0\n",
      "--- 1.7963628768920898 seconds ---\n",
      "episode 5374, reward 158.0, memory_length 2000, epsilon 0.06808488795979734\n",
      "travel time- 723.0\n",
      "--- 1.9469103813171387 seconds ---\n",
      "episode 5375, reward -136.0, memory_length 2000, epsilon 0.0680508540250102\n",
      "travel time- 724.0\n",
      "--- 1.6535398960113525 seconds ---\n",
      "episode 5376, reward 141.0, memory_length 2000, epsilon 0.06801683710293688\n",
      "travel time- 728.0\n",
      "--- 1.648116111755371 seconds ---\n",
      "episode 5377, reward -136.0, memory_length 2000, epsilon 0.06798283718507322\n",
      "travel time- 734.0\n",
      "--- 1.7214715480804443 seconds ---\n",
      "episode 5378, reward -157.0, memory_length 2000, epsilon 0.0679488542629192\n",
      "travel time- 725.0\n",
      "--- 1.5865931510925293 seconds ---\n",
      "episode 5379, reward -8.0, memory_length 2000, epsilon 0.06791488832797908\n",
      "travel time- 721.0\n",
      "--- 1.6184568405151367 seconds ---\n",
      "episode 5380, reward -179.0, memory_length 2000, epsilon 0.06788093937176144\n",
      "travel time- 733.0\n",
      "--- 1.7876136302947998 seconds ---\n",
      "episode 5381, reward -25.0, memory_length 2000, epsilon 0.06784700738577897\n",
      "travel time- 723.0\n",
      "--- 1.9535698890686035 seconds ---\n",
      "episode 5382, reward -45.0, memory_length 2000, epsilon 0.06781309236154871\n",
      "travel time- 722.0\n",
      "--- 1.5591826438903809 seconds ---\n",
      "episode 5383, reward 164.0, memory_length 2000, epsilon 0.06777919429059187\n",
      "travel time- 722.0\n",
      "--- 1.656641960144043 seconds ---\n",
      "episode 5384, reward 264.0, memory_length 2000, epsilon 0.06774531316443397\n",
      "travel time- 725.0\n",
      "--- 1.5488924980163574 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5385, reward -285.0, memory_length 2000, epsilon 0.06771144897460472\n",
      "travel time- 720.0\n",
      "--- 1.717198371887207 seconds ---\n",
      "episode 5386, reward -236.0, memory_length 2000, epsilon 0.06767760171263805\n",
      "travel time- 724.0\n",
      "--- 1.7336618900299072 seconds ---\n",
      "episode 5387, reward 187.0, memory_length 2000, epsilon 0.06764377137007216\n",
      "travel time- 725.0\n",
      "--- 1.8118386268615723 seconds ---\n",
      "episode 5388, reward 146.0, memory_length 2000, epsilon 0.0676099579384495\n",
      "travel time- 727.0\n",
      "--- 1.596412181854248 seconds ---\n",
      "episode 5389, reward -76.0, memory_length 2000, epsilon 0.06757616140931665\n",
      "travel time- 720.0\n",
      "--- 1.6888632774353027 seconds ---\n",
      "episode 5390, reward 163.0, memory_length 2000, epsilon 0.06754238177422452\n",
      "travel time- 721.0\n",
      "--- 1.5137090682983398 seconds ---\n",
      "episode 5391, reward -44.0, memory_length 2000, epsilon 0.06750861902472816\n",
      "travel time- 722.0\n",
      "--- 1.6924481391906738 seconds ---\n",
      "episode 5392, reward 52.0, memory_length 2000, epsilon 0.0674748731523869\n",
      "travel time- 723.0\n",
      "--- 1.5586886405944824 seconds ---\n",
      "episode 5393, reward -260.0, memory_length 2000, epsilon 0.06744114414876433\n",
      "travel time- 730.0\n",
      "--- 1.7259070873260498 seconds ---\n",
      "episode 5394, reward 100.0, memory_length 2000, epsilon 0.0674074320054281\n",
      "travel time- 723.0\n",
      "--- 1.53110671043396 seconds ---\n",
      "episode 5395, reward 119.0, memory_length 2000, epsilon 0.06737373671395024\n",
      "travel time- 720.0\n",
      "--- 1.807999610900879 seconds ---\n",
      "episode 5396, reward -187.0, memory_length 2000, epsilon 0.06734005826590692\n",
      "travel time- 722.0\n",
      "--- 1.9384398460388184 seconds ---\n",
      "episode 5397, reward 165.0, memory_length 2000, epsilon 0.06730639665287849\n",
      "travel time- 722.0\n",
      "--- 1.6420021057128906 seconds ---\n",
      "episode 5398, reward -43.0, memory_length 2000, epsilon 0.06727275186644961\n",
      "travel time- 728.0\n",
      "--- 1.6486117839813232 seconds ---\n",
      "episode 5399, reward -63.0, memory_length 2000, epsilon 0.06723912389820902\n",
      "travel time- 732.0\n",
      "--- 1.7734246253967285 seconds ---\n",
      "episode 5400, reward -41.0, memory_length 2000, epsilon 0.06720551273974976\n",
      "travel time- 725.0\n",
      "--- 1.847566843032837 seconds ---\n",
      "episode 5401, reward -156.0, memory_length 2000, epsilon 0.06717191838266905\n",
      "travel time- 722.0\n",
      "--- 1.7315845489501953 seconds ---\n",
      "episode 5402, reward -29.0, memory_length 2000, epsilon 0.06713834081856826\n",
      "travel time- 724.0\n",
      "--- 1.9504239559173584 seconds ---\n",
      "episode 5403, reward -12.0, memory_length 2000, epsilon 0.06710478003905303\n",
      "travel time- 726.0\n",
      "--- 1.7416620254516602 seconds ---\n",
      "episode 5404, reward 144.0, memory_length 2000, epsilon 0.06707123603573319\n",
      "travel time- 720.0\n",
      "--- 1.5757486820220947 seconds ---\n",
      "episode 5405, reward -222.0, memory_length 2000, epsilon 0.06703770880022267\n",
      "travel time- 724.0\n",
      "--- 1.717437505722046 seconds ---\n",
      "episode 5406, reward 93.0, memory_length 2000, epsilon 0.06700419832413973\n",
      "travel time- 724.0\n",
      "--- 1.568908452987671 seconds ---\n",
      "episode 5407, reward 50.0, memory_length 2000, epsilon 0.06697070459910669\n",
      "travel time- 736.0\n",
      "--- 1.6256330013275146 seconds ---\n",
      "episode 5408, reward -65.0, memory_length 2000, epsilon 0.06693722761675015\n",
      "travel time- 723.0\n",
      "--- 1.6353938579559326 seconds ---\n",
      "episode 5409, reward -147.0, memory_length 2000, epsilon 0.0669037673687009\n",
      "travel time- 724.0\n",
      "--- 1.7631919384002686 seconds ---\n",
      "episode 5410, reward -233.0, memory_length 2000, epsilon 0.0668703238465938\n",
      "travel time- 721.0\n",
      "--- 1.6958136558532715 seconds ---\n",
      "episode 5411, reward -8.0, memory_length 2000, epsilon 0.06683689704206802\n",
      "travel time- 724.0\n",
      "--- 1.7648463249206543 seconds ---\n",
      "episode 5412, reward -103.0, memory_length 2000, epsilon 0.06680348694676687\n",
      "travel time- 722.0\n",
      "--- 1.788923740386963 seconds ---\n",
      "episode 5413, reward 189.0, memory_length 2000, epsilon 0.06677009355233778\n",
      "travel time- 720.0\n",
      "--- 1.522096872329712 seconds ---\n",
      "episode 5414, reward -32.0, memory_length 2000, epsilon 0.06673671685043246\n",
      "travel time- 729.0\n",
      "--- 1.6838791370391846 seconds ---\n",
      "episode 5415, reward 153.0, memory_length 2000, epsilon 0.06670335683270666\n",
      "travel time- 726.0\n",
      "--- 1.6286053657531738 seconds ---\n",
      "episode 5416, reward 233.0, memory_length 2000, epsilon 0.06667001349082043\n",
      "travel time- 729.0\n",
      "--- 1.4036879539489746 seconds ---\n",
      "episode 5417, reward -298.0, memory_length 2000, epsilon 0.06663668681643793\n",
      "travel time- 723.0\n",
      "--- 1.7909741401672363 seconds ---\n",
      "episode 5418, reward 215.0, memory_length 2000, epsilon 0.06660337680122747\n",
      "travel time- 723.0\n",
      "--- 1.4610977172851562 seconds ---\n",
      "episode 5419, reward -291.0, memory_length 2000, epsilon 0.06657008343686154\n",
      "travel time- 722.0\n",
      "--- 1.7421462535858154 seconds ---\n",
      "episode 5420, reward 0.0, memory_length 2000, epsilon 0.06653680671501686\n",
      "travel time- 720.0\n",
      "--- 1.8318638801574707 seconds ---\n",
      "episode 5421, reward 38.0, memory_length 2000, epsilon 0.06650354662737416\n",
      "travel time- 725.0\n",
      "--- 1.7579092979431152 seconds ---\n",
      "episode 5422, reward 21.0, memory_length 2000, epsilon 0.0664703031656185\n",
      "travel time- 727.0\n",
      "--- 1.652108907699585 seconds ---\n",
      "episode 5423, reward 204.0, memory_length 2000, epsilon 0.06643707632143896\n",
      "travel time- 723.0\n",
      "--- 1.5913536548614502 seconds ---\n",
      "episode 5424, reward 82.0, memory_length 2000, epsilon 0.06640386608652883\n",
      "travel time- 722.0\n",
      "--- 1.651465892791748 seconds ---\n",
      "episode 5425, reward -335.0, memory_length 2000, epsilon 0.0663706724525856\n",
      "travel time- 725.0\n",
      "--- 1.6508073806762695 seconds ---\n",
      "episode 5426, reward 95.0, memory_length 2000, epsilon 0.06633749541131082\n",
      "travel time- 725.0\n",
      "--- 1.6584253311157227 seconds ---\n",
      "episode 5427, reward 435.0, memory_length 2000, epsilon 0.06630433495441021\n",
      "travel time- 726.0\n",
      "--- 1.6253843307495117 seconds ---\n",
      "episode 5428, reward -29.0, memory_length 2000, epsilon 0.06627119107359372\n",
      "travel time- 724.0\n",
      "--- 1.7250261306762695 seconds ---\n",
      "episode 5429, reward 85.0, memory_length 2000, epsilon 0.06623806376057532\n",
      "travel time- 722.0\n",
      "--- 1.5547747611999512 seconds ---\n",
      "episode 5430, reward 101.0, memory_length 2000, epsilon 0.06620495300707324\n",
      "travel time- 722.0\n",
      "--- 1.693291425704956 seconds ---\n",
      "episode 5431, reward 145.0, memory_length 2000, epsilon 0.06617185880480972\n",
      "travel time- 722.0\n",
      "--- 1.433802604675293 seconds ---\n",
      "episode 5432, reward -353.0, memory_length 2000, epsilon 0.06613878114551125\n",
      "travel time- 721.0\n",
      "--- 1.7585184574127197 seconds ---\n",
      "episode 5433, reward -107.0, memory_length 2000, epsilon 0.06610572002090843\n",
      "travel time- 722.0\n",
      "--- 1.702284812927246 seconds ---\n",
      "episode 5434, reward 148.0, memory_length 2000, epsilon 0.06607267542273594\n",
      "travel time- 726.0\n",
      "--- 1.542750358581543 seconds ---\n",
      "episode 5435, reward 190.0, memory_length 2000, epsilon 0.06603964734273264\n",
      "travel time- 724.0\n",
      "--- 1.5003399848937988 seconds ---\n",
      "episode 5436, reward -130.0, memory_length 2000, epsilon 0.06600663577264156\n",
      "travel time- 721.0\n",
      "--- 1.5636882781982422 seconds ---\n",
      "episode 5437, reward -29.0, memory_length 2000, epsilon 0.06597364070420973\n",
      "travel time- 722.0\n",
      "--- 1.6943087577819824 seconds ---\n",
      "episode 5438, reward 230.0, memory_length 2000, epsilon 0.06594066212918846\n",
      "travel time- 721.0\n",
      "--- 1.6163723468780518 seconds ---\n",
      "episode 5439, reward 3.0, memory_length 2000, epsilon 0.06590770003933302\n",
      "travel time- 722.0\n",
      "--- 1.6585638523101807 seconds ---\n",
      "episode 5440, reward 176.0, memory_length 2000, epsilon 0.06587475442640295\n",
      "travel time- 722.0\n",
      "--- 1.9925906658172607 seconds ---\n",
      "episode 5441, reward -381.0, memory_length 2000, epsilon 0.06584182528216186\n",
      "travel time- 725.0\n",
      "--- 1.972782850265503 seconds ---\n",
      "episode 5442, reward 108.0, memory_length 2000, epsilon 0.06580891259837739\n",
      "travel time- 722.0\n",
      "--- 1.728050947189331 seconds ---\n",
      "episode 5443, reward 86.0, memory_length 2000, epsilon 0.06577601636682141\n",
      "travel time- 720.0\n",
      "--- 1.7419850826263428 seconds ---\n",
      "episode 5444, reward 88.0, memory_length 2000, epsilon 0.0657431365792699\n",
      "travel time- 721.0\n",
      "--- 1.893538236618042 seconds ---\n",
      "episode 5445, reward -189.0, memory_length 2000, epsilon 0.06571027322750285\n",
      "travel time- 720.0\n",
      "--- 1.6420354843139648 seconds ---\n",
      "episode 5446, reward 40.0, memory_length 2000, epsilon 0.06567742630330448\n",
      "travel time- 721.0\n",
      "--- 1.6477992534637451 seconds ---\n",
      "episode 5447, reward 62.0, memory_length 2000, epsilon 0.06564459579846299\n",
      "travel time- 722.0\n",
      "--- 1.7478110790252686 seconds ---\n",
      "episode 5448, reward 68.0, memory_length 2000, epsilon 0.0656117817047708\n",
      "travel time- 731.0\n",
      "--- 1.7470107078552246 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5449, reward -58.0, memory_length 2000, epsilon 0.06557898401402441\n",
      "travel time- 722.0\n",
      "--- 1.727112054824829 seconds ---\n",
      "episode 5450, reward 75.0, memory_length 2000, epsilon 0.06554620271802433\n",
      "travel time- 723.0\n",
      "--- 1.6630017757415771 seconds ---\n",
      "episode 5451, reward 75.0, memory_length 2000, epsilon 0.06551343780857527\n",
      "travel time- 721.0\n",
      "--- 1.5942020416259766 seconds ---\n",
      "episode 5452, reward -59.0, memory_length 2000, epsilon 0.06548068927748603\n",
      "travel time- 726.0\n",
      "--- 1.7001824378967285 seconds ---\n",
      "episode 5453, reward 106.0, memory_length 2000, epsilon 0.06544795711656942\n",
      "travel time- 722.0\n",
      "--- 1.5674939155578613 seconds ---\n",
      "episode 5454, reward 464.0, memory_length 2000, epsilon 0.06541524131764247\n",
      "travel time- 728.0\n",
      "--- 1.6022975444793701 seconds ---\n",
      "episode 5455, reward 135.0, memory_length 2000, epsilon 0.06538254187252616\n",
      "travel time- 722.0\n",
      "--- 1.644395351409912 seconds ---\n",
      "episode 5456, reward -82.0, memory_length 2000, epsilon 0.06534985877304565\n",
      "travel time- 721.0\n",
      "--- 1.767967700958252 seconds ---\n",
      "episode 5457, reward 84.0, memory_length 2000, epsilon 0.06531719201103021\n",
      "travel time- 722.0\n",
      "--- 1.668475866317749 seconds ---\n",
      "episode 5458, reward 121.0, memory_length 2000, epsilon 0.06528454157831308\n",
      "travel time- 724.0\n",
      "--- 1.4778528213500977 seconds ---\n",
      "episode 5459, reward -65.0, memory_length 2000, epsilon 0.06525190746673168\n",
      "travel time- 725.0\n",
      "--- 1.830613613128662 seconds ---\n",
      "episode 5460, reward 54.0, memory_length 2000, epsilon 0.06521928966812753\n",
      "travel time- 720.0\n",
      "--- 1.6327934265136719 seconds ---\n",
      "episode 5461, reward 178.0, memory_length 2000, epsilon 0.0651866881743461\n",
      "travel time- 725.0\n",
      "--- 1.5339269638061523 seconds ---\n",
      "episode 5462, reward -197.0, memory_length 2000, epsilon 0.06515410297723707\n",
      "travel time- 730.0\n",
      "--- 1.7194609642028809 seconds ---\n",
      "episode 5463, reward 228.0, memory_length 2000, epsilon 0.0651215340686541\n",
      "travel time- 736.0\n",
      "--- 1.7035012245178223 seconds ---\n",
      "episode 5464, reward -173.0, memory_length 2000, epsilon 0.065088981440455\n",
      "travel time- 726.0\n",
      "--- 1.6920487880706787 seconds ---\n",
      "episode 5465, reward -123.0, memory_length 2000, epsilon 0.06505644508450162\n",
      "travel time- 722.0\n",
      "--- 1.6678366661071777 seconds ---\n",
      "episode 5466, reward -111.0, memory_length 2000, epsilon 0.06502392499265983\n",
      "travel time- 723.0\n",
      "--- 1.5749871730804443 seconds ---\n",
      "episode 5467, reward 61.0, memory_length 2000, epsilon 0.06499142115679961\n",
      "travel time- 725.0\n",
      "--- 1.628171443939209 seconds ---\n",
      "episode 5468, reward 145.0, memory_length 2000, epsilon 0.06495893356879505\n",
      "travel time- 724.0\n",
      "--- 1.8860712051391602 seconds ---\n",
      "episode 5469, reward -67.0, memory_length 2000, epsilon 0.0649264622205242\n",
      "travel time- 722.0\n",
      "--- 1.655012607574463 seconds ---\n",
      "episode 5470, reward 112.0, memory_length 2000, epsilon 0.06489400710386926\n",
      "travel time- 725.0\n",
      "--- 1.4871888160705566 seconds ---\n",
      "episode 5471, reward -373.0, memory_length 2000, epsilon 0.06486156821071642\n",
      "travel time- 724.0\n",
      "--- 1.8537538051605225 seconds ---\n",
      "episode 5472, reward 319.0, memory_length 2000, epsilon 0.06482914553295596\n",
      "travel time- 732.0\n",
      "--- 1.6194469928741455 seconds ---\n",
      "episode 5473, reward 121.0, memory_length 2000, epsilon 0.06479673906248226\n",
      "travel time- 727.0\n",
      "--- 1.6486296653747559 seconds ---\n",
      "episode 5474, reward 72.0, memory_length 2000, epsilon 0.06476434879119362\n",
      "travel time- 723.0\n",
      "--- 1.7978222370147705 seconds ---\n",
      "episode 5475, reward -51.0, memory_length 2000, epsilon 0.06473197471099253\n",
      "travel time- 723.0\n",
      "--- 1.6687519550323486 seconds ---\n",
      "episode 5476, reward 155.0, memory_length 2000, epsilon 0.06469961681378547\n",
      "travel time- 723.0\n",
      "--- 1.7739548683166504 seconds ---\n",
      "episode 5477, reward 310.0, memory_length 2000, epsilon 0.06466727509148293\n",
      "travel time- 736.0\n",
      "--- 1.7055916786193848 seconds ---\n",
      "episode 5478, reward 108.0, memory_length 2000, epsilon 0.06463494953599953\n",
      "travel time- 729.0\n",
      "--- 1.9740560054779053 seconds ---\n",
      "episode 5479, reward 177.0, memory_length 2000, epsilon 0.06460264013925382\n",
      "travel time- 723.0\n",
      "--- 1.7101702690124512 seconds ---\n",
      "episode 5480, reward -100.0, memory_length 2000, epsilon 0.06457034689316847\n",
      "travel time- 726.0\n",
      "--- 1.753209114074707 seconds ---\n",
      "episode 5481, reward 47.0, memory_length 2000, epsilon 0.06453806978967022\n",
      "travel time- 734.0\n",
      "--- 1.6582958698272705 seconds ---\n",
      "episode 5482, reward -229.0, memory_length 2000, epsilon 0.06450580882068972\n",
      "travel time- 722.0\n",
      "--- 1.6636652946472168 seconds ---\n",
      "episode 5483, reward -170.0, memory_length 2000, epsilon 0.06447356397816177\n",
      "travel time- 729.0\n",
      "--- 1.5929384231567383 seconds ---\n",
      "episode 5484, reward 87.0, memory_length 2000, epsilon 0.06444133525402518\n",
      "travel time- 730.0\n",
      "--- 1.6892061233520508 seconds ---\n",
      "episode 5485, reward -226.0, memory_length 2000, epsilon 0.0644091226402227\n",
      "travel time- 729.0\n",
      "--- 1.6702470779418945 seconds ---\n",
      "episode 5486, reward 305.0, memory_length 2000, epsilon 0.06437692612870125\n",
      "travel time- 720.0\n",
      "--- 1.5151383876800537 seconds ---\n",
      "episode 5487, reward 290.0, memory_length 2000, epsilon 0.06434474571141163\n",
      "travel time- 721.0\n",
      "--- 1.722332239151001 seconds ---\n",
      "episode 5488, reward 64.0, memory_length 2000, epsilon 0.06431258138030878\n",
      "travel time- 723.0\n",
      "--- 1.7136523723602295 seconds ---\n",
      "episode 5489, reward -114.0, memory_length 2000, epsilon 0.06428043312735164\n",
      "travel time- 721.0\n",
      "--- 1.5496387481689453 seconds ---\n",
      "episode 5490, reward 62.0, memory_length 2000, epsilon 0.06424830094450308\n",
      "travel time- 728.0\n",
      "--- 1.7811388969421387 seconds ---\n",
      "episode 5491, reward 345.0, memory_length 2000, epsilon 0.0642161848237301\n",
      "travel time- 720.0\n",
      "--- 1.4154253005981445 seconds ---\n",
      "episode 5492, reward 14.0, memory_length 2000, epsilon 0.06418408475700368\n",
      "travel time- 724.0\n",
      "--- 1.733922004699707 seconds ---\n",
      "episode 5493, reward 131.0, memory_length 2000, epsilon 0.06415200073629877\n",
      "travel time- 726.0\n",
      "--- 1.8486111164093018 seconds ---\n",
      "episode 5494, reward -62.0, memory_length 2000, epsilon 0.0641199327535944\n",
      "travel time- 726.0\n",
      "--- 1.5484120845794678 seconds ---\n",
      "episode 5495, reward -89.0, memory_length 2000, epsilon 0.06408788080087352\n",
      "travel time- 721.0\n",
      "--- 1.7562766075134277 seconds ---\n",
      "episode 5496, reward -41.0, memory_length 2000, epsilon 0.06405584487012317\n",
      "travel time- 724.0\n",
      "--- 1.655540943145752 seconds ---\n",
      "episode 5497, reward -53.0, memory_length 2000, epsilon 0.0640238249533344\n",
      "travel time- 724.0\n",
      "--- 1.6482975482940674 seconds ---\n",
      "episode 5498, reward -43.0, memory_length 2000, epsilon 0.06399182104250219\n",
      "travel time- 726.0\n",
      "--- 1.57411527633667 seconds ---\n",
      "episode 5499, reward 134.0, memory_length 2000, epsilon 0.06395983312962555\n",
      "travel time- 723.0\n",
      "--- 1.592071771621704 seconds ---\n",
      "episode 5500, reward -184.0, memory_length 2000, epsilon 0.06392786120670757\n",
      "travel time- 725.0\n",
      "--- 2.109225273132324 seconds ---\n",
      "episode 5501, reward 7.0, memory_length 2000, epsilon 0.0638959052657552\n",
      "travel time- 727.0\n",
      "--- 1.826439380645752 seconds ---\n",
      "episode 5502, reward -454.0, memory_length 2000, epsilon 0.0638639652987795\n",
      "travel time- 720.0\n",
      "--- 1.7211072444915771 seconds ---\n",
      "episode 5503, reward 213.0, memory_length 2000, epsilon 0.06383204129779542\n",
      "travel time- 721.0\n",
      "--- 1.728100299835205 seconds ---\n",
      "episode 5504, reward -78.0, memory_length 2000, epsilon 0.063800133254822\n",
      "travel time- 722.0\n",
      "--- 1.882115125656128 seconds ---\n",
      "episode 5505, reward 18.0, memory_length 2000, epsilon 0.06376824116188227\n",
      "travel time- 722.0\n",
      "--- 1.559349775314331 seconds ---\n",
      "episode 5506, reward 65.0, memory_length 2000, epsilon 0.06373636501100312\n",
      "travel time- 721.0\n",
      "--- 1.530527114868164 seconds ---\n",
      "episode 5507, reward 1.0, memory_length 2000, epsilon 0.06370450479421559\n",
      "travel time- 730.0\n",
      "--- 1.7795405387878418 seconds ---\n",
      "episode 5508, reward -81.0, memory_length 2000, epsilon 0.06367266050355457\n",
      "travel time- 721.0\n",
      "--- 1.7167332172393799 seconds ---\n",
      "episode 5509, reward -129.0, memory_length 2000, epsilon 0.06364083213105899\n",
      "travel time- 722.0\n",
      "--- 1.6000480651855469 seconds ---\n",
      "episode 5510, reward -302.0, memory_length 2000, epsilon 0.0636090196687718\n",
      "travel time- 726.0\n",
      "--- 1.6147913932800293 seconds ---\n",
      "episode 5511, reward 156.0, memory_length 2000, epsilon 0.06357722310873985\n",
      "travel time- 734.0\n",
      "--- 1.8084897994995117 seconds ---\n",
      "episode 5512, reward 163.0, memory_length 2000, epsilon 0.063545442443014\n",
      "travel time- 720.0\n",
      "--- 1.536196231842041 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5513, reward 287.0, memory_length 2000, epsilon 0.06351367766364911\n",
      "travel time- 721.0\n",
      "--- 1.5650227069854736 seconds ---\n",
      "episode 5514, reward 49.0, memory_length 2000, epsilon 0.06348192876270395\n",
      "travel time- 724.0\n",
      "--- 1.6648972034454346 seconds ---\n",
      "episode 5515, reward 14.0, memory_length 2000, epsilon 0.06345019573224134\n",
      "travel time- 720.0\n",
      "--- 1.60316801071167 seconds ---\n",
      "episode 5516, reward 50.0, memory_length 2000, epsilon 0.06341847856432796\n",
      "travel time- 720.0\n",
      "--- 1.6942849159240723 seconds ---\n",
      "episode 5517, reward 120.0, memory_length 2000, epsilon 0.06338677725103455\n",
      "travel time- 721.0\n",
      "--- 1.5723185539245605 seconds ---\n",
      "episode 5518, reward -61.0, memory_length 2000, epsilon 0.06335509178443581\n",
      "travel time- 725.0\n",
      "--- 1.648918867111206 seconds ---\n",
      "episode 5519, reward -32.0, memory_length 2000, epsilon 0.06332342215661033\n",
      "travel time- 725.0\n",
      "--- 1.6781556606292725 seconds ---\n",
      "episode 5520, reward -33.0, memory_length 2000, epsilon 0.0632917683596407\n",
      "travel time- 724.0\n",
      "--- 1.5091004371643066 seconds ---\n",
      "episode 5521, reward 199.0, memory_length 2000, epsilon 0.06326013038561354\n",
      "travel time- 727.0\n",
      "--- 1.5705444812774658 seconds ---\n",
      "episode 5522, reward -12.0, memory_length 2000, epsilon 0.06322850822661927\n",
      "travel time- 723.0\n",
      "--- 1.7441272735595703 seconds ---\n",
      "episode 5523, reward -163.0, memory_length 2000, epsilon 0.06319690187475241\n",
      "travel time- 720.0\n",
      "--- 1.6826858520507812 seconds ---\n",
      "episode 5524, reward -317.0, memory_length 2000, epsilon 0.06316531132211131\n",
      "travel time- 729.0\n",
      "--- 1.8855454921722412 seconds ---\n",
      "episode 5525, reward -170.0, memory_length 2000, epsilon 0.06313373656079838\n",
      "travel time- 721.0\n",
      "--- 1.6801869869232178 seconds ---\n",
      "episode 5526, reward 136.0, memory_length 2000, epsilon 0.06310217758291994\n",
      "travel time- 728.0\n",
      "--- 1.602687120437622 seconds ---\n",
      "episode 5527, reward -174.0, memory_length 2000, epsilon 0.06307063438058622\n",
      "travel time- 726.0\n",
      "--- 1.689927339553833 seconds ---\n",
      "episode 5528, reward 163.0, memory_length 2000, epsilon 0.0630391069459114\n",
      "travel time- 732.0\n",
      "--- 1.810227394104004 seconds ---\n",
      "episode 5529, reward -26.0, memory_length 2000, epsilon 0.06300759527101368\n",
      "travel time- 733.0\n",
      "--- 1.4301064014434814 seconds ---\n",
      "episode 5530, reward 100.0, memory_length 2000, epsilon 0.06297609934801507\n",
      "travel time- 732.0\n",
      "--- 1.67816162109375 seconds ---\n",
      "episode 5531, reward -49.0, memory_length 2000, epsilon 0.06294461916904166\n",
      "travel time- 724.0\n",
      "--- 1.4715652465820312 seconds ---\n",
      "episode 5532, reward 158.0, memory_length 2000, epsilon 0.06291315472622334\n",
      "travel time- 721.0\n",
      "--- 1.7030963897705078 seconds ---\n",
      "episode 5533, reward -1.0, memory_length 2000, epsilon 0.06288170601169404\n",
      "travel time- 722.0\n",
      "--- 1.6687190532684326 seconds ---\n",
      "episode 5534, reward 96.0, memory_length 2000, epsilon 0.06285027301759159\n",
      "travel time- 724.0\n",
      "--- 1.666893482208252 seconds ---\n",
      "episode 5535, reward 321.0, memory_length 2000, epsilon 0.0628188557360577\n",
      "travel time- 725.0\n",
      "--- 1.6461594104766846 seconds ---\n",
      "episode 5536, reward 52.0, memory_length 2000, epsilon 0.06278745415923806\n",
      "travel time- 726.0\n",
      "--- 1.7606127262115479 seconds ---\n",
      "episode 5537, reward 40.0, memory_length 2000, epsilon 0.06275606827928232\n",
      "travel time- 724.0\n",
      "--- 1.5837295055389404 seconds ---\n",
      "episode 5538, reward -96.0, memory_length 2000, epsilon 0.06272469808834395\n",
      "travel time- 720.0\n",
      "--- 1.469026803970337 seconds ---\n",
      "episode 5539, reward 172.0, memory_length 2000, epsilon 0.06269334357858045\n",
      "travel time- 726.0\n",
      "--- 1.5098557472229004 seconds ---\n",
      "episode 5540, reward 170.0, memory_length 2000, epsilon 0.06266200474215315\n",
      "travel time- 728.0\n",
      "--- 1.5661907196044922 seconds ---\n",
      "episode 5541, reward 17.0, memory_length 2000, epsilon 0.06263068157122736\n",
      "travel time- 734.0\n",
      "--- 1.6223113536834717 seconds ---\n",
      "episode 5542, reward 72.0, memory_length 2000, epsilon 0.06259937405797232\n",
      "travel time- 725.0\n",
      "--- 1.5836362838745117 seconds ---\n",
      "episode 5543, reward -275.0, memory_length 2000, epsilon 0.06256808219456109\n",
      "travel time- 726.0\n",
      "--- 1.6962926387786865 seconds ---\n",
      "episode 5544, reward -99.0, memory_length 2000, epsilon 0.06253680597317074\n",
      "travel time- 722.0\n",
      "--- 1.6114377975463867 seconds ---\n",
      "episode 5545, reward -198.0, memory_length 2000, epsilon 0.06250554538598223\n",
      "travel time- 721.0\n",
      "--- 1.602203607559204 seconds ---\n",
      "episode 5546, reward -240.0, memory_length 2000, epsilon 0.06247430042518036\n",
      "travel time- 722.0\n",
      "--- 1.5515656471252441 seconds ---\n",
      "episode 5547, reward -280.0, memory_length 2000, epsilon 0.06244307108295395\n",
      "travel time- 720.0\n",
      "--- 1.705368995666504 seconds ---\n",
      "episode 5548, reward 27.0, memory_length 2000, epsilon 0.06241185735149562\n",
      "travel time- 726.0\n",
      "--- 1.8693625926971436 seconds ---\n",
      "episode 5549, reward 218.0, memory_length 2000, epsilon 0.06238065922300194\n",
      "travel time- 725.0\n",
      "--- 1.5051531791687012 seconds ---\n",
      "episode 5550, reward -5.0, memory_length 2000, epsilon 0.06234947668967343\n",
      "travel time- 720.0\n",
      "--- 1.5363056659698486 seconds ---\n",
      "episode 5551, reward -15.0, memory_length 2000, epsilon 0.062318309743714384\n",
      "travel time- 724.0\n",
      "--- 1.6151103973388672 seconds ---\n",
      "episode 5552, reward -344.0, memory_length 2000, epsilon 0.0622871583773331\n",
      "travel time- 723.0\n",
      "--- 1.5736730098724365 seconds ---\n",
      "episode 5553, reward 130.0, memory_length 2000, epsilon 0.06225602258274176\n",
      "travel time- 729.0\n",
      "--- 1.5939669609069824 seconds ---\n",
      "episode 5554, reward 78.0, memory_length 2000, epsilon 0.06222490235215636\n",
      "travel time- 720.0\n",
      "--- 1.6276054382324219 seconds ---\n",
      "episode 5555, reward 37.0, memory_length 2000, epsilon 0.062193797677796904\n",
      "travel time- 733.0\n",
      "--- 1.6406323909759521 seconds ---\n",
      "episode 5556, reward -314.0, memory_length 2000, epsilon 0.062162708551887165\n",
      "travel time- 726.0\n",
      "--- 1.9328596591949463 seconds ---\n",
      "episode 5557, reward -92.0, memory_length 2000, epsilon 0.062131634966654886\n",
      "travel time- 725.0\n",
      "--- 1.7922577857971191 seconds ---\n",
      "episode 5558, reward -170.0, memory_length 2000, epsilon 0.0621005769143317\n",
      "travel time- 722.0\n",
      "--- 1.6661405563354492 seconds ---\n",
      "episode 5559, reward -76.0, memory_length 2000, epsilon 0.062069534387153034\n",
      "travel time- 726.0\n",
      "--- 1.7909224033355713 seconds ---\n",
      "episode 5560, reward 247.0, memory_length 2000, epsilon 0.06203850737735829\n",
      "travel time- 723.0\n",
      "--- 1.876413106918335 seconds ---\n",
      "episode 5561, reward -225.0, memory_length 2000, epsilon 0.062007495877190746\n",
      "travel time- 724.0\n",
      "--- 1.5818531513214111 seconds ---\n",
      "episode 5562, reward 79.0, memory_length 2000, epsilon 0.061976499878897466\n",
      "travel time- 727.0\n",
      "--- 1.5664489269256592 seconds ---\n",
      "episode 5563, reward 158.0, memory_length 2000, epsilon 0.0619455193747295\n",
      "travel time- 729.0\n",
      "--- 1.6077330112457275 seconds ---\n",
      "episode 5564, reward 63.0, memory_length 2000, epsilon 0.061914554356941674\n",
      "travel time- 733.0\n",
      "--- 1.5627927780151367 seconds ---\n",
      "episode 5565, reward -170.0, memory_length 2000, epsilon 0.061883604817792766\n",
      "travel time- 721.0\n",
      "--- 1.8457419872283936 seconds ---\n",
      "episode 5566, reward -31.0, memory_length 2000, epsilon 0.06185267074954541\n",
      "travel time- 728.0\n",
      "--- 1.817354679107666 seconds ---\n",
      "episode 5567, reward 62.0, memory_length 2000, epsilon 0.06182175214446603\n",
      "travel time- 732.0\n",
      "--- 1.409904956817627 seconds ---\n",
      "episode 5568, reward 374.0, memory_length 2000, epsilon 0.061790848994825016\n",
      "travel time- 721.0\n",
      "--- 1.5688602924346924 seconds ---\n",
      "episode 5569, reward 382.0, memory_length 2000, epsilon 0.0617599612928966\n",
      "travel time- 726.0\n",
      "--- 1.6462655067443848 seconds ---\n",
      "episode 5570, reward -194.0, memory_length 2000, epsilon 0.06172908903095879\n",
      "travel time- 725.0\n",
      "--- 1.6936943531036377 seconds ---\n",
      "episode 5571, reward 11.0, memory_length 2000, epsilon 0.0616982322012936\n",
      "travel time- 726.0\n",
      "--- 1.7044873237609863 seconds ---\n",
      "episode 5572, reward 212.0, memory_length 2000, epsilon 0.061667390796186744\n",
      "travel time- 726.0\n",
      "--- 1.642754077911377 seconds ---\n",
      "episode 5573, reward 67.0, memory_length 2000, epsilon 0.06163656480792792\n",
      "travel time- 721.0\n",
      "--- 1.5442869663238525 seconds ---\n",
      "episode 5574, reward 192.0, memory_length 2000, epsilon 0.061605754228810636\n",
      "travel time- 726.0\n",
      "--- 1.5079123973846436 seconds ---\n",
      "episode 5575, reward 46.0, memory_length 2000, epsilon 0.06157495905113221\n",
      "travel time- 733.0\n",
      "--- 1.7436916828155518 seconds ---\n",
      "episode 5576, reward -176.0, memory_length 2000, epsilon 0.06154417926719386\n",
      "travel time- 725.0\n",
      "--- 1.8501288890838623 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5577, reward 38.0, memory_length 2000, epsilon 0.061513414869300675\n",
      "travel time- 728.0\n",
      "--- 1.626225471496582 seconds ---\n",
      "episode 5578, reward -34.0, memory_length 2000, epsilon 0.0614826658497615\n",
      "travel time- 722.0\n",
      "--- 1.754913091659546 seconds ---\n",
      "episode 5579, reward -131.0, memory_length 2000, epsilon 0.061451932200889146\n",
      "travel time- 721.0\n",
      "--- 1.4438591003417969 seconds ---\n",
      "episode 5580, reward -258.0, memory_length 2000, epsilon 0.06142121391500013\n",
      "travel time- 723.0\n",
      "--- 1.764634609222412 seconds ---\n",
      "episode 5581, reward -102.0, memory_length 2000, epsilon 0.061390510984414906\n",
      "travel time- 724.0\n",
      "--- 1.5876400470733643 seconds ---\n",
      "episode 5582, reward -103.0, memory_length 2000, epsilon 0.06135982340145778\n",
      "travel time- 726.0\n",
      "--- 1.5038957595825195 seconds ---\n",
      "episode 5583, reward 42.0, memory_length 2000, epsilon 0.061329151158456795\n",
      "travel time- 725.0\n",
      "--- 1.5065093040466309 seconds ---\n",
      "episode 5584, reward -177.0, memory_length 2000, epsilon 0.061298494247743925\n",
      "travel time- 730.0\n",
      "--- 1.6287939548492432 seconds ---\n",
      "episode 5585, reward 59.0, memory_length 2000, epsilon 0.06126785266165496\n",
      "travel time- 728.0\n",
      "--- 1.7793159484863281 seconds ---\n",
      "episode 5586, reward -26.0, memory_length 2000, epsilon 0.061237226392529445\n",
      "travel time- 720.0\n",
      "--- 1.605966329574585 seconds ---\n",
      "episode 5587, reward 20.0, memory_length 2000, epsilon 0.06120661543271088\n",
      "travel time- 720.0\n",
      "--- 2.0689237117767334 seconds ---\n",
      "episode 5588, reward -209.0, memory_length 2000, epsilon 0.06117601977454647\n",
      "travel time- 725.0\n",
      "--- 1.7738194465637207 seconds ---\n",
      "episode 5589, reward -121.0, memory_length 2000, epsilon 0.06114543941038732\n",
      "travel time- 725.0\n",
      "--- 1.562422752380371 seconds ---\n",
      "episode 5590, reward 35.0, memory_length 2000, epsilon 0.06111487433258836\n",
      "travel time- 723.0\n",
      "--- 1.521960973739624 seconds ---\n",
      "episode 5591, reward 76.0, memory_length 2000, epsilon 0.06108432453350828\n",
      "travel time- 727.0\n",
      "--- 1.4607958793640137 seconds ---\n",
      "episode 5592, reward 102.0, memory_length 2000, epsilon 0.06105379000550965\n",
      "travel time- 734.0\n",
      "--- 1.6941137313842773 seconds ---\n",
      "episode 5593, reward -296.0, memory_length 2000, epsilon 0.06102327074095887\n",
      "travel time- 721.0\n",
      "--- 1.657909870147705 seconds ---\n",
      "episode 5594, reward -26.0, memory_length 2000, epsilon 0.06099276673222606\n",
      "travel time- 730.0\n",
      "--- 1.6184070110321045 seconds ---\n",
      "episode 5595, reward 172.0, memory_length 2000, epsilon 0.06096227797168528\n",
      "travel time- 733.0\n",
      "--- 1.471668004989624 seconds ---\n",
      "episode 5596, reward -95.0, memory_length 2000, epsilon 0.06093180445171429\n",
      "travel time- 721.0\n",
      "--- 1.6733810901641846 seconds ---\n",
      "episode 5597, reward 152.0, memory_length 2000, epsilon 0.060901346164694725\n",
      "travel time- 723.0\n",
      "--- 1.565748929977417 seconds ---\n",
      "episode 5598, reward 27.0, memory_length 2000, epsilon 0.06087090310301205\n",
      "travel time- 720.0\n",
      "--- 1.7255384922027588 seconds ---\n",
      "episode 5599, reward -76.0, memory_length 2000, epsilon 0.06084047525905543\n",
      "travel time- 725.0\n",
      "--- 1.8627591133117676 seconds ---\n",
      "episode 5600, reward 120.0, memory_length 2000, epsilon 0.06081006262521795\n",
      "travel time- 720.0\n",
      "--- 1.7103571891784668 seconds ---\n",
      "episode 5601, reward 57.0, memory_length 2000, epsilon 0.060779665193896465\n",
      "travel time- 728.0\n",
      "--- 1.638460636138916 seconds ---\n",
      "episode 5602, reward 80.0, memory_length 2000, epsilon 0.060749282957491574\n",
      "travel time- 722.0\n",
      "--- 1.5249485969543457 seconds ---\n",
      "episode 5603, reward -78.0, memory_length 2000, epsilon 0.060718915908407764\n",
      "travel time- 724.0\n",
      "--- 1.6847114562988281 seconds ---\n",
      "episode 5604, reward 102.0, memory_length 2000, epsilon 0.06068856403905322\n",
      "travel time- 722.0\n",
      "--- 1.454158067703247 seconds ---\n",
      "episode 5605, reward 15.0, memory_length 2000, epsilon 0.060658227341839996\n",
      "travel time- 728.0\n",
      "--- 1.6061522960662842 seconds ---\n",
      "episode 5606, reward 126.0, memory_length 2000, epsilon 0.06062790580918396\n",
      "travel time- 721.0\n",
      "--- 1.6155707836151123 seconds ---\n",
      "episode 5607, reward -21.0, memory_length 2000, epsilon 0.06059759943350466\n",
      "travel time- 724.0\n",
      "--- 1.5427565574645996 seconds ---\n",
      "episode 5608, reward -79.0, memory_length 2000, epsilon 0.060567308207225536\n",
      "travel time- 720.0\n",
      "--- 1.6280922889709473 seconds ---\n",
      "episode 5609, reward 48.0, memory_length 2000, epsilon 0.0605370321227738\n",
      "travel time- 728.0\n",
      "--- 1.60994291305542 seconds ---\n",
      "episode 5610, reward -57.0, memory_length 2000, epsilon 0.06050677117258039\n",
      "travel time- 727.0\n",
      "--- 1.555081844329834 seconds ---\n",
      "episode 5611, reward -14.0, memory_length 2000, epsilon 0.060476525349080115\n",
      "travel time- 722.0\n",
      "--- 1.5801661014556885 seconds ---\n",
      "episode 5612, reward 179.0, memory_length 2000, epsilon 0.06044629464471146\n",
      "travel time- 724.0\n",
      "--- 1.752511978149414 seconds ---\n",
      "episode 5613, reward 122.0, memory_length 2000, epsilon 0.06041607905191679\n",
      "travel time- 731.0\n",
      "--- 1.5516088008880615 seconds ---\n",
      "episode 5614, reward 184.0, memory_length 2000, epsilon 0.06038587856314221\n",
      "travel time- 732.0\n",
      "--- 1.5883488655090332 seconds ---\n",
      "episode 5615, reward -411.0, memory_length 2000, epsilon 0.06035569317083757\n",
      "travel time- 723.0\n",
      "--- 1.6048734188079834 seconds ---\n",
      "episode 5616, reward 128.0, memory_length 2000, epsilon 0.06032552286745654\n",
      "travel time- 728.0\n",
      "--- 1.5789093971252441 seconds ---\n",
      "episode 5617, reward 218.0, memory_length 2000, epsilon 0.06029536764545656\n",
      "travel time- 721.0\n",
      "--- 1.6431446075439453 seconds ---\n",
      "episode 5618, reward 120.0, memory_length 2000, epsilon 0.060265227497298776\n",
      "travel time- 721.0\n",
      "--- 1.5923149585723877 seconds ---\n",
      "episode 5619, reward -329.0, memory_length 2000, epsilon 0.060235102415448216\n",
      "travel time- 723.0\n",
      "--- 1.7498126029968262 seconds ---\n",
      "episode 5620, reward -71.0, memory_length 2000, epsilon 0.06020499239237354\n",
      "travel time- 723.0\n",
      "--- 1.8895258903503418 seconds ---\n",
      "episode 5621, reward 41.0, memory_length 2000, epsilon 0.06017489742054728\n",
      "travel time- 725.0\n",
      "--- 1.6832971572875977 seconds ---\n",
      "episode 5622, reward -57.0, memory_length 2000, epsilon 0.06014481749244571\n",
      "travel time- 725.0\n",
      "--- 1.751753568649292 seconds ---\n",
      "episode 5623, reward 198.0, memory_length 2000, epsilon 0.060114752600548806\n",
      "travel time- 721.0\n",
      "--- 1.5356616973876953 seconds ---\n",
      "episode 5624, reward -95.0, memory_length 2000, epsilon 0.06008470273734036\n",
      "travel time- 721.0\n",
      "--- 1.7834446430206299 seconds ---\n",
      "episode 5625, reward 79.0, memory_length 2000, epsilon 0.060054667895307945\n",
      "travel time- 720.0\n",
      "--- 1.6885900497436523 seconds ---\n",
      "episode 5626, reward 97.0, memory_length 2000, epsilon 0.060024648066942785\n",
      "travel time- 725.0\n",
      "--- 1.5900940895080566 seconds ---\n",
      "episode 5627, reward -161.0, memory_length 2000, epsilon 0.05999464324473998\n",
      "travel time- 723.0\n",
      "--- 1.6568403244018555 seconds ---\n",
      "episode 5628, reward 185.0, memory_length 2000, epsilon 0.05996465342119827\n",
      "travel time- 728.0\n",
      "--- 1.8306682109832764 seconds ---\n",
      "episode 5629, reward 369.0, memory_length 2000, epsilon 0.059934678588820234\n",
      "travel time- 723.0\n",
      "--- 1.6624114513397217 seconds ---\n",
      "episode 5630, reward 119.0, memory_length 2000, epsilon 0.05990471874011218\n",
      "travel time- 732.0\n",
      "--- 1.7702054977416992 seconds ---\n",
      "episode 5631, reward 177.0, memory_length 2000, epsilon 0.0598747738675841\n",
      "travel time- 722.0\n",
      "--- 1.4660699367523193 seconds ---\n",
      "episode 5632, reward 148.0, memory_length 2000, epsilon 0.059844843963749825\n",
      "travel time- 732.0\n",
      "--- 1.5132849216461182 seconds ---\n",
      "episode 5633, reward -194.0, memory_length 2000, epsilon 0.05981492902112682\n",
      "travel time- 720.0\n",
      "--- 1.827078104019165 seconds ---\n",
      "episode 5634, reward 111.0, memory_length 2000, epsilon 0.059785029032236384\n",
      "travel time- 722.0\n",
      "--- 1.4091525077819824 seconds ---\n",
      "episode 5635, reward 159.0, memory_length 2000, epsilon 0.05975514398960355\n",
      "travel time- 720.0\n",
      "--- 1.6196789741516113 seconds ---\n",
      "episode 5636, reward -221.0, memory_length 2000, epsilon 0.05972527388575699\n",
      "travel time- 720.0\n",
      "--- 1.5709228515625 seconds ---\n",
      "episode 5637, reward -60.0, memory_length 2000, epsilon 0.05969541871322922\n",
      "travel time- 725.0\n",
      "--- 1.6361169815063477 seconds ---\n",
      "episode 5638, reward -78.0, memory_length 2000, epsilon 0.05966557846455646\n",
      "travel time- 723.0\n",
      "--- 1.769432544708252 seconds ---\n",
      "episode 5639, reward -100.0, memory_length 2000, epsilon 0.059635753132278604\n",
      "travel time- 729.0\n",
      "--- 1.484365701675415 seconds ---\n",
      "episode 5640, reward -239.0, memory_length 2000, epsilon 0.05960594270893937\n",
      "travel time- 720.0\n",
      "--- 1.683037281036377 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5641, reward -95.0, memory_length 2000, epsilon 0.059576147187086086\n",
      "travel time- 725.0\n",
      "--- 1.5045106410980225 seconds ---\n",
      "episode 5642, reward 284.0, memory_length 2000, epsilon 0.05954636655926992\n",
      "travel time- 724.0\n",
      "--- 1.6280035972595215 seconds ---\n",
      "episode 5643, reward -60.0, memory_length 2000, epsilon 0.059516600818045724\n",
      "travel time- 728.0\n",
      "--- 1.6219732761383057 seconds ---\n",
      "episode 5644, reward 146.0, memory_length 2000, epsilon 0.05948684995597202\n",
      "travel time- 723.0\n",
      "--- 1.585280418395996 seconds ---\n",
      "episode 5645, reward 189.0, memory_length 2000, epsilon 0.05945711396561112\n",
      "travel time- 721.0\n",
      "--- 1.6567981243133545 seconds ---\n",
      "episode 5646, reward 269.0, memory_length 2000, epsilon 0.05942739283952904\n",
      "travel time- 730.0\n",
      "--- 1.46824312210083 seconds ---\n",
      "episode 5647, reward 105.0, memory_length 2000, epsilon 0.059397686570295455\n",
      "travel time- 725.0\n",
      "--- 1.518587589263916 seconds ---\n",
      "episode 5648, reward -72.0, memory_length 2000, epsilon 0.05936799515048385\n",
      "travel time- 731.0\n",
      "--- 1.8255398273468018 seconds ---\n",
      "episode 5649, reward 9.0, memory_length 2000, epsilon 0.05933831857267131\n",
      "travel time- 720.0\n",
      "--- 1.5973422527313232 seconds ---\n",
      "episode 5650, reward 223.0, memory_length 2000, epsilon 0.05930865682943872\n",
      "travel time- 725.0\n",
      "--- 1.6275603771209717 seconds ---\n",
      "episode 5651, reward -324.0, memory_length 2000, epsilon 0.05927900991337068\n",
      "travel time- 724.0\n",
      "--- 1.8913850784301758 seconds ---\n",
      "episode 5652, reward 64.0, memory_length 2000, epsilon 0.0592493778170554\n",
      "travel time- 721.0\n",
      "--- 1.5677456855773926 seconds ---\n",
      "episode 5653, reward 164.0, memory_length 2000, epsilon 0.059219760533084885\n",
      "travel time- 722.0\n",
      "--- 1.3395330905914307 seconds ---\n",
      "episode 5654, reward -23.0, memory_length 2000, epsilon 0.05919015805405483\n",
      "travel time- 727.0\n",
      "--- 1.6228852272033691 seconds ---\n",
      "episode 5655, reward -189.0, memory_length 2000, epsilon 0.05916057037256458\n",
      "travel time- 721.0\n",
      "--- 1.6577606201171875 seconds ---\n",
      "episode 5656, reward 148.0, memory_length 2000, epsilon 0.05913099748121725\n",
      "travel time- 728.0\n",
      "--- 1.5396933555603027 seconds ---\n",
      "episode 5657, reward -44.0, memory_length 2000, epsilon 0.05910143937261957\n",
      "travel time- 723.0\n",
      "--- 1.585679292678833 seconds ---\n",
      "episode 5658, reward -158.0, memory_length 2000, epsilon 0.05907189603938205\n",
      "travel time- 720.0\n",
      "--- 1.7242984771728516 seconds ---\n",
      "episode 5659, reward -31.0, memory_length 2000, epsilon 0.05904236747411887\n",
      "travel time- 720.0\n",
      "--- 1.6198086738586426 seconds ---\n",
      "episode 5660, reward 80.0, memory_length 2000, epsilon 0.05901285366944784\n",
      "travel time- 731.0\n",
      "--- 1.816274642944336 seconds ---\n",
      "episode 5661, reward 358.0, memory_length 2000, epsilon 0.058983354617990535\n",
      "travel time- 725.0\n",
      "--- 1.6542768478393555 seconds ---\n",
      "episode 5662, reward 39.0, memory_length 2000, epsilon 0.05895387031237222\n",
      "travel time- 727.0\n",
      "--- 1.6711256504058838 seconds ---\n",
      "episode 5663, reward -181.0, memory_length 2000, epsilon 0.058924400745221754\n",
      "travel time- 722.0\n",
      "--- 1.8338704109191895 seconds ---\n",
      "episode 5664, reward -164.0, memory_length 2000, epsilon 0.05889494590917182\n",
      "travel time- 726.0\n",
      "--- 1.7327215671539307 seconds ---\n",
      "episode 5665, reward 232.0, memory_length 2000, epsilon 0.05886550579685863\n",
      "travel time- 729.0\n",
      "--- 1.410172700881958 seconds ---\n",
      "episode 5666, reward 99.0, memory_length 2000, epsilon 0.05883608040092221\n",
      "travel time- 730.0\n",
      "--- 1.6645326614379883 seconds ---\n",
      "episode 5667, reward 3.0, memory_length 2000, epsilon 0.058806669714006214\n",
      "travel time- 723.0\n",
      "--- 1.4060049057006836 seconds ---\n",
      "episode 5668, reward 73.0, memory_length 2000, epsilon 0.058777273728757934\n",
      "travel time- 726.0\n",
      "--- 1.7548344135284424 seconds ---\n",
      "episode 5669, reward -30.0, memory_length 2000, epsilon 0.05874789243782839\n",
      "travel time- 730.0\n",
      "--- 1.586751937866211 seconds ---\n",
      "episode 5670, reward 109.0, memory_length 2000, epsilon 0.058718525833872284\n",
      "travel time- 721.0\n",
      "--- 1.6131553649902344 seconds ---\n",
      "episode 5671, reward 74.0, memory_length 2000, epsilon 0.05868917390954791\n",
      "travel time- 720.0\n",
      "--- 1.4953861236572266 seconds ---\n",
      "episode 5672, reward 329.0, memory_length 2000, epsilon 0.05865983665751736\n",
      "travel time- 722.0\n",
      "--- 1.5327699184417725 seconds ---\n",
      "episode 5673, reward 73.0, memory_length 2000, epsilon 0.05863051407044624\n",
      "travel time- 726.0\n",
      "--- 1.6191699504852295 seconds ---\n",
      "episode 5674, reward 17.0, memory_length 2000, epsilon 0.058601206141003954\n",
      "travel time- 729.0\n",
      "--- 1.7894387245178223 seconds ---\n",
      "episode 5675, reward -57.0, memory_length 2000, epsilon 0.05857191286186353\n",
      "travel time- 731.0\n",
      "--- 1.8081800937652588 seconds ---\n",
      "episode 5676, reward 136.0, memory_length 2000, epsilon 0.0585426342257016\n",
      "travel time- 721.0\n",
      "--- 1.5463616847991943 seconds ---\n",
      "episode 5677, reward -19.0, memory_length 2000, epsilon 0.05851337022519853\n",
      "travel time- 721.0\n",
      "--- 1.4010977745056152 seconds ---\n",
      "episode 5678, reward 33.0, memory_length 2000, epsilon 0.05848412085303835\n",
      "travel time- 720.0\n",
      "--- 1.6505017280578613 seconds ---\n",
      "episode 5679, reward 372.0, memory_length 2000, epsilon 0.05845488610190866\n",
      "travel time- 731.0\n",
      "--- 1.3574070930480957 seconds ---\n",
      "episode 5680, reward -99.0, memory_length 2000, epsilon 0.05842566596450083\n",
      "travel time- 728.0\n",
      "--- 1.8556323051452637 seconds ---\n",
      "episode 5681, reward -98.0, memory_length 2000, epsilon 0.05839646043350977\n",
      "travel time- 733.0\n",
      "--- 1.75761079788208 seconds ---\n",
      "episode 5682, reward -81.0, memory_length 2000, epsilon 0.058367269501634116\n",
      "travel time- 721.0\n",
      "--- 1.809953212738037 seconds ---\n",
      "episode 5683, reward -90.0, memory_length 2000, epsilon 0.05833809316157617\n",
      "travel time- 727.0\n",
      "--- 1.8532109260559082 seconds ---\n",
      "episode 5684, reward -5.0, memory_length 2000, epsilon 0.05830893140604179\n",
      "travel time- 725.0\n",
      "--- 1.621093511581421 seconds ---\n",
      "episode 5685, reward 70.0, memory_length 2000, epsilon 0.058279784227740564\n",
      "travel time- 722.0\n",
      "--- 1.7081692218780518 seconds ---\n",
      "episode 5686, reward 340.0, memory_length 2000, epsilon 0.05825065161938573\n",
      "travel time- 724.0\n",
      "--- 1.808079481124878 seconds ---\n",
      "episode 5687, reward -60.0, memory_length 2000, epsilon 0.05822153357369408\n",
      "travel time- 724.0\n",
      "--- 1.6424100399017334 seconds ---\n",
      "episode 5688, reward -137.0, memory_length 2000, epsilon 0.05819243008338615\n",
      "travel time- 722.0\n",
      "--- 1.7391040325164795 seconds ---\n",
      "episode 5689, reward 45.0, memory_length 2000, epsilon 0.058163341141186015\n",
      "travel time- 722.0\n",
      "--- 1.520104169845581 seconds ---\n",
      "episode 5690, reward 91.0, memory_length 2000, epsilon 0.058134266739821465\n",
      "travel time- 720.0\n",
      "--- 1.3996787071228027 seconds ---\n",
      "episode 5691, reward -17.0, memory_length 2000, epsilon 0.05810520687202394\n",
      "travel time- 727.0\n",
      "--- 1.7699155807495117 seconds ---\n",
      "episode 5692, reward -99.0, memory_length 2000, epsilon 0.0580761615305284\n",
      "travel time- 721.0\n",
      "--- 1.594482421875 seconds ---\n",
      "episode 5693, reward -35.0, memory_length 2000, epsilon 0.05804713070807355\n",
      "travel time- 730.0\n",
      "--- 1.6769342422485352 seconds ---\n",
      "episode 5694, reward 9.0, memory_length 2000, epsilon 0.058018114397401704\n",
      "travel time- 728.0\n",
      "--- 1.6816062927246094 seconds ---\n",
      "episode 5695, reward -65.0, memory_length 2000, epsilon 0.05798911259125873\n",
      "travel time- 721.0\n",
      "--- 1.5350186824798584 seconds ---\n",
      "episode 5696, reward 208.0, memory_length 2000, epsilon 0.057960125282394234\n",
      "travel time- 723.0\n",
      "--- 1.6750802993774414 seconds ---\n",
      "episode 5697, reward 432.0, memory_length 2000, epsilon 0.05793115246356134\n",
      "travel time- 721.0\n",
      "--- 1.5902106761932373 seconds ---\n",
      "episode 5698, reward 12.0, memory_length 2000, epsilon 0.057902194127516855\n",
      "travel time- 726.0\n",
      "--- 1.7339210510253906 seconds ---\n",
      "episode 5699, reward 60.0, memory_length 2000, epsilon 0.05787325026702124\n",
      "travel time- 726.0\n",
      "--- 1.640881061553955 seconds ---\n",
      "episode 5700, reward -178.0, memory_length 2000, epsilon 0.057844320874838456\n",
      "travel time- 721.0\n",
      "--- 1.6874394416809082 seconds ---\n",
      "episode 5701, reward -187.0, memory_length 2000, epsilon 0.0578154059437362\n",
      "travel time- 720.0\n",
      "--- 1.7512109279632568 seconds ---\n",
      "episode 5702, reward 30.0, memory_length 2000, epsilon 0.057786505466485755\n",
      "travel time- 720.0\n",
      "--- 1.5222601890563965 seconds ---\n",
      "episode 5703, reward 207.0, memory_length 2000, epsilon 0.05775761943586195\n",
      "travel time- 725.0\n",
      "--- 1.511298656463623 seconds ---\n",
      "episode 5704, reward -3.0, memory_length 2000, epsilon 0.05772874784464333\n",
      "travel time- 737.0\n",
      "--- 1.6320176124572754 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5705, reward -52.0, memory_length 2000, epsilon 0.057699890685611946\n",
      "travel time- 727.0\n",
      "--- 1.6703441143035889 seconds ---\n",
      "episode 5706, reward 188.0, memory_length 2000, epsilon 0.057671047951553533\n",
      "travel time- 722.0\n",
      "--- 1.7153828144073486 seconds ---\n",
      "episode 5707, reward 87.0, memory_length 2000, epsilon 0.05764221963525744\n",
      "travel time- 720.0\n",
      "--- 1.6019542217254639 seconds ---\n",
      "episode 5708, reward 398.0, memory_length 2000, epsilon 0.05761340572951652\n",
      "travel time- 731.0\n",
      "--- 1.6546826362609863 seconds ---\n",
      "episode 5709, reward 230.0, memory_length 2000, epsilon 0.05758460622712735\n",
      "travel time- 724.0\n",
      "--- 1.4857947826385498 seconds ---\n",
      "episode 5710, reward 217.0, memory_length 2000, epsilon 0.05755582112089005\n",
      "travel time- 729.0\n",
      "--- 1.4836421012878418 seconds ---\n",
      "episode 5711, reward -358.0, memory_length 2000, epsilon 0.0575270504036083\n",
      "travel time- 721.0\n",
      "--- 1.724362850189209 seconds ---\n",
      "episode 5712, reward 78.0, memory_length 2000, epsilon 0.057498294068089484\n",
      "travel time- 727.0\n",
      "--- 1.4284608364105225 seconds ---\n",
      "episode 5713, reward -156.0, memory_length 2000, epsilon 0.05746955210714446\n",
      "travel time- 720.0\n",
      "--- 1.6755144596099854 seconds ---\n",
      "episode 5714, reward -6.0, memory_length 2000, epsilon 0.05744082451358776\n",
      "travel time- 721.0\n",
      "--- 1.6294996738433838 seconds ---\n",
      "episode 5715, reward -33.0, memory_length 2000, epsilon 0.05741211128023751\n",
      "travel time- 723.0\n",
      "--- 1.4998388290405273 seconds ---\n",
      "episode 5716, reward -209.0, memory_length 2000, epsilon 0.05738341239991535\n",
      "travel time- 724.0\n",
      "--- 1.4357397556304932 seconds ---\n",
      "episode 5717, reward 390.0, memory_length 2000, epsilon 0.0573547278654466\n",
      "travel time- 727.0\n",
      "--- 1.756408929824829 seconds ---\n",
      "episode 5718, reward 54.0, memory_length 2000, epsilon 0.05732605766966013\n",
      "travel time- 722.0\n",
      "--- 1.539231538772583 seconds ---\n",
      "episode 5719, reward -10.0, memory_length 2000, epsilon 0.05729740180538836\n",
      "travel time- 721.0\n",
      "--- 1.8028161525726318 seconds ---\n",
      "episode 5720, reward -149.0, memory_length 2000, epsilon 0.05726876026546736\n",
      "travel time- 724.0\n",
      "--- 1.5565950870513916 seconds ---\n",
      "episode 5721, reward 198.0, memory_length 2000, epsilon 0.0572401330427367\n",
      "travel time- 726.0\n",
      "--- 1.5858771800994873 seconds ---\n",
      "episode 5722, reward 201.0, memory_length 2000, epsilon 0.0572115201300396\n",
      "travel time- 722.0\n",
      "--- 1.6539556980133057 seconds ---\n",
      "episode 5723, reward -18.0, memory_length 2000, epsilon 0.05718292152022285\n",
      "travel time- 723.0\n",
      "--- 1.7884509563446045 seconds ---\n",
      "episode 5724, reward -15.0, memory_length 2000, epsilon 0.05715433720613676\n",
      "travel time- 726.0\n",
      "--- 1.69600248336792 seconds ---\n",
      "episode 5725, reward 104.0, memory_length 2000, epsilon 0.057125767180635265\n",
      "travel time- 722.0\n",
      "--- 1.5339381694793701 seconds ---\n",
      "episode 5726, reward -7.0, memory_length 2000, epsilon 0.05709721143657589\n",
      "travel time- 725.0\n",
      "--- 1.5341243743896484 seconds ---\n",
      "episode 5727, reward -200.0, memory_length 2000, epsilon 0.05706866996681965\n",
      "travel time- 727.0\n",
      "--- 1.7646584510803223 seconds ---\n",
      "episode 5728, reward 16.0, memory_length 2000, epsilon 0.057040142764231215\n",
      "travel time- 727.0\n",
      "--- 1.708026647567749 seconds ---\n",
      "episode 5729, reward 42.0, memory_length 2000, epsilon 0.05701162982167875\n",
      "travel time- 724.0\n",
      "--- 1.62434720993042 seconds ---\n",
      "episode 5730, reward 159.0, memory_length 2000, epsilon 0.056983131132034036\n",
      "travel time- 727.0\n",
      "--- 1.669731855392456 seconds ---\n",
      "episode 5731, reward -120.0, memory_length 2000, epsilon 0.05695464668817242\n",
      "travel time- 722.0\n",
      "--- 1.4401583671569824 seconds ---\n",
      "episode 5732, reward -205.0, memory_length 2000, epsilon 0.056926176482972754\n",
      "travel time- 726.0\n",
      "--- 1.489915370941162 seconds ---\n",
      "episode 5733, reward 62.0, memory_length 2000, epsilon 0.056897720509317504\n",
      "travel time- 724.0\n",
      "--- 1.672410249710083 seconds ---\n",
      "episode 5734, reward -77.0, memory_length 2000, epsilon 0.056869278760092706\n",
      "travel time- 728.0\n",
      "--- 1.5772430896759033 seconds ---\n",
      "episode 5735, reward -44.0, memory_length 2000, epsilon 0.05684085122818787\n",
      "travel time- 728.0\n",
      "--- 1.5411746501922607 seconds ---\n",
      "episode 5736, reward -153.0, memory_length 2000, epsilon 0.056812437906496156\n",
      "travel time- 724.0\n",
      "--- 1.4701142311096191 seconds ---\n",
      "episode 5737, reward -39.0, memory_length 2000, epsilon 0.056784038787914194\n",
      "travel time- 720.0\n",
      "--- 1.6560773849487305 seconds ---\n",
      "episode 5738, reward 58.0, memory_length 2000, epsilon 0.056755653865342225\n",
      "travel time- 729.0\n",
      "--- 1.6372594833374023 seconds ---\n",
      "episode 5739, reward -348.0, memory_length 2000, epsilon 0.056727283131684035\n",
      "travel time- 720.0\n",
      "--- 1.5440890789031982 seconds ---\n",
      "episode 5740, reward -219.0, memory_length 2000, epsilon 0.0566989265798469\n",
      "travel time- 722.0\n",
      "--- 1.4626884460449219 seconds ---\n",
      "episode 5741, reward 93.0, memory_length 2000, epsilon 0.056670584202741715\n",
      "travel time- 720.0\n",
      "--- 1.7783203125 seconds ---\n",
      "episode 5742, reward 178.0, memory_length 2000, epsilon 0.056642255993282896\n",
      "travel time- 723.0\n",
      "--- 1.5913949012756348 seconds ---\n",
      "episode 5743, reward -49.0, memory_length 2000, epsilon 0.056613941944388346\n",
      "travel time- 727.0\n",
      "--- 1.8167731761932373 seconds ---\n",
      "episode 5744, reward -133.0, memory_length 2000, epsilon 0.056585642048979604\n",
      "travel time- 728.0\n",
      "--- 1.6085481643676758 seconds ---\n",
      "episode 5745, reward 420.0, memory_length 2000, epsilon 0.05655735629998164\n",
      "travel time- 731.0\n",
      "--- 1.7239065170288086 seconds ---\n",
      "episode 5746, reward 102.0, memory_length 2000, epsilon 0.05652908469032304\n",
      "travel time- 720.0\n",
      "--- 1.7339870929718018 seconds ---\n",
      "episode 5747, reward -26.0, memory_length 2000, epsilon 0.05650082721293594\n",
      "travel time- 720.0\n",
      "--- 1.643711805343628 seconds ---\n",
      "episode 5748, reward -230.0, memory_length 2000, epsilon 0.05647258386075591\n",
      "travel time- 720.0\n",
      "--- 1.8661601543426514 seconds ---\n",
      "episode 5749, reward -115.0, memory_length 2000, epsilon 0.05644435462672214\n",
      "travel time- 721.0\n",
      "--- 1.8726410865783691 seconds ---\n",
      "episode 5750, reward -141.0, memory_length 2000, epsilon 0.05641613950377735\n",
      "travel time- 720.0\n",
      "--- 2.0496408939361572 seconds ---\n",
      "episode 5751, reward 298.0, memory_length 2000, epsilon 0.0563879384848677\n",
      "travel time- 726.0\n",
      "--- 1.5022542476654053 seconds ---\n",
      "episode 5752, reward 313.0, memory_length 2000, epsilon 0.05635975156294299\n",
      "travel time- 721.0\n",
      "--- 1.4143037796020508 seconds ---\n",
      "episode 5753, reward -19.0, memory_length 2000, epsilon 0.05633157873095644\n",
      "travel time- 728.0\n",
      "--- 1.5757343769073486 seconds ---\n",
      "episode 5754, reward 274.0, memory_length 2000, epsilon 0.05630341998186487\n",
      "travel time- 727.0\n",
      "--- 1.787926435470581 seconds ---\n",
      "episode 5755, reward 126.0, memory_length 2000, epsilon 0.0562752753086286\n",
      "travel time- 726.0\n",
      "--- 1.525200366973877 seconds ---\n",
      "episode 5756, reward 356.0, memory_length 2000, epsilon 0.05624714470421144\n",
      "travel time- 731.0\n",
      "--- 1.688140630722046 seconds ---\n",
      "episode 5757, reward 232.0, memory_length 2000, epsilon 0.056219028161580746\n",
      "travel time- 723.0\n",
      "--- 1.7265903949737549 seconds ---\n",
      "episode 5758, reward 324.0, memory_length 2000, epsilon 0.056190925673707405\n",
      "travel time- 726.0\n",
      "--- 1.283785343170166 seconds ---\n",
      "episode 5759, reward 115.0, memory_length 2000, epsilon 0.05616283723356575\n",
      "travel time- 722.0\n",
      "--- 1.6829783916473389 seconds ---\n",
      "episode 5760, reward 108.0, memory_length 2000, epsilon 0.056134762834133725\n",
      "travel time- 720.0\n",
      "--- 1.6608033180236816 seconds ---\n",
      "episode 5761, reward -143.0, memory_length 2000, epsilon 0.05610670246839268\n",
      "travel time- 726.0\n",
      "--- 1.6957452297210693 seconds ---\n",
      "episode 5762, reward -42.0, memory_length 2000, epsilon 0.05607865612932754\n",
      "travel time- 726.0\n",
      "--- 1.9460029602050781 seconds ---\n",
      "episode 5763, reward -85.0, memory_length 2000, epsilon 0.056050623809926745\n",
      "travel time- 723.0\n",
      "--- 1.5263047218322754 seconds ---\n",
      "episode 5764, reward -89.0, memory_length 2000, epsilon 0.05602260550318217\n",
      "travel time- 722.0\n",
      "--- 1.5920372009277344 seconds ---\n",
      "episode 5765, reward -256.0, memory_length 2000, epsilon 0.055994601202089295\n",
      "travel time- 723.0\n",
      "--- 1.596695899963379 seconds ---\n",
      "episode 5766, reward 39.0, memory_length 2000, epsilon 0.05596661089964698\n",
      "travel time- 720.0\n",
      "--- 1.7232558727264404 seconds ---\n",
      "episode 5767, reward -127.0, memory_length 2000, epsilon 0.055938634588857686\n",
      "travel time- 730.0\n",
      "--- 1.646162509918213 seconds ---\n",
      "episode 5768, reward 205.0, memory_length 2000, epsilon 0.055910672262727355\n",
      "travel time- 725.0\n",
      "--- 1.7498447895050049 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5769, reward 48.0, memory_length 2000, epsilon 0.05588272391426535\n",
      "travel time- 729.0\n",
      "--- 1.5293138027191162 seconds ---\n",
      "episode 5770, reward 24.0, memory_length 2000, epsilon 0.05585478953648462\n",
      "travel time- 721.0\n",
      "--- 1.5670480728149414 seconds ---\n",
      "episode 5771, reward 190.0, memory_length 2000, epsilon 0.05582686912240159\n",
      "travel time- 723.0\n",
      "--- 1.7678132057189941 seconds ---\n",
      "episode 5772, reward 151.0, memory_length 2000, epsilon 0.05579896266503611\n",
      "travel time- 729.0\n",
      "--- 1.6880640983581543 seconds ---\n",
      "episode 5773, reward 64.0, memory_length 2000, epsilon 0.055771070157411604\n",
      "travel time- 720.0\n",
      "--- 1.7119348049163818 seconds ---\n",
      "episode 5774, reward 44.0, memory_length 2000, epsilon 0.055743191592554905\n",
      "travel time- 721.0\n",
      "--- 1.7387456893920898 seconds ---\n",
      "episode 5775, reward -198.0, memory_length 2000, epsilon 0.055715326963496396\n",
      "travel time- 720.0\n",
      "--- 1.626387596130371 seconds ---\n",
      "episode 5776, reward -159.0, memory_length 2000, epsilon 0.05568747626326995\n",
      "travel time- 721.0\n",
      "--- 1.7700929641723633 seconds ---\n",
      "episode 5777, reward 299.0, memory_length 2000, epsilon 0.05565963948491282\n",
      "travel time- 724.0\n",
      "--- 1.6079504489898682 seconds ---\n",
      "episode 5778, reward 41.0, memory_length 2000, epsilon 0.055631816621465865\n",
      "travel time- 720.0\n",
      "--- 1.6754512786865234 seconds ---\n",
      "episode 5779, reward 149.0, memory_length 2000, epsilon 0.05560400766597337\n",
      "travel time- 721.0\n",
      "--- 1.5897340774536133 seconds ---\n",
      "episode 5780, reward -175.0, memory_length 2000, epsilon 0.05557621261148306\n",
      "travel time- 727.0\n",
      "--- 1.6767776012420654 seconds ---\n",
      "episode 5781, reward -15.0, memory_length 2000, epsilon 0.05554843145104622\n",
      "travel time- 721.0\n",
      "--- 1.7190837860107422 seconds ---\n",
      "episode 5782, reward -64.0, memory_length 2000, epsilon 0.055520664177717505\n",
      "travel time- 722.0\n",
      "--- 1.7976274490356445 seconds ---\n",
      "episode 5783, reward -75.0, memory_length 2000, epsilon 0.05549291078455512\n",
      "travel time- 720.0\n",
      "--- 1.901151180267334 seconds ---\n",
      "episode 5784, reward 47.0, memory_length 2000, epsilon 0.05546517126462075\n",
      "travel time- 725.0\n",
      "--- 1.619798183441162 seconds ---\n",
      "episode 5785, reward -135.0, memory_length 2000, epsilon 0.055437445610979456\n",
      "travel time- 729.0\n",
      "--- 1.771986961364746 seconds ---\n",
      "episode 5786, reward -24.0, memory_length 2000, epsilon 0.055409733816699856\n",
      "travel time- 723.0\n",
      "--- 1.6697323322296143 seconds ---\n",
      "episode 5787, reward 215.0, memory_length 2000, epsilon 0.055382035874854026\n",
      "travel time- 720.0\n",
      "--- 1.5761702060699463 seconds ---\n",
      "episode 5788, reward 454.0, memory_length 2000, epsilon 0.05535435177851743\n",
      "travel time- 722.0\n",
      "--- 1.6899197101593018 seconds ---\n",
      "episode 5789, reward 179.0, memory_length 2000, epsilon 0.05532668152076908\n",
      "travel time- 720.0\n",
      "--- 1.7560105323791504 seconds ---\n",
      "episode 5790, reward -91.0, memory_length 2000, epsilon 0.05529902509469138\n",
      "travel time- 726.0\n",
      "--- 1.7187366485595703 seconds ---\n",
      "episode 5791, reward -257.0, memory_length 2000, epsilon 0.05527138249337025\n",
      "travel time- 723.0\n",
      "--- 1.642380952835083 seconds ---\n",
      "episode 5792, reward -68.0, memory_length 2000, epsilon 0.055243753709895045\n",
      "travel time- 721.0\n",
      "--- 1.8224210739135742 seconds ---\n",
      "episode 5793, reward 100.0, memory_length 2000, epsilon 0.05521613873735853\n",
      "travel time- 720.0\n",
      "--- 1.66367769241333 seconds ---\n",
      "episode 5794, reward 58.0, memory_length 2000, epsilon 0.055188537568857\n",
      "travel time- 724.0\n",
      "--- 1.5558533668518066 seconds ---\n",
      "episode 5795, reward -358.0, memory_length 2000, epsilon 0.05516095019749016\n",
      "travel time- 724.0\n",
      "--- 1.5130674839019775 seconds ---\n",
      "episode 5796, reward 217.0, memory_length 2000, epsilon 0.05513337661636114\n",
      "travel time- 722.0\n",
      "--- 1.5477356910705566 seconds ---\n",
      "episode 5797, reward 330.0, memory_length 2000, epsilon 0.05510581681857658\n",
      "travel time- 722.0\n",
      "--- 1.411719560623169 seconds ---\n",
      "episode 5798, reward -216.0, memory_length 2000, epsilon 0.05507827079724649\n",
      "travel time- 726.0\n",
      "--- 1.6083734035491943 seconds ---\n",
      "episode 5799, reward 282.0, memory_length 2000, epsilon 0.05505073854548439\n",
      "travel time- 723.0\n",
      "--- 1.4426543712615967 seconds ---\n",
      "episode 5800, reward 219.0, memory_length 2000, epsilon 0.05502322005640723\n",
      "travel time- 720.0\n",
      "--- 1.4893591403961182 seconds ---\n",
      "episode 5801, reward -127.0, memory_length 2000, epsilon 0.05499571532313535\n",
      "travel time- 720.0\n",
      "--- 1.618943691253662 seconds ---\n",
      "episode 5802, reward 37.0, memory_length 2000, epsilon 0.054968224338792594\n",
      "travel time- 730.0\n",
      "--- 1.814744472503662 seconds ---\n",
      "episode 5803, reward 131.0, memory_length 2000, epsilon 0.054940747096506225\n",
      "travel time- 723.0\n",
      "--- 1.5207886695861816 seconds ---\n",
      "episode 5804, reward -152.0, memory_length 2000, epsilon 0.05491328358940689\n",
      "travel time- 723.0\n",
      "--- 1.8110253810882568 seconds ---\n",
      "episode 5805, reward 101.0, memory_length 2000, epsilon 0.05488583381062877\n",
      "travel time- 727.0\n",
      "--- 1.5666859149932861 seconds ---\n",
      "episode 5806, reward 45.0, memory_length 2000, epsilon 0.05485839775330936\n",
      "travel time- 729.0\n",
      "--- 1.461683750152588 seconds ---\n",
      "episode 5807, reward 86.0, memory_length 2000, epsilon 0.05483097541058968\n",
      "travel time- 722.0\n",
      "--- 1.5380933284759521 seconds ---\n",
      "episode 5808, reward 154.0, memory_length 2000, epsilon 0.054803566775614154\n",
      "travel time- 726.0\n",
      "--- 1.5846080780029297 seconds ---\n",
      "episode 5809, reward 39.0, memory_length 2000, epsilon 0.05477617184153059\n",
      "travel time- 721.0\n",
      "--- 1.6051981449127197 seconds ---\n",
      "episode 5810, reward 211.0, memory_length 2000, epsilon 0.054748790601490266\n",
      "travel time- 721.0\n",
      "--- 1.4453110694885254 seconds ---\n",
      "episode 5811, reward 108.0, memory_length 2000, epsilon 0.0547214230486479\n",
      "travel time- 721.0\n",
      "--- 1.760359764099121 seconds ---\n",
      "episode 5812, reward 41.0, memory_length 2000, epsilon 0.05469406917616156\n",
      "travel time- 727.0\n",
      "--- 1.4445044994354248 seconds ---\n",
      "episode 5813, reward -48.0, memory_length 2000, epsilon 0.054666728977192824\n",
      "travel time- 731.0\n",
      "--- 1.7555067539215088 seconds ---\n",
      "episode 5814, reward -150.0, memory_length 2000, epsilon 0.054639402444906594\n",
      "travel time- 724.0\n",
      "--- 1.760422706604004 seconds ---\n",
      "episode 5815, reward 96.0, memory_length 2000, epsilon 0.05461208957247126\n",
      "travel time- 729.0\n",
      "--- 1.9019248485565186 seconds ---\n",
      "episode 5816, reward -104.0, memory_length 2000, epsilon 0.054584790353058625\n",
      "travel time- 722.0\n",
      "--- 1.596207857131958 seconds ---\n",
      "episode 5817, reward 226.0, memory_length 2000, epsilon 0.05455750477984384\n",
      "travel time- 733.0\n",
      "--- 1.5880913734436035 seconds ---\n",
      "episode 5818, reward 108.0, memory_length 2000, epsilon 0.054530232846005534\n",
      "travel time- 722.0\n",
      "--- 1.5782010555267334 seconds ---\n",
      "episode 5819, reward 422.0, memory_length 2000, epsilon 0.054502974544725746\n",
      "travel time- 720.0\n",
      "--- 1.6325323581695557 seconds ---\n",
      "episode 5820, reward -118.0, memory_length 2000, epsilon 0.05447572986918986\n",
      "travel time- 724.0\n",
      "--- 1.858825922012329 seconds ---\n",
      "episode 5821, reward 93.0, memory_length 2000, epsilon 0.054448498812586746\n",
      "travel time- 735.0\n",
      "--- 1.3476858139038086 seconds ---\n",
      "episode 5822, reward 41.0, memory_length 2000, epsilon 0.05442128136810859\n",
      "travel time- 720.0\n",
      "--- 1.5865111351013184 seconds ---\n",
      "episode 5823, reward -331.0, memory_length 2000, epsilon 0.05439407752895106\n",
      "travel time- 724.0\n",
      "--- 1.605194330215454 seconds ---\n",
      "episode 5824, reward -210.0, memory_length 2000, epsilon 0.05436688728831322\n",
      "travel time- 725.0\n",
      "--- 1.7100274562835693 seconds ---\n",
      "episode 5825, reward 139.0, memory_length 2000, epsilon 0.05433971063939747\n",
      "travel time- 722.0\n",
      "--- 1.89473295211792 seconds ---\n",
      "episode 5826, reward 102.0, memory_length 2000, epsilon 0.05431254757540965\n",
      "travel time- 720.0\n",
      "--- 1.6027228832244873 seconds ---\n",
      "episode 5827, reward -41.0, memory_length 2000, epsilon 0.05428539808955904\n",
      "travel time- 727.0\n",
      "--- 1.6901600360870361 seconds ---\n",
      "episode 5828, reward 7.0, memory_length 2000, epsilon 0.05425826217505821\n",
      "travel time- 720.0\n",
      "--- 1.7528865337371826 seconds ---\n",
      "episode 5829, reward 245.0, memory_length 2000, epsilon 0.05423113982512323\n",
      "travel time- 725.0\n",
      "--- 1.4186244010925293 seconds ---\n",
      "episode 5830, reward -203.0, memory_length 2000, epsilon 0.054204031032973464\n",
      "travel time- 723.0\n",
      "--- 1.4442133903503418 seconds ---\n",
      "episode 5831, reward -86.0, memory_length 2000, epsilon 0.054176935791831735\n",
      "travel time- 729.0\n",
      "--- 1.643254041671753 seconds ---\n",
      "episode 5832, reward 71.0, memory_length 2000, epsilon 0.05414985409492427\n",
      "travel time- 720.0\n",
      "--- 1.3664891719818115 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5833, reward -159.0, memory_length 2000, epsilon 0.054122785935480575\n",
      "travel time- 721.0\n",
      "--- 1.6873447895050049 seconds ---\n",
      "episode 5834, reward 20.0, memory_length 2000, epsilon 0.054095731306733646\n",
      "travel time- 731.0\n",
      "--- 1.6503138542175293 seconds ---\n",
      "episode 5835, reward -262.0, memory_length 2000, epsilon 0.05406869020191986\n",
      "travel time- 728.0\n",
      "--- 1.5910758972167969 seconds ---\n",
      "episode 5836, reward 13.0, memory_length 2000, epsilon 0.054041662614278875\n",
      "travel time- 726.0\n",
      "--- 1.5749366283416748 seconds ---\n",
      "episode 5837, reward 257.0, memory_length 2000, epsilon 0.05401464853705385\n",
      "travel time- 722.0\n",
      "--- 1.6035776138305664 seconds ---\n",
      "episode 5838, reward 227.0, memory_length 2000, epsilon 0.05398764796349122\n",
      "travel time- 720.0\n",
      "--- 1.6120121479034424 seconds ---\n",
      "episode 5839, reward -3.0, memory_length 2000, epsilon 0.05396066088684085\n",
      "travel time- 721.0\n",
      "--- 1.765066146850586 seconds ---\n",
      "episode 5840, reward -40.0, memory_length 2000, epsilon 0.05393368730035602\n",
      "travel time- 726.0\n",
      "--- 1.5598413944244385 seconds ---\n",
      "episode 5841, reward 354.0, memory_length 2000, epsilon 0.05390672719729327\n",
      "travel time- 729.0\n",
      "--- 1.3805925846099854 seconds ---\n",
      "episode 5842, reward -190.0, memory_length 2000, epsilon 0.0538797805709126\n",
      "travel time- 725.0\n",
      "--- 1.686143398284912 seconds ---\n",
      "episode 5843, reward -123.0, memory_length 2000, epsilon 0.05385284741447737\n",
      "travel time- 733.0\n",
      "--- 1.5472846031188965 seconds ---\n",
      "episode 5844, reward 95.0, memory_length 2000, epsilon 0.05382592772125425\n",
      "travel time- 723.0\n",
      "--- 1.5237083435058594 seconds ---\n",
      "episode 5845, reward -150.0, memory_length 2000, epsilon 0.053799021484513376\n",
      "travel time- 731.0\n",
      "--- 1.7920620441436768 seconds ---\n",
      "episode 5846, reward 30.0, memory_length 2000, epsilon 0.05377212869752812\n",
      "travel time- 720.0\n",
      "--- 1.4992084503173828 seconds ---\n",
      "episode 5847, reward -229.0, memory_length 2000, epsilon 0.053745249353575324\n",
      "travel time- 730.0\n",
      "--- 1.6116764545440674 seconds ---\n",
      "episode 5848, reward 255.0, memory_length 2000, epsilon 0.053718383445935165\n",
      "travel time- 720.0\n",
      "--- 1.623565912246704 seconds ---\n",
      "episode 5849, reward -219.0, memory_length 2000, epsilon 0.05369153096789113\n",
      "travel time- 730.0\n",
      "--- 1.4067604541778564 seconds ---\n",
      "episode 5850, reward -167.0, memory_length 2000, epsilon 0.05366469191273011\n",
      "travel time- 720.0\n",
      "--- 1.6093547344207764 seconds ---\n",
      "episode 5851, reward -142.0, memory_length 2000, epsilon 0.053637866273742375\n",
      "travel time- 725.0\n",
      "--- 1.8105840682983398 seconds ---\n",
      "episode 5852, reward 106.0, memory_length 2000, epsilon 0.053611054044221465\n",
      "travel time- 724.0\n",
      "--- 1.5974054336547852 seconds ---\n",
      "episode 5853, reward -315.0, memory_length 2000, epsilon 0.05358425521746436\n",
      "travel time- 723.0\n",
      "--- 1.733828067779541 seconds ---\n",
      "episode 5854, reward 151.0, memory_length 2000, epsilon 0.053557469786771325\n",
      "travel time- 721.0\n",
      "--- 1.4321401119232178 seconds ---\n",
      "episode 5855, reward -7.0, memory_length 2000, epsilon 0.05353069774544601\n",
      "travel time- 723.0\n",
      "--- 1.5921180248260498 seconds ---\n",
      "episode 5856, reward -304.0, memory_length 2000, epsilon 0.05350393908679544\n",
      "travel time- 720.0\n",
      "--- 1.7181575298309326 seconds ---\n",
      "episode 5857, reward 365.0, memory_length 2000, epsilon 0.053477193804129894\n",
      "travel time- 727.0\n",
      "--- 1.4427342414855957 seconds ---\n",
      "episode 5858, reward 58.0, memory_length 2000, epsilon 0.05345046189076308\n",
      "travel time- 721.0\n",
      "--- 1.608398675918579 seconds ---\n",
      "episode 5859, reward -135.0, memory_length 2000, epsilon 0.053423743340012035\n",
      "travel time- 721.0\n",
      "--- 1.4941184520721436 seconds ---\n",
      "episode 5860, reward 202.0, memory_length 2000, epsilon 0.053397038145197084\n",
      "travel time- 721.0\n",
      "--- 1.6564483642578125 seconds ---\n",
      "episode 5861, reward -102.0, memory_length 2000, epsilon 0.05337034629964196\n",
      "travel time- 733.0\n",
      "--- 1.7737324237823486 seconds ---\n",
      "episode 5862, reward -170.0, memory_length 2000, epsilon 0.05334366779667368\n",
      "travel time- 725.0\n",
      "--- 1.8098666667938232 seconds ---\n",
      "episode 5863, reward 33.0, memory_length 2000, epsilon 0.05331700262962262\n",
      "travel time- 727.0\n",
      "--- 1.6670045852661133 seconds ---\n",
      "episode 5864, reward -226.0, memory_length 2000, epsilon 0.053290350791822524\n",
      "travel time- 726.0\n",
      "--- 1.7431211471557617 seconds ---\n",
      "episode 5865, reward 54.0, memory_length 2000, epsilon 0.05326371227661037\n",
      "travel time- 728.0\n",
      "--- 1.7831072807312012 seconds ---\n",
      "episode 5866, reward 149.0, memory_length 2000, epsilon 0.05323708707732657\n",
      "travel time- 721.0\n",
      "--- 1.519080638885498 seconds ---\n",
      "episode 5867, reward 59.0, memory_length 2000, epsilon 0.053210475187314844\n",
      "travel time- 720.0\n",
      "--- 1.5180778503417969 seconds ---\n",
      "episode 5868, reward 12.0, memory_length 2000, epsilon 0.05318387659992216\n",
      "travel time- 723.0\n",
      "--- 1.4908311367034912 seconds ---\n",
      "episode 5869, reward -139.0, memory_length 2000, epsilon 0.05315729130849893\n",
      "travel time- 721.0\n",
      "--- 1.7828307151794434 seconds ---\n",
      "episode 5870, reward -91.0, memory_length 2000, epsilon 0.05313071930639878\n",
      "travel time- 724.0\n",
      "--- 1.7018883228302002 seconds ---\n",
      "episode 5871, reward 137.0, memory_length 2000, epsilon 0.053104160586978734\n",
      "travel time- 720.0\n",
      "--- 1.5100646018981934 seconds ---\n",
      "episode 5872, reward 83.0, memory_length 2000, epsilon 0.053077615143599134\n",
      "travel time- 727.0\n",
      "--- 1.4109716415405273 seconds ---\n",
      "episode 5873, reward 348.0, memory_length 2000, epsilon 0.053051082969623575\n",
      "travel time- 732.0\n",
      "--- 1.7120039463043213 seconds ---\n",
      "episode 5874, reward 311.0, memory_length 2000, epsilon 0.05302456405841903\n",
      "travel time- 726.0\n",
      "--- 1.6275014877319336 seconds ---\n",
      "episode 5875, reward -87.0, memory_length 2000, epsilon 0.0529980584033558\n",
      "travel time- 724.0\n",
      "--- 1.6995940208435059 seconds ---\n",
      "episode 5876, reward 92.0, memory_length 2000, epsilon 0.052971565997807425\n",
      "travel time- 725.0\n",
      "--- 1.7007644176483154 seconds ---\n",
      "episode 5877, reward -66.0, memory_length 2000, epsilon 0.052945086835150854\n",
      "travel time- 722.0\n",
      "--- 1.8598253726959229 seconds ---\n",
      "episode 5878, reward -44.0, memory_length 2000, epsilon 0.052918620908766235\n",
      "travel time- 721.0\n",
      "--- 1.8122189044952393 seconds ---\n",
      "episode 5879, reward -280.0, memory_length 2000, epsilon 0.05289216821203713\n",
      "travel time- 731.0\n",
      "--- 1.7258615493774414 seconds ---\n",
      "episode 5880, reward -17.0, memory_length 2000, epsilon 0.05286572873835037\n",
      "travel time- 726.0\n",
      "--- 1.707937240600586 seconds ---\n",
      "episode 5881, reward 95.0, memory_length 2000, epsilon 0.05283930248109604\n",
      "travel time- 727.0\n",
      "--- 1.6633682250976562 seconds ---\n",
      "episode 5882, reward -86.0, memory_length 2000, epsilon 0.05281288943366762\n",
      "travel time- 727.0\n",
      "--- 1.5278310775756836 seconds ---\n",
      "episode 5883, reward 34.0, memory_length 2000, epsilon 0.052786489589461846\n",
      "travel time- 723.0\n",
      "--- 1.729518175125122 seconds ---\n",
      "episode 5884, reward -122.0, memory_length 2000, epsilon 0.052760102941878724\n",
      "travel time- 726.0\n",
      "--- 1.6527507305145264 seconds ---\n",
      "episode 5885, reward -72.0, memory_length 2000, epsilon 0.05273372948432163\n",
      "travel time- 721.0\n",
      "--- 1.7894973754882812 seconds ---\n",
      "episode 5886, reward 62.0, memory_length 2000, epsilon 0.05270736921019717\n",
      "travel time- 725.0\n",
      "--- 1.4111993312835693 seconds ---\n",
      "episode 5887, reward 214.0, memory_length 2000, epsilon 0.052681022112915275\n",
      "travel time- 721.0\n",
      "--- 1.5793852806091309 seconds ---\n",
      "episode 5888, reward 262.0, memory_length 2000, epsilon 0.05265468818588921\n",
      "travel time- 720.0\n",
      "--- 1.6464405059814453 seconds ---\n",
      "episode 5889, reward 45.0, memory_length 2000, epsilon 0.052628367422535446\n",
      "travel time- 729.0\n",
      "--- 1.5151536464691162 seconds ---\n",
      "episode 5890, reward 231.0, memory_length 2000, epsilon 0.05260205981627384\n",
      "travel time- 725.0\n",
      "--- 1.7370200157165527 seconds ---\n",
      "episode 5891, reward 253.0, memory_length 2000, epsilon 0.05257576536052743\n",
      "travel time- 722.0\n",
      "--- 1.482081413269043 seconds ---\n",
      "episode 5892, reward 160.0, memory_length 2000, epsilon 0.05254948404872264\n",
      "travel time- 725.0\n",
      "--- 1.4631726741790771 seconds ---\n",
      "episode 5893, reward -103.0, memory_length 2000, epsilon 0.05252321587428915\n",
      "travel time- 728.0\n",
      "--- 1.4951345920562744 seconds ---\n",
      "episode 5894, reward 134.0, memory_length 2000, epsilon 0.05249696083065988\n",
      "travel time- 722.0\n",
      "--- 1.5216152667999268 seconds ---\n",
      "episode 5895, reward 159.0, memory_length 2000, epsilon 0.0524707189112711\n",
      "travel time- 722.0\n",
      "--- 1.3137702941894531 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5896, reward 159.0, memory_length 2000, epsilon 0.05244449010956234\n",
      "travel time- 722.0\n",
      "--- 1.756685733795166 seconds ---\n",
      "episode 5897, reward -101.0, memory_length 2000, epsilon 0.052418274418976354\n",
      "travel time- 723.0\n",
      "--- 1.5989251136779785 seconds ---\n",
      "episode 5898, reward 197.0, memory_length 2000, epsilon 0.052392071832959276\n",
      "travel time- 722.0\n",
      "--- 1.6490774154663086 seconds ---\n",
      "episode 5899, reward -128.0, memory_length 2000, epsilon 0.052365882344960396\n",
      "travel time- 727.0\n",
      "--- 1.5386364459991455 seconds ---\n",
      "episode 5900, reward 104.0, memory_length 2000, epsilon 0.05233970594843238\n",
      "travel time- 727.0\n",
      "--- 1.557218074798584 seconds ---\n",
      "episode 5901, reward -46.0, memory_length 2000, epsilon 0.052313542636831155\n",
      "travel time- 728.0\n",
      "--- 1.588735818862915 seconds ---\n",
      "episode 5902, reward 115.0, memory_length 2000, epsilon 0.05228739240361583\n",
      "travel time- 723.0\n",
      "--- 1.520127773284912 seconds ---\n",
      "episode 5903, reward -149.0, memory_length 2000, epsilon 0.05226125524224888\n",
      "travel time- 721.0\n",
      "--- 1.8891487121582031 seconds ---\n",
      "episode 5904, reward 290.0, memory_length 2000, epsilon 0.05223513114619603\n",
      "travel time- 720.0\n",
      "--- 1.5203502178192139 seconds ---\n",
      "episode 5905, reward 121.0, memory_length 2000, epsilon 0.052209020108926224\n",
      "travel time- 722.0\n",
      "--- 1.6264822483062744 seconds ---\n",
      "episode 5906, reward -225.0, memory_length 2000, epsilon 0.052182922123911735\n",
      "travel time- 728.0\n",
      "--- 1.5698673725128174 seconds ---\n",
      "episode 5907, reward 200.0, memory_length 2000, epsilon 0.052156837184628026\n",
      "travel time- 725.0\n",
      "--- 1.6925079822540283 seconds ---\n",
      "episode 5908, reward 174.0, memory_length 2000, epsilon 0.05213076528455389\n",
      "travel time- 723.0\n",
      "--- 1.6645879745483398 seconds ---\n",
      "episode 5909, reward 14.0, memory_length 2000, epsilon 0.05210470641717137\n",
      "travel time- 724.0\n",
      "--- 1.7336170673370361 seconds ---\n",
      "episode 5910, reward -278.0, memory_length 2000, epsilon 0.05207866057596569\n",
      "travel time- 728.0\n",
      "--- 1.6593763828277588 seconds ---\n",
      "episode 5911, reward 97.0, memory_length 2000, epsilon 0.052052627754425436\n",
      "travel time- 732.0\n",
      "--- 1.6074316501617432 seconds ---\n",
      "episode 5912, reward -49.0, memory_length 2000, epsilon 0.052026607946042414\n",
      "travel time- 722.0\n",
      "--- 1.5330564975738525 seconds ---\n",
      "episode 5913, reward 108.0, memory_length 2000, epsilon 0.052000601144311626\n",
      "travel time- 721.0\n",
      "--- 1.5272657871246338 seconds ---\n",
      "episode 5914, reward -9.0, memory_length 2000, epsilon 0.05197460734273142\n",
      "travel time- 731.0\n",
      "--- 1.5756957530975342 seconds ---\n",
      "episode 5915, reward 168.0, memory_length 2000, epsilon 0.05194862653480329\n",
      "travel time- 724.0\n",
      "--- 1.6205401420593262 seconds ---\n",
      "episode 5916, reward 341.0, memory_length 2000, epsilon 0.05192265871403207\n",
      "travel time- 723.0\n",
      "--- 1.5452661514282227 seconds ---\n",
      "episode 5917, reward 116.0, memory_length 2000, epsilon 0.05189670387392582\n",
      "travel time- 721.0\n",
      "--- 1.8025248050689697 seconds ---\n",
      "episode 5918, reward 239.0, memory_length 2000, epsilon 0.051870762007995785\n",
      "travel time- 721.0\n",
      "--- 1.4881253242492676 seconds ---\n",
      "episode 5919, reward 243.0, memory_length 2000, epsilon 0.05184483310975652\n",
      "travel time- 723.0\n",
      "--- 1.530304193496704 seconds ---\n",
      "episode 5920, reward 244.0, memory_length 2000, epsilon 0.05181891717272583\n",
      "travel time- 732.0\n",
      "--- 1.453780174255371 seconds ---\n",
      "episode 5921, reward -183.0, memory_length 2000, epsilon 0.05179301419042468\n",
      "travel time- 721.0\n",
      "--- 1.8203887939453125 seconds ---\n",
      "episode 5922, reward -151.0, memory_length 2000, epsilon 0.051767124156377374\n",
      "travel time- 726.0\n",
      "--- 1.6657402515411377 seconds ---\n",
      "episode 5923, reward -32.0, memory_length 2000, epsilon 0.05174124706411135\n",
      "travel time- 725.0\n",
      "--- 1.6707651615142822 seconds ---\n",
      "episode 5924, reward -351.0, memory_length 2000, epsilon 0.05171538290715736\n",
      "travel time- 722.0\n",
      "--- 1.7073631286621094 seconds ---\n",
      "episode 5925, reward 33.0, memory_length 2000, epsilon 0.05168953167904939\n",
      "travel time- 721.0\n",
      "--- 1.681858777999878 seconds ---\n",
      "episode 5926, reward -217.0, memory_length 2000, epsilon 0.05166369337332458\n",
      "travel time- 728.0\n",
      "--- 1.7656378746032715 seconds ---\n",
      "episode 5927, reward -69.0, memory_length 2000, epsilon 0.05163786798352339\n",
      "travel time- 720.0\n",
      "--- 1.7592060565948486 seconds ---\n",
      "episode 5928, reward 146.0, memory_length 2000, epsilon 0.05161205550318949\n",
      "travel time- 722.0\n",
      "--- 1.5515506267547607 seconds ---\n",
      "episode 5929, reward 76.0, memory_length 2000, epsilon 0.051586255925869705\n",
      "travel time- 727.0\n",
      "--- 1.7127363681793213 seconds ---\n",
      "episode 5930, reward -441.0, memory_length 2000, epsilon 0.0515604692451142\n",
      "travel time- 724.0\n",
      "--- 1.656595230102539 seconds ---\n",
      "episode 5931, reward -41.0, memory_length 2000, epsilon 0.05153469545447625\n",
      "travel time- 723.0\n",
      "--- 1.5751962661743164 seconds ---\n",
      "episode 5932, reward 19.0, memory_length 2000, epsilon 0.051508934547512424\n",
      "travel time- 725.0\n",
      "--- 1.7606053352355957 seconds ---\n",
      "episode 5933, reward 297.0, memory_length 2000, epsilon 0.05148318651778253\n",
      "travel time- 727.0\n",
      "--- 1.4827399253845215 seconds ---\n",
      "episode 5934, reward -97.0, memory_length 2000, epsilon 0.051457451358849514\n",
      "travel time- 728.0\n",
      "--- 1.6927480697631836 seconds ---\n",
      "episode 5935, reward -357.0, memory_length 2000, epsilon 0.051431729064279605\n",
      "travel time- 728.0\n",
      "--- 1.6344928741455078 seconds ---\n",
      "episode 5936, reward -94.0, memory_length 2000, epsilon 0.051406019627642255\n",
      "travel time- 729.0\n",
      "--- 1.5996944904327393 seconds ---\n",
      "episode 5937, reward 203.0, memory_length 2000, epsilon 0.05138032304251005\n",
      "travel time- 724.0\n",
      "--- 1.5743725299835205 seconds ---\n",
      "episode 5938, reward -326.0, memory_length 2000, epsilon 0.051354639302458906\n",
      "travel time- 723.0\n",
      "--- 1.7100639343261719 seconds ---\n",
      "episode 5939, reward 182.0, memory_length 2000, epsilon 0.05132896840106782\n",
      "travel time- 728.0\n",
      "--- 1.629333734512329 seconds ---\n",
      "episode 5940, reward 28.0, memory_length 2000, epsilon 0.05130331033191911\n",
      "travel time- 726.0\n",
      "--- 1.5274105072021484 seconds ---\n",
      "episode 5941, reward -44.0, memory_length 2000, epsilon 0.051277665088598275\n",
      "travel time- 720.0\n",
      "--- 1.8300740718841553 seconds ---\n",
      "episode 5942, reward 17.0, memory_length 2000, epsilon 0.05125203266469395\n",
      "travel time- 721.0\n",
      "--- 1.6697139739990234 seconds ---\n",
      "episode 5943, reward -146.0, memory_length 2000, epsilon 0.05122641305379806\n",
      "travel time- 723.0\n",
      "--- 1.7487518787384033 seconds ---\n",
      "episode 5944, reward -206.0, memory_length 2000, epsilon 0.05120080624950572\n",
      "travel time- 722.0\n",
      "--- 1.760974645614624 seconds ---\n",
      "episode 5945, reward 13.0, memory_length 2000, epsilon 0.05117521224541519\n",
      "travel time- 725.0\n",
      "--- 1.6961841583251953 seconds ---\n",
      "episode 5946, reward -24.0, memory_length 2000, epsilon 0.05114963103512801\n",
      "travel time- 721.0\n",
      "--- 1.6201465129852295 seconds ---\n",
      "episode 5947, reward 36.0, memory_length 2000, epsilon 0.05112406261224883\n",
      "travel time- 732.0\n",
      "--- 1.5927817821502686 seconds ---\n",
      "episode 5948, reward -141.0, memory_length 2000, epsilon 0.05109850697038558\n",
      "travel time- 725.0\n",
      "--- 1.882218837738037 seconds ---\n",
      "episode 5949, reward -224.0, memory_length 2000, epsilon 0.05107296410314935\n",
      "travel time- 722.0\n",
      "--- 1.902156114578247 seconds ---\n",
      "episode 5950, reward -163.0, memory_length 2000, epsilon 0.051047434004154395\n",
      "travel time- 721.0\n",
      "--- 1.6500320434570312 seconds ---\n",
      "episode 5951, reward 202.0, memory_length 2000, epsilon 0.051021916667018205\n",
      "travel time- 721.0\n",
      "--- 1.5654170513153076 seconds ---\n",
      "episode 5952, reward -179.0, memory_length 2000, epsilon 0.050996412085361466\n",
      "travel time- 731.0\n",
      "--- 1.7223453521728516 seconds ---\n",
      "episode 5953, reward 34.0, memory_length 2000, epsilon 0.05097092025280799\n",
      "travel time- 727.0\n",
      "--- 1.5325586795806885 seconds ---\n",
      "episode 5954, reward -156.0, memory_length 2000, epsilon 0.05094544116298488\n",
      "travel time- 722.0\n",
      "--- 1.6285524368286133 seconds ---\n",
      "episode 5955, reward -8.0, memory_length 2000, epsilon 0.05091997480952229\n",
      "travel time- 721.0\n",
      "--- 1.4682552814483643 seconds ---\n",
      "episode 5956, reward 45.0, memory_length 2000, epsilon 0.05089452118605367\n",
      "travel time- 721.0\n",
      "--- 1.6901235580444336 seconds ---\n",
      "episode 5957, reward -91.0, memory_length 2000, epsilon 0.05086908028621564\n",
      "travel time- 733.0\n",
      "--- 1.6540882587432861 seconds ---\n",
      "episode 5958, reward -144.0, memory_length 2000, epsilon 0.05084365210364792\n",
      "travel time- 727.0\n",
      "--- 1.7957253456115723 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5959, reward -222.0, memory_length 2000, epsilon 0.05081823663199349\n",
      "travel time- 732.0\n",
      "--- 2.0053021907806396 seconds ---\n",
      "episode 5960, reward 169.0, memory_length 2000, epsilon 0.0507928338648985\n",
      "travel time- 730.0\n",
      "--- 1.8456602096557617 seconds ---\n",
      "episode 5961, reward 37.0, memory_length 2000, epsilon 0.050767443796012224\n",
      "travel time- 722.0\n",
      "--- 1.906404733657837 seconds ---\n",
      "episode 5962, reward -68.0, memory_length 2000, epsilon 0.05074206641898719\n",
      "travel time- 720.0\n",
      "--- 1.579664707183838 seconds ---\n",
      "episode 5963, reward 223.0, memory_length 2000, epsilon 0.05071670172747899\n",
      "travel time- 725.0\n",
      "--- 1.7016844749450684 seconds ---\n",
      "episode 5964, reward 168.0, memory_length 2000, epsilon 0.050691349715146494\n",
      "travel time- 722.0\n",
      "--- 1.558650016784668 seconds ---\n",
      "episode 5965, reward 304.0, memory_length 2000, epsilon 0.05066601037565171\n",
      "travel time- 723.0\n",
      "--- 1.65903639793396 seconds ---\n",
      "episode 5966, reward -225.0, memory_length 2000, epsilon 0.05064068370265976\n",
      "travel time- 727.0\n",
      "--- 1.7543847560882568 seconds ---\n",
      "episode 5967, reward -374.0, memory_length 2000, epsilon 0.050615369689839006\n",
      "travel time- 722.0\n",
      "--- 1.8796679973602295 seconds ---\n",
      "episode 5968, reward -217.0, memory_length 2000, epsilon 0.05059006833086096\n",
      "travel time- 721.0\n",
      "--- 1.8672065734863281 seconds ---\n",
      "episode 5969, reward 282.0, memory_length 2000, epsilon 0.05056477961940023\n",
      "travel time- 732.0\n",
      "--- 1.836143970489502 seconds ---\n",
      "episode 5970, reward 18.0, memory_length 2000, epsilon 0.050539503549134696\n",
      "travel time- 723.0\n",
      "--- 1.5562396049499512 seconds ---\n",
      "episode 5971, reward 105.0, memory_length 2000, epsilon 0.050514240113745286\n",
      "travel time- 729.0\n",
      "--- 1.558530569076538 seconds ---\n",
      "episode 5972, reward 149.0, memory_length 2000, epsilon 0.05048898930691617\n",
      "travel time- 723.0\n",
      "--- 1.691056728363037 seconds ---\n",
      "episode 5973, reward 30.0, memory_length 2000, epsilon 0.05046375112233467\n",
      "travel time- 738.0\n",
      "--- 1.481515884399414 seconds ---\n",
      "episode 5974, reward -130.0, memory_length 2000, epsilon 0.05043852555369119\n",
      "travel time- 733.0\n",
      "--- 1.8894813060760498 seconds ---\n",
      "episode 5975, reward 206.0, memory_length 2000, epsilon 0.050413312594679356\n",
      "travel time- 726.0\n",
      "--- 1.6247591972351074 seconds ---\n",
      "episode 5976, reward 249.0, memory_length 2000, epsilon 0.05038811223899596\n",
      "travel time- 723.0\n",
      "--- 1.5406601428985596 seconds ---\n",
      "episode 5977, reward -114.0, memory_length 2000, epsilon 0.05036292448034086\n",
      "travel time- 733.0\n",
      "--- 1.6587131023406982 seconds ---\n",
      "episode 5978, reward 40.0, memory_length 2000, epsilon 0.05033774931241717\n",
      "travel time- 727.0\n",
      "--- 1.6075780391693115 seconds ---\n",
      "episode 5979, reward 258.0, memory_length 2000, epsilon 0.05031258672893105\n",
      "travel time- 726.0\n",
      "--- 1.6460535526275635 seconds ---\n",
      "episode 5980, reward -120.0, memory_length 2000, epsilon 0.050287436723591865\n",
      "travel time- 728.0\n",
      "--- 1.8276329040527344 seconds ---\n",
      "episode 5981, reward 129.0, memory_length 2000, epsilon 0.050262299290112146\n",
      "travel time- 721.0\n",
      "--- 1.5863037109375 seconds ---\n",
      "episode 5982, reward -146.0, memory_length 2000, epsilon 0.050237174422207494\n",
      "travel time- 727.0\n",
      "--- 1.8561880588531494 seconds ---\n",
      "episode 5983, reward 135.0, memory_length 2000, epsilon 0.05021206211359671\n",
      "travel time- 725.0\n",
      "--- 1.495823860168457 seconds ---\n",
      "episode 5984, reward 288.0, memory_length 2000, epsilon 0.050186962358001734\n",
      "travel time- 723.0\n",
      "--- 1.6886112689971924 seconds ---\n",
      "episode 5985, reward -123.0, memory_length 2000, epsilon 0.050161875149147585\n",
      "travel time- 722.0\n",
      "--- 1.7192714214324951 seconds ---\n",
      "episode 5986, reward -188.0, memory_length 2000, epsilon 0.050136800480762515\n",
      "travel time- 726.0\n",
      "--- 1.61250638961792 seconds ---\n",
      "episode 5987, reward -36.0, memory_length 2000, epsilon 0.0501117383465778\n",
      "travel time- 721.0\n",
      "--- 1.6285672187805176 seconds ---\n",
      "episode 5988, reward -66.0, memory_length 2000, epsilon 0.05008668874032793\n",
      "travel time- 721.0\n",
      "--- 1.6445534229278564 seconds ---\n",
      "episode 5989, reward 93.0, memory_length 2000, epsilon 0.05006165165575053\n",
      "travel time- 723.0\n",
      "--- 1.7508106231689453 seconds ---\n",
      "episode 5990, reward -35.0, memory_length 2000, epsilon 0.05003662708658628\n",
      "travel time- 724.0\n",
      "--- 1.9131720066070557 seconds ---\n",
      "episode 5991, reward -89.0, memory_length 2000, epsilon 0.05001161502657907\n",
      "travel time- 724.0\n",
      "--- 1.661055326461792 seconds ---\n",
      "episode 5992, reward -137.0, memory_length 2000, epsilon 0.049986615469475894\n",
      "travel time- 723.0\n",
      "--- 1.576390266418457 seconds ---\n",
      "episode 5993, reward 252.0, memory_length 2000, epsilon 0.04996162840902682\n",
      "travel time- 733.0\n",
      "--- 1.6646182537078857 seconds ---\n",
      "episode 5994, reward -48.0, memory_length 2000, epsilon 0.049936653838985136\n",
      "travel time- 732.0\n",
      "--- 1.6044666767120361 seconds ---\n",
      "episode 5995, reward -103.0, memory_length 2000, epsilon 0.04991169175310715\n",
      "travel time- 722.0\n",
      "--- 1.8263113498687744 seconds ---\n",
      "episode 5996, reward -92.0, memory_length 2000, epsilon 0.04988674214515236\n",
      "travel time- 724.0\n",
      "--- 1.7447328567504883 seconds ---\n",
      "episode 5997, reward 240.0, memory_length 2000, epsilon 0.04986180500888339\n",
      "travel time- 720.0\n",
      "--- 1.680741786956787 seconds ---\n",
      "episode 5998, reward 153.0, memory_length 2000, epsilon 0.0498368803380659\n",
      "travel time- 721.0\n",
      "--- 1.5010104179382324 seconds ---\n",
      "episode 5999, reward 36.0, memory_length 2000, epsilon 0.049811968126468764\n",
      "travel time- 722.0\n",
      "--- 1.5820114612579346 seconds ---\n",
      "episode 6000, reward 142.0, memory_length 2000, epsilon 0.049787068367863944\n",
      "travel time- 726.0\n",
      "--- 1.6941218376159668 seconds ---\n",
      "episode 6001, reward -105.0, memory_length 2000, epsilon 0.04976218105602645\n",
      "travel time- 721.0\n",
      "--- 1.6296160221099854 seconds ---\n",
      "episode 6002, reward 145.0, memory_length 2000, epsilon 0.0497373061847345\n",
      "travel time- 730.0\n",
      "--- 1.7807376384735107 seconds ---\n",
      "episode 6003, reward -137.0, memory_length 2000, epsilon 0.04971244374776933\n",
      "travel time- 720.0\n",
      "--- 1.6542692184448242 seconds ---\n",
      "episode 6004, reward 154.0, memory_length 2000, epsilon 0.04968759373891536\n",
      "travel time- 723.0\n",
      "--- 1.8252949714660645 seconds ---\n",
      "episode 6005, reward 316.0, memory_length 2000, epsilon 0.04966275615196011\n",
      "travel time- 721.0\n",
      "--- 1.5139188766479492 seconds ---\n",
      "episode 6006, reward -109.0, memory_length 2000, epsilon 0.04963793098069413\n",
      "travel time- 724.0\n",
      "--- 1.4317138195037842 seconds ---\n",
      "episode 6007, reward 225.0, memory_length 2000, epsilon 0.049613118218911144\n",
      "travel time- 723.0\n",
      "--- 1.5597748756408691 seconds ---\n",
      "episode 6008, reward 29.0, memory_length 2000, epsilon 0.049588317860408\n",
      "travel time- 722.0\n",
      "--- 1.6458375453948975 seconds ---\n",
      "episode 6009, reward -213.0, memory_length 2000, epsilon 0.04956352989898456\n",
      "travel time- 720.0\n",
      "--- 1.5569450855255127 seconds ---\n",
      "episode 6010, reward 105.0, memory_length 2000, epsilon 0.04953875432844388\n",
      "travel time- 732.0\n",
      "--- 1.5002305507659912 seconds ---\n",
      "episode 6011, reward 208.0, memory_length 2000, epsilon 0.04951399114259201\n",
      "travel time- 722.0\n",
      "--- 1.5932929515838623 seconds ---\n",
      "episode 6012, reward -161.0, memory_length 2000, epsilon 0.04948924033523819\n",
      "travel time- 722.0\n",
      "--- 1.6135742664337158 seconds ---\n",
      "episode 6013, reward 57.0, memory_length 2000, epsilon 0.049464501900194725\n",
      "travel time- 720.0\n",
      "--- 1.7506718635559082 seconds ---\n",
      "episode 6014, reward -298.0, memory_length 2000, epsilon 0.049439775831276976\n",
      "travel time- 726.0\n",
      "--- 1.8477253913879395 seconds ---\n",
      "episode 6015, reward -5.0, memory_length 2000, epsilon 0.04941506212230344\n",
      "travel time- 724.0\n",
      "--- 1.5768499374389648 seconds ---\n",
      "episode 6016, reward -10.0, memory_length 2000, epsilon 0.049390360767095715\n",
      "travel time- 726.0\n",
      "--- 1.6030147075653076 seconds ---\n",
      "episode 6017, reward 250.0, memory_length 2000, epsilon 0.04936567175947842\n",
      "travel time- 725.0\n",
      "--- 1.6161909103393555 seconds ---\n",
      "episode 6018, reward 16.0, memory_length 2000, epsilon 0.04934099509327934\n",
      "travel time- 720.0\n",
      "--- 1.3830156326293945 seconds ---\n",
      "episode 6019, reward 120.0, memory_length 2000, epsilon 0.049316330762329275\n",
      "travel time- 722.0\n",
      "--- 1.593519687652588 seconds ---\n",
      "episode 6020, reward -57.0, memory_length 2000, epsilon 0.04929167876046215\n",
      "travel time- 720.0\n",
      "--- 1.7994866371154785 seconds ---\n",
      "episode 6021, reward 61.0, memory_length 2000, epsilon 0.049267039081514995\n",
      "travel time- 721.0\n",
      "--- 1.9245867729187012 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6022, reward 227.0, memory_length 2000, epsilon 0.04924241171932785\n",
      "travel time- 722.0\n",
      "--- 1.6996889114379883 seconds ---\n",
      "episode 6023, reward -25.0, memory_length 2000, epsilon 0.0492177966677439\n",
      "travel time- 721.0\n",
      "--- 1.7380077838897705 seconds ---\n",
      "episode 6024, reward 47.0, memory_length 2000, epsilon 0.04919319392060936\n",
      "travel time- 726.0\n",
      "--- 1.594942331314087 seconds ---\n",
      "episode 6025, reward -3.0, memory_length 2000, epsilon 0.04916860347177356\n",
      "travel time- 723.0\n",
      "--- 1.6820449829101562 seconds ---\n",
      "episode 6026, reward -108.0, memory_length 2000, epsilon 0.04914402531508891\n",
      "travel time- 720.0\n",
      "--- 1.7239267826080322 seconds ---\n",
      "episode 6027, reward 134.0, memory_length 2000, epsilon 0.04911945944441081\n",
      "travel time- 723.0\n",
      "--- 1.4444379806518555 seconds ---\n",
      "episode 6028, reward 268.0, memory_length 2000, epsilon 0.04909490585359783\n",
      "travel time- 722.0\n",
      "--- 1.5605103969573975 seconds ---\n",
      "episode 6029, reward 165.0, memory_length 2000, epsilon 0.0490703645365116\n",
      "travel time- 720.0\n",
      "--- 1.6331782341003418 seconds ---\n",
      "episode 6030, reward 146.0, memory_length 2000, epsilon 0.04904583548701673\n",
      "travel time- 720.0\n",
      "--- 1.8086309432983398 seconds ---\n",
      "episode 6031, reward 196.0, memory_length 2000, epsilon 0.04902131869898101\n",
      "travel time- 725.0\n",
      "--- 1.4606425762176514 seconds ---\n",
      "episode 6032, reward 82.0, memory_length 2000, epsilon 0.0489968141662752\n",
      "travel time- 722.0\n",
      "--- 1.571516513824463 seconds ---\n",
      "episode 6033, reward 170.0, memory_length 2000, epsilon 0.04897232188277319\n",
      "travel time- 721.0\n",
      "--- 1.6893157958984375 seconds ---\n",
      "episode 6034, reward 11.0, memory_length 2000, epsilon 0.048947841842351916\n",
      "travel time- 724.0\n",
      "--- 1.692124843597412 seconds ---\n",
      "episode 6035, reward 74.0, memory_length 2000, epsilon 0.04892337403889135\n",
      "travel time- 720.0\n",
      "--- 1.575767993927002 seconds ---\n",
      "episode 6036, reward -59.0, memory_length 2000, epsilon 0.04889891846627454\n",
      "travel time- 721.0\n",
      "--- 1.674318790435791 seconds ---\n",
      "episode 6037, reward -4.0, memory_length 2000, epsilon 0.04887447511838762\n",
      "travel time- 725.0\n",
      "--- 1.643928050994873 seconds ---\n",
      "episode 6038, reward -301.0, memory_length 2000, epsilon 0.04885004398911972\n",
      "travel time- 723.0\n",
      "--- 1.650893211364746 seconds ---\n",
      "episode 6039, reward 156.0, memory_length 2000, epsilon 0.048825625072363085\n",
      "travel time- 726.0\n",
      "--- 1.5073943138122559 seconds ---\n",
      "episode 6040, reward -51.0, memory_length 2000, epsilon 0.04880121836201296\n",
      "travel time- 724.0\n",
      "--- 1.7321934700012207 seconds ---\n",
      "episode 6041, reward 199.0, memory_length 2000, epsilon 0.048776823851967674\n",
      "travel time- 734.0\n",
      "--- 1.6394498348236084 seconds ---\n",
      "episode 6042, reward -81.0, memory_length 2000, epsilon 0.04875244153612863\n",
      "travel time- 724.0\n",
      "--- 1.9697811603546143 seconds ---\n",
      "episode 6043, reward -31.0, memory_length 2000, epsilon 0.0487280714084002\n",
      "travel time- 722.0\n",
      "--- 1.4085547924041748 seconds ---\n",
      "episode 6044, reward -241.0, memory_length 2000, epsilon 0.048703713462689875\n",
      "travel time- 726.0\n",
      "--- 1.525273084640503 seconds ---\n",
      "episode 6045, reward -81.0, memory_length 2000, epsilon 0.0486793676929082\n",
      "travel time- 722.0\n",
      "--- 1.5602610111236572 seconds ---\n",
      "episode 6046, reward -276.0, memory_length 2000, epsilon 0.04865503409296867\n",
      "travel time- 721.0\n",
      "--- 1.4445536136627197 seconds ---\n",
      "episode 6047, reward 70.0, memory_length 2000, epsilon 0.048630712656787936\n",
      "travel time- 729.0\n",
      "--- 1.7909071445465088 seconds ---\n",
      "episode 6048, reward 75.0, memory_length 2000, epsilon 0.048606403378285604\n",
      "travel time- 721.0\n",
      "--- 1.647590160369873 seconds ---\n",
      "episode 6049, reward 88.0, memory_length 2000, epsilon 0.04858210625138437\n",
      "travel time- 722.0\n",
      "--- 1.7372844219207764 seconds ---\n",
      "episode 6050, reward 13.0, memory_length 2000, epsilon 0.048557821270009974\n",
      "travel time- 723.0\n",
      "--- 1.6999549865722656 seconds ---\n",
      "episode 6051, reward 38.0, memory_length 2000, epsilon 0.04853354842809112\n",
      "travel time- 720.0\n",
      "--- 1.652045726776123 seconds ---\n",
      "episode 6052, reward 169.0, memory_length 2000, epsilon 0.04850928771955963\n",
      "travel time- 722.0\n",
      "--- 1.5594840049743652 seconds ---\n",
      "episode 6053, reward 74.0, memory_length 2000, epsilon 0.048485039138350346\n",
      "travel time- 729.0\n",
      "--- 1.62406325340271 seconds ---\n",
      "episode 6054, reward 32.0, memory_length 2000, epsilon 0.048460802678401076\n",
      "travel time- 723.0\n",
      "--- 1.6417484283447266 seconds ---\n",
      "episode 6055, reward 282.0, memory_length 2000, epsilon 0.04843657833365275\n",
      "travel time- 726.0\n",
      "--- 1.7403955459594727 seconds ---\n",
      "episode 6056, reward -24.0, memory_length 2000, epsilon 0.04841236609804924\n",
      "travel time- 731.0\n",
      "--- 1.4985136985778809 seconds ---\n",
      "episode 6057, reward 161.0, memory_length 2000, epsilon 0.0483881659655375\n",
      "travel time- 725.0\n",
      "--- 1.6669082641601562 seconds ---\n",
      "episode 6058, reward 207.0, memory_length 2000, epsilon 0.04836397793006753\n",
      "travel time- 736.0\n",
      "--- 1.667856216430664 seconds ---\n",
      "episode 6059, reward 138.0, memory_length 2000, epsilon 0.048339801985592276\n",
      "travel time- 720.0\n",
      "--- 1.4903035163879395 seconds ---\n",
      "episode 6060, reward 12.0, memory_length 2000, epsilon 0.04831563812606777\n",
      "travel time- 725.0\n",
      "--- 1.73103928565979 seconds ---\n",
      "episode 6061, reward -86.0, memory_length 2000, epsilon 0.048291486345453064\n",
      "travel time- 720.0\n",
      "--- 1.6070036888122559 seconds ---\n",
      "episode 6062, reward -77.0, memory_length 2000, epsilon 0.04826734663771017\n",
      "travel time- 727.0\n",
      "--- 1.6409986019134521 seconds ---\n",
      "episode 6063, reward -437.0, memory_length 2000, epsilon 0.04824321899680422\n",
      "travel time- 720.0\n",
      "--- 1.8318424224853516 seconds ---\n",
      "episode 6064, reward -164.0, memory_length 2000, epsilon 0.04821910341670324\n",
      "travel time- 731.0\n",
      "--- 1.613201379776001 seconds ---\n",
      "episode 6065, reward 41.0, memory_length 2000, epsilon 0.04819499989137837\n",
      "travel time- 730.0\n",
      "--- 1.5399260520935059 seconds ---\n",
      "episode 6066, reward 52.0, memory_length 2000, epsilon 0.048170908414803745\n",
      "travel time- 720.0\n",
      "--- 1.548879861831665 seconds ---\n",
      "episode 6067, reward 134.0, memory_length 2000, epsilon 0.04814682898095645\n",
      "travel time- 727.0\n",
      "--- 1.627506971359253 seconds ---\n",
      "episode 6068, reward -83.0, memory_length 2000, epsilon 0.048122761583816655\n",
      "travel time- 721.0\n",
      "--- 1.7190213203430176 seconds ---\n",
      "episode 6069, reward -13.0, memory_length 2000, epsilon 0.048098706217367525\n",
      "travel time- 720.0\n",
      "--- 1.5613915920257568 seconds ---\n",
      "episode 6070, reward 188.0, memory_length 2000, epsilon 0.04807466287559518\n",
      "travel time- 725.0\n",
      "--- 1.6488282680511475 seconds ---\n",
      "episode 6071, reward 68.0, memory_length 2000, epsilon 0.04805063155248882\n",
      "travel time- 731.0\n",
      "--- 1.835754632949829 seconds ---\n",
      "episode 6072, reward 115.0, memory_length 2000, epsilon 0.048026612242040585\n",
      "travel time- 721.0\n",
      "--- 1.8121399879455566 seconds ---\n",
      "episode 6073, reward -141.0, memory_length 2000, epsilon 0.04800260493824566\n",
      "travel time- 725.0\n",
      "--- 1.5771265029907227 seconds ---\n",
      "episode 6074, reward 140.0, memory_length 2000, epsilon 0.04797860963510223\n",
      "travel time- 723.0\n",
      "--- 1.5726299285888672 seconds ---\n",
      "episode 6075, reward 118.0, memory_length 2000, epsilon 0.04795462632661145\n",
      "travel time- 720.0\n",
      "--- 1.6855442523956299 seconds ---\n",
      "episode 6076, reward 32.0, memory_length 2000, epsilon 0.0479306550067775\n",
      "travel time- 723.0\n",
      "--- 1.2904858589172363 seconds ---\n",
      "episode 6077, reward -141.0, memory_length 2000, epsilon 0.04790669566960757\n",
      "travel time- 729.0\n",
      "--- 1.7534372806549072 seconds ---\n",
      "episode 6078, reward 56.0, memory_length 2000, epsilon 0.04788274830911178\n",
      "travel time- 724.0\n",
      "--- 1.6353139877319336 seconds ---\n",
      "episode 6079, reward 75.0, memory_length 2000, epsilon 0.04785881291930335\n",
      "travel time- 720.0\n",
      "--- 1.8349454402923584 seconds ---\n",
      "episode 6080, reward 157.0, memory_length 2000, epsilon 0.04783488949419837\n",
      "travel time- 729.0\n",
      "--- 1.5147807598114014 seconds ---\n",
      "episode 6081, reward -109.0, memory_length 2000, epsilon 0.04781097802781601\n",
      "travel time- 721.0\n",
      "--- 1.6359474658966064 seconds ---\n",
      "episode 6082, reward -12.0, memory_length 2000, epsilon 0.04778707851417843\n",
      "travel time- 728.0\n",
      "--- 1.7291529178619385 seconds ---\n",
      "episode 6083, reward -360.0, memory_length 2000, epsilon 0.04776319094731071\n",
      "travel time- 720.0\n",
      "--- 1.610795497894287 seconds ---\n",
      "episode 6084, reward -219.0, memory_length 2000, epsilon 0.047739315321240976\n",
      "travel time- 724.0\n",
      "--- 1.488053321838379 seconds ---\n",
      "episode 6085, reward -34.0, memory_length 2000, epsilon 0.047715451630000336\n",
      "travel time- 721.0\n",
      "--- 1.6100366115570068 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6086, reward -89.0, memory_length 2000, epsilon 0.047691599867622836\n",
      "travel time- 727.0\n",
      "--- 1.8017926216125488 seconds ---\n",
      "episode 6087, reward 62.0, memory_length 2000, epsilon 0.047667760028145566\n",
      "travel time- 722.0\n",
      "--- 1.669975757598877 seconds ---\n",
      "episode 6088, reward 145.0, memory_length 2000, epsilon 0.047643932105608536\n",
      "travel time- 722.0\n",
      "--- 1.5917255878448486 seconds ---\n",
      "episode 6089, reward 235.0, memory_length 2000, epsilon 0.04762011609405478\n",
      "travel time- 727.0\n",
      "--- 1.5412452220916748 seconds ---\n",
      "episode 6090, reward -129.0, memory_length 2000, epsilon 0.04759631198753032\n",
      "travel time- 727.0\n",
      "--- 1.6346776485443115 seconds ---\n",
      "episode 6091, reward -157.0, memory_length 2000, epsilon 0.047572519780084074\n",
      "travel time- 723.0\n",
      "--- 1.8009815216064453 seconds ---\n",
      "episode 6092, reward -53.0, memory_length 2000, epsilon 0.04754873946576803\n",
      "travel time- 729.0\n",
      "--- 1.7716343402862549 seconds ---\n",
      "episode 6093, reward 187.0, memory_length 2000, epsilon 0.047524971038637114\n",
      "travel time- 725.0\n",
      "--- 1.6150100231170654 seconds ---\n",
      "episode 6094, reward 44.0, memory_length 2000, epsilon 0.04750121449274919\n",
      "travel time- 723.0\n",
      "--- 1.612657070159912 seconds ---\n",
      "episode 6095, reward -11.0, memory_length 2000, epsilon 0.04747746982216516\n",
      "travel time- 722.0\n",
      "--- 1.7037880420684814 seconds ---\n",
      "episode 6096, reward 48.0, memory_length 2000, epsilon 0.0474537370209488\n",
      "travel time- 725.0\n",
      "--- 1.6351335048675537 seconds ---\n",
      "episode 6097, reward 160.0, memory_length 2000, epsilon 0.04743001608316695\n",
      "travel time- 721.0\n",
      "--- 1.7632622718811035 seconds ---\n",
      "episode 6098, reward -90.0, memory_length 2000, epsilon 0.04740630700288939\n",
      "travel time- 724.0\n",
      "--- 1.578174352645874 seconds ---\n",
      "episode 6099, reward 324.0, memory_length 2000, epsilon 0.0473826097741888\n",
      "travel time- 722.0\n",
      "--- 1.6443297863006592 seconds ---\n",
      "episode 6100, reward 146.0, memory_length 2000, epsilon 0.04735892439114091\n",
      "travel time- 729.0\n",
      "--- 1.7917759418487549 seconds ---\n",
      "episode 6101, reward 186.0, memory_length 2000, epsilon 0.04733525084782438\n",
      "travel time- 724.0\n",
      "--- 1.4189577102661133 seconds ---\n",
      "episode 6102, reward 176.0, memory_length 2000, epsilon 0.047311589138320786\n",
      "travel time- 723.0\n",
      "--- 1.6853487491607666 seconds ---\n",
      "episode 6103, reward -29.0, memory_length 2000, epsilon 0.04728793925671475\n",
      "travel time- 721.0\n",
      "--- 1.6595399379730225 seconds ---\n",
      "episode 6104, reward 61.0, memory_length 2000, epsilon 0.047264301197093746\n",
      "travel time- 720.0\n",
      "--- 1.7127172946929932 seconds ---\n",
      "episode 6105, reward -46.0, memory_length 2000, epsilon 0.04724067495354829\n",
      "travel time- 722.0\n",
      "--- 1.5139756202697754 seconds ---\n",
      "episode 6106, reward -147.0, memory_length 2000, epsilon 0.04721706052017184\n",
      "travel time- 725.0\n",
      "--- 1.7399346828460693 seconds ---\n",
      "episode 6107, reward 206.0, memory_length 2000, epsilon 0.04719345789106075\n",
      "travel time- 723.0\n",
      "--- 1.606142282485962 seconds ---\n",
      "episode 6108, reward 290.0, memory_length 2000, epsilon 0.04716986706031437\n",
      "travel time- 724.0\n",
      "--- 1.529996633529663 seconds ---\n",
      "episode 6109, reward -22.0, memory_length 2000, epsilon 0.04714628802203503\n",
      "travel time- 721.0\n",
      "--- 1.6975739002227783 seconds ---\n",
      "episode 6110, reward 19.0, memory_length 2000, epsilon 0.04712272077032791\n",
      "travel time- 721.0\n",
      "--- 1.681624412536621 seconds ---\n",
      "episode 6111, reward -43.0, memory_length 2000, epsilon 0.047099165299301256\n",
      "travel time- 728.0\n",
      "--- 1.4636778831481934 seconds ---\n",
      "episode 6112, reward -7.0, memory_length 2000, epsilon 0.04707562160306615\n",
      "travel time- 728.0\n",
      "--- 1.43015718460083 seconds ---\n",
      "episode 6113, reward 69.0, memory_length 2000, epsilon 0.047052089675736694\n",
      "travel time- 735.0\n",
      "--- 1.480804681777954 seconds ---\n",
      "episode 6114, reward -34.0, memory_length 2000, epsilon 0.04702856951142992\n",
      "travel time- 725.0\n",
      "--- 1.5550012588500977 seconds ---\n",
      "episode 6115, reward 63.0, memory_length 2000, epsilon 0.04700506110426574\n",
      "travel time- 723.0\n",
      "--- 1.7519874572753906 seconds ---\n",
      "episode 6116, reward 58.0, memory_length 2000, epsilon 0.04698156444836709\n",
      "travel time- 731.0\n",
      "--- 1.5939991474151611 seconds ---\n",
      "episode 6117, reward -168.0, memory_length 2000, epsilon 0.04695807953785982\n",
      "travel time- 726.0\n",
      "--- 1.5996649265289307 seconds ---\n",
      "episode 6118, reward 114.0, memory_length 2000, epsilon 0.04693460636687265\n",
      "travel time- 735.0\n",
      "--- 1.8127529621124268 seconds ---\n",
      "episode 6119, reward 110.0, memory_length 2000, epsilon 0.04691114492953734\n",
      "travel time- 721.0\n",
      "--- 1.6952762603759766 seconds ---\n",
      "episode 6120, reward 109.0, memory_length 2000, epsilon 0.046887695219988486\n",
      "travel time- 721.0\n",
      "--- 1.6701455116271973 seconds ---\n",
      "episode 6121, reward 104.0, memory_length 2000, epsilon 0.04686425723236368\n",
      "travel time- 725.0\n",
      "--- 1.6350586414337158 seconds ---\n",
      "episode 6122, reward 277.0, memory_length 2000, epsilon 0.04684083096080345\n",
      "travel time- 723.0\n",
      "--- 1.7109098434448242 seconds ---\n",
      "episode 6123, reward -75.0, memory_length 2000, epsilon 0.04681741639945118\n",
      "travel time- 721.0\n",
      "--- 1.8258545398712158 seconds ---\n",
      "episode 6124, reward -292.0, memory_length 2000, epsilon 0.04679401354245326\n",
      "travel time- 721.0\n",
      "--- 1.8627955913543701 seconds ---\n",
      "episode 6125, reward -20.0, memory_length 2000, epsilon 0.04677062238395898\n",
      "travel time- 727.0\n",
      "--- 1.7824573516845703 seconds ---\n",
      "episode 6126, reward 292.0, memory_length 2000, epsilon 0.046747242918120525\n",
      "travel time- 721.0\n",
      "--- 1.8458318710327148 seconds ---\n",
      "episode 6127, reward 245.0, memory_length 2000, epsilon 0.04672387513909307\n",
      "travel time- 728.0\n",
      "--- 1.617351770401001 seconds ---\n",
      "episode 6128, reward 159.0, memory_length 2000, epsilon 0.04670051904103461\n",
      "travel time- 723.0\n",
      "--- 1.8915162086486816 seconds ---\n",
      "episode 6129, reward 85.0, memory_length 2000, epsilon 0.04667717461810616\n",
      "travel time- 726.0\n",
      "--- 1.6952142715454102 seconds ---\n",
      "episode 6130, reward -129.0, memory_length 2000, epsilon 0.04665384186447163\n",
      "travel time- 726.0\n",
      "--- 1.6697709560394287 seconds ---\n",
      "episode 6131, reward -383.0, memory_length 2000, epsilon 0.04663052077429779\n",
      "travel time- 730.0\n",
      "--- 1.9055049419403076 seconds ---\n",
      "episode 6132, reward 139.0, memory_length 2000, epsilon 0.04660721134175438\n",
      "travel time- 722.0\n",
      "--- 1.5761899948120117 seconds ---\n",
      "episode 6133, reward -143.0, memory_length 2000, epsilon 0.046583913561014066\n",
      "travel time- 723.0\n",
      "--- 1.709287405014038 seconds ---\n",
      "episode 6134, reward -110.0, memory_length 2000, epsilon 0.046560627426252374\n",
      "travel time- 730.0\n",
      "--- 1.6949329376220703 seconds ---\n",
      "episode 6135, reward 205.0, memory_length 2000, epsilon 0.0465373529316478\n",
      "travel time- 723.0\n",
      "--- 1.875455379486084 seconds ---\n",
      "episode 6136, reward 50.0, memory_length 2000, epsilon 0.04651409007138167\n",
      "travel time- 722.0\n",
      "--- 1.6306252479553223 seconds ---\n",
      "episode 6137, reward 31.0, memory_length 2000, epsilon 0.04649083883963831\n",
      "travel time- 735.0\n",
      "--- 1.5611867904663086 seconds ---\n",
      "episode 6138, reward -34.0, memory_length 2000, epsilon 0.04646759923060492\n",
      "travel time- 721.0\n",
      "--- 1.883497714996338 seconds ---\n",
      "episode 6139, reward 80.0, memory_length 2000, epsilon 0.04644437123847156\n",
      "travel time- 730.0\n",
      "--- 1.6467421054840088 seconds ---\n",
      "episode 6140, reward -187.0, memory_length 2000, epsilon 0.04642115485743125\n",
      "travel time- 722.0\n",
      "--- 1.6243205070495605 seconds ---\n",
      "episode 6141, reward 221.0, memory_length 2000, epsilon 0.04639795008167992\n",
      "travel time- 724.0\n",
      "--- 1.5379862785339355 seconds ---\n",
      "episode 6142, reward -52.0, memory_length 2000, epsilon 0.04637475690541633\n",
      "travel time- 720.0\n",
      "--- 1.6695475578308105 seconds ---\n",
      "episode 6143, reward -131.0, memory_length 2000, epsilon 0.046351575322842224\n",
      "travel time- 722.0\n",
      "--- 1.8353562355041504 seconds ---\n",
      "episode 6144, reward 235.0, memory_length 2000, epsilon 0.046328405328162174\n",
      "travel time- 722.0\n",
      "--- 1.7238399982452393 seconds ---\n",
      "episode 6145, reward -44.0, memory_length 2000, epsilon 0.0463052469155837\n",
      "travel time- 725.0\n",
      "--- 1.5178170204162598 seconds ---\n",
      "episode 6146, reward -181.0, memory_length 2000, epsilon 0.04628210007931721\n",
      "travel time- 724.0\n",
      "--- 1.5521223545074463 seconds ---\n",
      "episode 6147, reward 279.0, memory_length 2000, epsilon 0.04625896481357596\n",
      "travel time- 726.0\n",
      "--- 1.6343903541564941 seconds ---\n",
      "episode 6148, reward 77.0, memory_length 2000, epsilon 0.046235841112576184\n",
      "travel time- 723.0\n",
      "--- 1.5938301086425781 seconds ---\n",
      "episode 6149, reward -72.0, memory_length 2000, epsilon 0.0462127289705369\n",
      "travel time- 729.0\n",
      "--- 1.7781546115875244 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6150, reward -9.0, memory_length 2000, epsilon 0.0461896283816801\n",
      "travel time- 726.0\n",
      "--- 1.7741963863372803 seconds ---\n",
      "episode 6151, reward -245.0, memory_length 2000, epsilon 0.046166539340230656\n",
      "travel time- 723.0\n",
      "--- 1.719053030014038 seconds ---\n",
      "episode 6152, reward 18.0, memory_length 2000, epsilon 0.04614346184041627\n",
      "travel time- 726.0\n",
      "--- 1.6003565788269043 seconds ---\n",
      "episode 6153, reward 190.0, memory_length 2000, epsilon 0.04612039587646758\n",
      "travel time- 730.0\n",
      "--- 1.4905731678009033 seconds ---\n",
      "episode 6154, reward -293.0, memory_length 2000, epsilon 0.04609734144261812\n",
      "travel time- 721.0\n",
      "--- 1.4973523616790771 seconds ---\n",
      "episode 6155, reward -168.0, memory_length 2000, epsilon 0.04607429853310425\n",
      "travel time- 729.0\n",
      "--- 1.7766480445861816 seconds ---\n",
      "episode 6156, reward -105.0, memory_length 2000, epsilon 0.046051267142165266\n",
      "travel time- 721.0\n",
      "--- 1.5904600620269775 seconds ---\n",
      "episode 6157, reward -114.0, memory_length 2000, epsilon 0.04602824726404328\n",
      "travel time- 722.0\n",
      "--- 1.6379039287567139 seconds ---\n",
      "episode 6158, reward 10.0, memory_length 2000, epsilon 0.04600523889298336\n",
      "travel time- 726.0\n",
      "--- 1.5868699550628662 seconds ---\n",
      "episode 6159, reward 229.0, memory_length 2000, epsilon 0.04598224202323342\n",
      "travel time- 724.0\n",
      "--- 1.805765151977539 seconds ---\n",
      "episode 6160, reward 260.0, memory_length 2000, epsilon 0.045959256649044204\n",
      "travel time- 727.0\n",
      "--- 1.4709584712982178 seconds ---\n",
      "episode 6161, reward -345.0, memory_length 2000, epsilon 0.04593628276466939\n",
      "travel time- 720.0\n",
      "--- 1.6750800609588623 seconds ---\n",
      "episode 6162, reward 383.0, memory_length 2000, epsilon 0.04591332036436553\n",
      "travel time- 721.0\n",
      "--- 1.7489326000213623 seconds ---\n",
      "episode 6163, reward 35.0, memory_length 2000, epsilon 0.04589036944239198\n",
      "travel time- 721.0\n",
      "--- 1.5732285976409912 seconds ---\n",
      "episode 6164, reward 57.0, memory_length 2000, epsilon 0.04586742999301104\n",
      "travel time- 728.0\n",
      "--- 1.7442426681518555 seconds ---\n",
      "episode 6165, reward -298.0, memory_length 2000, epsilon 0.04584450201048783\n",
      "travel time- 733.0\n",
      "--- 1.7493858337402344 seconds ---\n",
      "episode 6166, reward 144.0, memory_length 2000, epsilon 0.045821585489090357\n",
      "travel time- 723.0\n",
      "--- 1.7245218753814697 seconds ---\n",
      "episode 6167, reward 81.0, memory_length 2000, epsilon 0.04579868042308951\n",
      "travel time- 723.0\n",
      "--- 1.5186309814453125 seconds ---\n",
      "episode 6168, reward 513.0, memory_length 2000, epsilon 0.04577578680675899\n",
      "travel time- 729.0\n",
      "--- 1.721679449081421 seconds ---\n",
      "episode 6169, reward 448.0, memory_length 2000, epsilon 0.04575290463437541\n",
      "travel time- 722.0\n",
      "--- 1.577406644821167 seconds ---\n",
      "episode 6170, reward 161.0, memory_length 2000, epsilon 0.04573003390021825\n",
      "travel time- 720.0\n",
      "--- 1.4500877857208252 seconds ---\n",
      "episode 6171, reward -114.0, memory_length 2000, epsilon 0.04570717459856978\n",
      "travel time- 725.0\n",
      "--- 1.667574167251587 seconds ---\n",
      "episode 6172, reward 227.0, memory_length 2000, epsilon 0.04568432672371522\n",
      "travel time- 724.0\n",
      "--- 1.539313793182373 seconds ---\n",
      "episode 6173, reward 141.0, memory_length 2000, epsilon 0.04566149026994255\n",
      "travel time- 721.0\n",
      "--- 1.5458722114562988 seconds ---\n",
      "episode 6174, reward -225.0, memory_length 2000, epsilon 0.0456386652315427\n",
      "travel time- 723.0\n",
      "--- 1.6540863513946533 seconds ---\n",
      "episode 6175, reward 12.0, memory_length 2000, epsilon 0.045615851602809405\n",
      "travel time- 721.0\n",
      "--- 1.7876079082489014 seconds ---\n",
      "episode 6176, reward -17.0, memory_length 2000, epsilon 0.045593049378039235\n",
      "travel time- 721.0\n",
      "--- 1.7078485488891602 seconds ---\n",
      "episode 6177, reward -35.0, memory_length 2000, epsilon 0.04557025855153164\n",
      "travel time- 722.0\n",
      "--- 1.7240939140319824 seconds ---\n",
      "episode 6178, reward -176.0, memory_length 2000, epsilon 0.04554747911758895\n",
      "travel time- 722.0\n",
      "--- 1.541205644607544 seconds ---\n",
      "episode 6179, reward 318.0, memory_length 2000, epsilon 0.04552471107051625\n",
      "travel time- 728.0\n",
      "--- 1.623110055923462 seconds ---\n",
      "episode 6180, reward 275.0, memory_length 2000, epsilon 0.04550195440462157\n",
      "travel time- 723.0\n",
      "--- 1.6575045585632324 seconds ---\n",
      "episode 6181, reward 74.0, memory_length 2000, epsilon 0.04547920911421571\n",
      "travel time- 725.0\n",
      "--- 1.8220279216766357 seconds ---\n",
      "episode 6182, reward 7.0, memory_length 2000, epsilon 0.04545647519361237\n",
      "travel time- 730.0\n",
      "--- 1.6380033493041992 seconds ---\n",
      "episode 6183, reward -40.0, memory_length 2000, epsilon 0.04543375263712809\n",
      "travel time- 727.0\n",
      "--- 1.7329003810882568 seconds ---\n",
      "episode 6184, reward -154.0, memory_length 2000, epsilon 0.04541104143908218\n",
      "travel time- 722.0\n",
      "--- 1.7952091693878174 seconds ---\n",
      "episode 6185, reward 112.0, memory_length 2000, epsilon 0.045388341593796865\n",
      "travel time- 723.0\n",
      "--- 1.7463901042938232 seconds ---\n",
      "episode 6186, reward 323.0, memory_length 2000, epsilon 0.0453656530955972\n",
      "travel time- 730.0\n",
      "--- 1.4523742198944092 seconds ---\n",
      "episode 6187, reward -299.0, memory_length 2000, epsilon 0.045342975938811036\n",
      "travel time- 726.0\n",
      "--- 1.5487112998962402 seconds ---\n",
      "episode 6188, reward -23.0, memory_length 2000, epsilon 0.04532031011776911\n",
      "travel time- 725.0\n",
      "--- 1.7805733680725098 seconds ---\n",
      "episode 6189, reward -116.0, memory_length 2000, epsilon 0.04529765562680493\n",
      "travel time- 727.0\n",
      "--- 1.5358803272247314 seconds ---\n",
      "episode 6190, reward 251.0, memory_length 2000, epsilon 0.045275012460254886\n",
      "travel time- 720.0\n",
      "--- 1.4870271682739258 seconds ---\n",
      "episode 6191, reward 183.0, memory_length 2000, epsilon 0.04525238061245822\n",
      "travel time- 723.0\n",
      "--- 1.6333072185516357 seconds ---\n",
      "episode 6192, reward 166.0, memory_length 2000, epsilon 0.04522976007775692\n",
      "travel time- 721.0\n",
      "--- 1.6120820045471191 seconds ---\n",
      "episode 6193, reward -98.0, memory_length 2000, epsilon 0.04520715085049587\n",
      "travel time- 732.0\n",
      "--- 1.5344970226287842 seconds ---\n",
      "episode 6194, reward 76.0, memory_length 2000, epsilon 0.0451845529250228\n",
      "travel time- 730.0\n",
      "--- 1.6284360885620117 seconds ---\n",
      "episode 6195, reward 103.0, memory_length 2000, epsilon 0.045161966295688166\n",
      "travel time- 722.0\n",
      "--- 1.8726832866668701 seconds ---\n",
      "episode 6196, reward -56.0, memory_length 2000, epsilon 0.04513939095684536\n",
      "travel time- 720.0\n",
      "--- 1.777949571609497 seconds ---\n",
      "episode 6197, reward -90.0, memory_length 2000, epsilon 0.045116826902850515\n",
      "travel time- 721.0\n",
      "--- 1.8733835220336914 seconds ---\n",
      "episode 6198, reward 155.0, memory_length 2000, epsilon 0.04509427412806263\n",
      "travel time- 725.0\n",
      "--- 1.7374119758605957 seconds ---\n",
      "episode 6199, reward 66.0, memory_length 2000, epsilon 0.04507173262684353\n",
      "travel time- 722.0\n",
      "--- 1.4637608528137207 seconds ---\n",
      "episode 6200, reward 127.0, memory_length 2000, epsilon 0.0450492023935578\n",
      "travel time- 731.0\n",
      "--- 1.5958013534545898 seconds ---\n",
      "episode 6201, reward 138.0, memory_length 2000, epsilon 0.045026683422572905\n",
      "travel time- 720.0\n",
      "--- 1.7206997871398926 seconds ---\n",
      "episode 6202, reward 100.0, memory_length 2000, epsilon 0.045004175708259125\n",
      "travel time- 721.0\n",
      "--- 1.6375091075897217 seconds ---\n",
      "episode 6203, reward -442.0, memory_length 2000, epsilon 0.04498167924498948\n",
      "travel time- 727.0\n",
      "--- 1.6994614601135254 seconds ---\n",
      "episode 6204, reward 26.0, memory_length 2000, epsilon 0.0449591940271399\n",
      "travel time- 721.0\n",
      "--- 1.76224684715271 seconds ---\n",
      "episode 6205, reward -247.0, memory_length 2000, epsilon 0.044936720049089045\n",
      "travel time- 723.0\n",
      "--- 1.9930334091186523 seconds ---\n",
      "episode 6206, reward 301.0, memory_length 2000, epsilon 0.04491425730521843\n",
      "travel time- 729.0\n",
      "--- 1.5424649715423584 seconds ---\n",
      "episode 6207, reward 28.0, memory_length 2000, epsilon 0.044891805789912406\n",
      "travel time- 720.0\n",
      "--- 1.733536720275879 seconds ---\n",
      "episode 6208, reward -166.0, memory_length 2000, epsilon 0.04486936549755803\n",
      "travel time- 734.0\n",
      "--- 1.562938928604126 seconds ---\n",
      "episode 6209, reward 50.0, memory_length 2000, epsilon 0.044846936422545274\n",
      "travel time- 723.0\n",
      "--- 1.7412660121917725 seconds ---\n",
      "episode 6210, reward 126.0, memory_length 2000, epsilon 0.04482451855926687\n",
      "travel time- 725.0\n",
      "--- 1.6847777366638184 seconds ---\n",
      "episode 6211, reward 160.0, memory_length 2000, epsilon 0.04480211190211832\n",
      "travel time- 733.0\n",
      "--- 1.7191951274871826 seconds ---\n",
      "episode 6212, reward 68.0, memory_length 2000, epsilon 0.044779716445498004\n",
      "travel time- 726.0\n",
      "--- 1.9334690570831299 seconds ---\n",
      "episode 6213, reward 55.0, memory_length 2000, epsilon 0.04475733218380701\n",
      "travel time- 722.0\n",
      "--- 1.699967384338379 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6214, reward 222.0, memory_length 2000, epsilon 0.04473495911144929\n",
      "travel time- 729.0\n",
      "--- 1.606175184249878 seconds ---\n",
      "episode 6215, reward -83.0, memory_length 2000, epsilon 0.04471259722283161\n",
      "travel time- 726.0\n",
      "--- 1.6328296661376953 seconds ---\n",
      "episode 6216, reward 218.0, memory_length 2000, epsilon 0.04469024651236344\n",
      "travel time- 721.0\n",
      "--- 1.605384349822998 seconds ---\n",
      "episode 6217, reward -59.0, memory_length 2000, epsilon 0.04466790697445713\n",
      "travel time- 721.0\n",
      "--- 1.8210880756378174 seconds ---\n",
      "episode 6218, reward -117.0, memory_length 2000, epsilon 0.04464557860352782\n",
      "travel time- 730.0\n",
      "--- 1.7189359664916992 seconds ---\n",
      "episode 6219, reward 189.0, memory_length 2000, epsilon 0.04462326139399338\n",
      "travel time- 727.0\n",
      "--- 1.6556217670440674 seconds ---\n",
      "episode 6220, reward 64.0, memory_length 2000, epsilon 0.044600955340274535\n",
      "travel time- 722.0\n",
      "--- 1.525411605834961 seconds ---\n",
      "episode 6221, reward -228.0, memory_length 2000, epsilon 0.04457866043679474\n",
      "travel time- 721.0\n",
      "--- 1.6763591766357422 seconds ---\n",
      "episode 6222, reward -168.0, memory_length 2000, epsilon 0.04455637667798028\n",
      "travel time- 722.0\n",
      "--- 1.746755838394165 seconds ---\n",
      "episode 6223, reward 281.0, memory_length 2000, epsilon 0.04453410405826025\n",
      "travel time- 728.0\n",
      "--- 1.6334953308105469 seconds ---\n",
      "episode 6224, reward 14.0, memory_length 2000, epsilon 0.04451184257206644\n",
      "travel time- 723.0\n",
      "--- 1.331923007965088 seconds ---\n",
      "episode 6225, reward -56.0, memory_length 2000, epsilon 0.04448959221383351\n",
      "travel time- 720.0\n",
      "--- 1.537508249282837 seconds ---\n",
      "episode 6226, reward -269.0, memory_length 2000, epsilon 0.04446735297799888\n",
      "travel time- 721.0\n",
      "--- 1.736344337463379 seconds ---\n",
      "episode 6227, reward -444.0, memory_length 2000, epsilon 0.044445124859002705\n",
      "travel time- 727.0\n",
      "--- 1.7674462795257568 seconds ---\n",
      "episode 6228, reward -78.0, memory_length 2000, epsilon 0.044422907851287996\n",
      "travel time- 725.0\n",
      "--- 1.571486234664917 seconds ---\n",
      "episode 6229, reward 44.0, memory_length 2000, epsilon 0.044400701949300465\n",
      "travel time- 727.0\n",
      "--- 1.7571096420288086 seconds ---\n",
      "episode 6230, reward 27.0, memory_length 2000, epsilon 0.04437850714748865\n",
      "travel time- 720.0\n",
      "--- 1.757300615310669 seconds ---\n",
      "episode 6231, reward 143.0, memory_length 2000, epsilon 0.04435632344030388\n",
      "travel time- 728.0\n",
      "--- 1.7655596733093262 seconds ---\n",
      "episode 6232, reward 372.0, memory_length 2000, epsilon 0.04433415082220017\n",
      "travel time- 721.0\n",
      "--- 1.4281246662139893 seconds ---\n",
      "episode 6233, reward -212.0, memory_length 2000, epsilon 0.044311989287634405\n",
      "travel time- 731.0\n",
      "--- 1.6237444877624512 seconds ---\n",
      "episode 6234, reward -58.0, memory_length 2000, epsilon 0.044289838831066214\n",
      "travel time- 724.0\n",
      "--- 1.7519116401672363 seconds ---\n",
      "episode 6235, reward 133.0, memory_length 2000, epsilon 0.04426769944695794\n",
      "travel time- 720.0\n",
      "--- 2.104886054992676 seconds ---\n",
      "episode 6236, reward 162.0, memory_length 2000, epsilon 0.04424557112977477\n",
      "travel time- 728.0\n",
      "--- 1.6393215656280518 seconds ---\n",
      "episode 6237, reward 40.0, memory_length 2000, epsilon 0.0442234538739846\n",
      "travel time- 729.0\n",
      "--- 1.5856266021728516 seconds ---\n",
      "episode 6238, reward 182.0, memory_length 2000, epsilon 0.04420134767405813\n",
      "travel time- 724.0\n",
      "--- 1.4495716094970703 seconds ---\n",
      "episode 6239, reward 170.0, memory_length 2000, epsilon 0.044179252524468825\n",
      "travel time- 721.0\n",
      "--- 1.6200778484344482 seconds ---\n",
      "episode 6240, reward 4.0, memory_length 2000, epsilon 0.04415716841969286\n",
      "travel time- 721.0\n",
      "--- 1.5971198081970215 seconds ---\n",
      "episode 6241, reward 236.0, memory_length 2000, epsilon 0.04413509535420924\n",
      "travel time- 720.0\n",
      "--- 1.624868631362915 seconds ---\n",
      "episode 6242, reward 178.0, memory_length 2000, epsilon 0.044113033322499696\n",
      "travel time- 721.0\n",
      "--- 1.4235563278198242 seconds ---\n",
      "episode 6243, reward -35.0, memory_length 2000, epsilon 0.0440909823190487\n",
      "travel time- 724.0\n",
      "--- 1.5520257949829102 seconds ---\n",
      "episode 6244, reward 133.0, memory_length 2000, epsilon 0.04406894233834353\n",
      "travel time- 720.0\n",
      "--- 1.8586187362670898 seconds ---\n",
      "episode 6245, reward -30.0, memory_length 2000, epsilon 0.04404691337487415\n",
      "travel time- 724.0\n",
      "--- 1.777127742767334 seconds ---\n",
      "episode 6246, reward 67.0, memory_length 2000, epsilon 0.04402489542313335\n",
      "travel time- 726.0\n",
      "--- 1.6025114059448242 seconds ---\n",
      "episode 6247, reward 8.0, memory_length 2000, epsilon 0.04400288847761665\n",
      "travel time- 721.0\n",
      "--- 1.407472848892212 seconds ---\n",
      "episode 6248, reward 161.0, memory_length 2000, epsilon 0.04398089253282229\n",
      "travel time- 723.0\n",
      "--- 1.5008783340454102 seconds ---\n",
      "episode 6249, reward -178.0, memory_length 2000, epsilon 0.04395890758325128\n",
      "travel time- 721.0\n",
      "--- 1.6024956703186035 seconds ---\n",
      "episode 6250, reward -94.0, memory_length 2000, epsilon 0.04393693362340742\n",
      "travel time- 721.0\n",
      "--- 1.5372114181518555 seconds ---\n",
      "episode 6251, reward 70.0, memory_length 2000, epsilon 0.04391497064779717\n",
      "travel time- 723.0\n",
      "--- 1.600215196609497 seconds ---\n",
      "episode 6252, reward 192.0, memory_length 2000, epsilon 0.04389301865092984\n",
      "travel time- 722.0\n",
      "--- 1.7459115982055664 seconds ---\n",
      "episode 6253, reward -49.0, memory_length 2000, epsilon 0.04387107762731737\n",
      "travel time- 721.0\n",
      "--- 1.6844642162322998 seconds ---\n",
      "episode 6254, reward -108.0, memory_length 2000, epsilon 0.04384914757147454\n",
      "travel time- 728.0\n",
      "--- 1.5713016986846924 seconds ---\n",
      "episode 6255, reward -205.0, memory_length 2000, epsilon 0.04382722847791885\n",
      "travel time- 720.0\n",
      "--- 1.669992208480835 seconds ---\n",
      "episode 6256, reward -62.0, memory_length 2000, epsilon 0.04380532034117049\n",
      "travel time- 722.0\n",
      "--- 1.6185846328735352 seconds ---\n",
      "episode 6257, reward 14.0, memory_length 2000, epsilon 0.04378342315575245\n",
      "travel time- 726.0\n",
      "--- 1.5621299743652344 seconds ---\n",
      "episode 6258, reward 56.0, memory_length 2000, epsilon 0.04376153691619043\n",
      "travel time- 721.0\n",
      "--- 1.4588069915771484 seconds ---\n",
      "episode 6259, reward 4.0, memory_length 2000, epsilon 0.043739661617012864\n",
      "travel time- 727.0\n",
      "--- 1.758868932723999 seconds ---\n",
      "episode 6260, reward -139.0, memory_length 2000, epsilon 0.04371779725275094\n",
      "travel time- 723.0\n",
      "--- 1.8145077228546143 seconds ---\n",
      "episode 6261, reward 251.0, memory_length 2000, epsilon 0.043695943817938544\n",
      "travel time- 724.0\n",
      "--- 1.5371427536010742 seconds ---\n",
      "episode 6262, reward 139.0, memory_length 2000, epsilon 0.04367410130711232\n",
      "travel time- 725.0\n",
      "--- 1.5326228141784668 seconds ---\n",
      "episode 6263, reward 116.0, memory_length 2000, epsilon 0.04365226971481168\n",
      "travel time- 723.0\n",
      "--- 1.4696743488311768 seconds ---\n",
      "episode 6264, reward -67.0, memory_length 2000, epsilon 0.043630449035578674\n",
      "travel time- 730.0\n",
      "--- 1.5752604007720947 seconds ---\n",
      "episode 6265, reward -72.0, memory_length 2000, epsilon 0.04360863926395815\n",
      "travel time- 726.0\n",
      "--- 1.8092470169067383 seconds ---\n",
      "episode 6266, reward -10.0, memory_length 2000, epsilon 0.04358684039449769\n",
      "travel time- 720.0\n",
      "--- 1.710766315460205 seconds ---\n",
      "episode 6267, reward 174.0, memory_length 2000, epsilon 0.04356505242174754\n",
      "travel time- 721.0\n",
      "--- 1.5713889598846436 seconds ---\n",
      "episode 6268, reward -15.0, memory_length 2000, epsilon 0.04354327534026074\n",
      "travel time- 725.0\n",
      "--- 1.5507910251617432 seconds ---\n",
      "episode 6269, reward -69.0, memory_length 2000, epsilon 0.04352150914459298\n",
      "travel time- 723.0\n",
      "--- 1.7045071125030518 seconds ---\n",
      "episode 6270, reward 310.0, memory_length 2000, epsilon 0.04349975382930273\n",
      "travel time- 720.0\n",
      "--- 1.476142406463623 seconds ---\n",
      "episode 6271, reward 25.0, memory_length 2000, epsilon 0.043478009388951196\n",
      "travel time- 725.0\n",
      "--- 1.6927053928375244 seconds ---\n",
      "episode 6272, reward -162.0, memory_length 2000, epsilon 0.04345627581810221\n",
      "travel time- 724.0\n",
      "--- 1.7839596271514893 seconds ---\n",
      "episode 6273, reward 187.0, memory_length 2000, epsilon 0.04343455311132242\n",
      "travel time- 723.0\n",
      "--- 1.7472708225250244 seconds ---\n",
      "episode 6274, reward 146.0, memory_length 2000, epsilon 0.043412841263181116\n",
      "travel time- 723.0\n",
      "--- 1.7756245136260986 seconds ---\n",
      "episode 6275, reward 84.0, memory_length 2000, epsilon 0.043391140268250354\n",
      "travel time- 727.0\n",
      "--- 1.8467738628387451 seconds ---\n",
      "episode 6276, reward 220.0, memory_length 2000, epsilon 0.04336945012110491\n",
      "travel time- 723.0\n",
      "--- 1.5834667682647705 seconds ---\n",
      "episode 6277, reward 117.0, memory_length 2000, epsilon 0.04334777081632219\n",
      "travel time- 725.0\n",
      "--- 1.6519474983215332 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6278, reward -161.0, memory_length 2000, epsilon 0.04332610234848241\n",
      "travel time- 721.0\n",
      "--- 1.7327635288238525 seconds ---\n",
      "episode 6279, reward -164.0, memory_length 2000, epsilon 0.04330444471216846\n",
      "travel time- 721.0\n",
      "--- 1.6045637130737305 seconds ---\n",
      "episode 6280, reward 109.0, memory_length 2000, epsilon 0.043282797901965896\n",
      "travel time- 724.0\n",
      "--- 1.614900827407837 seconds ---\n",
      "episode 6281, reward -66.0, memory_length 2000, epsilon 0.04326116191246305\n",
      "travel time- 722.0\n",
      "--- 1.699427843093872 seconds ---\n",
      "episode 6282, reward -8.0, memory_length 2000, epsilon 0.043239536738250886\n",
      "travel time- 724.0\n",
      "--- 1.6847283840179443 seconds ---\n",
      "episode 6283, reward -53.0, memory_length 2000, epsilon 0.043217922373923134\n",
      "travel time- 720.0\n",
      "--- 1.714491367340088 seconds ---\n",
      "episode 6284, reward -134.0, memory_length 2000, epsilon 0.04319631881407622\n",
      "travel time- 726.0\n",
      "--- 1.662369728088379 seconds ---\n",
      "episode 6285, reward 138.0, memory_length 2000, epsilon 0.04317472605330922\n",
      "travel time- 723.0\n",
      "--- 1.617845058441162 seconds ---\n",
      "episode 6286, reward -68.0, memory_length 2000, epsilon 0.043153144086223956\n",
      "travel time- 726.0\n",
      "--- 1.7556476593017578 seconds ---\n",
      "episode 6287, reward 54.0, memory_length 2000, epsilon 0.043131572907424955\n",
      "travel time- 720.0\n",
      "--- 1.5897471904754639 seconds ---\n",
      "episode 6288, reward -31.0, memory_length 2000, epsilon 0.043110012511519386\n",
      "travel time- 724.0\n",
      "--- 1.7498652935028076 seconds ---\n",
      "episode 6289, reward -132.0, memory_length 2000, epsilon 0.043088462893117185\n",
      "travel time- 721.0\n",
      "--- 1.5930743217468262 seconds ---\n",
      "episode 6290, reward -133.0, memory_length 2000, epsilon 0.04306692404683092\n",
      "travel time- 725.0\n",
      "--- 1.5102851390838623 seconds ---\n",
      "episode 6291, reward 247.0, memory_length 2000, epsilon 0.043045395967275885\n",
      "travel time- 722.0\n",
      "--- 1.4911808967590332 seconds ---\n",
      "episode 6292, reward 14.0, memory_length 2000, epsilon 0.04302387864907009\n",
      "travel time- 722.0\n",
      "--- 1.7316160202026367 seconds ---\n",
      "episode 6293, reward 185.0, memory_length 2000, epsilon 0.04300237208683416\n",
      "travel time- 723.0\n",
      "--- 1.9603173732757568 seconds ---\n",
      "episode 6294, reward 159.0, memory_length 2000, epsilon 0.042980876275191475\n",
      "travel time- 727.0\n",
      "--- 1.5476558208465576 seconds ---\n",
      "episode 6295, reward 286.0, memory_length 2000, epsilon 0.0429593912087681\n",
      "travel time- 731.0\n",
      "--- 1.7049505710601807 seconds ---\n",
      "episode 6296, reward 46.0, memory_length 2000, epsilon 0.042937916882192735\n",
      "travel time- 722.0\n",
      "--- 1.6429352760314941 seconds ---\n",
      "episode 6297, reward 133.0, memory_length 2000, epsilon 0.042916453290096836\n",
      "travel time- 721.0\n",
      "--- 1.5089285373687744 seconds ---\n",
      "episode 6298, reward -17.0, memory_length 2000, epsilon 0.04289500042711446\n",
      "travel time- 726.0\n",
      "--- 1.7259230613708496 seconds ---\n",
      "episode 6299, reward 55.0, memory_length 2000, epsilon 0.04287355828788241\n",
      "travel time- 724.0\n",
      "--- 1.5018155574798584 seconds ---\n",
      "episode 6300, reward -35.0, memory_length 2000, epsilon 0.04285212686704019\n",
      "travel time- 722.0\n",
      "--- 1.8283028602600098 seconds ---\n",
      "episode 6301, reward 224.0, memory_length 2000, epsilon 0.042830706159229875\n",
      "travel time- 724.0\n",
      "--- 1.5997929573059082 seconds ---\n",
      "episode 6302, reward -42.0, memory_length 2000, epsilon 0.04280929615909633\n",
      "travel time- 721.0\n",
      "--- 1.576308250427246 seconds ---\n",
      "episode 6303, reward 13.0, memory_length 2000, epsilon 0.04278789686128706\n",
      "travel time- 725.0\n",
      "--- 1.6188910007476807 seconds ---\n",
      "episode 6304, reward 138.0, memory_length 2000, epsilon 0.04276650826045222\n",
      "travel time- 723.0\n",
      "--- 1.6508221626281738 seconds ---\n",
      "episode 6305, reward -234.0, memory_length 2000, epsilon 0.04274513035124468\n",
      "travel time- 720.0\n",
      "--- 1.6415934562683105 seconds ---\n",
      "episode 6306, reward -84.0, memory_length 2000, epsilon 0.04272376312831993\n",
      "travel time- 726.0\n",
      "--- 1.788041591644287 seconds ---\n",
      "episode 6307, reward 64.0, memory_length 2000, epsilon 0.042702406586336186\n",
      "travel time- 728.0\n",
      "--- 1.7232062816619873 seconds ---\n",
      "episode 6308, reward 35.0, memory_length 2000, epsilon 0.04268106071995433\n",
      "travel time- 723.0\n",
      "--- 1.6339426040649414 seconds ---\n",
      "episode 6309, reward -49.0, memory_length 2000, epsilon 0.04265972552383786\n",
      "travel time- 728.0\n",
      "--- 1.594372034072876 seconds ---\n",
      "episode 6310, reward -131.0, memory_length 2000, epsilon 0.04263840099265299\n",
      "travel time- 722.0\n",
      "--- 1.7011172771453857 seconds ---\n",
      "episode 6311, reward 159.0, memory_length 2000, epsilon 0.04261708712106861\n",
      "travel time- 720.0\n",
      "--- 1.7770471572875977 seconds ---\n",
      "episode 6312, reward 214.0, memory_length 2000, epsilon 0.042595783903756214\n",
      "travel time- 723.0\n",
      "--- 1.7630021572113037 seconds ---\n",
      "episode 6313, reward 258.0, memory_length 2000, epsilon 0.042574491335390034\n",
      "travel time- 726.0\n",
      "--- 1.815100908279419 seconds ---\n",
      "episode 6314, reward 275.0, memory_length 2000, epsilon 0.04255320941064689\n",
      "travel time- 723.0\n",
      "--- 1.8249404430389404 seconds ---\n",
      "episode 6315, reward 202.0, memory_length 2000, epsilon 0.042531938124206324\n",
      "travel time- 722.0\n",
      "--- 1.5271966457366943 seconds ---\n",
      "episode 6316, reward -149.0, memory_length 2000, epsilon 0.042510677470750526\n",
      "travel time- 721.0\n",
      "--- 1.5091867446899414 seconds ---\n",
      "episode 6317, reward -14.0, memory_length 2000, epsilon 0.0424894274449643\n",
      "travel time- 726.0\n",
      "--- 1.6021184921264648 seconds ---\n",
      "episode 6318, reward -68.0, memory_length 2000, epsilon 0.042468188041535154\n",
      "travel time- 724.0\n",
      "--- 1.5679852962493896 seconds ---\n",
      "episode 6319, reward 4.0, memory_length 2000, epsilon 0.04244695925515326\n",
      "travel time- 722.0\n",
      "--- 1.687422513961792 seconds ---\n",
      "episode 6320, reward -12.0, memory_length 2000, epsilon 0.042425741080511385\n",
      "travel time- 729.0\n",
      "--- 1.5922353267669678 seconds ---\n",
      "episode 6321, reward -3.0, memory_length 2000, epsilon 0.04240453351230501\n",
      "travel time- 728.0\n",
      "--- 1.6516759395599365 seconds ---\n",
      "episode 6322, reward 247.0, memory_length 2000, epsilon 0.04238333654523223\n",
      "travel time- 729.0\n",
      "--- 1.8045201301574707 seconds ---\n",
      "episode 6323, reward -121.0, memory_length 2000, epsilon 0.04236215017399379\n",
      "travel time- 720.0\n",
      "--- 1.5686120986938477 seconds ---\n",
      "episode 6324, reward 7.0, memory_length 2000, epsilon 0.042340974393293145\n",
      "travel time- 725.0\n",
      "--- 1.7349600791931152 seconds ---\n",
      "episode 6325, reward -191.0, memory_length 2000, epsilon 0.042319809197836296\n",
      "travel time- 722.0\n",
      "--- 1.4504849910736084 seconds ---\n",
      "episode 6326, reward -17.0, memory_length 2000, epsilon 0.04229865458233197\n",
      "travel time- 721.0\n",
      "--- 1.8111693859100342 seconds ---\n",
      "episode 6327, reward 217.0, memory_length 2000, epsilon 0.04227751054149153\n",
      "travel time- 725.0\n",
      "--- 1.6456069946289062 seconds ---\n",
      "episode 6328, reward -100.0, memory_length 2000, epsilon 0.042256377070028925\n",
      "travel time- 728.0\n",
      "--- 1.953885793685913 seconds ---\n",
      "episode 6329, reward -2.0, memory_length 2000, epsilon 0.04223525416266082\n",
      "travel time- 727.0\n",
      "--- 1.7319841384887695 seconds ---\n",
      "episode 6330, reward -202.0, memory_length 2000, epsilon 0.042214141814106466\n",
      "travel time- 726.0\n",
      "--- 1.7643342018127441 seconds ---\n",
      "episode 6331, reward 343.0, memory_length 2000, epsilon 0.04219304001908778\n",
      "travel time- 721.0\n",
      "--- 1.5428385734558105 seconds ---\n",
      "episode 6332, reward -63.0, memory_length 2000, epsilon 0.04217194877232933\n",
      "travel time- 732.0\n",
      "--- 1.618028163909912 seconds ---\n",
      "episode 6333, reward -92.0, memory_length 2000, epsilon 0.04215086806855829\n",
      "travel time- 723.0\n",
      "--- 1.5402843952178955 seconds ---\n",
      "episode 6334, reward 155.0, memory_length 2000, epsilon 0.04212979790250448\n",
      "travel time- 721.0\n",
      "--- 1.5812196731567383 seconds ---\n",
      "episode 6335, reward -167.0, memory_length 2000, epsilon 0.04210873826890038\n",
      "travel time- 720.0\n",
      "--- 1.6013188362121582 seconds ---\n",
      "episode 6336, reward 51.0, memory_length 2000, epsilon 0.042087689162481054\n",
      "travel time- 720.0\n",
      "--- 1.4603312015533447 seconds ---\n",
      "episode 6337, reward -96.0, memory_length 2000, epsilon 0.04206665057798425\n",
      "travel time- 726.0\n",
      "--- 1.7683610916137695 seconds ---\n",
      "episode 6338, reward 126.0, memory_length 2000, epsilon 0.042045622510150295\n",
      "travel time- 721.0\n",
      "--- 1.5615966320037842 seconds ---\n",
      "episode 6339, reward -247.0, memory_length 2000, epsilon 0.042024604953722185\n",
      "travel time- 724.0\n",
      "--- 1.818155288696289 seconds ---\n",
      "episode 6340, reward 189.0, memory_length 2000, epsilon 0.04200359790344555\n",
      "travel time- 721.0\n",
      "--- 1.6510224342346191 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6341, reward -262.0, memory_length 2000, epsilon 0.041982601354068595\n",
      "travel time- 720.0\n",
      "--- 1.8826379776000977 seconds ---\n",
      "episode 6342, reward -28.0, memory_length 2000, epsilon 0.041961615300342196\n",
      "travel time- 722.0\n",
      "--- 1.7644124031066895 seconds ---\n",
      "episode 6343, reward -55.0, memory_length 2000, epsilon 0.04194063973701986\n",
      "travel time- 735.0\n",
      "--- 1.5081439018249512 seconds ---\n",
      "episode 6344, reward 164.0, memory_length 2000, epsilon 0.04191967465885765\n",
      "travel time- 720.0\n",
      "--- 1.734894037246704 seconds ---\n",
      "episode 6345, reward 323.0, memory_length 2000, epsilon 0.04189872006061435\n",
      "travel time- 729.0\n",
      "--- 1.6864664554595947 seconds ---\n",
      "episode 6346, reward -180.0, memory_length 2000, epsilon 0.04187777593705126\n",
      "travel time- 722.0\n",
      "--- 1.7940216064453125 seconds ---\n",
      "episode 6347, reward 211.0, memory_length 2000, epsilon 0.04185684228293238\n",
      "travel time- 721.0\n",
      "--- 1.6107633113861084 seconds ---\n",
      "episode 6348, reward -118.0, memory_length 2000, epsilon 0.0418359190930243\n",
      "travel time- 720.0\n",
      "--- 1.6197631359100342 seconds ---\n",
      "episode 6349, reward 113.0, memory_length 2000, epsilon 0.041815006362096195\n",
      "travel time- 721.0\n",
      "--- 1.56783127784729 seconds ---\n",
      "episode 6350, reward -30.0, memory_length 2000, epsilon 0.041794104084919896\n",
      "travel time- 724.0\n",
      "--- 1.8837573528289795 seconds ---\n",
      "episode 6351, reward -30.0, memory_length 2000, epsilon 0.04177321225626986\n",
      "travel time- 724.0\n",
      "--- 1.408128023147583 seconds ---\n",
      "episode 6352, reward 191.0, memory_length 2000, epsilon 0.04175233087092308\n",
      "travel time- 722.0\n",
      "--- 1.7062771320343018 seconds ---\n",
      "episode 6353, reward -51.0, memory_length 2000, epsilon 0.04173145992365926\n",
      "travel time- 722.0\n",
      "--- 1.6563217639923096 seconds ---\n",
      "episode 6354, reward -96.0, memory_length 2000, epsilon 0.04171059940926062\n",
      "travel time- 720.0\n",
      "--- 1.7580881118774414 seconds ---\n",
      "episode 6355, reward 486.0, memory_length 2000, epsilon 0.04168974932251204\n",
      "travel time- 722.0\n",
      "--- 1.7011568546295166 seconds ---\n",
      "episode 6356, reward 325.0, memory_length 2000, epsilon 0.04166890965820104\n",
      "travel time- 721.0\n",
      "--- 1.6130623817443848 seconds ---\n",
      "episode 6357, reward 91.0, memory_length 2000, epsilon 0.041648080411117644\n",
      "travel time- 722.0\n",
      "--- 1.4680263996124268 seconds ---\n",
      "episode 6358, reward -6.0, memory_length 2000, epsilon 0.04162726157605457\n",
      "travel time- 722.0\n",
      "--- 1.506239652633667 seconds ---\n",
      "episode 6359, reward 41.0, memory_length 2000, epsilon 0.04160645314780712\n",
      "travel time- 724.0\n",
      "--- 1.6607749462127686 seconds ---\n",
      "episode 6360, reward 512.0, memory_length 2000, epsilon 0.04158565512117316\n",
      "travel time- 720.0\n",
      "--- 1.4747862815856934 seconds ---\n",
      "episode 6361, reward 255.0, memory_length 2000, epsilon 0.04156486749095322\n",
      "travel time- 720.0\n",
      "--- 1.657327651977539 seconds ---\n",
      "episode 6362, reward 81.0, memory_length 2000, epsilon 0.04154409025195034\n",
      "travel time- 721.0\n",
      "--- 1.8326959609985352 seconds ---\n",
      "episode 6363, reward 186.0, memory_length 2000, epsilon 0.041523323398970254\n",
      "travel time- 726.0\n",
      "--- 1.3971014022827148 seconds ---\n",
      "episode 6364, reward -87.0, memory_length 2000, epsilon 0.04150256692682124\n",
      "travel time- 733.0\n",
      "--- 1.6655244827270508 seconds ---\n",
      "episode 6365, reward -105.0, memory_length 2000, epsilon 0.04148182083031416\n",
      "travel time- 729.0\n",
      "--- 1.6383440494537354 seconds ---\n",
      "episode 6366, reward -155.0, memory_length 2000, epsilon 0.0414610851042625\n",
      "travel time- 726.0\n",
      "--- 1.7744250297546387 seconds ---\n",
      "episode 6367, reward 140.0, memory_length 2000, epsilon 0.041440359743482355\n",
      "travel time- 720.0\n",
      "--- 1.613278865814209 seconds ---\n",
      "episode 6368, reward 158.0, memory_length 2000, epsilon 0.04141964474279235\n",
      "travel time- 722.0\n",
      "--- 1.576915979385376 seconds ---\n",
      "episode 6369, reward 37.0, memory_length 2000, epsilon 0.04139894009701375\n",
      "travel time- 723.0\n",
      "--- 1.8287227153778076 seconds ---\n",
      "episode 6370, reward -223.0, memory_length 2000, epsilon 0.04137824580097038\n",
      "travel time- 723.0\n",
      "--- 1.5927610397338867 seconds ---\n",
      "episode 6371, reward -32.0, memory_length 2000, epsilon 0.041357561849488675\n",
      "travel time- 726.0\n",
      "--- 1.5781843662261963 seconds ---\n",
      "episode 6372, reward 1.0, memory_length 2000, epsilon 0.041336888237397666\n",
      "travel time- 722.0\n",
      "--- 1.6108906269073486 seconds ---\n",
      "episode 6373, reward -93.0, memory_length 2000, epsilon 0.041316224959528906\n",
      "travel time- 720.0\n",
      "--- 1.8511106967926025 seconds ---\n",
      "episode 6374, reward -196.0, memory_length 2000, epsilon 0.04129557201071661\n",
      "travel time- 723.0\n",
      "--- 1.5882532596588135 seconds ---\n",
      "episode 6375, reward 96.0, memory_length 2000, epsilon 0.04127492938579755\n",
      "travel time- 727.0\n",
      "--- 1.5866355895996094 seconds ---\n",
      "episode 6376, reward 515.0, memory_length 2000, epsilon 0.04125429707961103\n",
      "travel time- 723.0\n",
      "--- 1.555290937423706 seconds ---\n",
      "episode 6377, reward -106.0, memory_length 2000, epsilon 0.04123367508699901\n",
      "travel time- 721.0\n",
      "--- 1.8231985569000244 seconds ---\n",
      "episode 6378, reward 7.0, memory_length 2000, epsilon 0.04121306340280596\n",
      "travel time- 723.0\n",
      "--- 1.6381025314331055 seconds ---\n",
      "episode 6379, reward 90.0, memory_length 2000, epsilon 0.041192462021878984\n",
      "travel time- 725.0\n",
      "--- 1.6825411319732666 seconds ---\n",
      "episode 6380, reward 84.0, memory_length 2000, epsilon 0.04117187093906774\n",
      "travel time- 720.0\n",
      "--- 1.5110042095184326 seconds ---\n",
      "episode 6381, reward 78.0, memory_length 2000, epsilon 0.041151290149224425\n",
      "travel time- 725.0\n",
      "--- 1.7131316661834717 seconds ---\n",
      "episode 6382, reward -194.0, memory_length 2000, epsilon 0.04113071964720386\n",
      "travel time- 728.0\n",
      "--- 1.6219854354858398 seconds ---\n",
      "episode 6383, reward -16.0, memory_length 2000, epsilon 0.041110159427863446\n",
      "travel time- 720.0\n",
      "--- 1.5974483489990234 seconds ---\n",
      "episode 6384, reward 73.0, memory_length 2000, epsilon 0.04108960948606308\n",
      "travel time- 728.0\n",
      "--- 1.6328110694885254 seconds ---\n",
      "episode 6385, reward -261.0, memory_length 2000, epsilon 0.04106906981666532\n",
      "travel time- 722.0\n",
      "--- 1.7822678089141846 seconds ---\n",
      "episode 6386, reward 373.0, memory_length 2000, epsilon 0.041048540414535206\n",
      "travel time- 729.0\n",
      "--- 1.775238037109375 seconds ---\n",
      "episode 6387, reward 55.0, memory_length 2000, epsilon 0.041028021274540416\n",
      "travel time- 721.0\n",
      "--- 1.628157615661621 seconds ---\n",
      "episode 6388, reward -47.0, memory_length 2000, epsilon 0.04100751239155117\n",
      "travel time- 722.0\n",
      "--- 1.5285582542419434 seconds ---\n",
      "episode 6389, reward -296.0, memory_length 2000, epsilon 0.04098701376044022\n",
      "travel time- 720.0\n",
      "--- 1.746405839920044 seconds ---\n",
      "episode 6390, reward 117.0, memory_length 2000, epsilon 0.040966525376082925\n",
      "travel time- 725.0\n",
      "--- 1.6009445190429688 seconds ---\n",
      "episode 6391, reward 207.0, memory_length 2000, epsilon 0.04094604723335721\n",
      "travel time- 722.0\n",
      "--- 1.4028987884521484 seconds ---\n",
      "episode 6392, reward 134.0, memory_length 2000, epsilon 0.04092557932714349\n",
      "travel time- 725.0\n",
      "--- 1.7137186527252197 seconds ---\n",
      "episode 6393, reward -263.0, memory_length 2000, epsilon 0.040905121652324836\n",
      "travel time- 726.0\n",
      "--- 1.7142689228057861 seconds ---\n",
      "episode 6394, reward -264.0, memory_length 2000, epsilon 0.04088467420378679\n",
      "travel time- 722.0\n",
      "--- 1.7293522357940674 seconds ---\n",
      "episode 6395, reward 187.0, memory_length 2000, epsilon 0.04086423697641751\n",
      "travel time- 725.0\n",
      "--- 1.530759572982788 seconds ---\n",
      "episode 6396, reward -28.0, memory_length 2000, epsilon 0.0408438099651077\n",
      "travel time- 720.0\n",
      "--- 1.6060264110565186 seconds ---\n",
      "episode 6397, reward 71.0, memory_length 2000, epsilon 0.040823393164750574\n",
      "travel time- 724.0\n",
      "--- 1.6322441101074219 seconds ---\n",
      "episode 6398, reward -383.0, memory_length 2000, epsilon 0.04080298657024196\n",
      "travel time- 723.0\n",
      "--- 1.7044401168823242 seconds ---\n",
      "episode 6399, reward 105.0, memory_length 2000, epsilon 0.04078259017648021\n",
      "travel time- 720.0\n",
      "--- 1.6183457374572754 seconds ---\n",
      "episode 6400, reward -33.0, memory_length 2000, epsilon 0.04076220397836621\n",
      "travel time- 724.0\n",
      "--- 1.973109245300293 seconds ---\n",
      "episode 6401, reward 363.0, memory_length 2000, epsilon 0.040741827970803425\n",
      "travel time- 722.0\n",
      "--- 1.6978135108947754 seconds ---\n",
      "episode 6402, reward 105.0, memory_length 2000, epsilon 0.04072146214869783\n",
      "travel time- 725.0\n",
      "--- 1.52728271484375 seconds ---\n",
      "episode 6403, reward -142.0, memory_length 2000, epsilon 0.04070110650695799\n",
      "travel time- 732.0\n",
      "--- 1.6462359428405762 seconds ---\n",
      "episode 6404, reward 48.0, memory_length 2000, epsilon 0.040680761040495\n",
      "travel time- 721.0\n",
      "--- 1.4913923740386963 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6405, reward -17.0, memory_length 2000, epsilon 0.04066042574422247\n",
      "travel time- 728.0\n",
      "--- 1.674661636352539 seconds ---\n",
      "episode 6406, reward 167.0, memory_length 2000, epsilon 0.0406401006130566\n",
      "travel time- 721.0\n",
      "--- 1.7025668621063232 seconds ---\n",
      "episode 6407, reward -564.0, memory_length 2000, epsilon 0.040619785641916074\n",
      "travel time- 720.0\n",
      "--- 1.616363525390625 seconds ---\n",
      "episode 6408, reward 154.0, memory_length 2000, epsilon 0.04059948082572218\n",
      "travel time- 720.0\n",
      "--- 1.534064531326294 seconds ---\n",
      "episode 6409, reward -87.0, memory_length 2000, epsilon 0.04057918615939871\n",
      "travel time- 722.0\n",
      "--- 1.6640217304229736 seconds ---\n",
      "episode 6410, reward 181.0, memory_length 2000, epsilon 0.040558901637871986\n",
      "travel time- 729.0\n",
      "--- 1.5092482566833496 seconds ---\n",
      "episode 6411, reward -84.0, memory_length 2000, epsilon 0.040538627256070874\n",
      "travel time- 725.0\n",
      "--- 1.4754881858825684 seconds ---\n",
      "episode 6412, reward 91.0, memory_length 2000, epsilon 0.040518363008926805\n",
      "travel time- 724.0\n",
      "--- 1.770235300064087 seconds ---\n",
      "episode 6413, reward 286.0, memory_length 2000, epsilon 0.04049810889137369\n",
      "travel time- 722.0\n",
      "--- 1.52547025680542 seconds ---\n",
      "episode 6414, reward 298.0, memory_length 2000, epsilon 0.040477864898348016\n",
      "travel time- 729.0\n",
      "--- 1.3473124504089355 seconds ---\n",
      "episode 6415, reward 129.0, memory_length 2000, epsilon 0.04045763102478876\n",
      "travel time- 727.0\n",
      "--- 1.4280848503112793 seconds ---\n",
      "episode 6416, reward -49.0, memory_length 2000, epsilon 0.04043740726563748\n",
      "travel time- 722.0\n",
      "--- 1.6481571197509766 seconds ---\n",
      "episode 6417, reward -79.0, memory_length 2000, epsilon 0.04041719361583824\n",
      "travel time- 720.0\n",
      "--- 1.6335461139678955 seconds ---\n",
      "episode 6418, reward -183.0, memory_length 2000, epsilon 0.0403969900703376\n",
      "travel time- 726.0\n",
      "--- 1.5918605327606201 seconds ---\n",
      "episode 6419, reward 154.0, memory_length 2000, epsilon 0.04037679662408468\n",
      "travel time- 725.0\n",
      "--- 1.4988093376159668 seconds ---\n",
      "episode 6420, reward 147.0, memory_length 2000, epsilon 0.04035661327203115\n",
      "travel time- 724.0\n",
      "--- 1.4738764762878418 seconds ---\n",
      "episode 6421, reward -134.0, memory_length 2000, epsilon 0.04033644000913113\n",
      "travel time- 720.0\n",
      "--- 1.4349091053009033 seconds ---\n",
      "episode 6422, reward 9.0, memory_length 2000, epsilon 0.040316276830341335\n",
      "travel time- 725.0\n",
      "--- 1.4752039909362793 seconds ---\n",
      "episode 6423, reward -130.0, memory_length 2000, epsilon 0.04029612373062095\n",
      "travel time- 730.0\n",
      "--- 1.5965406894683838 seconds ---\n",
      "episode 6424, reward -2.0, memory_length 2000, epsilon 0.0402759807049317\n",
      "travel time- 724.0\n",
      "--- 1.5605933666229248 seconds ---\n",
      "episode 6425, reward -61.0, memory_length 2000, epsilon 0.04025584774823785\n",
      "travel time- 722.0\n",
      "--- 1.593290090560913 seconds ---\n",
      "episode 6426, reward -200.0, memory_length 2000, epsilon 0.04023572485550614\n",
      "travel time- 725.0\n",
      "--- 1.5614678859710693 seconds ---\n",
      "episode 6427, reward -37.0, memory_length 2000, epsilon 0.04021561202170584\n",
      "travel time- 720.0\n",
      "--- 1.5167920589447021 seconds ---\n",
      "episode 6428, reward -302.0, memory_length 2000, epsilon 0.040195509241808786\n",
      "travel time- 724.0\n",
      "--- 1.8317875862121582 seconds ---\n",
      "episode 6429, reward -80.0, memory_length 2000, epsilon 0.04017541651078923\n",
      "travel time- 723.0\n",
      "--- 1.6112017631530762 seconds ---\n",
      "episode 6430, reward -69.0, memory_length 2000, epsilon 0.040155333823624025\n",
      "travel time- 720.0\n",
      "--- 1.6184790134429932 seconds ---\n",
      "episode 6431, reward 418.0, memory_length 2000, epsilon 0.040135261175292467\n",
      "travel time- 725.0\n",
      "--- 1.6061856746673584 seconds ---\n",
      "episode 6432, reward 5.0, memory_length 2000, epsilon 0.040115198560776416\n",
      "travel time- 720.0\n",
      "--- 1.5775859355926514 seconds ---\n",
      "episode 6433, reward 79.0, memory_length 2000, epsilon 0.04009514597506023\n",
      "travel time- 720.0\n",
      "--- 1.5425434112548828 seconds ---\n",
      "episode 6434, reward -57.0, memory_length 2000, epsilon 0.04007510341313073\n",
      "travel time- 724.0\n",
      "--- 1.6826543807983398 seconds ---\n",
      "episode 6435, reward -38.0, memory_length 2000, epsilon 0.04005507086997729\n",
      "travel time- 726.0\n",
      "--- 1.4476282596588135 seconds ---\n",
      "episode 6436, reward 395.0, memory_length 2000, epsilon 0.040035048340591795\n",
      "travel time- 720.0\n",
      "--- 1.5411510467529297 seconds ---\n",
      "episode 6437, reward -79.0, memory_length 2000, epsilon 0.04001503581996858\n",
      "travel time- 726.0\n",
      "--- 1.7251927852630615 seconds ---\n",
      "episode 6438, reward 76.0, memory_length 2000, epsilon 0.03999503330310454\n",
      "travel time- 724.0\n",
      "--- 1.533165693283081 seconds ---\n",
      "episode 6439, reward 99.0, memory_length 2000, epsilon 0.039975040784999014\n",
      "travel time- 726.0\n",
      "--- 1.7997994422912598 seconds ---\n",
      "episode 6440, reward 168.0, memory_length 2000, epsilon 0.039955058260653896\n",
      "travel time- 721.0\n",
      "--- 1.638291835784912 seconds ---\n",
      "episode 6441, reward 114.0, memory_length 2000, epsilon 0.03993508572507357\n",
      "travel time- 726.0\n",
      "--- 1.6214394569396973 seconds ---\n",
      "episode 6442, reward 74.0, memory_length 2000, epsilon 0.03991512317326487\n",
      "travel time- 729.0\n",
      "--- 1.6380093097686768 seconds ---\n",
      "episode 6443, reward 204.0, memory_length 2000, epsilon 0.039895170600237166\n",
      "travel time- 728.0\n",
      "--- 1.830420732498169 seconds ---\n",
      "episode 6444, reward 123.0, memory_length 2000, epsilon 0.039875228001002336\n",
      "travel time- 727.0\n",
      "--- 1.7528724670410156 seconds ---\n",
      "episode 6445, reward 90.0, memory_length 2000, epsilon 0.0398552953705747\n",
      "travel time- 723.0\n",
      "--- 1.6009080410003662 seconds ---\n",
      "episode 6446, reward -148.0, memory_length 2000, epsilon 0.03983537270397113\n",
      "travel time- 728.0\n",
      "--- 1.5504121780395508 seconds ---\n",
      "episode 6447, reward -6.0, memory_length 2000, epsilon 0.039815459996210924\n",
      "travel time- 730.0\n",
      "--- 1.585028886795044 seconds ---\n",
      "episode 6448, reward 61.0, memory_length 2000, epsilon 0.039795557242315927\n",
      "travel time- 722.0\n",
      "--- 1.589446783065796 seconds ---\n",
      "episode 6449, reward 253.0, memory_length 2000, epsilon 0.03977566443731047\n",
      "travel time- 721.0\n",
      "--- 1.53865647315979 seconds ---\n",
      "episode 6450, reward 168.0, memory_length 2000, epsilon 0.039755781576221304\n",
      "travel time- 726.0\n",
      "--- 1.457730770111084 seconds ---\n",
      "episode 6451, reward -97.0, memory_length 2000, epsilon 0.03973590865407774\n",
      "travel time- 720.0\n",
      "--- 1.5758371353149414 seconds ---\n",
      "episode 6452, reward 72.0, memory_length 2000, epsilon 0.03971604566591157\n",
      "travel time- 728.0\n",
      "--- 1.432159423828125 seconds ---\n",
      "episode 6453, reward 140.0, memory_length 2000, epsilon 0.039696192606757\n",
      "travel time- 726.0\n",
      "--- 1.6708686351776123 seconds ---\n",
      "episode 6454, reward -87.0, memory_length 2000, epsilon 0.0396763494716508\n",
      "travel time- 723.0\n",
      "--- 1.6510751247406006 seconds ---\n",
      "episode 6455, reward 301.0, memory_length 2000, epsilon 0.03965651625563217\n",
      "travel time- 725.0\n",
      "--- 1.5585947036743164 seconds ---\n",
      "episode 6456, reward -109.0, memory_length 2000, epsilon 0.0396366929537428\n",
      "travel time- 722.0\n",
      "--- 1.7562389373779297 seconds ---\n",
      "episode 6457, reward -106.0, memory_length 2000, epsilon 0.0396168795610269\n",
      "travel time- 724.0\n",
      "--- 1.707759141921997 seconds ---\n",
      "episode 6458, reward -34.0, memory_length 2000, epsilon 0.03959707607253108\n",
      "travel time- 720.0\n",
      "--- 1.6432650089263916 seconds ---\n",
      "episode 6459, reward -173.0, memory_length 2000, epsilon 0.03957728248330448\n",
      "travel time- 726.0\n",
      "--- 1.8291020393371582 seconds ---\n",
      "episode 6460, reward 121.0, memory_length 2000, epsilon 0.039557498788398725\n",
      "travel time- 721.0\n",
      "--- 1.482297420501709 seconds ---\n",
      "episode 6461, reward 285.0, memory_length 2000, epsilon 0.03953772498286785\n",
      "travel time- 722.0\n",
      "--- 1.631643295288086 seconds ---\n",
      "episode 6462, reward 11.0, memory_length 2000, epsilon 0.039517961061768456\n",
      "travel time- 726.0\n",
      "--- 1.7624742984771729 seconds ---\n",
      "episode 6463, reward 133.0, memory_length 2000, epsilon 0.03949820702015951\n",
      "travel time- 727.0\n",
      "--- 1.7276217937469482 seconds ---\n",
      "episode 6464, reward 105.0, memory_length 2000, epsilon 0.039478462853102525\n",
      "travel time- 720.0\n",
      "--- 1.525536060333252 seconds ---\n",
      "episode 6465, reward -169.0, memory_length 2000, epsilon 0.039458728555661474\n",
      "travel time- 721.0\n",
      "--- 1.63218355178833 seconds ---\n",
      "episode 6466, reward -350.0, memory_length 2000, epsilon 0.03943900412290276\n",
      "travel time- 723.0\n",
      "--- 1.6064355373382568 seconds ---\n",
      "episode 6467, reward 335.0, memory_length 2000, epsilon 0.03941928954989527\n",
      "travel time- 724.0\n",
      "--- 1.6365301609039307 seconds ---\n",
      "episode 6468, reward -6.0, memory_length 2000, epsilon 0.03939958483171039\n",
      "travel time- 736.0\n",
      "--- 1.6741971969604492 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6469, reward 200.0, memory_length 2000, epsilon 0.03937988996342191\n",
      "travel time- 720.0\n",
      "--- 1.422738790512085 seconds ---\n",
      "episode 6470, reward 259.0, memory_length 2000, epsilon 0.03936020494010615\n",
      "travel time- 720.0\n",
      "--- 1.7638084888458252 seconds ---\n",
      "episode 6471, reward -228.0, memory_length 2000, epsilon 0.039340529756841804\n",
      "travel time- 727.0\n",
      "--- 1.5998156070709229 seconds ---\n",
      "episode 6472, reward -127.0, memory_length 2000, epsilon 0.039320864408710104\n",
      "travel time- 726.0\n",
      "--- 1.6741151809692383 seconds ---\n",
      "episode 6473, reward 94.0, memory_length 2000, epsilon 0.03930120889079473\n",
      "travel time- 720.0\n",
      "--- 1.621117115020752 seconds ---\n",
      "episode 6474, reward 113.0, memory_length 2000, epsilon 0.03928156319818176\n",
      "travel time- 725.0\n",
      "--- 1.7365565299987793 seconds ---\n",
      "episode 6475, reward 206.0, memory_length 2000, epsilon 0.0392619273259598\n",
      "travel time- 725.0\n",
      "--- 1.5760185718536377 seconds ---\n",
      "episode 6476, reward 79.0, memory_length 2000, epsilon 0.03924230126921989\n",
      "travel time- 729.0\n",
      "--- 1.6224372386932373 seconds ---\n",
      "episode 6477, reward -197.0, memory_length 2000, epsilon 0.03922268502305549\n",
      "travel time- 725.0\n",
      "--- 1.3971412181854248 seconds ---\n",
      "episode 6478, reward -16.0, memory_length 2000, epsilon 0.03920307858256256\n",
      "travel time- 723.0\n",
      "--- 1.5897760391235352 seconds ---\n",
      "episode 6479, reward 65.0, memory_length 2000, epsilon 0.03918348194283947\n",
      "travel time- 721.0\n",
      "--- 1.748143196105957 seconds ---\n",
      "episode 6480, reward 102.0, memory_length 2000, epsilon 0.039163895098987066\n",
      "travel time- 727.0\n",
      "--- 1.8578572273254395 seconds ---\n",
      "episode 6481, reward -354.0, memory_length 2000, epsilon 0.039144318046108656\n",
      "travel time- 723.0\n",
      "--- 1.7617263793945312 seconds ---\n",
      "episode 6482, reward 118.0, memory_length 2000, epsilon 0.03912475077930995\n",
      "travel time- 726.0\n",
      "--- 1.5772345066070557 seconds ---\n",
      "episode 6483, reward 4.0, memory_length 2000, epsilon 0.03910519329369914\n",
      "travel time- 727.0\n",
      "--- 1.674074411392212 seconds ---\n",
      "episode 6484, reward -131.0, memory_length 2000, epsilon 0.03908564558438687\n",
      "travel time- 735.0\n",
      "--- 1.6353180408477783 seconds ---\n",
      "episode 6485, reward 90.0, memory_length 2000, epsilon 0.03906610764648619\n",
      "travel time- 722.0\n",
      "--- 1.6494841575622559 seconds ---\n",
      "episode 6486, reward 161.0, memory_length 2000, epsilon 0.039046579475112635\n",
      "travel time- 722.0\n",
      "--- 1.6363451480865479 seconds ---\n",
      "episode 6487, reward 32.0, memory_length 2000, epsilon 0.03902706106538414\n",
      "travel time- 730.0\n",
      "--- 1.8235101699829102 seconds ---\n",
      "episode 6488, reward -126.0, memory_length 2000, epsilon 0.03900755241242111\n",
      "travel time- 726.0\n",
      "--- 1.5571329593658447 seconds ---\n",
      "episode 6489, reward -228.0, memory_length 2000, epsilon 0.038988053511346404\n",
      "travel time- 723.0\n",
      "--- 1.7246801853179932 seconds ---\n",
      "episode 6490, reward -143.0, memory_length 2000, epsilon 0.03896856435728526\n",
      "travel time- 725.0\n",
      "--- 1.7106478214263916 seconds ---\n",
      "episode 6491, reward 242.0, memory_length 2000, epsilon 0.03894908494536541\n",
      "travel time- 726.0\n",
      "--- 1.6032140254974365 seconds ---\n",
      "episode 6492, reward 0.0, memory_length 2000, epsilon 0.038929615270717026\n",
      "travel time- 726.0\n",
      "--- 1.6326425075531006 seconds ---\n",
      "episode 6493, reward -380.0, memory_length 2000, epsilon 0.03891015532847263\n",
      "travel time- 725.0\n",
      "--- 1.6794703006744385 seconds ---\n",
      "episode 6494, reward -259.0, memory_length 2000, epsilon 0.0388907051137673\n",
      "travel time- 724.0\n",
      "--- 1.66935133934021 seconds ---\n",
      "episode 6495, reward 133.0, memory_length 2000, epsilon 0.03887126462173843\n",
      "travel time- 725.0\n",
      "--- 1.820530891418457 seconds ---\n",
      "episode 6496, reward 10.0, memory_length 2000, epsilon 0.03885183384752591\n",
      "travel time- 720.0\n",
      "--- 1.6529772281646729 seconds ---\n",
      "episode 6497, reward -95.0, memory_length 2000, epsilon 0.03883241278627208\n",
      "travel time- 721.0\n",
      "--- 1.7261502742767334 seconds ---\n",
      "episode 6498, reward 61.0, memory_length 2000, epsilon 0.03881300143312163\n",
      "travel time- 725.0\n",
      "--- 1.60878324508667 seconds ---\n",
      "episode 6499, reward 10.0, memory_length 2000, epsilon 0.038793599783221736\n",
      "travel time- 725.0\n",
      "--- 1.5879685878753662 seconds ---\n",
      "episode 6500, reward 87.0, memory_length 2000, epsilon 0.03877420783172201\n",
      "travel time- 720.0\n",
      "--- 1.7913975715637207 seconds ---\n",
      "episode 6501, reward -348.0, memory_length 2000, epsilon 0.038754825573774423\n",
      "travel time- 729.0\n",
      "--- 1.9879450798034668 seconds ---\n",
      "episode 6502, reward -163.0, memory_length 2000, epsilon 0.03873545300453345\n",
      "travel time- 722.0\n",
      "--- 1.8025085926055908 seconds ---\n",
      "episode 6503, reward -216.0, memory_length 2000, epsilon 0.03871609011915592\n",
      "travel time- 720.0\n",
      "--- 1.9262440204620361 seconds ---\n",
      "episode 6504, reward -243.0, memory_length 2000, epsilon 0.038696736912801115\n",
      "travel time- 724.0\n",
      "--- 1.9681684970855713 seconds ---\n",
      "episode 6505, reward -174.0, memory_length 2000, epsilon 0.03867739338063076\n",
      "travel time- 724.0\n",
      "--- 1.832228660583496 seconds ---\n",
      "episode 6506, reward -162.0, memory_length 2000, epsilon 0.03865805951780893\n",
      "travel time- 720.0\n",
      "--- 1.652174472808838 seconds ---\n",
      "episode 6507, reward -224.0, memory_length 2000, epsilon 0.03863873531950218\n",
      "travel time- 723.0\n",
      "--- 1.748621940612793 seconds ---\n",
      "episode 6508, reward 10.0, memory_length 2000, epsilon 0.03861942078087949\n",
      "travel time- 727.0\n",
      "--- 1.6074914932250977 seconds ---\n",
      "episode 6509, reward 293.0, memory_length 2000, epsilon 0.03860011589711217\n",
      "travel time- 731.0\n",
      "--- 1.6424601078033447 seconds ---\n",
      "episode 6510, reward -313.0, memory_length 2000, epsilon 0.03858082066337404\n",
      "travel time- 720.0\n",
      "--- 1.6456937789916992 seconds ---\n",
      "episode 6511, reward 124.0, memory_length 2000, epsilon 0.038561535074841266\n",
      "travel time- 723.0\n",
      "--- 1.403780221939087 seconds ---\n",
      "episode 6512, reward -264.0, memory_length 2000, epsilon 0.03854225912669246\n",
      "travel time- 720.0\n",
      "--- 1.5708222389221191 seconds ---\n",
      "episode 6513, reward -484.0, memory_length 2000, epsilon 0.03852299281410865\n",
      "travel time- 723.0\n",
      "--- 1.857100009918213 seconds ---\n",
      "episode 6514, reward -109.0, memory_length 2000, epsilon 0.038503736132273224\n",
      "travel time- 727.0\n",
      "--- 1.9612534046173096 seconds ---\n",
      "episode 6515, reward -73.0, memory_length 2000, epsilon 0.03848448907637204\n",
      "travel time- 732.0\n",
      "--- 1.786595344543457 seconds ---\n",
      "episode 6516, reward 148.0, memory_length 2000, epsilon 0.03846525164159334\n",
      "travel time- 728.0\n",
      "--- 1.6435284614562988 seconds ---\n",
      "episode 6517, reward -145.0, memory_length 2000, epsilon 0.03844602382312773\n",
      "travel time- 720.0\n",
      "--- 1.6769492626190186 seconds ---\n",
      "episode 6518, reward -237.0, memory_length 2000, epsilon 0.0384268056161683\n",
      "travel time- 725.0\n",
      "--- 1.6787664890289307 seconds ---\n",
      "episode 6519, reward 55.0, memory_length 2000, epsilon 0.03840759701591045\n",
      "travel time- 721.0\n",
      "--- 1.597938060760498 seconds ---\n",
      "episode 6520, reward -236.0, memory_length 2000, epsilon 0.038388398017552054\n",
      "travel time- 730.0\n",
      "--- 1.6441242694854736 seconds ---\n",
      "episode 6521, reward 131.0, memory_length 2000, epsilon 0.038369208616293386\n",
      "travel time- 720.0\n",
      "--- 1.6651854515075684 seconds ---\n",
      "episode 6522, reward -228.0, memory_length 2000, epsilon 0.03835002880733705\n",
      "travel time- 727.0\n",
      "--- 1.6944749355316162 seconds ---\n",
      "episode 6523, reward 197.0, memory_length 2000, epsilon 0.03833085858588812\n",
      "travel time- 721.0\n",
      "--- 1.6176488399505615 seconds ---\n",
      "episode 6524, reward -369.0, memory_length 2000, epsilon 0.03831169794715405\n",
      "travel time- 721.0\n",
      "--- 1.9158883094787598 seconds ---\n",
      "episode 6525, reward 38.0, memory_length 2000, epsilon 0.03829254688634465\n",
      "travel time- 720.0\n",
      "--- 1.6166751384735107 seconds ---\n",
      "episode 6526, reward -118.0, memory_length 2000, epsilon 0.03827340539867218\n",
      "travel time- 724.0\n",
      "--- 1.877793788909912 seconds ---\n",
      "episode 6527, reward 251.0, memory_length 2000, epsilon 0.03825427347935125\n",
      "travel time- 726.0\n",
      "--- 1.6547067165374756 seconds ---\n",
      "episode 6528, reward 249.0, memory_length 2000, epsilon 0.03823515112359889\n",
      "travel time- 720.0\n",
      "--- 1.6039152145385742 seconds ---\n",
      "episode 6529, reward -221.0, memory_length 2000, epsilon 0.038216038326634526\n",
      "travel time- 723.0\n",
      "--- 1.4915878772735596 seconds ---\n",
      "episode 6530, reward 322.0, memory_length 2000, epsilon 0.038196935083679925\n",
      "travel time- 723.0\n",
      "--- 1.669226884841919 seconds ---\n",
      "episode 6531, reward -284.0, memory_length 2000, epsilon 0.03817784138995931\n",
      "travel time- 721.0\n",
      "--- 1.6541569232940674 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6532, reward -49.0, memory_length 2000, epsilon 0.038158757240699226\n",
      "travel time- 721.0\n",
      "--- 1.555974006652832 seconds ---\n",
      "episode 6533, reward -44.0, memory_length 2000, epsilon 0.03813968263112865\n",
      "travel time- 724.0\n",
      "--- 1.8456292152404785 seconds ---\n",
      "episode 6534, reward 137.0, memory_length 2000, epsilon 0.03812061755647895\n",
      "travel time- 720.0\n",
      "--- 1.543982744216919 seconds ---\n",
      "episode 6535, reward -62.0, memory_length 2000, epsilon 0.03810156201198382\n",
      "travel time- 720.0\n",
      "--- 1.9240295886993408 seconds ---\n",
      "episode 6536, reward -129.0, memory_length 2000, epsilon 0.03808251599287939\n",
      "travel time- 729.0\n",
      "--- 1.728865385055542 seconds ---\n",
      "episode 6537, reward 305.0, memory_length 2000, epsilon 0.038063479494404175\n",
      "travel time- 731.0\n",
      "--- 1.7025220394134521 seconds ---\n",
      "episode 6538, reward 295.0, memory_length 2000, epsilon 0.03804445251179901\n",
      "travel time- 722.0\n",
      "--- 1.4613919258117676 seconds ---\n",
      "episode 6539, reward 346.0, memory_length 2000, epsilon 0.03802543504030719\n",
      "travel time- 720.0\n",
      "--- 1.852891206741333 seconds ---\n",
      "episode 6540, reward -223.0, memory_length 2000, epsilon 0.038006427075174314\n",
      "travel time- 720.0\n",
      "--- 1.7090721130371094 seconds ---\n",
      "episode 6541, reward 22.0, memory_length 2000, epsilon 0.0379874286116484\n",
      "travel time- 725.0\n",
      "--- 1.8287150859832764 seconds ---\n",
      "episode 6542, reward 62.0, memory_length 2000, epsilon 0.03796843964497986\n",
      "travel time- 721.0\n",
      "--- 1.568246841430664 seconds ---\n",
      "episode 6543, reward -24.0, memory_length 2000, epsilon 0.03794946017042141\n",
      "travel time- 737.0\n",
      "--- 1.6592609882354736 seconds ---\n",
      "episode 6544, reward 79.0, memory_length 2000, epsilon 0.0379304901832282\n",
      "travel time- 720.0\n",
      "--- 1.6230201721191406 seconds ---\n",
      "episode 6545, reward 335.0, memory_length 2000, epsilon 0.03791152967865775\n",
      "travel time- 720.0\n",
      "--- 1.6092653274536133 seconds ---\n",
      "episode 6546, reward -80.0, memory_length 2000, epsilon 0.0378925786519699\n",
      "travel time- 724.0\n",
      "--- 1.6099865436553955 seconds ---\n",
      "episode 6547, reward -101.0, memory_length 2000, epsilon 0.03787363709842693\n",
      "travel time- 721.0\n",
      "--- 1.5968537330627441 seconds ---\n",
      "episode 6548, reward 8.0, memory_length 2000, epsilon 0.03785470501329341\n",
      "travel time- 724.0\n",
      "--- 1.494612455368042 seconds ---\n",
      "episode 6549, reward 239.0, memory_length 2000, epsilon 0.03783578239183634\n",
      "travel time- 720.0\n",
      "--- 1.6433122158050537 seconds ---\n",
      "episode 6550, reward 78.0, memory_length 2000, epsilon 0.03781686922932508\n",
      "travel time- 720.0\n",
      "--- 1.689007043838501 seconds ---\n",
      "episode 6551, reward 205.0, memory_length 2000, epsilon 0.03779796552103132\n",
      "travel time- 731.0\n",
      "--- 1.9416687488555908 seconds ---\n",
      "episode 6552, reward 262.0, memory_length 2000, epsilon 0.037779071262229125\n",
      "travel time- 733.0\n",
      "--- 1.7419664859771729 seconds ---\n",
      "episode 6553, reward 241.0, memory_length 2000, epsilon 0.03776018644819496\n",
      "travel time- 722.0\n",
      "--- 1.6163709163665771 seconds ---\n",
      "episode 6554, reward 30.0, memory_length 2000, epsilon 0.03774131107420759\n",
      "travel time- 727.0\n",
      "--- 1.522463321685791 seconds ---\n",
      "episode 6555, reward 485.0, memory_length 2000, epsilon 0.037722445135548205\n",
      "travel time- 723.0\n",
      "--- 1.8065369129180908 seconds ---\n",
      "episode 6556, reward -141.0, memory_length 2000, epsilon 0.037703588627500284\n",
      "travel time- 723.0\n",
      "--- 1.8095264434814453 seconds ---\n",
      "episode 6557, reward 42.0, memory_length 2000, epsilon 0.03768474154534971\n",
      "travel time- 720.0\n",
      "--- 1.5056190490722656 seconds ---\n",
      "episode 6558, reward -102.0, memory_length 2000, epsilon 0.03766590388438474\n",
      "travel time- 730.0\n",
      "--- 1.4886326789855957 seconds ---\n",
      "episode 6559, reward -122.0, memory_length 2000, epsilon 0.037647075639895916\n",
      "travel time- 726.0\n",
      "--- 1.6211912631988525 seconds ---\n",
      "episode 6560, reward -113.0, memory_length 2000, epsilon 0.0376282568071762\n",
      "travel time- 723.0\n",
      "--- 1.6570420265197754 seconds ---\n",
      "episode 6561, reward 135.0, memory_length 2000, epsilon 0.0376094473815209\n",
      "travel time- 723.0\n",
      "--- 1.672600269317627 seconds ---\n",
      "episode 6562, reward -214.0, memory_length 2000, epsilon 0.037590647358227626\n",
      "travel time- 722.0\n",
      "--- 1.726142406463623 seconds ---\n",
      "episode 6563, reward -173.0, memory_length 2000, epsilon 0.0375718567325964\n",
      "travel time- 727.0\n",
      "--- 1.8878228664398193 seconds ---\n",
      "episode 6564, reward 207.0, memory_length 2000, epsilon 0.03755307549992954\n",
      "travel time- 723.0\n",
      "--- 1.4937195777893066 seconds ---\n",
      "episode 6565, reward 3.0, memory_length 2000, epsilon 0.037534303655531745\n",
      "travel time- 724.0\n",
      "--- 1.447277307510376 seconds ---\n",
      "episode 6566, reward 96.0, memory_length 2000, epsilon 0.03751554119471008\n",
      "travel time- 720.0\n",
      "--- 1.7013850212097168 seconds ---\n",
      "episode 6567, reward -108.0, memory_length 2000, epsilon 0.03749678811277389\n",
      "travel time- 721.0\n",
      "--- 1.6566247940063477 seconds ---\n",
      "episode 6568, reward -123.0, memory_length 2000, epsilon 0.03747804440503493\n",
      "travel time- 722.0\n",
      "--- 1.8331565856933594 seconds ---\n",
      "episode 6569, reward 116.0, memory_length 2000, epsilon 0.03745931006680728\n",
      "travel time- 730.0\n",
      "--- 1.7289786338806152 seconds ---\n",
      "episode 6570, reward -155.0, memory_length 2000, epsilon 0.03744058509340732\n",
      "travel time- 720.0\n",
      "--- 1.6074535846710205 seconds ---\n",
      "episode 6571, reward -232.0, memory_length 2000, epsilon 0.03742186948015385\n",
      "travel time- 726.0\n",
      "--- 1.7293674945831299 seconds ---\n",
      "episode 6572, reward 262.0, memory_length 2000, epsilon 0.037403163222367926\n",
      "travel time- 727.0\n",
      "--- 1.6435706615447998 seconds ---\n",
      "episode 6573, reward -245.0, memory_length 2000, epsilon 0.037384466315373004\n",
      "travel time- 723.0\n",
      "--- 1.665045976638794 seconds ---\n",
      "episode 6574, reward 52.0, memory_length 2000, epsilon 0.03736577875449487\n",
      "travel time- 724.0\n",
      "--- 1.5571997165679932 seconds ---\n",
      "episode 6575, reward -166.0, memory_length 2000, epsilon 0.03734710053506161\n",
      "travel time- 724.0\n",
      "--- 1.8893721103668213 seconds ---\n",
      "episode 6576, reward -152.0, memory_length 2000, epsilon 0.03732843165240367\n",
      "travel time- 728.0\n",
      "--- 1.549797773361206 seconds ---\n",
      "episode 6577, reward 572.0, memory_length 2000, epsilon 0.03730977210185386\n",
      "travel time- 725.0\n",
      "--- 1.5892877578735352 seconds ---\n",
      "episode 6578, reward 113.0, memory_length 2000, epsilon 0.037291121878747245\n",
      "travel time- 720.0\n",
      "--- 1.3751022815704346 seconds ---\n",
      "episode 6579, reward -129.0, memory_length 2000, epsilon 0.03727248097842131\n",
      "travel time- 722.0\n",
      "--- 1.660454511642456 seconds ---\n",
      "episode 6580, reward 233.0, memory_length 2000, epsilon 0.03725384939621581\n",
      "travel time- 726.0\n",
      "--- 1.6225907802581787 seconds ---\n",
      "episode 6581, reward 174.0, memory_length 2000, epsilon 0.03723522712747284\n",
      "travel time- 726.0\n",
      "--- 1.713651418685913 seconds ---\n",
      "episode 6582, reward 107.0, memory_length 2000, epsilon 0.03721661416753687\n",
      "travel time- 722.0\n",
      "--- 1.7596375942230225 seconds ---\n",
      "episode 6583, reward -266.0, memory_length 2000, epsilon 0.037198010511754614\n",
      "travel time- 720.0\n",
      "--- 1.456904649734497 seconds ---\n",
      "episode 6584, reward 130.0, memory_length 2000, epsilon 0.03717941615547519\n",
      "travel time- 727.0\n",
      "--- 1.5626037120819092 seconds ---\n",
      "episode 6585, reward 104.0, memory_length 2000, epsilon 0.03716083109405\n",
      "travel time- 725.0\n",
      "--- 1.618267297744751 seconds ---\n",
      "episode 6586, reward -178.0, memory_length 2000, epsilon 0.03714225532283277\n",
      "travel time- 726.0\n",
      "--- 1.6672492027282715 seconds ---\n",
      "episode 6587, reward -31.0, memory_length 2000, epsilon 0.037123688837179585\n",
      "travel time- 720.0\n",
      "--- 1.8430755138397217 seconds ---\n",
      "episode 6588, reward -125.0, memory_length 2000, epsilon 0.03710513163244877\n",
      "travel time- 723.0\n",
      "--- 1.8371810913085938 seconds ---\n",
      "episode 6589, reward 44.0, memory_length 2000, epsilon 0.03708658370400107\n",
      "travel time- 725.0\n",
      "--- 1.5173301696777344 seconds ---\n",
      "episode 6590, reward -279.0, memory_length 2000, epsilon 0.0370680450471995\n",
      "travel time- 724.0\n",
      "--- 1.647207498550415 seconds ---\n",
      "episode 6591, reward 30.0, memory_length 2000, epsilon 0.037049515657409375\n",
      "travel time- 725.0\n",
      "--- 1.544320821762085 seconds ---\n",
      "episode 6592, reward 119.0, memory_length 2000, epsilon 0.037030995529998355\n",
      "travel time- 720.0\n",
      "--- 1.635956048965454 seconds ---\n",
      "episode 6593, reward -45.0, memory_length 2000, epsilon 0.03701248466033642\n",
      "travel time- 720.0\n",
      "--- 1.907865285873413 seconds ---\n",
      "episode 6594, reward -76.0, memory_length 2000, epsilon 0.036993983043795836\n",
      "travel time- 720.0\n",
      "--- 1.5455338954925537 seconds ---\n",
      "episode 6595, reward 50.0, memory_length 2000, epsilon 0.03697549067575122\n",
      "travel time- 723.0\n",
      "--- 1.6620500087738037 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6596, reward -46.0, memory_length 2000, epsilon 0.03695700755157944\n",
      "travel time- 722.0\n",
      "--- 1.6797659397125244 seconds ---\n",
      "episode 6597, reward 159.0, memory_length 2000, epsilon 0.03693853366665975\n",
      "travel time- 729.0\n",
      "--- 1.824528455734253 seconds ---\n",
      "episode 6598, reward -140.0, memory_length 2000, epsilon 0.03692006901637368\n",
      "travel time- 721.0\n",
      "--- 1.8446879386901855 seconds ---\n",
      "episode 6599, reward 235.0, memory_length 2000, epsilon 0.03690161359610504\n",
      "travel time- 724.0\n",
      "--- 1.4897539615631104 seconds ---\n",
      "episode 6600, reward 112.0, memory_length 2000, epsilon 0.036883167401239994\n",
      "travel time- 722.0\n",
      "--- 1.505523443222046 seconds ---\n",
      "episode 6601, reward -394.0, memory_length 2000, epsilon 0.03686473042716701\n",
      "travel time- 721.0\n",
      "--- 1.6790802478790283 seconds ---\n",
      "episode 6602, reward 97.0, memory_length 2000, epsilon 0.036846302669276805\n",
      "travel time- 727.0\n",
      "--- 1.8473317623138428 seconds ---\n",
      "episode 6603, reward -157.0, memory_length 2000, epsilon 0.03682788412296247\n",
      "travel time- 723.0\n",
      "--- 1.5498943328857422 seconds ---\n",
      "episode 6604, reward 65.0, memory_length 2000, epsilon 0.03680947478361935\n",
      "travel time- 726.0\n",
      "--- 1.5678448677062988 seconds ---\n",
      "episode 6605, reward 117.0, memory_length 2000, epsilon 0.03679107464664511\n",
      "travel time- 732.0\n",
      "--- 1.77937912940979 seconds ---\n",
      "episode 6606, reward 13.0, memory_length 2000, epsilon 0.036772683707439746\n",
      "travel time- 726.0\n",
      "--- 1.6372640132904053 seconds ---\n",
      "episode 6607, reward 147.0, memory_length 2000, epsilon 0.03675430196140548\n",
      "travel time- 726.0\n",
      "--- 1.58894944190979 seconds ---\n",
      "episode 6608, reward -37.0, memory_length 2000, epsilon 0.0367359294039469\n",
      "travel time- 728.0\n",
      "--- 1.4987728595733643 seconds ---\n",
      "episode 6609, reward 112.0, memory_length 2000, epsilon 0.036717566030470876\n",
      "travel time- 730.0\n",
      "--- 1.8510329723358154 seconds ---\n",
      "episode 6610, reward 94.0, memory_length 2000, epsilon 0.03669921183638653\n",
      "travel time- 720.0\n",
      "--- 1.7534348964691162 seconds ---\n",
      "episode 6611, reward -273.0, memory_length 2000, epsilon 0.03668086681710536\n",
      "travel time- 720.0\n",
      "--- 1.5641191005706787 seconds ---\n",
      "episode 6612, reward -73.0, memory_length 2000, epsilon 0.03666253096804106\n",
      "travel time- 720.0\n",
      "--- 1.5350582599639893 seconds ---\n",
      "episode 6613, reward -56.0, memory_length 2000, epsilon 0.0366442042846097\n",
      "travel time- 721.0\n",
      "--- 1.8476314544677734 seconds ---\n",
      "episode 6614, reward 25.0, memory_length 2000, epsilon 0.036625886762229616\n",
      "travel time- 720.0\n",
      "--- 1.7899959087371826 seconds ---\n",
      "episode 6615, reward 211.0, memory_length 2000, epsilon 0.036607578396321394\n",
      "travel time- 726.0\n",
      "--- 1.6382288932800293 seconds ---\n",
      "episode 6616, reward 82.0, memory_length 2000, epsilon 0.03658927918230796\n",
      "travel time- 720.0\n",
      "--- 1.6641371250152588 seconds ---\n",
      "episode 6617, reward -23.0, memory_length 2000, epsilon 0.03657098911561454\n",
      "travel time- 722.0\n",
      "--- 1.8559753894805908 seconds ---\n",
      "episode 6618, reward -107.0, memory_length 2000, epsilon 0.036552708191668566\n",
      "travel time- 721.0\n",
      "--- 1.772026777267456 seconds ---\n",
      "episode 6619, reward 122.0, memory_length 2000, epsilon 0.036534436405899845\n",
      "travel time- 729.0\n",
      "--- 1.41192626953125 seconds ---\n",
      "episode 6620, reward 207.0, memory_length 2000, epsilon 0.0365161737537404\n",
      "travel time- 721.0\n",
      "--- 1.5190904140472412 seconds ---\n",
      "episode 6621, reward 22.0, memory_length 2000, epsilon 0.036497920230624585\n",
      "travel time- 728.0\n",
      "--- 1.913611650466919 seconds ---\n",
      "episode 6622, reward 105.0, memory_length 2000, epsilon 0.036479675831989036\n",
      "travel time- 725.0\n",
      "--- 1.6380362510681152 seconds ---\n",
      "episode 6623, reward 128.0, memory_length 2000, epsilon 0.03646144055327261\n",
      "travel time- 720.0\n",
      "--- 1.723496913909912 seconds ---\n",
      "episode 6624, reward 320.0, memory_length 2000, epsilon 0.036443214389916524\n",
      "travel time- 720.0\n",
      "--- 1.180842399597168 seconds ---\n",
      "episode 6625, reward -36.0, memory_length 2000, epsilon 0.036424997337364234\n",
      "travel time- 720.0\n",
      "--- 1.4425337314605713 seconds ---\n",
      "episode 6626, reward 296.0, memory_length 2000, epsilon 0.036406789391061456\n",
      "travel time- 726.0\n",
      "--- 1.621476411819458 seconds ---\n",
      "episode 6627, reward 289.0, memory_length 2000, epsilon 0.036388590546456226\n",
      "travel time- 723.0\n",
      "--- 1.752657175064087 seconds ---\n",
      "episode 6628, reward 173.0, memory_length 2000, epsilon 0.03637040079899881\n",
      "travel time- 721.0\n",
      "--- 1.6008398532867432 seconds ---\n",
      "episode 6629, reward 219.0, memory_length 2000, epsilon 0.03635222014414178\n",
      "travel time- 723.0\n",
      "--- 1.5291852951049805 seconds ---\n",
      "episode 6630, reward 114.0, memory_length 2000, epsilon 0.036334048577339996\n",
      "travel time- 725.0\n",
      "--- 1.76902437210083 seconds ---\n",
      "episode 6631, reward 190.0, memory_length 2000, epsilon 0.03631588609405053\n",
      "travel time- 722.0\n",
      "--- 1.6694118976593018 seconds ---\n",
      "episode 6632, reward -92.0, memory_length 2000, epsilon 0.03629773268973277\n",
      "travel time- 720.0\n",
      "--- 1.5232017040252686 seconds ---\n",
      "episode 6633, reward -86.0, memory_length 2000, epsilon 0.036279588359848396\n",
      "travel time- 721.0\n",
      "--- 1.585045337677002 seconds ---\n",
      "episode 6634, reward -169.0, memory_length 2000, epsilon 0.03626145309986128\n",
      "travel time- 730.0\n",
      "--- 1.479233980178833 seconds ---\n",
      "episode 6635, reward 219.0, memory_length 2000, epsilon 0.03624332690523764\n",
      "travel time- 733.0\n",
      "--- 1.743281602859497 seconds ---\n",
      "episode 6636, reward 165.0, memory_length 2000, epsilon 0.03622520977144591\n",
      "travel time- 721.0\n",
      "--- 1.575221300125122 seconds ---\n",
      "episode 6637, reward -199.0, memory_length 2000, epsilon 0.0362071016939568\n",
      "travel time- 720.0\n",
      "--- 1.7417147159576416 seconds ---\n",
      "episode 6638, reward -245.0, memory_length 2000, epsilon 0.03618900266824332\n",
      "travel time- 720.0\n",
      "--- 1.6672370433807373 seconds ---\n",
      "episode 6639, reward -87.0, memory_length 2000, epsilon 0.03617091268978068\n",
      "travel time- 721.0\n",
      "--- 1.5577507019042969 seconds ---\n",
      "episode 6640, reward 135.0, memory_length 2000, epsilon 0.03615283175404641\n",
      "travel time- 721.0\n",
      "--- 1.6239407062530518 seconds ---\n",
      "episode 6641, reward -171.0, memory_length 2000, epsilon 0.036134759856520274\n",
      "travel time- 726.0\n",
      "--- 1.545614242553711 seconds ---\n",
      "episode 6642, reward 145.0, memory_length 2000, epsilon 0.03611669699268428\n",
      "travel time- 723.0\n",
      "--- 1.8983516693115234 seconds ---\n",
      "episode 6643, reward 232.0, memory_length 2000, epsilon 0.036098643158022733\n",
      "travel time- 722.0\n",
      "--- 1.7708795070648193 seconds ---\n",
      "episode 6644, reward 48.0, memory_length 2000, epsilon 0.03608059834802215\n",
      "travel time- 727.0\n",
      "--- 1.6584770679473877 seconds ---\n",
      "episode 6645, reward 5.0, memory_length 2000, epsilon 0.03606256255817134\n",
      "travel time- 723.0\n",
      "--- 1.6856577396392822 seconds ---\n",
      "episode 6646, reward -336.0, memory_length 2000, epsilon 0.03604453578396138\n",
      "travel time- 729.0\n",
      "--- 1.9532067775726318 seconds ---\n",
      "episode 6647, reward 274.0, memory_length 2000, epsilon 0.03602651802088553\n",
      "travel time- 721.0\n",
      "--- 1.5950050354003906 seconds ---\n",
      "episode 6648, reward 242.0, memory_length 2000, epsilon 0.036008509264439374\n",
      "travel time- 727.0\n",
      "--- 1.816345453262329 seconds ---\n",
      "episode 6649, reward 281.0, memory_length 2000, epsilon 0.035990509510120734\n",
      "travel time- 723.0\n",
      "--- 1.5803544521331787 seconds ---\n",
      "episode 6650, reward 34.0, memory_length 2000, epsilon 0.035972518753429654\n",
      "travel time- 720.0\n",
      "--- 1.6536054611206055 seconds ---\n",
      "episode 6651, reward 272.0, memory_length 2000, epsilon 0.03595453698986845\n",
      "travel time- 724.0\n",
      "--- 1.425832986831665 seconds ---\n",
      "episode 6652, reward 219.0, memory_length 2000, epsilon 0.03593656421494168\n",
      "travel time- 726.0\n",
      "--- 1.4469523429870605 seconds ---\n",
      "episode 6653, reward 138.0, memory_length 2000, epsilon 0.03591860042415614\n",
      "travel time- 722.0\n",
      "--- 1.720710277557373 seconds ---\n",
      "episode 6654, reward 23.0, memory_length 2000, epsilon 0.03590064561302092\n",
      "travel time- 721.0\n",
      "--- 1.6359636783599854 seconds ---\n",
      "episode 6655, reward -57.0, memory_length 2000, epsilon 0.03588269977704727\n",
      "travel time- 726.0\n",
      "--- 1.7399659156799316 seconds ---\n",
      "episode 6656, reward 54.0, memory_length 2000, epsilon 0.03586476291174875\n",
      "travel time- 723.0\n",
      "--- 1.6319501399993896 seconds ---\n",
      "episode 6657, reward -37.0, memory_length 2000, epsilon 0.03584683501264116\n",
      "travel time- 726.0\n",
      "--- 1.543717861175537 seconds ---\n",
      "episode 6658, reward 129.0, memory_length 2000, epsilon 0.035828916075242495\n",
      "travel time- 723.0\n",
      "--- 1.4594776630401611 seconds ---\n",
      "episode 6659, reward -120.0, memory_length 2000, epsilon 0.035811006095073046\n",
      "travel time- 720.0\n",
      "--- 1.6488757133483887 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6660, reward -46.0, memory_length 2000, epsilon 0.0357931050676553\n",
      "travel time- 722.0\n",
      "--- 1.662041187286377 seconds ---\n",
      "episode 6661, reward -83.0, memory_length 2000, epsilon 0.035775212988514\n",
      "travel time- 737.0\n",
      "--- 1.727482795715332 seconds ---\n",
      "episode 6662, reward -13.0, memory_length 2000, epsilon 0.03575732985317615\n",
      "travel time- 726.0\n",
      "--- 1.7306602001190186 seconds ---\n",
      "episode 6663, reward 119.0, memory_length 2000, epsilon 0.03573945565717094\n",
      "travel time- 727.0\n",
      "--- 1.4946107864379883 seconds ---\n",
      "episode 6664, reward -68.0, memory_length 2000, epsilon 0.035721590396029845\n",
      "travel time- 727.0\n",
      "--- 1.6859655380249023 seconds ---\n",
      "episode 6665, reward 306.0, memory_length 2000, epsilon 0.03570373406528651\n",
      "travel time- 721.0\n",
      "--- 1.6193838119506836 seconds ---\n",
      "episode 6666, reward -251.0, memory_length 2000, epsilon 0.03568588666047689\n",
      "travel time- 720.0\n",
      "--- 1.6469237804412842 seconds ---\n",
      "episode 6667, reward 140.0, memory_length 2000, epsilon 0.03566804817713913\n",
      "travel time- 721.0\n",
      "--- 1.8389499187469482 seconds ---\n",
      "episode 6668, reward -170.0, memory_length 2000, epsilon 0.035650218610813585\n",
      "travel time- 721.0\n",
      "--- 1.6326265335083008 seconds ---\n",
      "episode 6669, reward 57.0, memory_length 2000, epsilon 0.03563239795704288\n",
      "travel time- 723.0\n",
      "--- 1.5760390758514404 seconds ---\n",
      "episode 6670, reward -154.0, memory_length 2000, epsilon 0.03561458621137186\n",
      "travel time- 730.0\n",
      "--- 1.6068856716156006 seconds ---\n",
      "episode 6671, reward -85.0, memory_length 2000, epsilon 0.03559678336934757\n",
      "travel time- 728.0\n",
      "--- 1.7237610816955566 seconds ---\n",
      "episode 6672, reward -163.0, memory_length 2000, epsilon 0.03557898942651932\n",
      "travel time- 727.0\n",
      "--- 1.56654691696167 seconds ---\n",
      "episode 6673, reward 103.0, memory_length 2000, epsilon 0.0355612043784386\n",
      "travel time- 722.0\n",
      "--- 1.5196959972381592 seconds ---\n",
      "episode 6674, reward -49.0, memory_length 2000, epsilon 0.03554342822065915\n",
      "travel time- 721.0\n",
      "--- 1.718193769454956 seconds ---\n",
      "episode 6675, reward 113.0, memory_length 2000, epsilon 0.035525660948736965\n",
      "travel time- 725.0\n",
      "--- 1.6787919998168945 seconds ---\n",
      "episode 6676, reward -363.0, memory_length 2000, epsilon 0.035507902558230185\n",
      "travel time- 720.0\n",
      "--- 1.6875016689300537 seconds ---\n",
      "episode 6677, reward -543.0, memory_length 2000, epsilon 0.03549015304469923\n",
      "travel time- 722.0\n",
      "--- 1.6056227684020996 seconds ---\n",
      "episode 6678, reward 70.0, memory_length 2000, epsilon 0.03547241240370673\n",
      "travel time- 726.0\n",
      "--- 1.6616981029510498 seconds ---\n",
      "episode 6679, reward -10.0, memory_length 2000, epsilon 0.035454680630817505\n",
      "travel time- 721.0\n",
      "--- 1.7431845664978027 seconds ---\n",
      "episode 6680, reward 102.0, memory_length 2000, epsilon 0.03543695772159864\n",
      "travel time- 725.0\n",
      "--- 1.4835422039031982 seconds ---\n",
      "episode 6681, reward -251.0, memory_length 2000, epsilon 0.035419243671619374\n",
      "travel time- 728.0\n",
      "--- 1.730006456375122 seconds ---\n",
      "episode 6682, reward 112.0, memory_length 2000, epsilon 0.03540153847645121\n",
      "travel time- 725.0\n",
      "--- 1.5237925052642822 seconds ---\n",
      "episode 6683, reward 166.0, memory_length 2000, epsilon 0.03538384213166786\n",
      "travel time- 727.0\n",
      "--- 1.6649539470672607 seconds ---\n",
      "episode 6684, reward -123.0, memory_length 2000, epsilon 0.03536615463284522\n",
      "travel time- 729.0\n",
      "--- 1.6692402362823486 seconds ---\n",
      "episode 6685, reward 112.0, memory_length 2000, epsilon 0.035348475975561414\n",
      "travel time- 721.0\n",
      "--- 1.502791166305542 seconds ---\n",
      "episode 6686, reward -141.0, memory_length 2000, epsilon 0.035330806155396806\n",
      "travel time- 733.0\n",
      "--- 1.6441583633422852 seconds ---\n",
      "episode 6687, reward -159.0, memory_length 2000, epsilon 0.03531314516793391\n",
      "travel time- 722.0\n",
      "--- 1.7323431968688965 seconds ---\n",
      "episode 6688, reward 82.0, memory_length 2000, epsilon 0.03529549300875749\n",
      "travel time- 721.0\n",
      "--- 1.8093993663787842 seconds ---\n",
      "episode 6689, reward -97.0, memory_length 2000, epsilon 0.03527784967345451\n",
      "travel time- 725.0\n",
      "--- 1.8032174110412598 seconds ---\n",
      "episode 6690, reward -110.0, memory_length 2000, epsilon 0.03526021515761412\n",
      "travel time- 720.0\n",
      "--- 2.0193967819213867 seconds ---\n",
      "episode 6691, reward 80.0, memory_length 2000, epsilon 0.03524258945682772\n",
      "travel time- 724.0\n",
      "--- 1.764261245727539 seconds ---\n",
      "episode 6692, reward -211.0, memory_length 2000, epsilon 0.035224972566688856\n",
      "travel time- 721.0\n",
      "--- 1.8787875175476074 seconds ---\n",
      "episode 6693, reward -10.0, memory_length 2000, epsilon 0.03520736448279331\n",
      "travel time- 722.0\n",
      "--- 1.7117834091186523 seconds ---\n",
      "episode 6694, reward 269.0, memory_length 2000, epsilon 0.03518976520073909\n",
      "travel time- 721.0\n",
      "--- 1.6088745594024658 seconds ---\n",
      "episode 6695, reward 83.0, memory_length 2000, epsilon 0.03517217471612634\n",
      "travel time- 721.0\n",
      "--- 1.5237421989440918 seconds ---\n",
      "episode 6696, reward 62.0, memory_length 2000, epsilon 0.03515459302455746\n",
      "travel time- 722.0\n",
      "--- 1.6904582977294922 seconds ---\n",
      "episode 6697, reward 30.0, memory_length 2000, epsilon 0.03513702012163701\n",
      "travel time- 727.0\n",
      "--- 1.4764697551727295 seconds ---\n",
      "episode 6698, reward 165.0, memory_length 2000, epsilon 0.03511945600297177\n",
      "travel time- 725.0\n",
      "--- 1.6643376350402832 seconds ---\n",
      "episode 6699, reward 80.0, memory_length 2000, epsilon 0.03510190066417073\n",
      "travel time- 721.0\n",
      "--- 1.6357793807983398 seconds ---\n",
      "episode 6700, reward -38.0, memory_length 2000, epsilon 0.035084354100845025\n",
      "travel time- 731.0\n",
      "--- 1.8286190032958984 seconds ---\n",
      "episode 6701, reward 309.0, memory_length 2000, epsilon 0.03506681630860802\n",
      "travel time- 720.0\n",
      "--- 1.5129451751708984 seconds ---\n",
      "episode 6702, reward -169.0, memory_length 2000, epsilon 0.035049287283075305\n",
      "travel time- 729.0\n",
      "--- 1.7096121311187744 seconds ---\n",
      "episode 6703, reward 140.0, memory_length 2000, epsilon 0.03503176701986457\n",
      "travel time- 722.0\n",
      "--- 1.657968521118164 seconds ---\n",
      "episode 6704, reward -79.0, memory_length 2000, epsilon 0.035014255514595784\n",
      "travel time- 727.0\n",
      "--- 1.677095651626587 seconds ---\n",
      "episode 6705, reward -16.0, memory_length 2000, epsilon 0.03499675276289105\n",
      "travel time- 722.0\n",
      "--- 1.6518967151641846 seconds ---\n",
      "episode 6706, reward 10.0, memory_length 2000, epsilon 0.034979258760374686\n",
      "travel time- 727.0\n",
      "--- 1.5176126956939697 seconds ---\n",
      "episode 6707, reward 20.0, memory_length 2000, epsilon 0.0349617735026732\n",
      "travel time- 724.0\n",
      "--- 1.5087144374847412 seconds ---\n",
      "episode 6708, reward -61.0, memory_length 2000, epsilon 0.03494429698541527\n",
      "travel time- 725.0\n",
      "--- 1.6917171478271484 seconds ---\n",
      "episode 6709, reward -235.0, memory_length 2000, epsilon 0.03492682920423177\n",
      "travel time- 727.0\n",
      "--- 1.6655313968658447 seconds ---\n",
      "episode 6710, reward -83.0, memory_length 2000, epsilon 0.03490937015475576\n",
      "travel time- 721.0\n",
      "--- 1.6640081405639648 seconds ---\n",
      "episode 6711, reward 83.0, memory_length 2000, epsilon 0.03489191983262246\n",
      "travel time- 721.0\n",
      "--- 1.513540506362915 seconds ---\n",
      "episode 6712, reward 48.0, memory_length 2000, epsilon 0.034874478233469314\n",
      "travel time- 724.0\n",
      "--- 1.5360496044158936 seconds ---\n",
      "episode 6713, reward 239.0, memory_length 2000, epsilon 0.03485704535293589\n",
      "travel time- 722.0\n",
      "--- 1.5528059005737305 seconds ---\n",
      "episode 6714, reward 140.0, memory_length 2000, epsilon 0.034839621186663984\n",
      "travel time- 720.0\n",
      "--- 1.5074462890625 seconds ---\n",
      "episode 6715, reward 70.0, memory_length 2000, epsilon 0.03482220573029758\n",
      "travel time- 721.0\n",
      "--- 1.6633481979370117 seconds ---\n",
      "episode 6716, reward 55.0, memory_length 2000, epsilon 0.03480479897948277\n",
      "travel time- 722.0\n",
      "--- 1.6357457637786865 seconds ---\n",
      "episode 6717, reward -386.0, memory_length 2000, epsilon 0.03478740092986789\n",
      "travel time- 720.0\n",
      "--- 1.62949800491333 seconds ---\n",
      "episode 6718, reward -92.0, memory_length 2000, epsilon 0.03477001157710343\n",
      "travel time- 722.0\n",
      "--- 1.6259381771087646 seconds ---\n",
      "episode 6719, reward 37.0, memory_length 2000, epsilon 0.03475263091684203\n",
      "travel time- 723.0\n",
      "--- 1.6111564636230469 seconds ---\n",
      "episode 6720, reward -304.0, memory_length 2000, epsilon 0.03473525894473856\n",
      "travel time- 720.0\n",
      "--- 1.551992654800415 seconds ---\n",
      "episode 6721, reward -271.0, memory_length 2000, epsilon 0.03471789565645\n",
      "travel time- 722.0\n",
      "--- 1.5741033554077148 seconds ---\n",
      "episode 6722, reward 69.0, memory_length 2000, epsilon 0.03470054104763552\n",
      "travel time- 720.0\n",
      "--- 1.4435462951660156 seconds ---\n",
      "episode 6723, reward 62.0, memory_length 2000, epsilon 0.03468319511395651\n",
      "travel time- 724.0\n",
      "--- 1.6450214385986328 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6724, reward -167.0, memory_length 2000, epsilon 0.03466585785107644\n",
      "travel time- 723.0\n",
      "--- 1.685537576675415 seconds ---\n",
      "episode 6725, reward -147.0, memory_length 2000, epsilon 0.03464852925466101\n",
      "travel time- 721.0\n",
      "--- 1.7044074535369873 seconds ---\n",
      "episode 6726, reward 95.0, memory_length 2000, epsilon 0.034631209320378095\n",
      "travel time- 729.0\n",
      "--- 1.6531651020050049 seconds ---\n",
      "episode 6727, reward 48.0, memory_length 2000, epsilon 0.03461389804389767\n",
      "travel time- 723.0\n",
      "--- 1.7502009868621826 seconds ---\n",
      "episode 6728, reward 3.0, memory_length 2000, epsilon 0.034596595420891954\n",
      "travel time- 726.0\n",
      "--- 1.6391654014587402 seconds ---\n",
      "episode 6729, reward 22.0, memory_length 2000, epsilon 0.034579301447035256\n",
      "travel time- 723.0\n",
      "--- 1.6922039985656738 seconds ---\n",
      "episode 6730, reward 122.0, memory_length 2000, epsilon 0.0345620161180041\n",
      "travel time- 726.0\n",
      "--- 1.5405974388122559 seconds ---\n",
      "episode 6731, reward 121.0, memory_length 2000, epsilon 0.034544739429477174\n",
      "travel time- 723.0\n",
      "--- 1.7480638027191162 seconds ---\n",
      "episode 6732, reward 6.0, memory_length 2000, epsilon 0.034527471377135265\n",
      "travel time- 729.0\n",
      "--- 1.7047202587127686 seconds ---\n",
      "episode 6733, reward -61.0, memory_length 2000, epsilon 0.03451021195666138\n",
      "travel time- 723.0\n",
      "--- 1.6558647155761719 seconds ---\n",
      "episode 6734, reward 223.0, memory_length 2000, epsilon 0.03449296116374068\n",
      "travel time- 724.0\n",
      "--- 1.5866076946258545 seconds ---\n",
      "episode 6735, reward -96.0, memory_length 2000, epsilon 0.034475718994060434\n",
      "travel time- 726.0\n",
      "--- 1.928969144821167 seconds ---\n",
      "episode 6736, reward -20.0, memory_length 2000, epsilon 0.034458485443310136\n",
      "travel time- 730.0\n",
      "--- 1.5334551334381104 seconds ---\n",
      "episode 6737, reward 186.0, memory_length 2000, epsilon 0.03444126050718136\n",
      "travel time- 728.0\n",
      "--- 1.770782232284546 seconds ---\n",
      "episode 6738, reward -34.0, memory_length 2000, epsilon 0.034424044181367894\n",
      "travel time- 725.0\n",
      "--- 1.6213161945343018 seconds ---\n",
      "episode 6739, reward 247.0, memory_length 2000, epsilon 0.034406836461565664\n",
      "travel time- 729.0\n",
      "--- 1.4927647113800049 seconds ---\n",
      "episode 6740, reward 395.0, memory_length 2000, epsilon 0.03438963734347271\n",
      "travel time- 722.0\n",
      "--- 1.6073353290557861 seconds ---\n",
      "episode 6741, reward -41.0, memory_length 2000, epsilon 0.034372446822789275\n",
      "travel time- 729.0\n",
      "--- 1.5717804431915283 seconds ---\n",
      "episode 6742, reward 77.0, memory_length 2000, epsilon 0.03435526489521774\n",
      "travel time- 731.0\n",
      "--- 1.9542016983032227 seconds ---\n",
      "episode 6743, reward -17.0, memory_length 2000, epsilon 0.03433809155646259\n",
      "travel time- 721.0\n",
      "--- 1.7051975727081299 seconds ---\n",
      "episode 6744, reward -308.0, memory_length 2000, epsilon 0.03432092680223053\n",
      "travel time- 724.0\n",
      "--- 1.720984935760498 seconds ---\n",
      "episode 6745, reward 99.0, memory_length 2000, epsilon 0.034303770628230326\n",
      "travel time- 728.0\n",
      "--- 1.51924467086792 seconds ---\n",
      "episode 6746, reward 20.0, memory_length 2000, epsilon 0.034286623030172964\n",
      "travel time- 720.0\n",
      "--- 1.6132397651672363 seconds ---\n",
      "episode 6747, reward 158.0, memory_length 2000, epsilon 0.03426948400377155\n",
      "travel time- 723.0\n",
      "--- 1.556513786315918 seconds ---\n",
      "episode 6748, reward -331.0, memory_length 2000, epsilon 0.0342523535447413\n",
      "travel time- 721.0\n",
      "--- 1.7728474140167236 seconds ---\n",
      "episode 6749, reward 95.0, memory_length 2000, epsilon 0.034235231648799616\n",
      "travel time- 720.0\n",
      "--- 1.5718111991882324 seconds ---\n",
      "episode 6750, reward -114.0, memory_length 2000, epsilon 0.03421811831166603\n",
      "travel time- 723.0\n",
      "--- 1.7349400520324707 seconds ---\n",
      "episode 6751, reward 323.0, memory_length 2000, epsilon 0.0342010135290622\n",
      "travel time- 728.0\n",
      "--- 1.60585618019104 seconds ---\n",
      "episode 6752, reward 153.0, memory_length 2000, epsilon 0.034183917296711934\n",
      "travel time- 723.0\n",
      "--- 1.6788666248321533 seconds ---\n",
      "episode 6753, reward -78.0, memory_length 2000, epsilon 0.034166829610341155\n",
      "travel time- 720.0\n",
      "--- 1.723365068435669 seconds ---\n",
      "episode 6754, reward 402.0, memory_length 2000, epsilon 0.03414975046567796\n",
      "travel time- 720.0\n",
      "--- 1.460381269454956 seconds ---\n",
      "episode 6755, reward -9.0, memory_length 2000, epsilon 0.03413267985845258\n",
      "travel time- 731.0\n",
      "--- 1.6298043727874756 seconds ---\n",
      "episode 6756, reward 401.0, memory_length 2000, epsilon 0.03411561778439732\n",
      "travel time- 723.0\n",
      "--- 1.630157470703125 seconds ---\n",
      "episode 6757, reward -7.0, memory_length 2000, epsilon 0.03409856423924668\n",
      "travel time- 723.0\n",
      "--- 1.6458182334899902 seconds ---\n",
      "episode 6758, reward 164.0, memory_length 2000, epsilon 0.034081519218737304\n",
      "travel time- 725.0\n",
      "--- 1.5809204578399658 seconds ---\n",
      "episode 6759, reward 135.0, memory_length 2000, epsilon 0.03406448271860789\n",
      "travel time- 725.0\n",
      "--- 1.41300368309021 seconds ---\n",
      "episode 6760, reward -14.0, memory_length 2000, epsilon 0.034047454734599344\n",
      "travel time- 724.0\n",
      "--- 1.6111514568328857 seconds ---\n",
      "episode 6761, reward 222.0, memory_length 2000, epsilon 0.034030435262454646\n",
      "travel time- 729.0\n",
      "--- 1.6920740604400635 seconds ---\n",
      "episode 6762, reward 63.0, memory_length 2000, epsilon 0.03401342429791895\n",
      "travel time- 728.0\n",
      "--- 1.4378533363342285 seconds ---\n",
      "episode 6763, reward -447.0, memory_length 2000, epsilon 0.03399642183673951\n",
      "travel time- 721.0\n",
      "--- 1.8609912395477295 seconds ---\n",
      "episode 6764, reward 55.0, memory_length 2000, epsilon 0.033979427874665694\n",
      "travel time- 734.0\n",
      "--- 1.6792831420898438 seconds ---\n",
      "episode 6765, reward -61.0, memory_length 2000, epsilon 0.03396244240744902\n",
      "travel time- 721.0\n",
      "--- 1.6946663856506348 seconds ---\n",
      "episode 6766, reward 104.0, memory_length 2000, epsilon 0.03394546543084315\n",
      "travel time- 724.0\n",
      "--- 1.6144120693206787 seconds ---\n",
      "episode 6767, reward 316.0, memory_length 2000, epsilon 0.033928496940603785\n",
      "travel time- 722.0\n",
      "--- 1.5536746978759766 seconds ---\n",
      "episode 6768, reward -33.0, memory_length 2000, epsilon 0.033911536932488856\n",
      "travel time- 727.0\n",
      "--- 1.5534610748291016 seconds ---\n",
      "episode 6769, reward 273.0, memory_length 2000, epsilon 0.03389458540225832\n",
      "travel time- 724.0\n",
      "--- 1.5979173183441162 seconds ---\n",
      "episode 6770, reward -17.0, memory_length 2000, epsilon 0.033877642345674315\n",
      "travel time- 721.0\n",
      "--- 1.7648932933807373 seconds ---\n",
      "episode 6771, reward 184.0, memory_length 2000, epsilon 0.033860707758501085\n",
      "travel time- 723.0\n",
      "--- 1.5133171081542969 seconds ---\n",
      "episode 6772, reward -109.0, memory_length 2000, epsilon 0.03384378163650495\n",
      "travel time- 726.0\n",
      "--- 1.5236248970031738 seconds ---\n",
      "episode 6773, reward -52.0, memory_length 2000, epsilon 0.03382686397545441\n",
      "travel time- 721.0\n",
      "--- 1.7199065685272217 seconds ---\n",
      "episode 6774, reward 183.0, memory_length 2000, epsilon 0.033809954771120046\n",
      "travel time- 727.0\n",
      "--- 1.697443962097168 seconds ---\n",
      "episode 6775, reward -47.0, memory_length 2000, epsilon 0.03379305401927454\n",
      "travel time- 732.0\n",
      "--- 1.642047643661499 seconds ---\n",
      "episode 6776, reward 285.0, memory_length 2000, epsilon 0.03377616171569273\n",
      "travel time- 723.0\n",
      "--- 1.7619712352752686 seconds ---\n",
      "episode 6777, reward -99.0, memory_length 2000, epsilon 0.033759277856151515\n",
      "travel time- 722.0\n",
      "--- 1.6125872135162354 seconds ---\n",
      "episode 6778, reward 118.0, memory_length 2000, epsilon 0.03374240243642994\n",
      "travel time- 733.0\n",
      "--- 1.477168321609497 seconds ---\n",
      "episode 6779, reward 228.0, memory_length 2000, epsilon 0.033725535452309156\n",
      "travel time- 724.0\n",
      "--- 1.6047189235687256 seconds ---\n",
      "episode 6780, reward 9.0, memory_length 2000, epsilon 0.033708676899572396\n",
      "travel time- 721.0\n",
      "--- 1.5802502632141113 seconds ---\n",
      "episode 6781, reward -51.0, memory_length 2000, epsilon 0.03369182677400504\n",
      "travel time- 722.0\n",
      "--- 1.5843048095703125 seconds ---\n",
      "episode 6782, reward 22.0, memory_length 2000, epsilon 0.03367498507139457\n",
      "travel time- 724.0\n",
      "--- 1.429828405380249 seconds ---\n",
      "episode 6783, reward -233.0, memory_length 2000, epsilon 0.03365815178753053\n",
      "travel time- 727.0\n",
      "--- 1.6412560939788818 seconds ---\n",
      "episode 6784, reward -256.0, memory_length 2000, epsilon 0.03364132691820462\n",
      "travel time- 730.0\n",
      "--- 1.821211814880371 seconds ---\n",
      "episode 6785, reward -14.0, memory_length 2000, epsilon 0.0336245104592106\n",
      "travel time- 721.0\n",
      "--- 1.5024774074554443 seconds ---\n",
      "episode 6786, reward 75.0, memory_length 2000, epsilon 0.03360770240634438\n",
      "travel time- 727.0\n",
      "--- 1.597174882888794 seconds ---\n",
      "episode 6787, reward 256.0, memory_length 2000, epsilon 0.03359090275540395\n",
      "travel time- 721.0\n",
      "--- 1.6357746124267578 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6788, reward 503.0, memory_length 2000, epsilon 0.033574111502189356\n",
      "travel time- 727.0\n",
      "--- 1.6210579872131348 seconds ---\n",
      "episode 6789, reward -324.0, memory_length 2000, epsilon 0.03355732864250284\n",
      "travel time- 728.0\n",
      "--- 1.752974510192871 seconds ---\n",
      "episode 6790, reward 144.0, memory_length 2000, epsilon 0.033540554172148636\n",
      "travel time- 727.0\n",
      "--- 1.736083984375 seconds ---\n",
      "episode 6791, reward 29.0, memory_length 2000, epsilon 0.033523788086933154\n",
      "travel time- 729.0\n",
      "--- 1.5525758266448975 seconds ---\n",
      "episode 6792, reward -179.0, memory_length 2000, epsilon 0.03350703038266488\n",
      "travel time- 733.0\n",
      "--- 1.525489330291748 seconds ---\n",
      "episode 6793, reward 175.0, memory_length 2000, epsilon 0.033490281055154364\n",
      "travel time- 725.0\n",
      "--- 1.4920234680175781 seconds ---\n",
      "episode 6794, reward -109.0, memory_length 2000, epsilon 0.03347354010021429\n",
      "travel time- 723.0\n",
      "--- 1.8498573303222656 seconds ---\n",
      "episode 6795, reward 145.0, memory_length 2000, epsilon 0.033456807513659426\n",
      "travel time- 732.0\n",
      "--- 1.622574806213379 seconds ---\n",
      "episode 6796, reward 381.0, memory_length 2000, epsilon 0.0334400832913066\n",
      "travel time- 720.0\n",
      "--- 1.7188804149627686 seconds ---\n",
      "episode 6797, reward -71.0, memory_length 2000, epsilon 0.03342336742897478\n",
      "travel time- 721.0\n",
      "--- 1.7269837856292725 seconds ---\n",
      "episode 6798, reward 435.0, memory_length 2000, epsilon 0.03340665992248499\n",
      "travel time- 720.0\n",
      "--- 1.4402005672454834 seconds ---\n",
      "episode 6799, reward -42.0, memory_length 2000, epsilon 0.03338996076766034\n",
      "travel time- 721.0\n",
      "--- 1.535337209701538 seconds ---\n",
      "episode 6800, reward 101.0, memory_length 2000, epsilon 0.03337326996032608\n",
      "travel time- 724.0\n",
      "--- 1.7680244445800781 seconds ---\n",
      "episode 6801, reward 19.0, memory_length 2000, epsilon 0.03335658749630947\n",
      "travel time- 725.0\n",
      "--- 1.5086524486541748 seconds ---\n",
      "episode 6802, reward 59.0, memory_length 2000, epsilon 0.033339913371439905\n",
      "travel time- 733.0\n",
      "--- 1.8313922882080078 seconds ---\n",
      "episode 6803, reward 101.0, memory_length 2000, epsilon 0.03332324758154887\n",
      "travel time- 720.0\n",
      "--- 1.6005189418792725 seconds ---\n",
      "episode 6804, reward 68.0, memory_length 2000, epsilon 0.03330659012246989\n",
      "travel time- 724.0\n",
      "--- 1.6517748832702637 seconds ---\n",
      "episode 6805, reward 431.0, memory_length 2000, epsilon 0.03328994099003863\n",
      "travel time- 724.0\n",
      "--- 1.586954116821289 seconds ---\n",
      "episode 6806, reward -69.0, memory_length 2000, epsilon 0.03327330018009277\n",
      "travel time- 721.0\n",
      "--- 1.713191032409668 seconds ---\n",
      "episode 6807, reward 105.0, memory_length 2000, epsilon 0.03325666768847214\n",
      "travel time- 725.0\n",
      "--- 1.6187076568603516 seconds ---\n",
      "episode 6808, reward -444.0, memory_length 2000, epsilon 0.03324004351101861\n",
      "travel time- 722.0\n",
      "--- 1.792891263961792 seconds ---\n",
      "episode 6809, reward 207.0, memory_length 2000, epsilon 0.03322342764357612\n",
      "travel time- 720.0\n",
      "--- 1.6173696517944336 seconds ---\n",
      "episode 6810, reward 52.0, memory_length 2000, epsilon 0.03320682008199072\n",
      "travel time- 721.0\n",
      "--- 1.8085167407989502 seconds ---\n",
      "episode 6811, reward 161.0, memory_length 2000, epsilon 0.03319022082211052\n",
      "travel time- 728.0\n",
      "--- 1.694352388381958 seconds ---\n",
      "episode 6812, reward -18.0, memory_length 2000, epsilon 0.03317362985978568\n",
      "travel time- 723.0\n",
      "--- 1.6551833152770996 seconds ---\n",
      "episode 6813, reward 45.0, memory_length 2000, epsilon 0.0331570471908685\n",
      "travel time- 722.0\n",
      "--- 1.3931403160095215 seconds ---\n",
      "episode 6814, reward -299.0, memory_length 2000, epsilon 0.033140472811213274\n",
      "travel time- 720.0\n",
      "--- 1.7686498165130615 seconds ---\n",
      "episode 6815, reward 27.0, memory_length 2000, epsilon 0.03312390671667642\n",
      "travel time- 727.0\n",
      "--- 1.5610616207122803 seconds ---\n",
      "episode 6816, reward 248.0, memory_length 2000, epsilon 0.03310734890311644\n",
      "travel time- 725.0\n",
      "--- 1.7461988925933838 seconds ---\n",
      "episode 6817, reward 67.0, memory_length 2000, epsilon 0.033090799366393836\n",
      "travel time- 727.0\n",
      "--- 1.556671380996704 seconds ---\n",
      "episode 6818, reward 18.0, memory_length 2000, epsilon 0.03307425810237125\n",
      "travel time- 724.0\n",
      "--- 1.5431194305419922 seconds ---\n",
      "episode 6819, reward 70.0, memory_length 2000, epsilon 0.03305772510691338\n",
      "travel time- 728.0\n",
      "--- 1.6207575798034668 seconds ---\n",
      "episode 6820, reward 227.0, memory_length 2000, epsilon 0.03304120037588693\n",
      "travel time- 721.0\n",
      "--- 1.6457288265228271 seconds ---\n",
      "episode 6821, reward -155.0, memory_length 2000, epsilon 0.03302468390516077\n",
      "travel time- 722.0\n",
      "--- 1.565735101699829 seconds ---\n",
      "episode 6822, reward 88.0, memory_length 2000, epsilon 0.03300817569060575\n",
      "travel time- 721.0\n",
      "--- 1.6500370502471924 seconds ---\n",
      "episode 6823, reward -139.0, memory_length 2000, epsilon 0.03299167572809482\n",
      "travel time- 720.0\n",
      "--- 1.705578327178955 seconds ---\n",
      "episode 6824, reward 5.0, memory_length 2000, epsilon 0.032975184013503\n",
      "travel time- 720.0\n",
      "--- 1.5636765956878662 seconds ---\n",
      "episode 6825, reward 29.0, memory_length 2000, epsilon 0.03295870054270735\n",
      "travel time- 730.0\n",
      "--- 1.5763490200042725 seconds ---\n",
      "episode 6826, reward 180.0, memory_length 2000, epsilon 0.032942225311587005\n",
      "travel time- 729.0\n",
      "--- 1.7765181064605713 seconds ---\n",
      "episode 6827, reward 40.0, memory_length 2000, epsilon 0.03292575831602318\n",
      "travel time- 726.0\n",
      "--- 1.553675651550293 seconds ---\n",
      "episode 6828, reward -6.0, memory_length 2000, epsilon 0.03290929955189908\n",
      "travel time- 722.0\n",
      "--- 1.5653817653656006 seconds ---\n",
      "episode 6829, reward -146.0, memory_length 2000, epsilon 0.03289284901510006\n",
      "travel time- 726.0\n",
      "--- 1.601456642150879 seconds ---\n",
      "episode 6830, reward -63.0, memory_length 2000, epsilon 0.03287640670151345\n",
      "travel time- 723.0\n",
      "--- 1.8146638870239258 seconds ---\n",
      "episode 6831, reward -338.0, memory_length 2000, epsilon 0.032859972607028685\n",
      "travel time- 725.0\n",
      "--- 1.6465296745300293 seconds ---\n",
      "episode 6832, reward -358.0, memory_length 2000, epsilon 0.03284354672753726\n",
      "travel time- 722.0\n",
      "--- 1.7095482349395752 seconds ---\n",
      "episode 6833, reward 333.0, memory_length 2000, epsilon 0.03282712905893267\n",
      "travel time- 722.0\n",
      "--- 1.5919084548950195 seconds ---\n",
      "episode 6834, reward 226.0, memory_length 2000, epsilon 0.032810719597110516\n",
      "travel time- 721.0\n",
      "--- 1.720351219177246 seconds ---\n",
      "episode 6835, reward 287.0, memory_length 2000, epsilon 0.03279431833796845\n",
      "travel time- 720.0\n",
      "--- 1.5961430072784424 seconds ---\n",
      "episode 6836, reward 110.0, memory_length 2000, epsilon 0.032777925277406125\n",
      "travel time- 726.0\n",
      "--- 1.5883033275604248 seconds ---\n",
      "episode 6837, reward 47.0, memory_length 2000, epsilon 0.0327615404113253\n",
      "travel time- 721.0\n",
      "--- 1.6535451412200928 seconds ---\n",
      "episode 6838, reward 149.0, memory_length 2000, epsilon 0.03274516373562974\n",
      "travel time- 720.0\n",
      "--- 1.613269567489624 seconds ---\n",
      "episode 6839, reward 122.0, memory_length 2000, epsilon 0.03272879524622528\n",
      "travel time- 729.0\n",
      "--- 1.4308900833129883 seconds ---\n",
      "episode 6840, reward 133.0, memory_length 2000, epsilon 0.03271243493901982\n",
      "travel time- 721.0\n",
      "--- 1.5459554195404053 seconds ---\n",
      "episode 6841, reward 108.0, memory_length 2000, epsilon 0.03269608280992324\n",
      "travel time- 720.0\n",
      "--- 1.5151989459991455 seconds ---\n",
      "episode 6842, reward 109.0, memory_length 2000, epsilon 0.03267973885484755\n",
      "travel time- 733.0\n",
      "--- 1.6154298782348633 seconds ---\n",
      "episode 6843, reward 245.0, memory_length 2000, epsilon 0.03266340306970674\n",
      "travel time- 724.0\n",
      "--- 1.4604675769805908 seconds ---\n",
      "episode 6844, reward -415.0, memory_length 2000, epsilon 0.03264707545041687\n",
      "travel time- 729.0\n",
      "--- 1.8282504081726074 seconds ---\n",
      "episode 6845, reward 175.0, memory_length 2000, epsilon 0.032630755992896034\n",
      "travel time- 720.0\n",
      "--- 1.636488437652588 seconds ---\n",
      "episode 6846, reward 130.0, memory_length 2000, epsilon 0.03261444469306436\n",
      "travel time- 723.0\n",
      "--- 1.645172119140625 seconds ---\n",
      "episode 6847, reward 127.0, memory_length 2000, epsilon 0.032598141546844026\n",
      "travel time- 723.0\n",
      "--- 1.576141119003296 seconds ---\n",
      "episode 6848, reward 64.0, memory_length 2000, epsilon 0.03258184655015926\n",
      "travel time- 721.0\n",
      "--- 1.644700527191162 seconds ---\n",
      "episode 6849, reward 335.0, memory_length 2000, epsilon 0.03256555969893629\n",
      "travel time- 726.0\n",
      "--- 1.5125408172607422 seconds ---\n",
      "episode 6850, reward -237.0, memory_length 2000, epsilon 0.03254928098910342\n",
      "travel time- 729.0\n",
      "--- 1.6700592041015625 seconds ---\n",
      "episode 6851, reward 329.0, memory_length 2000, epsilon 0.03253301041659097\n",
      "travel time- 721.0\n",
      "--- 1.6199531555175781 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6852, reward 42.0, memory_length 2000, epsilon 0.03251674797733129\n",
      "travel time- 727.0\n",
      "--- 1.6852872371673584 seconds ---\n",
      "episode 6853, reward -99.0, memory_length 2000, epsilon 0.03250049366725878\n",
      "travel time- 723.0\n",
      "--- 1.7490031719207764 seconds ---\n",
      "episode 6854, reward 158.0, memory_length 2000, epsilon 0.032484247482309846\n",
      "travel time- 726.0\n",
      "--- 1.575469732284546 seconds ---\n",
      "episode 6855, reward -186.0, memory_length 2000, epsilon 0.03246800941842295\n",
      "travel time- 721.0\n",
      "--- 1.8822190761566162 seconds ---\n",
      "episode 6856, reward 65.0, memory_length 2000, epsilon 0.03245177947153859\n",
      "travel time- 721.0\n",
      "--- 1.618058443069458 seconds ---\n",
      "episode 6857, reward 286.0, memory_length 2000, epsilon 0.032435557637599255\n",
      "travel time- 720.0\n",
      "--- 1.5305566787719727 seconds ---\n",
      "episode 6858, reward 196.0, memory_length 2000, epsilon 0.0324193439125495\n",
      "travel time- 733.0\n",
      "--- 1.7045793533325195 seconds ---\n",
      "episode 6859, reward -68.0, memory_length 2000, epsilon 0.032403138292335903\n",
      "travel time- 726.0\n",
      "--- 1.5822436809539795 seconds ---\n",
      "episode 6860, reward 124.0, memory_length 2000, epsilon 0.03238694077290704\n",
      "travel time- 726.0\n",
      "--- 1.7936594486236572 seconds ---\n",
      "episode 6861, reward 10.0, memory_length 2000, epsilon 0.03237075135021355\n",
      "travel time- 722.0\n",
      "--- 1.6041674613952637 seconds ---\n",
      "episode 6862, reward 56.0, memory_length 2000, epsilon 0.03235457002020804\n",
      "travel time- 724.0\n",
      "--- 1.6373000144958496 seconds ---\n",
      "episode 6863, reward -95.0, memory_length 2000, epsilon 0.03233839677884522\n",
      "travel time- 723.0\n",
      "--- 1.5560030937194824 seconds ---\n",
      "episode 6864, reward 109.0, memory_length 2000, epsilon 0.03232223162208177\n",
      "travel time- 732.0\n",
      "--- 1.6390306949615479 seconds ---\n",
      "episode 6865, reward -226.0, memory_length 2000, epsilon 0.03230607454587638\n",
      "travel time- 720.0\n",
      "--- 1.6595942974090576 seconds ---\n",
      "episode 6866, reward 293.0, memory_length 2000, epsilon 0.0322899255461898\n",
      "travel time- 723.0\n",
      "--- 1.5391921997070312 seconds ---\n",
      "episode 6867, reward -88.0, memory_length 2000, epsilon 0.03227378461898478\n",
      "travel time- 729.0\n",
      "--- 1.7150154113769531 seconds ---\n",
      "episode 6868, reward 151.0, memory_length 2000, epsilon 0.032257651760226075\n",
      "travel time- 721.0\n",
      "--- 1.6429226398468018 seconds ---\n",
      "episode 6869, reward 169.0, memory_length 2000, epsilon 0.03224152696588049\n",
      "travel time- 737.0\n",
      "--- 1.405346393585205 seconds ---\n",
      "episode 6870, reward 175.0, memory_length 2000, epsilon 0.0322254102319168\n",
      "travel time- 725.0\n",
      "--- 1.6682791709899902 seconds ---\n",
      "episode 6871, reward 385.0, memory_length 2000, epsilon 0.03220930155430584\n",
      "travel time- 721.0\n",
      "--- 1.5782454013824463 seconds ---\n",
      "episode 6872, reward 197.0, memory_length 2000, epsilon 0.03219320092902044\n",
      "travel time- 728.0\n",
      "--- 1.531238317489624 seconds ---\n",
      "episode 6873, reward 4.0, memory_length 2000, epsilon 0.03217710835203544\n",
      "travel time- 724.0\n",
      "--- 1.789236068725586 seconds ---\n",
      "episode 6874, reward 151.0, memory_length 2000, epsilon 0.032161023819327686\n",
      "travel time- 724.0\n",
      "--- 1.6697282791137695 seconds ---\n",
      "episode 6875, reward 107.0, memory_length 2000, epsilon 0.03214494732687607\n",
      "travel time- 730.0\n",
      "--- 1.6892344951629639 seconds ---\n",
      "episode 6876, reward 148.0, memory_length 2000, epsilon 0.03212887887066144\n",
      "travel time- 729.0\n",
      "--- 1.5849695205688477 seconds ---\n",
      "episode 6877, reward -598.0, memory_length 2000, epsilon 0.03211281844666671\n",
      "travel time- 720.0\n",
      "--- 1.6545393466949463 seconds ---\n",
      "episode 6878, reward -56.0, memory_length 2000, epsilon 0.032096766050876746\n",
      "travel time- 726.0\n",
      "--- 1.734231948852539 seconds ---\n",
      "episode 6879, reward 7.0, memory_length 2000, epsilon 0.03208072167927846\n",
      "travel time- 726.0\n",
      "--- 1.5740900039672852 seconds ---\n",
      "episode 6880, reward -97.0, memory_length 2000, epsilon 0.03206468532786077\n",
      "travel time- 720.0\n",
      "--- 1.5750226974487305 seconds ---\n",
      "episode 6881, reward 44.0, memory_length 2000, epsilon 0.03204865699261457\n",
      "travel time- 723.0\n",
      "--- 1.770531415939331 seconds ---\n",
      "episode 6882, reward -404.0, memory_length 2000, epsilon 0.03203263666953279\n",
      "travel time- 720.0\n",
      "--- 1.7845590114593506 seconds ---\n",
      "episode 6883, reward -12.0, memory_length 2000, epsilon 0.03201662435461035\n",
      "travel time- 720.0\n",
      "--- 1.6486093997955322 seconds ---\n",
      "episode 6884, reward 147.0, memory_length 2000, epsilon 0.03200062004384415\n",
      "travel time- 724.0\n",
      "--- 1.8238165378570557 seconds ---\n",
      "episode 6885, reward 80.0, memory_length 2000, epsilon 0.03198462373323315\n",
      "travel time- 721.0\n",
      "--- 1.8435182571411133 seconds ---\n",
      "episode 6886, reward 217.0, memory_length 2000, epsilon 0.03196863541877823\n",
      "travel time- 724.0\n",
      "--- 1.5968561172485352 seconds ---\n",
      "episode 6887, reward -94.0, memory_length 2000, epsilon 0.03195265509648233\n",
      "travel time- 723.0\n",
      "--- 1.5784876346588135 seconds ---\n",
      "episode 6888, reward -197.0, memory_length 2000, epsilon 0.03193668276235039\n",
      "travel time- 725.0\n",
      "--- 1.5714480876922607 seconds ---\n",
      "episode 6889, reward 127.0, memory_length 2000, epsilon 0.03192071841238929\n",
      "travel time- 722.0\n",
      "--- 1.5116291046142578 seconds ---\n",
      "episode 6890, reward 177.0, memory_length 2000, epsilon 0.03190476204260796\n",
      "travel time- 726.0\n",
      "--- 1.6212217807769775 seconds ---\n",
      "episode 6891, reward 204.0, memory_length 2000, epsilon 0.03188881364901732\n",
      "travel time- 721.0\n",
      "--- 1.618100643157959 seconds ---\n",
      "episode 6892, reward -146.0, memory_length 2000, epsilon 0.031872873227630244\n",
      "travel time- 723.0\n",
      "--- 1.3922817707061768 seconds ---\n",
      "episode 6893, reward -109.0, memory_length 2000, epsilon 0.03185694077446166\n",
      "travel time- 732.0\n",
      "--- 1.7638404369354248 seconds ---\n",
      "episode 6894, reward -109.0, memory_length 2000, epsilon 0.03184101628552841\n",
      "travel time- 724.0\n",
      "--- 1.7933459281921387 seconds ---\n",
      "episode 6895, reward 123.0, memory_length 2000, epsilon 0.03182509975684941\n",
      "travel time- 720.0\n",
      "--- 1.681903600692749 seconds ---\n",
      "episode 6896, reward 140.0, memory_length 2000, epsilon 0.03180919118444552\n",
      "travel time- 726.0\n",
      "--- 1.423581838607788 seconds ---\n",
      "episode 6897, reward 277.0, memory_length 2000, epsilon 0.031793290564339584\n",
      "travel time- 725.0\n",
      "--- 1.4423580169677734 seconds ---\n",
      "episode 6898, reward 137.0, memory_length 2000, epsilon 0.03177739789255645\n",
      "travel time- 723.0\n",
      "--- 1.429605484008789 seconds ---\n",
      "episode 6899, reward -506.0, memory_length 2000, epsilon 0.031761513165122976\n",
      "travel time- 723.0\n",
      "--- 1.9865531921386719 seconds ---\n",
      "episode 6900, reward -258.0, memory_length 2000, epsilon 0.03174563637806794\n",
      "travel time- 725.0\n",
      "--- 1.7546977996826172 seconds ---\n",
      "episode 6901, reward 152.0, memory_length 2000, epsilon 0.031729767527422174\n",
      "travel time- 727.0\n",
      "--- 1.4536855220794678 seconds ---\n",
      "episode 6902, reward -63.0, memory_length 2000, epsilon 0.03171390660921845\n",
      "travel time- 728.0\n",
      "--- 1.526282787322998 seconds ---\n",
      "episode 6903, reward -226.0, memory_length 2000, epsilon 0.03169805361949153\n",
      "travel time- 722.0\n",
      "--- 1.5716803073883057 seconds ---\n",
      "episode 6904, reward 69.0, memory_length 2000, epsilon 0.0316822085542782\n",
      "travel time- 724.0\n",
      "--- 1.5015325546264648 seconds ---\n",
      "episode 6905, reward -112.0, memory_length 2000, epsilon 0.031666371409617165\n",
      "travel time- 720.0\n",
      "--- 1.7196784019470215 seconds ---\n",
      "episode 6906, reward -41.0, memory_length 2000, epsilon 0.03165054218154915\n",
      "travel time- 723.0\n",
      "--- 1.591224193572998 seconds ---\n",
      "episode 6907, reward 98.0, memory_length 2000, epsilon 0.03163472086611685\n",
      "travel time- 721.0\n",
      "--- 1.5828688144683838 seconds ---\n",
      "episode 6908, reward 203.0, memory_length 2000, epsilon 0.031618907459364916\n",
      "travel time- 720.0\n",
      "--- 1.7269840240478516 seconds ---\n",
      "episode 6909, reward -187.0, memory_length 2000, epsilon 0.031603101957340035\n",
      "travel time- 723.0\n",
      "--- 1.6407763957977295 seconds ---\n",
      "episode 6910, reward -340.0, memory_length 2000, epsilon 0.031587304356090785\n",
      "travel time- 723.0\n",
      "--- 1.8711841106414795 seconds ---\n",
      "episode 6911, reward 3.0, memory_length 2000, epsilon 0.03157151465166779\n",
      "travel time- 722.0\n",
      "--- 1.6046733856201172 seconds ---\n",
      "episode 6912, reward -322.0, memory_length 2000, epsilon 0.03155573284012364\n",
      "travel time- 728.0\n",
      "--- 1.6110479831695557 seconds ---\n",
      "episode 6913, reward 140.0, memory_length 2000, epsilon 0.03153995891751285\n",
      "travel time- 729.0\n",
      "--- 1.505636215209961 seconds ---\n",
      "episode 6914, reward -79.0, memory_length 2000, epsilon 0.031524192879891964\n",
      "travel time- 721.0\n",
      "--- 1.652470350265503 seconds ---\n",
      "episode 6915, reward 68.0, memory_length 2000, epsilon 0.031508434723319455\n",
      "travel time- 722.0\n",
      "--- 1.6440637111663818 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6916, reward -252.0, memory_length 2000, epsilon 0.031492684443855785\n",
      "travel time- 724.0\n",
      "--- 1.6603882312774658 seconds ---\n",
      "episode 6917, reward -109.0, memory_length 2000, epsilon 0.031476942037563405\n",
      "travel time- 721.0\n",
      "--- 1.7161815166473389 seconds ---\n",
      "episode 6918, reward 248.0, memory_length 2000, epsilon 0.03146120750050669\n",
      "travel time- 720.0\n",
      "--- 1.7988159656524658 seconds ---\n",
      "episode 6919, reward 152.0, memory_length 2000, epsilon 0.031445480828752\n",
      "travel time- 721.0\n",
      "--- 1.5409820079803467 seconds ---\n",
      "episode 6920, reward 65.0, memory_length 2000, epsilon 0.03142976201836771\n",
      "travel time- 722.0\n",
      "--- 1.6148319244384766 seconds ---\n",
      "episode 6921, reward 225.0, memory_length 2000, epsilon 0.03141405106542407\n",
      "travel time- 726.0\n",
      "--- 1.6848902702331543 seconds ---\n",
      "episode 6922, reward 142.0, memory_length 2000, epsilon 0.03139834796599337\n",
      "travel time- 723.0\n",
      "--- 1.6499278545379639 seconds ---\n",
      "episode 6923, reward -3.0, memory_length 2000, epsilon 0.03138265271614982\n",
      "travel time- 726.0\n",
      "--- 1.689209222793579 seconds ---\n",
      "episode 6924, reward 93.0, memory_length 2000, epsilon 0.0313669653119696\n",
      "travel time- 722.0\n",
      "--- 1.8048326969146729 seconds ---\n",
      "episode 6925, reward 62.0, memory_length 2000, epsilon 0.03135128574953089\n",
      "travel time- 720.0\n",
      "--- 1.7582736015319824 seconds ---\n",
      "episode 6926, reward 198.0, memory_length 2000, epsilon 0.03133561402491377\n",
      "travel time- 732.0\n",
      "--- 1.389296054840088 seconds ---\n",
      "episode 6927, reward -138.0, memory_length 2000, epsilon 0.03131995013420032\n",
      "travel time- 720.0\n",
      "--- 1.8012235164642334 seconds ---\n",
      "episode 6928, reward 423.0, memory_length 2000, epsilon 0.03130429407347458\n",
      "travel time- 731.0\n",
      "--- 1.8001186847686768 seconds ---\n",
      "episode 6929, reward -10.0, memory_length 2000, epsilon 0.0312886458388225\n",
      "travel time- 722.0\n",
      "--- 1.7808640003204346 seconds ---\n",
      "episode 6930, reward -234.0, memory_length 2000, epsilon 0.03127300542633206\n",
      "travel time- 727.0\n",
      "--- 1.5617079734802246 seconds ---\n",
      "episode 6931, reward -19.0, memory_length 2000, epsilon 0.03125737283209313\n",
      "travel time- 720.0\n",
      "--- 1.8230364322662354 seconds ---\n",
      "episode 6932, reward -14.0, memory_length 2000, epsilon 0.031241748052197565\n",
      "travel time- 720.0\n",
      "--- 1.6776068210601807 seconds ---\n",
      "episode 6933, reward 26.0, memory_length 2000, epsilon 0.031226131082739195\n",
      "travel time- 724.0\n",
      "--- 1.633448839187622 seconds ---\n",
      "episode 6934, reward -220.0, memory_length 2000, epsilon 0.031210521919813744\n",
      "travel time- 722.0\n",
      "--- 1.6339306831359863 seconds ---\n",
      "episode 6935, reward -319.0, memory_length 2000, epsilon 0.031194920559518932\n",
      "travel time- 723.0\n",
      "--- 1.620737075805664 seconds ---\n",
      "episode 6936, reward 186.0, memory_length 2000, epsilon 0.031179326997954438\n",
      "travel time- 723.0\n",
      "--- 1.7528736591339111 seconds ---\n",
      "episode 6937, reward -159.0, memory_length 2000, epsilon 0.031163741231221842\n",
      "travel time- 721.0\n",
      "--- 1.7196123600006104 seconds ---\n",
      "episode 6938, reward 259.0, memory_length 2000, epsilon 0.03114816325542473\n",
      "travel time- 726.0\n",
      "--- 1.6254687309265137 seconds ---\n",
      "episode 6939, reward 93.0, memory_length 2000, epsilon 0.03113259306666858\n",
      "travel time- 726.0\n",
      "--- 1.5679121017456055 seconds ---\n",
      "episode 6940, reward -174.0, memory_length 2000, epsilon 0.03111703066106086\n",
      "travel time- 727.0\n",
      "--- 1.4793920516967773 seconds ---\n",
      "episode 6941, reward 202.0, memory_length 2000, epsilon 0.03110147603471098\n",
      "travel time- 723.0\n",
      "--- 1.6205124855041504 seconds ---\n",
      "episode 6942, reward 207.0, memory_length 2000, epsilon 0.03108592918373026\n",
      "travel time- 726.0\n",
      "--- 1.520470142364502 seconds ---\n",
      "episode 6943, reward 220.0, memory_length 2000, epsilon 0.031070390104231994\n",
      "travel time- 728.0\n",
      "--- 1.7188289165496826 seconds ---\n",
      "episode 6944, reward -117.0, memory_length 2000, epsilon 0.03105485879233143\n",
      "travel time- 724.0\n",
      "--- 1.5197348594665527 seconds ---\n",
      "episode 6945, reward 123.0, memory_length 2000, epsilon 0.031039335244145712\n",
      "travel time- 723.0\n",
      "--- 1.7255959510803223 seconds ---\n",
      "episode 6946, reward -79.0, memory_length 2000, epsilon 0.031023819455793984\n",
      "travel time- 720.0\n",
      "--- 1.8483245372772217 seconds ---\n",
      "episode 6947, reward 269.0, memory_length 2000, epsilon 0.031008311423397262\n",
      "travel time- 723.0\n",
      "--- 1.605954885482788 seconds ---\n",
      "episode 6948, reward -294.0, memory_length 2000, epsilon 0.03099281114307856\n",
      "travel time- 729.0\n",
      "--- 1.7110979557037354 seconds ---\n",
      "episode 6949, reward -68.0, memory_length 2000, epsilon 0.030977318610962822\n",
      "travel time- 722.0\n",
      "--- 1.7331509590148926 seconds ---\n",
      "episode 6950, reward -134.0, memory_length 2000, epsilon 0.030961833823176882\n",
      "travel time- 729.0\n",
      "--- 1.6674010753631592 seconds ---\n",
      "episode 6951, reward 281.0, memory_length 2000, epsilon 0.030946356775849556\n",
      "travel time- 721.0\n",
      "--- 1.6604061126708984 seconds ---\n",
      "episode 6952, reward 361.0, memory_length 2000, epsilon 0.030930887465111603\n",
      "travel time- 720.0\n",
      "--- 1.6941943168640137 seconds ---\n",
      "episode 6953, reward 68.0, memory_length 2000, epsilon 0.03091542588709566\n",
      "travel time- 722.0\n",
      "--- 1.497802734375 seconds ---\n",
      "episode 6954, reward 368.0, memory_length 2000, epsilon 0.030899972037936367\n",
      "travel time- 724.0\n",
      "--- 1.412477731704712 seconds ---\n",
      "episode 6955, reward 31.0, memory_length 2000, epsilon 0.03088452591377023\n",
      "travel time- 726.0\n",
      "--- 1.247450828552246 seconds ---\n",
      "episode 6956, reward 136.0, memory_length 2000, epsilon 0.03086908751073573\n",
      "travel time- 723.0\n",
      "--- 1.7475712299346924 seconds ---\n",
      "episode 6957, reward 161.0, memory_length 2000, epsilon 0.030853656824973284\n",
      "travel time- 730.0\n",
      "--- 1.61466383934021 seconds ---\n",
      "episode 6958, reward 103.0, memory_length 2000, epsilon 0.030838233852625192\n",
      "travel time- 727.0\n",
      "--- 1.5483310222625732 seconds ---\n",
      "episode 6959, reward -19.0, memory_length 2000, epsilon 0.030822818589835724\n",
      "travel time- 730.0\n",
      "--- 1.7948644161224365 seconds ---\n",
      "episode 6960, reward -14.0, memory_length 2000, epsilon 0.030807411032751076\n",
      "travel time- 729.0\n",
      "--- 1.5902457237243652 seconds ---\n",
      "episode 6961, reward 100.0, memory_length 2000, epsilon 0.030792011177519334\n",
      "travel time- 720.0\n",
      "--- 1.6488902568817139 seconds ---\n",
      "episode 6962, reward 104.0, memory_length 2000, epsilon 0.03077661902029056\n",
      "travel time- 734.0\n",
      "--- 1.361494541168213 seconds ---\n",
      "episode 6963, reward -120.0, memory_length 2000, epsilon 0.030761234557216688\n",
      "travel time- 725.0\n",
      "--- 1.585350513458252 seconds ---\n",
      "episode 6964, reward -137.0, memory_length 2000, epsilon 0.030745857784451616\n",
      "travel time- 724.0\n",
      "--- 1.6698260307312012 seconds ---\n",
      "episode 6965, reward -99.0, memory_length 2000, epsilon 0.030730488698151162\n",
      "travel time- 721.0\n",
      "--- 1.5503175258636475 seconds ---\n",
      "episode 6966, reward -125.0, memory_length 2000, epsilon 0.03071512729447303\n",
      "travel time- 723.0\n",
      "--- 1.3166213035583496 seconds ---\n",
      "episode 6967, reward -40.0, memory_length 2000, epsilon 0.030699773569576882\n",
      "travel time- 727.0\n",
      "--- 1.5154621601104736 seconds ---\n",
      "episode 6968, reward 121.0, memory_length 2000, epsilon 0.0306844275196243\n",
      "travel time- 720.0\n",
      "--- 1.5821871757507324 seconds ---\n",
      "episode 6969, reward 48.0, memory_length 2000, epsilon 0.030669089140778743\n",
      "travel time- 721.0\n",
      "--- 1.762833595275879 seconds ---\n",
      "episode 6970, reward 239.0, memory_length 2000, epsilon 0.030653758429205646\n",
      "travel time- 721.0\n",
      "--- 1.7692012786865234 seconds ---\n",
      "episode 6971, reward 41.0, memory_length 2000, epsilon 0.0306384353810723\n",
      "travel time- 720.0\n",
      "--- 1.7011260986328125 seconds ---\n",
      "episode 6972, reward -34.0, memory_length 2000, epsilon 0.03062311999254796\n",
      "travel time- 726.0\n",
      "--- 1.6147451400756836 seconds ---\n",
      "episode 6973, reward 243.0, memory_length 2000, epsilon 0.03060781225980379\n",
      "travel time- 723.0\n",
      "--- 1.5804638862609863 seconds ---\n",
      "episode 6974, reward 247.0, memory_length 2000, epsilon 0.030592512179012835\n",
      "travel time- 735.0\n",
      "--- 1.530501127243042 seconds ---\n",
      "episode 6975, reward 51.0, memory_length 2000, epsilon 0.03057721974635008\n",
      "travel time- 725.0\n",
      "--- 1.418471336364746 seconds ---\n",
      "episode 6976, reward 138.0, memory_length 2000, epsilon 0.030561934957992438\n",
      "travel time- 727.0\n",
      "--- 1.5635619163513184 seconds ---\n",
      "episode 6977, reward 132.0, memory_length 2000, epsilon 0.03054665781011868\n",
      "travel time- 721.0\n",
      "--- 1.565258264541626 seconds ---\n",
      "episode 6978, reward -7.0, memory_length 2000, epsilon 0.030531388298909546\n",
      "travel time- 722.0\n",
      "--- 1.7477679252624512 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6979, reward -174.0, memory_length 2000, epsilon 0.030516126420547632\n",
      "travel time- 722.0\n",
      "--- 1.4320135116577148 seconds ---\n",
      "episode 6980, reward -15.0, memory_length 2000, epsilon 0.030500872171217483\n",
      "travel time- 724.0\n",
      "--- 1.8286335468292236 seconds ---\n",
      "episode 6981, reward 37.0, memory_length 2000, epsilon 0.030485625547105547\n",
      "travel time- 728.0\n",
      "--- 1.6197690963745117 seconds ---\n",
      "episode 6982, reward 328.0, memory_length 2000, epsilon 0.030470386544400145\n",
      "travel time- 723.0\n",
      "--- 1.5169219970703125 seconds ---\n",
      "episode 6983, reward 241.0, memory_length 2000, epsilon 0.03045515515929154\n",
      "travel time- 727.0\n",
      "--- 1.6965656280517578 seconds ---\n",
      "episode 6984, reward 339.0, memory_length 2000, epsilon 0.03043993138797189\n",
      "travel time- 723.0\n",
      "--- 1.603853702545166 seconds ---\n",
      "episode 6985, reward 67.0, memory_length 2000, epsilon 0.03042471522663524\n",
      "travel time- 721.0\n",
      "--- 1.5385282039642334 seconds ---\n",
      "episode 6986, reward 225.0, memory_length 2000, epsilon 0.030409506671477564\n",
      "travel time- 721.0\n",
      "--- 1.5842804908752441 seconds ---\n",
      "episode 6987, reward 85.0, memory_length 2000, epsilon 0.030394305718696703\n",
      "travel time- 724.0\n",
      "--- 1.6507289409637451 seconds ---\n",
      "episode 6988, reward 1.0, memory_length 2000, epsilon 0.03037911236449243\n",
      "travel time- 723.0\n",
      "--- 1.7513175010681152 seconds ---\n",
      "episode 6989, reward 21.0, memory_length 2000, epsilon 0.030363926605066417\n",
      "travel time- 720.0\n",
      "--- 1.4755325317382812 seconds ---\n",
      "episode 6990, reward -130.0, memory_length 2000, epsilon 0.030348748436622202\n",
      "travel time- 724.0\n",
      "--- 1.4597620964050293 seconds ---\n",
      "episode 6991, reward 275.0, memory_length 2000, epsilon 0.03033357785536525\n",
      "travel time- 720.0\n",
      "--- 1.6278753280639648 seconds ---\n",
      "episode 6992, reward -94.0, memory_length 2000, epsilon 0.03031841485750294\n",
      "travel time- 725.0\n",
      "--- 1.8061282634735107 seconds ---\n",
      "episode 6993, reward -205.0, memory_length 2000, epsilon 0.030303259439244487\n",
      "travel time- 723.0\n",
      "--- 1.7581870555877686 seconds ---\n",
      "episode 6994, reward -213.0, memory_length 2000, epsilon 0.030288111596801063\n",
      "travel time- 725.0\n",
      "--- 1.828657627105713 seconds ---\n",
      "episode 6995, reward -8.0, memory_length 2000, epsilon 0.030272971326385685\n",
      "travel time- 720.0\n",
      "--- 1.942453384399414 seconds ---\n",
      "episode 6996, reward 106.0, memory_length 2000, epsilon 0.030257838624213294\n",
      "travel time- 726.0\n",
      "--- 1.6701993942260742 seconds ---\n",
      "episode 6997, reward -132.0, memory_length 2000, epsilon 0.03024271348650073\n",
      "travel time- 723.0\n",
      "--- 1.5250933170318604 seconds ---\n",
      "episode 6998, reward -243.0, memory_length 2000, epsilon 0.030227595909466682\n",
      "travel time- 723.0\n",
      "--- 1.8478891849517822 seconds ---\n",
      "episode 6999, reward -163.0, memory_length 2000, epsilon 0.03021248588933177\n",
      "travel time- 722.0\n",
      "--- 1.811525583267212 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Call the environment\n",
    "# Call all the initialised variables of the environment\n",
    "# state size and action size\n",
    "state_size = 36\n",
    "action_size = 21\n",
    "\n",
    "# Calling the env\n",
    "env = CabDriver()\n",
    "\n",
    "# Initialising the agent class\n",
    "dqn_agent = DQNAgent(state_size=state_size,action_size=action_size)\n",
    "\n",
    "rewards_per_episode, episodes = [], []\n",
    "\n",
    "if not os.path.exists(\"saved_model_weights\"):\n",
    "    os.mkdir(\"saved_model_weights\")\n",
    "\n",
    "for episode in range(Episodes):\n",
    "    \n",
    "    # to track the processing time taken per episode \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # to track rewards per episode\n",
    "    score = 0\n",
    "    \n",
    "    _,_,state = env.reset()\n",
    "    \n",
    "    # each episode is assumed to consists of ride hours per month(30 days)\n",
    "    total_hours_per_episode = 24*30\n",
    "    \n",
    "    total_time_taken = 0\n",
    "    \n",
    "    terminal_state = False\n",
    "    \n",
    "    while not terminal_state:\n",
    "        \n",
    "        action = dqn_agent.get_action(state)\n",
    "        \n",
    "        next_state = env.next_state_func(state, action, Time_matrix)\n",
    "        \n",
    "        reward = env.reward_func(state, action, Time_matrix)\n",
    "                  \n",
    "        dqn_agent.append_sample(state, action, reward, next_state)\n",
    "\n",
    "        dqn_agent.train_model()\n",
    "        \n",
    "        score += reward\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        if action==(0,0):\n",
    "            \n",
    "            total_time_taken += 1\n",
    "        \n",
    "        else:\n",
    "            # our state_space is encoded from 1 to 5 while the Time_matrix works on states encoded 0 to 4\n",
    "            time_taken_curr_to_pickup = Time_matrix[ state[0] - 1 ][ action[0] - 1 ][ state[1] ][ state[2] ]\n",
    "            \n",
    "            # if time exceeds 23 hours, make necessary changes\n",
    "            if state[1] + time_taken_curr_to_pickup > 23:\n",
    "                time_taken_pickup_to_drop = Time_matrix[ action[0] - 1 ][ action[1] - 1 ][ state[1] + int(time_taken_curr_to_pickup) - 24 ][ (state[2]+1)%7 ]\n",
    "\n",
    "            else:\n",
    "                time_taken_pickup_to_drop = Time_matrix[ action[0] - 1 ][ action[1] - 1 ][ state[1] + int(time_taken_curr_to_pickup) ][ state[2] ]\n",
    "            \n",
    "            total_time = time_taken_curr_to_pickup + time_taken_pickup_to_drop\n",
    "            \n",
    "            total_time_taken += total_time\n",
    "        \n",
    "        if total_time_taken>=total_hours_per_episode:\n",
    "            terminal_state=True\n",
    "        \n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "    \n",
    "    # updating the value of epsilon after each episode\n",
    "    if dqn_agent.epsilon > dqn_agent.epsilon_min:\n",
    "        # the curve for this function is given below\n",
    "        dqn_agent.epsilon = (1 - 0) * np.exp(-0.0005*episode)\n",
    "        \n",
    "    # every episode:\n",
    "    print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3}\".format(episode,\n",
    "                                                                         score,\n",
    "                                                                         len(dqn_agent.memory),\n",
    "                                                                         dqn_agent.epsilon))\n",
    "    end_time = time.time()\n",
    "    print(\"travel time-\",total_time_taken)\n",
    "    print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "    \n",
    "    # storing model_weights after every 10 episodes\n",
    "    # was commented out and only the final model weights were saved\n",
    "    if episode % 10 == 0:\n",
    "        \n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        # q_dict = agent.store_q_values()\n",
    "\n",
    "        # save model weights\n",
    "        model_name = \"model_weights\"+\"_\"+str(episode)+\".h5\"\n",
    "        #dqn_agent.save(name=model_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save stuff as pickle\n",
    "def save_pickle(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# make directory\n",
    "if not os.path.exists(\"saved_pickle_files\"):\n",
    "    os.mkdir(\"saved_pickle_files\")\n",
    "\n",
    "# save rewards_per_episode\n",
    "save_pickle(rewards_per_episode, \"saved_pickle_files/rewards_per_episode\")\n",
    "\n",
    "# save model weights\n",
    "model_name = \"model_weights.h5\"\n",
    "dqn_agent.save(name=model_name)\n",
    "\n",
    "# save model architecture\n",
    "dqn_agent.save_model_arch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward of first 100 episodes is -152.68\n",
      "Average reward of middle 100 episodes is 3.88\n",
      "Average reward of last 100 episodes is 26.81\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "with open('saved_pickle_files/rewards_per_episode.pkl', 'rb') as f:\n",
    "    rewards_per_episode = pickle.load(f)\n",
    "\n",
    "plt.plot(list(range(len(rewards_per_episode))), rewards_per_episode)\n",
    "plt.xlabel(\"episode number\")\n",
    "plt.ylabel(\"reward per episode\")\n",
    "\n",
    "# save plots in saved_plots/ directory\n",
    "plt.savefig('rewards.png')\n",
    "\n",
    "print(\"Average reward of first 100 episodes is {0}\".format(np.mean(rewards_per_episode[:100]))) \n",
    "print(\"Average reward of middle 100 episodes is {0}\".format(np.mean(rewards_per_episode[3450:3550]))) \n",
    "print(\"Average reward of last 100 episodes is {0}\".format(np.mean(rewards_per_episode[-100:]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "b=100\n",
    "avg_rewards_per_100_episodes = []\n",
    "while b<=len(rewards_per_episode):\n",
    "    avg_rewards = np.mean(rewards_per_episode[a:b])\n",
    "    avg_rewards_per_100_episodes.append(avg_rewards)\n",
    "    a+=100\n",
    "    b+=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(avg_rewards_per_100_episodes))), avg_rewards_per_100_episodes)\n",
    "plt.xlabel(\"episodes in hundred\")\n",
    "plt.ylabel(\"avg reward per 100 episodes\")\n",
    "plt.axis([0, 70, -180, 50])\n",
    "# save plots in saved_plots/ directory\n",
    "plt.savefig('avg_rewards_per_100_episodes.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay function used - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0005*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model (for Upgrad) - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_weights.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model.compile(loss='rms', optimizer='Adam', metrics=['accuracy'])\n",
    "#score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "#print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
